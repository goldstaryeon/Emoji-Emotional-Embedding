{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "import emoji\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from transformers import pipeline\n",
    "import ast\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics, model_selection\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import gensim.models as gsm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the dataset since go_emotions couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'simplified' at C:\\Users\\김성연\\.cache\\huggingface\\datasets\\go_emotions\\simplified\\0.0.0\\add492243ff905527e67aeb8b80c082af02207c3 (last modified on Thu Jan 11 19:31:53 2024).\n"
     ]
    }
   ],
   "source": [
    "# 훈련 데이터 셋 불러오기\n",
    "dataset = load_dataset('go_emotions', 'simplified')\n",
    "dataset = dataset['train'].to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>My favourite food is anything I didn't have to...</td>\n",
       "      <td>[27]</td>\n",
       "      <td>eebbqej</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Now if he does off himself, everyone will thin...</td>\n",
       "      <td>[27]</td>\n",
       "      <td>ed00q6i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WHY THE FUCK IS BAYLESS ISOING</td>\n",
       "      <td>[2]</td>\n",
       "      <td>eezlygj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>To make her feel threatened</td>\n",
       "      <td>[14]</td>\n",
       "      <td>ed7ypvh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dirty Southern Wankers</td>\n",
       "      <td>[3]</td>\n",
       "      <td>ed0bdzj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43405</th>\n",
       "      <td>Added you mate well I’ve just got the bow and ...</td>\n",
       "      <td>[18]</td>\n",
       "      <td>edsb738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43406</th>\n",
       "      <td>Always thought that was funny but is it a refe...</td>\n",
       "      <td>[6]</td>\n",
       "      <td>ee7fdou</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43407</th>\n",
       "      <td>What are you talking about? Anything bad that ...</td>\n",
       "      <td>[3]</td>\n",
       "      <td>efgbhks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43408</th>\n",
       "      <td>More like a baptism, with sexy results!</td>\n",
       "      <td>[13]</td>\n",
       "      <td>ed1naf8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43409</th>\n",
       "      <td>Enjoy the ride!</td>\n",
       "      <td>[17]</td>\n",
       "      <td>eecwmbq</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>43410 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text labels       id\n",
       "0      My favourite food is anything I didn't have to...   [27]  eebbqej\n",
       "1      Now if he does off himself, everyone will thin...   [27]  ed00q6i\n",
       "2                         WHY THE FUCK IS BAYLESS ISOING    [2]  eezlygj\n",
       "3                            To make her feel threatened   [14]  ed7ypvh\n",
       "4                                 Dirty Southern Wankers    [3]  ed0bdzj\n",
       "...                                                  ...    ...      ...\n",
       "43405  Added you mate well I’ve just got the bow and ...   [18]  edsb738\n",
       "43406  Always thought that was funny but is it a refe...    [6]  ee7fdou\n",
       "43407  What are you talking about? Anything bad that ...    [3]  efgbhks\n",
       "43408            More like a baptism, with sexy results!   [13]  ed1naf8\n",
       "43409                                    Enjoy the ride!   [17]  eecwmbq\n",
       "\n",
       "[43410 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원래 데이터 개수:  43410\n",
      "emoji 1개 이상 포함되어 있는 데이터 추출:  1841\n",
      "emoji 포함된 데이터 개수:  841\n",
      "emoji 포함되지 않은 데이터 개수:  1000\n"
     ]
    }
   ],
   "source": [
    "print(\"원래 데이터 개수: \", len(dataset))\n",
    "\n",
    "cols = ['text', 'labels']\n",
    "mid_dataset = pd.DataFrame(columns=cols)\n",
    "new_dataset = pd.DataFrame(columns=cols)\n",
    "\n",
    "# k = 0\n",
    "# for i in range(len(dataset)):\n",
    "#     if len(dataset.iloc[i]['labels']) == 1:\n",
    "#         mid_dataset.loc[k] = dataset.iloc[i][['text', 'labels']]\n",
    "#         k += 1\n",
    "# print(\"label 1개인 데이터 추출: \", len(mid_dataset))\n",
    "\n",
    "j=0\n",
    "l=1000\n",
    "for i in range(len(dataset)):\n",
    "    if emoji.emoji_count(dataset.iloc[i]['text']) == 0:  # 이모지 들어있지 않은 텍스트\n",
    "        if j < 1000:\n",
    "            new_dataset.loc[j] = dataset.iloc[i][['text', 'labels']]\n",
    "            j += 1\n",
    "    else:  # 이모지 들어있는 텍스트\n",
    "        if l < 5000:\n",
    "            new_dataset.loc[l] = dataset.iloc[i][['text', 'labels']]\n",
    "            l += 1\n",
    "        \n",
    "print(\"추출한 데이터 총 개수: \", len(new_dataset))\n",
    "print(\"emoji 포함된 데이터 개수: \", len([text for text in new_dataset['text'] if emoji.emoji_count(text) > 0]))\n",
    "print(\"emoji 포함되지 않은 데이터 개수: \", len([text for text in new_dataset['text'] if emoji.emoji_count(text) == 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>My favourite food is anything I didn't have to...</td>\n",
       "      <td>[27]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Now if he does off himself, everyone will thin...</td>\n",
       "      <td>[27]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WHY THE FUCK IS BAYLESS ISOING</td>\n",
       "      <td>[2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>To make her feel threatened</td>\n",
       "      <td>[14]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dirty Southern Wankers</td>\n",
       "      <td>[3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1836</th>\n",
       "      <td>it’s happened before?! love my hometown of bea...</td>\n",
       "      <td>[7, 18]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1837</th>\n",
       "      <td>Talked with my parents. It was so relaxing and...</td>\n",
       "      <td>[15]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1838</th>\n",
       "      <td>OMG, is this the one that wore white? 😳</td>\n",
       "      <td>[7, 26]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1839</th>\n",
       "      <td>Nope! His real name starts with a G. Weird spe...</td>\n",
       "      <td>[10, 11]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1840</th>\n",
       "      <td>Just \"asking for a friend\"...huh? 😂</td>\n",
       "      <td>[7]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1841 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text    labels\n",
       "0     My favourite food is anything I didn't have to...      [27]\n",
       "1     Now if he does off himself, everyone will thin...      [27]\n",
       "2                        WHY THE FUCK IS BAYLESS ISOING       [2]\n",
       "3                           To make her feel threatened      [14]\n",
       "4                                Dirty Southern Wankers       [3]\n",
       "...                                                 ...       ...\n",
       "1836  it’s happened before?! love my hometown of bea...   [7, 18]\n",
       "1837  Talked with my parents. It was so relaxing and...      [15]\n",
       "1838            OMG, is this the one that wore white? 😳   [7, 26]\n",
       "1839  Nope! His real name starts with a G. Weird spe...  [10, 11]\n",
       "1840                Just \"asking for a friend\"...huh? 😂       [7]\n",
       "\n",
       "[1841 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 이모지 포함되지 않은 텍스트\n",
    "# print(\"0번 text: \", new_dataset.iloc[0]['text'], ', labels: ', new_dataset.iloc[0]['labels'])\n",
    "# print(\"499번 text: \", new_dataset.iloc[499]['text'], ', labels: ', new_dataset.iloc[499]['labels'])\n",
    "\n",
    "# # 이모지 포함된 텍스트\n",
    "# print(\"500번 text: \", new_dataset.iloc[500]['text'], ', labels: ', new_dataset.iloc[500]['labels'])\n",
    "# print(\"999번 text: \", new_dataset.iloc[999]['text'], ', labels: ', new_dataset.iloc[999]['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 불용어 리스트\n",
    "\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data preprocess function\n",
    "\n",
    "def preprocess_data(text):\n",
    "    emoji_list = emoji.distinct_emoji_list(text)\n",
    "    emoji_string = ''.join(emoji_list)\n",
    "    text = re.sub(r'(\\[.+\\])', '', text)\n",
    "    text = re.sub(r'[^a-zA-Z\\s'+emoji_string+']', ' ', text)\n",
    "    for char in text:\n",
    "        if char in emoji_string:\n",
    "            text = re.sub(r'['+char+']', ' '+char+' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    text = text.split(' ') \n",
    "    text = [word.lower() for word in text if len(word) > 0]\n",
    "    text = [word for word in text if word not in stop_words]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['OMG', 'is', 'this', 'the', 'one', 'that', 'wore', 'white', '😳']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preprocess_data function example\n",
    "\n",
    "text = new_dataset.iloc[1838]['text']\n",
    "tokenized = preprocess_data(text)\n",
    "tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tokenized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>[NAME], [NAME] is the most underrated [NAME]. ...</td>\n",
       "      <td>[I, love, that, guy]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>I was actually a little lost here and there fo...</td>\n",
       "      <td>[I, was, actually, a, little, lost, here, and,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>Oh my god. Don't you know it's illegal to shar...</td>\n",
       "      <td>[Oh, my, god, Don, t, you, know, it, s, illega...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>[NAME] and [NAME] should be there too E: Damn ...</td>\n",
       "      <td>[should, be, there, too, E, Damn, didn, t, thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>I think [NAME] could've been a long term quali...</td>\n",
       "      <td>[I, think, like, a, bad, habit]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  \\\n",
       "487  [NAME], [NAME] is the most underrated [NAME]. ...   \n",
       "488  I was actually a little lost here and there fo...   \n",
       "489  Oh my god. Don't you know it's illegal to shar...   \n",
       "490  [NAME] and [NAME] should be there too E: Damn ...   \n",
       "491  I think [NAME] could've been a long term quali...   \n",
       "\n",
       "                                        tokenized_text  \n",
       "487                               [I, love, that, guy]  \n",
       "488  [I, was, actually, a, little, lost, here, and,...  \n",
       "489  [Oh, my, god, Don, t, you, know, it, s, illega...  \n",
       "490  [should, be, there, too, E, Damn, didn, t, thi...  \n",
       "491                    [I, think, like, a, bad, habit]  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# new_dataset preprocess\n",
    "\n",
    "new_dataset['tokenized_text'] = new_dataset['text'].apply(preprocess_data)\n",
    "new_dataset.iloc[499:504][['text', 'tokenized_text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "      <th>tokenized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>My favourite food is anything I didn't have to...</td>\n",
       "      <td>[27]</td>\n",
       "      <td>[My, favourite, food, is, anything, I, didn, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Now if he does off himself, everyone will thin...</td>\n",
       "      <td>[27]</td>\n",
       "      <td>[Now, if, he, does, off, himself, everyone, wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WHY THE FUCK IS BAYLESS ISOING</td>\n",
       "      <td>[2]</td>\n",
       "      <td>[WHY, THE, FUCK, IS, BAYLESS, ISOING]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>To make her feel threatened</td>\n",
       "      <td>[14]</td>\n",
       "      <td>[To, make, her, feel, threatened]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dirty Southern Wankers</td>\n",
       "      <td>[3]</td>\n",
       "      <td>[Dirty, Southern, Wankers]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1836</th>\n",
       "      <td>it’s happened before?! love my hometown of bea...</td>\n",
       "      <td>[7, 18]</td>\n",
       "      <td>[it, s, happened, before, love, my, hometown, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1837</th>\n",
       "      <td>Talked with my parents. It was so relaxing and...</td>\n",
       "      <td>[15]</td>\n",
       "      <td>[Talked, with, my, parents, It, was, so, relax...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1838</th>\n",
       "      <td>OMG, is this the one that wore white? 😳</td>\n",
       "      <td>[7, 26]</td>\n",
       "      <td>[OMG, is, this, the, one, that, wore, white, 😳]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1839</th>\n",
       "      <td>Nope! His real name starts with a G. Weird spe...</td>\n",
       "      <td>[10, 11]</td>\n",
       "      <td>[Nope, His, real, name, starts, with, a, G, We...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1840</th>\n",
       "      <td>Just \"asking for a friend\"...huh? 😂</td>\n",
       "      <td>[7]</td>\n",
       "      <td>[Just, asking, for, a, friend, huh, 😂]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1841 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text    labels  \\\n",
       "0     My favourite food is anything I didn't have to...      [27]   \n",
       "1     Now if he does off himself, everyone will thin...      [27]   \n",
       "2                        WHY THE FUCK IS BAYLESS ISOING       [2]   \n",
       "3                           To make her feel threatened      [14]   \n",
       "4                                Dirty Southern Wankers       [3]   \n",
       "...                                                 ...       ...   \n",
       "1836  it’s happened before?! love my hometown of bea...   [7, 18]   \n",
       "1837  Talked with my parents. It was so relaxing and...      [15]   \n",
       "1838            OMG, is this the one that wore white? 😳   [7, 26]   \n",
       "1839  Nope! His real name starts with a G. Weird spe...  [10, 11]   \n",
       "1840                Just \"asking for a friend\"...huh? 😂       [7]   \n",
       "\n",
       "                                         tokenized_text  \n",
       "0     [My, favourite, food, is, anything, I, didn, t...  \n",
       "1     [Now, if, he, does, off, himself, everyone, wi...  \n",
       "2                 [WHY, THE, FUCK, IS, BAYLESS, ISOING]  \n",
       "3                     [To, make, her, feel, threatened]  \n",
       "4                            [Dirty, Southern, Wankers]  \n",
       "...                                                 ...  \n",
       "1836  [it, s, happened, before, love, my, hometown, ...  \n",
       "1837  [Talked, with, my, parents, It, was, so, relax...  \n",
       "1838    [OMG, is, this, the, one, that, wore, white, 😳]  \n",
       "1839  [Nope, His, real, name, starts, with, a, G, We...  \n",
       "1840             [Just, asking, for, a, friend, huh, 😂]  \n",
       "\n",
       "[1841 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word emotion analysis\n",
    "\n",
    "classifier = pipeline(task=\"text-classification\",\n",
    "                      model=\"SamLowe/roberta-base-go_emotions\",\n",
    "                      top_k=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# emotion classes (medium output)\n",
    "\n",
    "idx_to_emotion = {\n",
    "    0: 'admiration',\n",
    "    1: 'amusement',\n",
    "    2: 'anger',\n",
    "    3: 'annoyance',\n",
    "    4: 'approval',\n",
    "    5: 'caring',\n",
    "    6: 'confusion',\n",
    "    7: 'curiosity',\n",
    "    8: 'desire',\n",
    "    9: 'disappointment',\n",
    "    10: 'disapproval',\n",
    "    11: 'disgust',\n",
    "    12: 'embarrassment',\n",
    "    13: 'excitement',\n",
    "    14: 'fear',\n",
    "    15: 'gratitude',\n",
    "    16: 'grief',\n",
    "    17: 'joy',\n",
    "    18: 'love',\n",
    "    19: 'nervousness',\n",
    "    20: 'optimism',\n",
    "    21: 'pride',\n",
    "    22: 'realization',\n",
    "    23: 'relief',\n",
    "    24: 'remorse',\n",
    "    25: 'sadness',\n",
    "    26: 'surprise',\n",
    "    27: 'neutral'\n",
    "}\n",
    "\n",
    "emotion_to_idx = {\n",
    "    'admiration': 0,\n",
    "    'amusement': 1,\n",
    "    'anger': 2,\n",
    "    'annoyance': 3,\n",
    "    'approval': 4,\n",
    "    'caring': 5,\n",
    "    'confusion': 6,\n",
    "    'curiosity': 7,\n",
    "    'desire': 8,\n",
    "    'disappointment': 9,\n",
    "    'disapproval': 10,\n",
    "    'disgust': 11,\n",
    "    'embarrassment': 12,\n",
    "    'excitement': 13,\n",
    "    'fear': 14,\n",
    "    'gratitude': 15,\n",
    "    'grief': 16,\n",
    "    'joy': 17,\n",
    "    'love': 18,\n",
    "    'nervousness': 19,\n",
    "    'optimism': 20,\n",
    "    'pride': 21,\n",
    "    'realization': 22,\n",
    "    'relief': 23,\n",
    "    'remorse': 24,\n",
    "    'sadness': 25,\n",
    "    'surprise': 26,\n",
    "    'neutral': 27\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the number of emotion classes:  28\n",
      "idx_to_emotion:  {0: 'admiration', 1: 'amusement', 2: 'anger', 3: 'annoyance', 4: 'approval', 5: 'caring', 6: 'confusion', 7: 'curiosity', 8: 'desire', 9: 'disappointment', 10: 'disapproval', 11: 'disgust', 12: 'embarrassment', 13: 'excitement', 14: 'fear', 15: 'gratitude', 16: 'grief', 17: 'joy', 18: 'love', 19: 'nervousness', 20: 'optimism', 21: 'pride', 22: 'realization', 23: 'relief', 24: 'remorse', 25: 'sadness', 26: 'surprise', 27: 'neutral'}\n",
      "emotion_to_idx:  {'admiration': 0, 'amusement': 1, 'anger': 2, 'annoyance': 3, 'approval': 4, 'caring': 5, 'confusion': 6, 'curiosity': 7, 'desire': 8, 'disappointment': 9, 'disapproval': 10, 'disgust': 11, 'embarrassment': 12, 'excitement': 13, 'fear': 14, 'gratitude': 15, 'grief': 16, 'joy': 17, 'love': 18, 'nervousness': 19, 'optimism': 20, 'pride': 21, 'realization': 22, 'relief': 23, 'remorse': 24, 'sadness': 25, 'surprise': 26, 'neutral': 27}\n"
     ]
    }
   ],
   "source": [
    "print(\"the number of emotion classes: \", len((idx_to_emotion)))\n",
    "print(\"idx_to_emotion: \", idx_to_emotion)\n",
    "print(\"emotion_to_idx: \", emotion_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_emotion(text):\n",
    "    emotions = classifier(text)\n",
    "    output = [0]*28\n",
    "    for emotion in emotions[0]:\n",
    "        num_emotion = emotion_to_idx[emotion['label']]\n",
    "        output[num_emotion] = emotion['score']\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_emotion_col(data):\n",
    "    tokenized_text = data['tokenized_text']\n",
    "    col_emotion = []\n",
    "    for text in tokenized_text:\n",
    "        text_emotion = []\n",
    "        for i in range(len(text)):\n",
    "            if emoji.emoji_count(text[i]) > 0:\n",
    "                emoji_name = emoji.demojize(text[i])[1:-1]\n",
    "                emoji_emotion = word_emotion(emoji_name)\n",
    "                text_emotion.append(emoji_emotion)\n",
    "            else:\n",
    "                text_emotion.append(word_emotion(text[i]))\n",
    "        col_emotion.append(text_emotion)\n",
    "    data['emotion'] = col_emotion\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dataset = add_emotion_col(new_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "      <th>tokenized_text</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>My favourite food is anything I didn't have to...</td>\n",
       "      <td>[27]</td>\n",
       "      <td>[My, favourite, food, is, anything, I, didn, t...</td>\n",
       "      <td>[[0.003761823521926999, 0.0014409106224775314,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Now if he does off himself, everyone will thin...</td>\n",
       "      <td>[27]</td>\n",
       "      <td>[Now, if, he, does, off, himself, everyone, wi...</td>\n",
       "      <td>[[0.0026063367258757353, 0.0013388615334406495...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WHY THE FUCK IS BAYLESS ISOING</td>\n",
       "      <td>[2]</td>\n",
       "      <td>[WHY, THE, FUCK, IS, BAYLESS, ISOING]</td>\n",
       "      <td>[[0.0019205614225938916, 0.001291286083869636,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>To make her feel threatened</td>\n",
       "      <td>[14]</td>\n",
       "      <td>[To, make, her, feel, threatened]</td>\n",
       "      <td>[[0.0035849562846124172, 0.001992727629840374,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dirty Southern Wankers</td>\n",
       "      <td>[3]</td>\n",
       "      <td>[Dirty, Southern, Wankers]</td>\n",
       "      <td>[[0.0049132914282381535, 0.005827016197144985,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1836</th>\n",
       "      <td>it’s happened before?! love my hometown of bea...</td>\n",
       "      <td>[7, 18]</td>\n",
       "      <td>[it, s, happened, before, love, my, hometown, ...</td>\n",
       "      <td>[[0.0035167797468602657, 0.0014414149336516857...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1837</th>\n",
       "      <td>Talked with my parents. It was so relaxing and...</td>\n",
       "      <td>[15]</td>\n",
       "      <td>[Talked, with, my, parents, It, was, so, relax...</td>\n",
       "      <td>[[0.002665032632648945, 0.002374983159825206, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1838</th>\n",
       "      <td>OMG, is this the one that wore white? 😳</td>\n",
       "      <td>[7, 26]</td>\n",
       "      <td>[OMG, is, this, the, one, that, wore, white, 😳]</td>\n",
       "      <td>[[0.02350100688636303, 0.008980895392596722, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1839</th>\n",
       "      <td>Nope! His real name starts with a G. Weird spe...</td>\n",
       "      <td>[10, 11]</td>\n",
       "      <td>[Nope, His, real, name, starts, with, a, G, We...</td>\n",
       "      <td>[[0.002730799373239279, 0.0026100073009729385,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1840</th>\n",
       "      <td>Just \"asking for a friend\"...huh? 😂</td>\n",
       "      <td>[7]</td>\n",
       "      <td>[Just, asking, for, a, friend, huh, 😂]</td>\n",
       "      <td>[[0.0025353622622787952, 0.0013934231828898191...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1841 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text    labels  \\\n",
       "0     My favourite food is anything I didn't have to...      [27]   \n",
       "1     Now if he does off himself, everyone will thin...      [27]   \n",
       "2                        WHY THE FUCK IS BAYLESS ISOING       [2]   \n",
       "3                           To make her feel threatened      [14]   \n",
       "4                                Dirty Southern Wankers       [3]   \n",
       "...                                                 ...       ...   \n",
       "1836  it’s happened before?! love my hometown of bea...   [7, 18]   \n",
       "1837  Talked with my parents. It was so relaxing and...      [15]   \n",
       "1838            OMG, is this the one that wore white? 😳   [7, 26]   \n",
       "1839  Nope! His real name starts with a G. Weird spe...  [10, 11]   \n",
       "1840                Just \"asking for a friend\"...huh? 😂       [7]   \n",
       "\n",
       "                                         tokenized_text  \\\n",
       "0     [My, favourite, food, is, anything, I, didn, t...   \n",
       "1     [Now, if, he, does, off, himself, everyone, wi...   \n",
       "2                 [WHY, THE, FUCK, IS, BAYLESS, ISOING]   \n",
       "3                     [To, make, her, feel, threatened]   \n",
       "4                            [Dirty, Southern, Wankers]   \n",
       "...                                                 ...   \n",
       "1836  [it, s, happened, before, love, my, hometown, ...   \n",
       "1837  [Talked, with, my, parents, It, was, so, relax...   \n",
       "1838    [OMG, is, this, the, one, that, wore, white, 😳]   \n",
       "1839  [Nope, His, real, name, starts, with, a, G, We...   \n",
       "1840             [Just, asking, for, a, friend, huh, 😂]   \n",
       "\n",
       "                                                emotion  \n",
       "0     [[0.003761823521926999, 0.0014409106224775314,...  \n",
       "1     [[0.0026063367258757353, 0.0013388615334406495...  \n",
       "2     [[0.0019205614225938916, 0.001291286083869636,...  \n",
       "3     [[0.0035849562846124172, 0.001992727629840374,...  \n",
       "4     [[0.0049132914282381535, 0.005827016197144985,...  \n",
       "...                                                 ...  \n",
       "1836  [[0.0035167797468602657, 0.0014414149336516857...  \n",
       "1837  [[0.002665032632648945, 0.002374983159825206, ...  \n",
       "1838  [[0.02350100688636303, 0.008980895392596722, 0...  \n",
       "1839  [[0.002730799373239279, 0.0026100073009729385,...  \n",
       "1840  [[0.0025353622622787952, 0.0013934231828898191...  \n",
       "\n",
       "[1841 rows x 4 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = new_dataset.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # loading new_dataset\n",
    "\n",
    "# new_dataset = pd.read_csv('new_dataset.csv', encoding='utf-8')\n",
    "# new_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def process_emotion_col(row):\n",
    "#     try:\n",
    "#         py_list = ast.literal_eval(row['emotion'])\n",
    "#         return py_list\n",
    "#     except Exception as e:\n",
    "#         print(\"에러가 발생했습니다\")\n",
    "#         return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 문자열 리스트로 변환\n",
    "# new_dataset['tokenized_text'] = new_dataset['tokenized_text'].apply(ast.literal_eval)\n",
    "# new_dataset['labels'] = new_dataset['labels'].apply(ast.literal_eval)\n",
    "# new_dataset['emotion'] = new_dataset.apply(process_emotion_col, axis=1)\n",
    "# new_dataset = new_dataset.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "      <th>tokenized_text</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>My favourite food is anything I didn't have to...</td>\n",
       "      <td>[27]</td>\n",
       "      <td>[My, favourite, food, is, anything, I, didn, t...</td>\n",
       "      <td>[[0.003761823521926999, 0.0014409106224775314,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Now if he does off himself, everyone will thin...</td>\n",
       "      <td>[27]</td>\n",
       "      <td>[Now, if, he, does, off, himself, everyone, wi...</td>\n",
       "      <td>[[0.0026063367258757353, 0.0013388615334406495...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WHY THE FUCK IS BAYLESS ISOING</td>\n",
       "      <td>[2]</td>\n",
       "      <td>[WHY, THE, FUCK, IS, BAYLESS, ISOING]</td>\n",
       "      <td>[[0.0019205614225938916, 0.001291286083869636,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>To make her feel threatened</td>\n",
       "      <td>[14]</td>\n",
       "      <td>[To, make, her, feel, threatened]</td>\n",
       "      <td>[[0.0035849562846124172, 0.001992727629840374,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dirty Southern Wankers</td>\n",
       "      <td>[3]</td>\n",
       "      <td>[Dirty, Southern, Wankers]</td>\n",
       "      <td>[[0.0049132914282381535, 0.005827016197144985,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1836</th>\n",
       "      <td>it’s happened before?! love my hometown of bea...</td>\n",
       "      <td>[7, 18]</td>\n",
       "      <td>[it, s, happened, before, love, my, hometown, ...</td>\n",
       "      <td>[[0.0035167797468602657, 0.0014414149336516857...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1837</th>\n",
       "      <td>Talked with my parents. It was so relaxing and...</td>\n",
       "      <td>[15]</td>\n",
       "      <td>[Talked, with, my, parents, It, was, so, relax...</td>\n",
       "      <td>[[0.002665032632648945, 0.002374983159825206, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1838</th>\n",
       "      <td>OMG, is this the one that wore white? 😳</td>\n",
       "      <td>[7, 26]</td>\n",
       "      <td>[OMG, is, this, the, one, that, wore, white, 😳]</td>\n",
       "      <td>[[0.02350100688636303, 0.008980895392596722, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1839</th>\n",
       "      <td>Nope! His real name starts with a G. Weird spe...</td>\n",
       "      <td>[10, 11]</td>\n",
       "      <td>[Nope, His, real, name, starts, with, a, G, We...</td>\n",
       "      <td>[[0.002730799373239279, 0.0026100073009729385,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1840</th>\n",
       "      <td>Just \"asking for a friend\"...huh? 😂</td>\n",
       "      <td>[7]</td>\n",
       "      <td>[Just, asking, for, a, friend, huh, 😂]</td>\n",
       "      <td>[[0.0025353622622787952, 0.0013934231828898191...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1841 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text    labels  \\\n",
       "0     My favourite food is anything I didn't have to...      [27]   \n",
       "1     Now if he does off himself, everyone will thin...      [27]   \n",
       "2                        WHY THE FUCK IS BAYLESS ISOING       [2]   \n",
       "3                           To make her feel threatened      [14]   \n",
       "4                                Dirty Southern Wankers       [3]   \n",
       "...                                                 ...       ...   \n",
       "1836  it’s happened before?! love my hometown of bea...   [7, 18]   \n",
       "1837  Talked with my parents. It was so relaxing and...      [15]   \n",
       "1838            OMG, is this the one that wore white? 😳   [7, 26]   \n",
       "1839  Nope! His real name starts with a G. Weird spe...  [10, 11]   \n",
       "1840                Just \"asking for a friend\"...huh? 😂       [7]   \n",
       "\n",
       "                                         tokenized_text  \\\n",
       "0     [My, favourite, food, is, anything, I, didn, t...   \n",
       "1     [Now, if, he, does, off, himself, everyone, wi...   \n",
       "2                 [WHY, THE, FUCK, IS, BAYLESS, ISOING]   \n",
       "3                     [To, make, her, feel, threatened]   \n",
       "4                            [Dirty, Southern, Wankers]   \n",
       "...                                                 ...   \n",
       "1836  [it, s, happened, before, love, my, hometown, ...   \n",
       "1837  [Talked, with, my, parents, It, was, so, relax...   \n",
       "1838    [OMG, is, this, the, one, that, wore, white, 😳]   \n",
       "1839  [Nope, His, real, name, starts, with, a, G, We...   \n",
       "1840             [Just, asking, for, a, friend, huh, 😂]   \n",
       "\n",
       "                                                emotion  \n",
       "0     [[0.003761823521926999, 0.0014409106224775314,...  \n",
       "1     [[0.0026063367258757353, 0.0013388615334406495...  \n",
       "2     [[0.0019205614225938916, 0.001291286083869636,...  \n",
       "3     [[0.0035849562846124172, 0.001992727629840374,...  \n",
       "4     [[0.0049132914282381535, 0.005827016197144985,...  \n",
       "...                                                 ...  \n",
       "1836  [[0.0035167797468602657, 0.0014414149336516857...  \n",
       "1837  [[0.002665032632648945, 0.002374983159825206, ...  \n",
       "1838  [[0.02350100688636303, 0.008980895392596722, 0...  \n",
       "1839  [[0.002730799373239279, 0.0026100073009729385,...  \n",
       "1840  [[0.0025353622622787952, 0.0013934231828898191...  \n",
       "\n",
       "[1841 rows x 4 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 중 최대 단어 수:  47\n"
     ]
    }
   ],
   "source": [
    "#padding하기 위해\n",
    "\n",
    "print(\"데이터 중 최대 단어 수: \", max([len(instance) for instance in dataset['emotion']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# padding\n",
    "\n",
    "def flattening_padding(col):\n",
    "    tensor = [torch.tensor(instance).reshape(-1) for instance in col]\n",
    "    padded_tensor = pad_sequence(tensor, batch_first=True, padding_value=0)\n",
    "    return [item for item in padded_tensor]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['flattened_padded_emotion'] = flattening_padding(dataset['emotion'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인스턴스 별 emotion_embedding 벡터 길이:  1316\n"
     ]
    }
   ],
   "source": [
    "print(\"인스턴스 별 emotion_embedding 벡터 길이: \", len(dataset['flattened_padded_emotion'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tesor들 전부 일반 리스트로 & flattening\n",
    "result = [instance.tolist() for instance in dataset['flattened_padded_emotion']]\n",
    "dataset['flattened_padded_emotion'] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "      <th>tokenized_text</th>\n",
       "      <th>emotion</th>\n",
       "      <th>flattened_padded_emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>My favourite food is anything I didn't have to...</td>\n",
       "      <td>[27]</td>\n",
       "      <td>[My, favourite, food, is, anything, I, didn, t...</td>\n",
       "      <td>[[0.003761823521926999, 0.0014409106224775314,...</td>\n",
       "      <td>[0.003761823521926999, 0.0014409106224775314, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Now if he does off himself, everyone will thin...</td>\n",
       "      <td>[27]</td>\n",
       "      <td>[Now, if, he, does, off, himself, everyone, wi...</td>\n",
       "      <td>[[0.0026063367258757353, 0.0013388615334406495...</td>\n",
       "      <td>[0.0026063367258757353, 0.0013388615334406495,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WHY THE FUCK IS BAYLESS ISOING</td>\n",
       "      <td>[2]</td>\n",
       "      <td>[WHY, THE, FUCK, IS, BAYLESS, ISOING]</td>\n",
       "      <td>[[0.0019205614225938916, 0.001291286083869636,...</td>\n",
       "      <td>[0.0019205614225938916, 0.001291286083869636, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>To make her feel threatened</td>\n",
       "      <td>[14]</td>\n",
       "      <td>[To, make, her, feel, threatened]</td>\n",
       "      <td>[[0.0035849562846124172, 0.001992727629840374,...</td>\n",
       "      <td>[0.0035849562846124172, 0.001992727629840374, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dirty Southern Wankers</td>\n",
       "      <td>[3]</td>\n",
       "      <td>[Dirty, Southern, Wankers]</td>\n",
       "      <td>[[0.0049132914282381535, 0.005827016197144985,...</td>\n",
       "      <td>[0.0049132914282381535, 0.005827016197144985, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1836</th>\n",
       "      <td>it’s happened before?! love my hometown of bea...</td>\n",
       "      <td>[7, 18]</td>\n",
       "      <td>[it, s, happened, before, love, my, hometown, ...</td>\n",
       "      <td>[[0.0035167797468602657, 0.0014414149336516857...</td>\n",
       "      <td>[0.0035167797468602657, 0.0014414149336516857,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1837</th>\n",
       "      <td>Talked with my parents. It was so relaxing and...</td>\n",
       "      <td>[15]</td>\n",
       "      <td>[Talked, with, my, parents, It, was, so, relax...</td>\n",
       "      <td>[[0.002665032632648945, 0.002374983159825206, ...</td>\n",
       "      <td>[0.002665032632648945, 0.002374983159825206, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1838</th>\n",
       "      <td>OMG, is this the one that wore white? 😳</td>\n",
       "      <td>[7, 26]</td>\n",
       "      <td>[OMG, is, this, the, one, that, wore, white, 😳]</td>\n",
       "      <td>[[0.02350100688636303, 0.008980895392596722, 0...</td>\n",
       "      <td>[0.02350100688636303, 0.008980895392596722, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1839</th>\n",
       "      <td>Nope! His real name starts with a G. Weird spe...</td>\n",
       "      <td>[10, 11]</td>\n",
       "      <td>[Nope, His, real, name, starts, with, a, G, We...</td>\n",
       "      <td>[[0.002730799373239279, 0.0026100073009729385,...</td>\n",
       "      <td>[0.002730799373239279, 0.0026100073009729385, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1840</th>\n",
       "      <td>Just \"asking for a friend\"...huh? 😂</td>\n",
       "      <td>[7]</td>\n",
       "      <td>[Just, asking, for, a, friend, huh, 😂]</td>\n",
       "      <td>[[0.0025353622622787952, 0.0013934231828898191...</td>\n",
       "      <td>[0.0025353622622787952, 0.0013934231828898191,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1841 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text    labels  \\\n",
       "0     My favourite food is anything I didn't have to...      [27]   \n",
       "1     Now if he does off himself, everyone will thin...      [27]   \n",
       "2                        WHY THE FUCK IS BAYLESS ISOING       [2]   \n",
       "3                           To make her feel threatened      [14]   \n",
       "4                                Dirty Southern Wankers       [3]   \n",
       "...                                                 ...       ...   \n",
       "1836  it’s happened before?! love my hometown of bea...   [7, 18]   \n",
       "1837  Talked with my parents. It was so relaxing and...      [15]   \n",
       "1838            OMG, is this the one that wore white? 😳   [7, 26]   \n",
       "1839  Nope! His real name starts with a G. Weird spe...  [10, 11]   \n",
       "1840                Just \"asking for a friend\"...huh? 😂       [7]   \n",
       "\n",
       "                                         tokenized_text  \\\n",
       "0     [My, favourite, food, is, anything, I, didn, t...   \n",
       "1     [Now, if, he, does, off, himself, everyone, wi...   \n",
       "2                 [WHY, THE, FUCK, IS, BAYLESS, ISOING]   \n",
       "3                     [To, make, her, feel, threatened]   \n",
       "4                            [Dirty, Southern, Wankers]   \n",
       "...                                                 ...   \n",
       "1836  [it, s, happened, before, love, my, hometown, ...   \n",
       "1837  [Talked, with, my, parents, It, was, so, relax...   \n",
       "1838    [OMG, is, this, the, one, that, wore, white, 😳]   \n",
       "1839  [Nope, His, real, name, starts, with, a, G, We...   \n",
       "1840             [Just, asking, for, a, friend, huh, 😂]   \n",
       "\n",
       "                                                emotion  \\\n",
       "0     [[0.003761823521926999, 0.0014409106224775314,...   \n",
       "1     [[0.0026063367258757353, 0.0013388615334406495...   \n",
       "2     [[0.0019205614225938916, 0.001291286083869636,...   \n",
       "3     [[0.0035849562846124172, 0.001992727629840374,...   \n",
       "4     [[0.0049132914282381535, 0.005827016197144985,...   \n",
       "...                                                 ...   \n",
       "1836  [[0.0035167797468602657, 0.0014414149336516857...   \n",
       "1837  [[0.002665032632648945, 0.002374983159825206, ...   \n",
       "1838  [[0.02350100688636303, 0.008980895392596722, 0...   \n",
       "1839  [[0.002730799373239279, 0.0026100073009729385,...   \n",
       "1840  [[0.0025353622622787952, 0.0013934231828898191...   \n",
       "\n",
       "                               flattened_padded_emotion  \n",
       "0     [0.003761823521926999, 0.0014409106224775314, ...  \n",
       "1     [0.0026063367258757353, 0.0013388615334406495,...  \n",
       "2     [0.0019205614225938916, 0.001291286083869636, ...  \n",
       "3     [0.0035849562846124172, 0.001992727629840374, ...  \n",
       "4     [0.0049132914282381535, 0.005827016197144985, ...  \n",
       "...                                                 ...  \n",
       "1836  [0.0035167797468602657, 0.0014414149336516857,...  \n",
       "1837  [0.002665032632648945, 0.002374983159825206, 0...  \n",
       "1838  [0.02350100688636303, 0.008980895392596722, 0....  \n",
       "1839  [0.002730799373239279, 0.0026100073009729385, ...  \n",
       "1840  [0.0025353622622787952, 0.0013934231828898191,...  \n",
       "\n",
       "[1841 rows x 5 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_to_vector(labels):\n",
    "    init = [0]*28\n",
    "    for label in labels:\n",
    "        init[label] = 1\n",
    "    return init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "      <th>tokenized_text</th>\n",
       "      <th>emotion</th>\n",
       "      <th>flattened_padded_emotion</th>\n",
       "      <th>label_to_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>My favourite food is anything I didn't have to...</td>\n",
       "      <td>[27]</td>\n",
       "      <td>[My, favourite, food, is, anything, I, didn, t...</td>\n",
       "      <td>[[0.003761823521926999, 0.0014409106224775314,...</td>\n",
       "      <td>[0.003761823521926999, 0.0014409106224775314, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Now if he does off himself, everyone will thin...</td>\n",
       "      <td>[27]</td>\n",
       "      <td>[Now, if, he, does, off, himself, everyone, wi...</td>\n",
       "      <td>[[0.0026063367258757353, 0.0013388615334406495...</td>\n",
       "      <td>[0.0026063367258757353, 0.0013388615334406495,...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WHY THE FUCK IS BAYLESS ISOING</td>\n",
       "      <td>[2]</td>\n",
       "      <td>[WHY, THE, FUCK, IS, BAYLESS, ISOING]</td>\n",
       "      <td>[[0.0019205614225938916, 0.001291286083869636,...</td>\n",
       "      <td>[0.0019205614225938916, 0.001291286083869636, ...</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>To make her feel threatened</td>\n",
       "      <td>[14]</td>\n",
       "      <td>[To, make, her, feel, threatened]</td>\n",
       "      <td>[[0.0035849562846124172, 0.001992727629840374,...</td>\n",
       "      <td>[0.0035849562846124172, 0.001992727629840374, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dirty Southern Wankers</td>\n",
       "      <td>[3]</td>\n",
       "      <td>[Dirty, Southern, Wankers]</td>\n",
       "      <td>[[0.0049132914282381535, 0.005827016197144985,...</td>\n",
       "      <td>[0.0049132914282381535, 0.005827016197144985, ...</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1836</th>\n",
       "      <td>it’s happened before?! love my hometown of bea...</td>\n",
       "      <td>[7, 18]</td>\n",
       "      <td>[it, s, happened, before, love, my, hometown, ...</td>\n",
       "      <td>[[0.0035167797468602657, 0.0014414149336516857...</td>\n",
       "      <td>[0.0035167797468602657, 0.0014414149336516857,...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1837</th>\n",
       "      <td>Talked with my parents. It was so relaxing and...</td>\n",
       "      <td>[15]</td>\n",
       "      <td>[Talked, with, my, parents, It, was, so, relax...</td>\n",
       "      <td>[[0.002665032632648945, 0.002374983159825206, ...</td>\n",
       "      <td>[0.002665032632648945, 0.002374983159825206, 0...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1838</th>\n",
       "      <td>OMG, is this the one that wore white? 😳</td>\n",
       "      <td>[7, 26]</td>\n",
       "      <td>[OMG, is, this, the, one, that, wore, white, 😳]</td>\n",
       "      <td>[[0.02350100688636303, 0.008980895392596722, 0...</td>\n",
       "      <td>[0.02350100688636303, 0.008980895392596722, 0....</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1839</th>\n",
       "      <td>Nope! His real name starts with a G. Weird spe...</td>\n",
       "      <td>[10, 11]</td>\n",
       "      <td>[Nope, His, real, name, starts, with, a, G, We...</td>\n",
       "      <td>[[0.002730799373239279, 0.0026100073009729385,...</td>\n",
       "      <td>[0.002730799373239279, 0.0026100073009729385, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1840</th>\n",
       "      <td>Just \"asking for a friend\"...huh? 😂</td>\n",
       "      <td>[7]</td>\n",
       "      <td>[Just, asking, for, a, friend, huh, 😂]</td>\n",
       "      <td>[[0.0025353622622787952, 0.0013934231828898191...</td>\n",
       "      <td>[0.0025353622622787952, 0.0013934231828898191,...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1841 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text    labels  \\\n",
       "0     My favourite food is anything I didn't have to...      [27]   \n",
       "1     Now if he does off himself, everyone will thin...      [27]   \n",
       "2                        WHY THE FUCK IS BAYLESS ISOING       [2]   \n",
       "3                           To make her feel threatened      [14]   \n",
       "4                                Dirty Southern Wankers       [3]   \n",
       "...                                                 ...       ...   \n",
       "1836  it’s happened before?! love my hometown of bea...   [7, 18]   \n",
       "1837  Talked with my parents. It was so relaxing and...      [15]   \n",
       "1838            OMG, is this the one that wore white? 😳   [7, 26]   \n",
       "1839  Nope! His real name starts with a G. Weird spe...  [10, 11]   \n",
       "1840                Just \"asking for a friend\"...huh? 😂       [7]   \n",
       "\n",
       "                                         tokenized_text  \\\n",
       "0     [My, favourite, food, is, anything, I, didn, t...   \n",
       "1     [Now, if, he, does, off, himself, everyone, wi...   \n",
       "2                 [WHY, THE, FUCK, IS, BAYLESS, ISOING]   \n",
       "3                     [To, make, her, feel, threatened]   \n",
       "4                            [Dirty, Southern, Wankers]   \n",
       "...                                                 ...   \n",
       "1836  [it, s, happened, before, love, my, hometown, ...   \n",
       "1837  [Talked, with, my, parents, It, was, so, relax...   \n",
       "1838    [OMG, is, this, the, one, that, wore, white, 😳]   \n",
       "1839  [Nope, His, real, name, starts, with, a, G, We...   \n",
       "1840             [Just, asking, for, a, friend, huh, 😂]   \n",
       "\n",
       "                                                emotion  \\\n",
       "0     [[0.003761823521926999, 0.0014409106224775314,...   \n",
       "1     [[0.0026063367258757353, 0.0013388615334406495...   \n",
       "2     [[0.0019205614225938916, 0.001291286083869636,...   \n",
       "3     [[0.0035849562846124172, 0.001992727629840374,...   \n",
       "4     [[0.0049132914282381535, 0.005827016197144985,...   \n",
       "...                                                 ...   \n",
       "1836  [[0.0035167797468602657, 0.0014414149336516857...   \n",
       "1837  [[0.002665032632648945, 0.002374983159825206, ...   \n",
       "1838  [[0.02350100688636303, 0.008980895392596722, 0...   \n",
       "1839  [[0.002730799373239279, 0.0026100073009729385,...   \n",
       "1840  [[0.0025353622622787952, 0.0013934231828898191...   \n",
       "\n",
       "                               flattened_padded_emotion  \\\n",
       "0     [0.003761823521926999, 0.0014409106224775314, ...   \n",
       "1     [0.0026063367258757353, 0.0013388615334406495,...   \n",
       "2     [0.0019205614225938916, 0.001291286083869636, ...   \n",
       "3     [0.0035849562846124172, 0.001992727629840374, ...   \n",
       "4     [0.0049132914282381535, 0.005827016197144985, ...   \n",
       "...                                                 ...   \n",
       "1836  [0.0035167797468602657, 0.0014414149336516857,...   \n",
       "1837  [0.002665032632648945, 0.002374983159825206, 0...   \n",
       "1838  [0.02350100688636303, 0.008980895392596722, 0....   \n",
       "1839  [0.002730799373239279, 0.0026100073009729385, ...   \n",
       "1840  [0.0025353622622787952, 0.0013934231828898191,...   \n",
       "\n",
       "                                        label_to_vector  \n",
       "0     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2     [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "3     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...  \n",
       "4     [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "...                                                 ...  \n",
       "1836  [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1837  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1838  [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1839  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, ...  \n",
       "1840  [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "\n",
       "[1841 rows x 6 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['label_to_vector'] = dataset['labels'].apply(label_to_vector)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "      <th>tokenized_text</th>\n",
       "      <th>emotion</th>\n",
       "      <th>flattened_padded_emotion</th>\n",
       "      <th>label_to_vector</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>My favourite food is anything I didn't have to...</td>\n",
       "      <td>[27]</td>\n",
       "      <td>[My, favourite, food, is, anything, I, didn, t...</td>\n",
       "      <td>[[0.003761823521926999, 0.0014409106224775314,...</td>\n",
       "      <td>[0.003761823521926999, 0.0014409106224775314, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Now if he does off himself, everyone will thin...</td>\n",
       "      <td>[27]</td>\n",
       "      <td>[Now, if, he, does, off, himself, everyone, wi...</td>\n",
       "      <td>[[0.0026063367258757353, 0.0013388615334406495...</td>\n",
       "      <td>[0.0026063367258757353, 0.0013388615334406495,...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WHY THE FUCK IS BAYLESS ISOING</td>\n",
       "      <td>[2]</td>\n",
       "      <td>[WHY, THE, FUCK, IS, BAYLESS, ISOING]</td>\n",
       "      <td>[[0.0019205614225938916, 0.001291286083869636,...</td>\n",
       "      <td>[0.0019205614225938916, 0.001291286083869636, ...</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>To make her feel threatened</td>\n",
       "      <td>[14]</td>\n",
       "      <td>[To, make, her, feel, threatened]</td>\n",
       "      <td>[[0.0035849562846124172, 0.001992727629840374,...</td>\n",
       "      <td>[0.0035849562846124172, 0.001992727629840374, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dirty Southern Wankers</td>\n",
       "      <td>[3]</td>\n",
       "      <td>[Dirty, Southern, Wankers]</td>\n",
       "      <td>[[0.0049132914282381535, 0.005827016197144985,...</td>\n",
       "      <td>[0.0049132914282381535, 0.005827016197144985, ...</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1836</th>\n",
       "      <td>it’s happened before?! love my hometown of bea...</td>\n",
       "      <td>[7, 18]</td>\n",
       "      <td>[it, s, happened, before, love, my, hometown, ...</td>\n",
       "      <td>[[0.0035167797468602657, 0.0014414149336516857...</td>\n",
       "      <td>[0.0035167797468602657, 0.0014414149336516857,...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>1836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1837</th>\n",
       "      <td>Talked with my parents. It was so relaxing and...</td>\n",
       "      <td>[15]</td>\n",
       "      <td>[Talked, with, my, parents, It, was, so, relax...</td>\n",
       "      <td>[[0.002665032632648945, 0.002374983159825206, ...</td>\n",
       "      <td>[0.002665032632648945, 0.002374983159825206, 0...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>1837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1838</th>\n",
       "      <td>OMG, is this the one that wore white? 😳</td>\n",
       "      <td>[7, 26]</td>\n",
       "      <td>[OMG, is, this, the, one, that, wore, white, 😳]</td>\n",
       "      <td>[[0.02350100688636303, 0.008980895392596722, 0...</td>\n",
       "      <td>[0.02350100688636303, 0.008980895392596722, 0....</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>1838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1839</th>\n",
       "      <td>Nope! His real name starts with a G. Weird spe...</td>\n",
       "      <td>[10, 11]</td>\n",
       "      <td>[Nope, His, real, name, starts, with, a, G, We...</td>\n",
       "      <td>[[0.002730799373239279, 0.0026100073009729385,...</td>\n",
       "      <td>[0.002730799373239279, 0.0026100073009729385, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, ...</td>\n",
       "      <td>1839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1840</th>\n",
       "      <td>Just \"asking for a friend\"...huh? 😂</td>\n",
       "      <td>[7]</td>\n",
       "      <td>[Just, asking, for, a, friend, huh, 😂]</td>\n",
       "      <td>[[0.0025353622622787952, 0.0013934231828898191...</td>\n",
       "      <td>[0.0025353622622787952, 0.0013934231828898191,...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>1840</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1841 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text    labels  \\\n",
       "0     My favourite food is anything I didn't have to...      [27]   \n",
       "1     Now if he does off himself, everyone will thin...      [27]   \n",
       "2                        WHY THE FUCK IS BAYLESS ISOING       [2]   \n",
       "3                           To make her feel threatened      [14]   \n",
       "4                                Dirty Southern Wankers       [3]   \n",
       "...                                                 ...       ...   \n",
       "1836  it’s happened before?! love my hometown of bea...   [7, 18]   \n",
       "1837  Talked with my parents. It was so relaxing and...      [15]   \n",
       "1838            OMG, is this the one that wore white? 😳   [7, 26]   \n",
       "1839  Nope! His real name starts with a G. Weird spe...  [10, 11]   \n",
       "1840                Just \"asking for a friend\"...huh? 😂       [7]   \n",
       "\n",
       "                                         tokenized_text  \\\n",
       "0     [My, favourite, food, is, anything, I, didn, t...   \n",
       "1     [Now, if, he, does, off, himself, everyone, wi...   \n",
       "2                 [WHY, THE, FUCK, IS, BAYLESS, ISOING]   \n",
       "3                     [To, make, her, feel, threatened]   \n",
       "4                            [Dirty, Southern, Wankers]   \n",
       "...                                                 ...   \n",
       "1836  [it, s, happened, before, love, my, hometown, ...   \n",
       "1837  [Talked, with, my, parents, It, was, so, relax...   \n",
       "1838    [OMG, is, this, the, one, that, wore, white, 😳]   \n",
       "1839  [Nope, His, real, name, starts, with, a, G, We...   \n",
       "1840             [Just, asking, for, a, friend, huh, 😂]   \n",
       "\n",
       "                                                emotion  \\\n",
       "0     [[0.003761823521926999, 0.0014409106224775314,...   \n",
       "1     [[0.0026063367258757353, 0.0013388615334406495...   \n",
       "2     [[0.0019205614225938916, 0.001291286083869636,...   \n",
       "3     [[0.0035849562846124172, 0.001992727629840374,...   \n",
       "4     [[0.0049132914282381535, 0.005827016197144985,...   \n",
       "...                                                 ...   \n",
       "1836  [[0.0035167797468602657, 0.0014414149336516857...   \n",
       "1837  [[0.002665032632648945, 0.002374983159825206, ...   \n",
       "1838  [[0.02350100688636303, 0.008980895392596722, 0...   \n",
       "1839  [[0.002730799373239279, 0.0026100073009729385,...   \n",
       "1840  [[0.0025353622622787952, 0.0013934231828898191...   \n",
       "\n",
       "                               flattened_padded_emotion  \\\n",
       "0     [0.003761823521926999, 0.0014409106224775314, ...   \n",
       "1     [0.0026063367258757353, 0.0013388615334406495,...   \n",
       "2     [0.0019205614225938916, 0.001291286083869636, ...   \n",
       "3     [0.0035849562846124172, 0.001992727629840374, ...   \n",
       "4     [0.0049132914282381535, 0.005827016197144985, ...   \n",
       "...                                                 ...   \n",
       "1836  [0.0035167797468602657, 0.0014414149336516857,...   \n",
       "1837  [0.002665032632648945, 0.002374983159825206, 0...   \n",
       "1838  [0.02350100688636303, 0.008980895392596722, 0....   \n",
       "1839  [0.002730799373239279, 0.0026100073009729385, ...   \n",
       "1840  [0.0025353622622787952, 0.0013934231828898191,...   \n",
       "\n",
       "                                        label_to_vector  index  \n",
       "0     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...      0  \n",
       "1     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...      1  \n",
       "2     [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...      2  \n",
       "3     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...      3  \n",
       "4     [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...      4  \n",
       "...                                                 ...    ...  \n",
       "1836  [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...   1836  \n",
       "1837  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   1837  \n",
       "1838  [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...   1838  \n",
       "1839  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, ...   1839  \n",
       "1840  [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...   1840  \n",
       "\n",
       "[1841 rows x 7 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['index'] = list(range(len(dataset)))\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, validation, test split\n",
    "indices = dataset['index'].to_list()\n",
    "X1 = dataset['flattened_padded_emotion'].to_list()\n",
    "y1 = dataset['label_to_vector'].to_list()\n",
    "X1_train, X1_temp, y1_train, y1_temp, indices_train, indices_temp = train_test_split(X1, y1, indices, test_size=0.3, random_state=42)\n",
    "X1_val, X1_test, y1_val, y1_test, indices_val, indices_test = train_test_split(X1_temp, y1_temp, indices_temp, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of X1_train:  1288 , number of y1_train: 1288\n",
      "number of X1_val:  276 , number of y1_val: 276\n",
      "number of X1_test:  277 , number of y1_test: 277\n"
     ]
    }
   ],
   "source": [
    "print(\"number of X1_train: \", len(X1_train), \", number of y1_train:\", len(y1_train))\n",
    "print(\"number of X1_val: \", len(X1_val), \", number of y1_val:\", len(y1_val))\n",
    "print(\"number of X1_test: \", len(X1_test), \", number of y1_test:\", len(y1_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# customizing dataset class\n",
    "\n",
    "class Dataset1(Dataset):\n",
    "    def __init__(self, X, y, indices):\n",
    "        self.X_train = torch.tensor(X)\n",
    "        self.y_train = torch.tensor(y)\n",
    "        self.indices = indices\n",
    " \n",
    "    def __len__(self):\n",
    "        return len(self.X_train)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X_train[idx], self.y_train[idx], self.indices[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model1(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size=1316, num_classes=28):\n",
    "        super(Model1, self).__init__()\n",
    "        self.linear1 = nn.Linear(input_size, input_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(input_size, num_classes) \n",
    "        #self.sigmoid_layers = nn.ModuleList([nn.Sigmoid() for _ in range(num_classes)])\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.relu(x)\n",
    "        out = self.linear2(x)\n",
    "        #output = [sigmoid(x2) for sigmoid in self.sigmoid_layers] \n",
    "        #output = torch.stack(output, dim=1)\n",
    "\n",
    "        return out, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create train, validation, test dataset\n",
    "\n",
    "train_dataset1 = Dataset1(X1_train, y1_train, indices_train)\n",
    "validation_dataset1 = Dataset1(X1_val, y1_val, indices_val)\n",
    "test_dataset1 = Dataset1(X1_test, y1_test, indices_test)\n",
    "\n",
    "# create train, validation, test dataloader\n",
    "batch_size = 32\n",
    "train_dataloader = DataLoader(train_dataset1, batch_size, shuffle=True)\n",
    "validation_dataloader = DataLoader(validation_dataset1, batch_size=32)\n",
    "test_dataloader = DataLoader(test_dataset1, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = len(dataset['flattened_padded_emotion'][0]))\n",
    "model1 = Model1(input_size=input_size)\n",
    "optimizer = optim.Adam(model1.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(outputs, labels):\n",
    "    if labels is None:\n",
    "        return None\n",
    "    return nn.BCEWithLogitsLoss()(outputs, labels.float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_metrics(preds, labels):\n",
    "    preds = torch.stack(preds)\n",
    "    preds = preds.cpu().detach().numpy()\n",
    "    labels = torch.stack(labels)\n",
    "    labels = labels.cpu().detach().numpy()\n",
    "\n",
    "    fpr_micro, tpr_micro, _ = metrics.roc_curve(labels.ravel(), preds.ravel())\n",
    "    auc_micro = metrics.auc(fpr_micro, tpr_micro)\n",
    "\n",
    "    return {\"auc_micro\": auc_micro}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Training Loss: 0.009655867813166625, Validation Loss: 0.005800380870915841, ACU Score: 0.7227630588256813\n",
      "Model saved as current validation loss is:  0.005800380870915841\n",
      "Epoch 2/100, Training Loss: 0.0053563219327363906, Validation Loss: 0.00528937831952952, ACU Score: 0.7726098447206863\n",
      "Model saved as current validation loss is:  0.00528937831952952\n",
      "Epoch 3/100, Training Loss: 0.0050797796351198824, Validation Loss: 0.0051360895884209785, ACU Score: 0.7995413864790551\n",
      "Model saved as current validation loss is:  0.0051360895884209785\n",
      "Epoch 4/100, Training Loss: 0.004857034393534157, Validation Loss: 0.004932128972765328, ACU Score: 0.8110189176172217\n",
      "Model saved as current validation loss is:  0.004932128972765328\n",
      "Epoch 5/100, Training Loss: 0.004576732676406825, Validation Loss: 0.004723669394202854, ACU Score: 0.8339442591768429\n",
      "Model saved as current validation loss is:  0.004723669394202854\n",
      "Epoch 6/100, Training Loss: 0.004278739648205894, Validation Loss: 0.004587555115205654, ACU Score: 0.8449736933553621\n",
      "Model saved as current validation loss is:  0.004587555115205654\n",
      "Epoch 7/100, Training Loss: 0.004011615017509978, Validation Loss: 0.004509491063114526, ACU Score: 0.8472225609198485\n",
      "Model saved as current validation loss is:  0.004509491063114526\n",
      "Epoch 8/100, Training Loss: 0.003785712337873367, Validation Loss: 0.004369567566807719, ACU Score: 0.8586577971919257\n",
      "Model saved as current validation loss is:  0.004369567566807719\n",
      "Epoch 9/100, Training Loss: 0.0035664011660662496, Validation Loss: 0.004354513425757919, ACU Score: 0.8573504666914594\n",
      "Model saved as current validation loss is:  0.004354513425757919\n",
      "Epoch 10/100, Training Loss: 0.003361504877807561, Validation Loss: 0.004349410884838173, ACU Score: 0.8620017588567737\n",
      "Model saved as current validation loss is:  0.004349410884838173\n",
      "Epoch 11/100, Training Loss: 0.003187920452783937, Validation Loss: 0.004359451567997103, ACU Score: 0.8594972169216044\n",
      "Epoch 12/100, Training Loss: 0.0030175768047200967, Validation Loss: 0.0043626470842223234, ACU Score: 0.8599780828765996\n",
      "Epoch 13/100, Training Loss: 0.0028828951640066155, Validation Loss: 0.004340204315772955, ACU Score: 0.8615064135782523\n",
      "Model saved as current validation loss is:  0.004340204315772955\n",
      "Epoch 14/100, Training Loss: 0.002761786994495377, Validation Loss: 0.004443099641281626, ACU Score: 0.8541010016643601\n",
      "Epoch 15/100, Training Loss: 0.0026435826656333408, Validation Loss: 0.004508849449347758, ACU Score: 0.8545917745249257\n",
      "Epoch 16/100, Training Loss: 0.0025377407965036284, Validation Loss: 0.0046726312164379205, ACU Score: 0.8423849427228444\n",
      "Epoch 17/100, Training Loss: 0.00241685658404083, Validation Loss: 0.004766404385799947, ACU Score: 0.844281734104751\n",
      "Epoch 18/100, Training Loss: 0.0023251439600905275, Validation Loss: 0.004810822317781655, ACU Score: 0.8412220244228084\n",
      "Early stopping at epoch 18 as there was no improvement in validation loss.\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "epochs = 100\n",
    "patience = 5\n",
    "best_val_loss = np.Inf\n",
    "current_patience = 0\n",
    "# word_embedding_dict = dict()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model1.train()\n",
    "    total_train_loss = 0.0\n",
    "\n",
    "    for inputs, labels, indices in train_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs, embedding = model1(inputs)\n",
    "        train_loss = loss_fn(outputs, labels)\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "        total_train_loss += train_loss.item()\n",
    "        # word_embedding_dict[indices] = embedding\n",
    "\n",
    "    model1.eval()\n",
    "    total_val_loss = 0.0\n",
    "    fin_labels = []\n",
    "    fin_outputs = []\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        for inputs, labels, indices in validation_dataloader:\n",
    "            outputs, embedding = model1(inputs)\n",
    "            val_loss = loss_fn(outputs, labels)\n",
    "            total_val_loss += val_loss.item()\n",
    "            # word_embedding_dict[indices] = embedding\n",
    "            fin_labels.extend(labels)\n",
    "            fin_outputs.extend(torch.sigmoid(outputs))\n",
    "\n",
    "    avg_train_loss = total_train_loss / len(train_dataloader.dataset)\n",
    "    avg_val_loss = total_val_loss / len(validation_dataloader.dataset)\n",
    "    auc_score = log_metrics(fin_outputs, fin_labels)[\"auc_micro\"]\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{epochs}, Training Loss: {avg_train_loss}, Validation Loss: {avg_val_loss}, ACU Score: {auc_score}')\n",
    "\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        current_patience = 0\n",
    "        torch.save(model1.state_dict(), 'best_model.pth')\n",
    "        print(\"Model saved as current validation loss is: \", best_val_loss)\n",
    "    else:\n",
    "        current_patience += 1\n",
    "    \n",
    "    if current_patience >= patience:\n",
    "        print(f'Early stopping at epoch {epoch+1} as there was no improvement in validation loss.')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "word_embedding_dict = dict()\n",
    "model1.eval\n",
    "with torch.inference_mode():\n",
    "    for inputs, _, indices in train_dataloader:\n",
    "        _, embedding = model1(inputs)\n",
    "        word_embedding_dict[indices] = embedding\n",
    "    for inputs, _, indices in validation_dataloader:\n",
    "        _, embedding = model1(inputs)\n",
    "        word_embedding_dict[indices] = embedding\n",
    "    for inputs, _, indices in test_dataloader:\n",
    "        _, embedding = model1(inputs)\n",
    "        word_embedding_dict[indices] = embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the number of words:  4503\n",
      "idx_to_word:  {0: 'A', 1: 'AA', 2: 'AB', 3: 'ABH', 4: 'AHAHA', 5: 'AM', 6: 'AMA', 7: 'AND', 8: 'ANGEL', 9: 'ANYONE', 10: 'APPROVE', 11: 'AR', 12: 'ARE', 13: 'AROUND', 14: 'AS', 15: 'ASAP', 16: 'ASD', 17: 'ATF', 18: 'ATM', 19: 'Aaahahahha', 20: 'Ab', 21: 'Absolutely', 22: 'Actually', 23: 'Acura', 24: 'Addison', 25: 'After', 26: 'Again', 27: 'Aggieopoly', 28: 'Aghulas', 29: 'Agreed', 30: 'Ah', 31: 'Ahem', 32: 'Ahh', 33: 'Ahhh', 34: 'Ahhhh', 35: 'AiG', 36: 'Al', 37: 'Alarming', 38: 'Alert', 39: 'All', 40: 'Allow', 41: 'Alright', 42: 'Also', 43: 'Although', 44: 'Alvalade', 45: 'Always', 46: 'Am', 47: 'Amateurs', 48: 'Amazing', 49: 'Amazon', 50: 'Ameen', 51: 'America', 52: 'American', 53: 'And', 54: 'Angel', 55: 'Animal', 56: 'Animation', 57: 'Another', 58: 'Any', 59: 'Anymore', 60: 'Anything', 61: 'Anytime', 62: 'Anyway', 63: 'Apologies', 64: 'Appalachia', 65: 'Apple', 66: 'Applying', 67: 'Are', 68: 'Aren', 69: 'Argh', 70: 'Argue', 71: 'Arizona', 72: 'Arm', 73: 'Arsenal', 74: 'As', 75: 'Ask', 76: 'At', 77: 'Au', 78: 'Austin', 79: 'Austinfred', 80: 'Australia', 81: 'Avocado', 82: 'Awesome', 83: 'Aww', 84: 'Ayyy', 85: 'Azusa', 86: 'B', 87: 'BACK', 88: 'BAYLESS', 89: 'BBC', 90: 'BIG', 91: 'BLADE', 92: 'BO', 93: 'BOMB', 94: 'BOTTOM', 95: 'BS', 96: 'BTS', 97: 'BURN', 98: 'Back', 99: 'Bae', 100: 'Barf', 101: 'Bc', 102: 'Be', 103: 'Beauty', 104: 'Because', 105: 'Being', 106: 'Belgian', 107: 'Believe', 108: 'Bellevue', 109: 'Ben', 110: 'Bengals', 111: 'Berlin', 112: 'Best', 113: 'Bet', 114: 'Big', 115: 'Bills', 116: 'Bingo', 117: 'Birthday', 118: 'Bit', 119: 'Bitch', 120: 'BlOod', 121: 'Black', 122: 'Blasted', 123: 'Block', 124: 'Blockbusters', 125: 'Bo', 126: 'Body', 127: 'Bold', 128: 'Bolts', 129: 'Bort', 130: 'Bowl', 131: 'Bowral', 132: 'Boys', 133: 'Brass', 134: 'Brave', 135: 'Bravo', 136: 'Bro', 137: 'Broncos', 138: 'Broncs', 139: 'Bruh', 140: 'Brussels', 141: 'Brutal', 142: 'Btw', 143: 'Bud', 144: 'Buddy', 145: 'Buff', 146: 'Bulls', 147: 'But', 148: 'Buying', 149: 'By', 150: 'C', 151: 'CANTTTT', 152: 'CARE', 153: 'CHAD', 154: 'CHOICE', 155: 'COOL', 156: 'Cake', 157: 'Cakeday', 158: 'Calling', 159: 'Came', 160: 'Can', 161: 'Canada', 162: 'Canadian', 163: 'Canon', 164: 'Capitalism', 165: 'Cardinals', 166: 'Casino', 167: 'Cat', 168: 'Catcher', 169: 'Change', 170: 'Check', 171: 'Cheers', 172: 'Chelsea', 173: 'China', 174: 'Cholent', 175: 'Christmas', 176: 'Cities', 177: 'Classic', 178: 'Clean', 179: 'Cleavage', 180: 'Clouds', 181: 'College', 182: 'Colts', 183: 'Come', 184: 'Comments', 185: 'Communication', 186: 'Community', 187: 'Company', 188: 'Con', 189: 'Concussions', 190: 'Congrats', 191: 'Congratulations', 192: 'Consider', 193: 'Contenders', 194: 'Convenient', 195: 'Corgis', 196: 'Corinthians', 197: 'Corsi', 198: 'Could', 199: 'Covington', 200: 'Crazy', 201: 'Crickets', 202: 'Crocodile', 203: 'Crossing', 204: 'Cruelty', 205: 'Cry', 206: 'Cute', 207: 'D', 208: 'DAMN', 209: 'DB', 210: 'DEVICE', 211: 'DEVOTED', 212: 'DICE', 213: 'DIE', 214: 'DIG', 215: 'DIVE', 216: 'DM', 217: 'DO', 218: 'DOIN', 219: 'DON', 220: 'DOPE', 221: 'DR', 222: 'DREAM', 223: 'DSJ', 224: 'Dachshund', 225: 'Dad', 226: 'Damn', 227: 'Danganronpa', 228: 'Darth', 229: 'Day', 230: 'Deal', 231: 'December', 232: 'Defense', 233: 'Define', 234: 'Definitely', 235: 'Degrees', 236: 'Del', 237: 'Deluxe', 238: 'Democrips', 239: 'Demographics', 240: 'Despite', 241: 'Detective', 242: 'Detroit', 243: 'Did', 244: 'Didn', 245: 'Didnt', 246: 'Ding', 247: 'Dirty', 248: 'Disagree', 249: 'Disco', 250: 'Discord', 251: 'Discovery', 252: 'Disease', 253: 'Do', 254: 'Does', 255: 'Doesn', 256: 'Don', 257: 'Done', 258: 'Dont', 259: 'Donut', 260: 'Doordash', 261: 'Dornish', 262: 'Dosing', 263: 'Down', 264: 'Dragonpit', 265: 'Drive', 266: 'Dude', 267: 'Dumbass', 268: 'Dunder', 269: 'Dv', 270: 'E', 271: 'ED', 272: 'EDIT', 273: 'ENGLAND', 274: 'ERA', 275: 'ESPN', 276: 'EST', 277: 'EU', 278: 'EVERYONE', 279: 'EXO', 280: 'Earth', 281: 'Easy', 282: 'Eat', 283: 'Edit', 284: 'Edited', 285: 'Either', 286: 'Ellsworth', 287: 'Embarrassing', 288: 'Emotes', 289: 'Enchanted', 290: 'English', 291: 'Enjoy', 292: 'Esp', 293: 'Especially', 294: 'Estee', 295: 'Europe', 296: 'Even', 297: 'Eventually', 298: 'Every', 299: 'Everyday', 300: 'Everyone', 301: 'Everywhere', 302: 'Exactly', 303: 'Excellent', 304: 'Except', 305: 'Executive', 306: 'F', 307: 'FBI', 308: 'FIGHT', 309: 'FINISH', 310: 'FIRE', 311: 'FOR', 312: 'FPS', 313: 'FPTP', 314: 'FUCK', 315: 'FURRIES', 316: 'FURRY', 317: 'Fab', 318: 'Fake', 319: 'Fall', 320: 'Family', 321: 'Famous', 322: 'Fantasy', 323: 'Fcuk', 324: 'Feel', 325: 'Fiddish', 326: 'Film', 327: 'Final', 328: 'Finale', 329: 'Finally', 330: 'Fine', 331: 'Fk', 332: 'Florence', 333: 'Focus', 334: 'Food', 335: 'For', 336: 'Forgive', 337: 'Found', 338: 'Frankly', 339: 'Friends', 340: 'From', 341: 'Fruit', 342: 'Fuck', 343: 'Fucking', 344: 'Funny', 345: 'G', 346: 'GAMERS', 347: 'GG', 348: 'GIRL', 349: 'GO', 350: 'GOD', 351: 'GOING', 352: 'GT', 353: 'Galaxy', 354: 'Gamers', 355: 'Gap', 356: 'Gather', 357: 'Genius', 358: 'Gentle', 359: 'Genuinely', 360: 'Germans', 361: 'Germany', 362: 'Get', 363: 'Getting', 364: 'Girl', 365: 'Girls', 366: 'Give', 367: 'Glad', 368: 'Glucose', 369: 'Go', 370: 'God', 371: 'Godlish', 372: 'Good', 373: 'Google', 374: 'Got', 375: 'Gotta', 376: 'Government', 377: 'Granville', 378: 'Great', 379: 'Greetings', 380: 'Gross', 381: 'Growing', 382: 'Guadalupe', 383: 'Guardian', 384: 'Guess', 385: 'Guy', 386: 'HA', 387: 'HAD', 388: 'HAHAHAHHA', 389: 'HATE', 390: 'HEAD', 391: 'HER', 392: 'HIGHS', 393: 'HIT', 394: 'HOPE', 395: 'HR', 396: 'Ha', 397: 'Haha', 398: 'Hahaha', 399: 'Hanoi', 400: 'Happy', 401: 'HappyFriendlyBot', 402: 'Hard', 403: 'Harris', 404: 'Has', 405: 'Hate', 406: 'Have', 407: 'Having', 408: 'Hawks', 409: 'He', 410: 'Hearts', 411: 'Hell', 412: 'Hello', 413: 'Her', 414: 'Here', 415: 'Hey', 416: 'Hi', 417: 'His', 418: 'Hitting', 419: 'Hiya', 420: 'Hm', 421: 'Hmm', 422: 'Hmmm', 423: 'Hollywood', 424: 'Holy', 425: 'Honestly', 426: 'Honey', 427: 'Hope', 428: 'Hopefully', 429: 'Horns', 430: 'House', 431: 'Houston', 432: 'How', 433: 'Hugs', 434: 'Huh', 435: 'Hun', 436: 'Hungover', 437: 'Hut', 438: 'HvV', 439: 'Hypocrisy', 440: 'I', 441: 'IIRC', 442: 'IMAX', 443: 'INTO', 444: 'IQ', 445: 'IRL', 446: 'IS', 447: 'ISO', 448: 'ISOING', 449: 'IT', 450: 'ITS', 451: 'Ice', 452: 'Idk', 453: 'If', 454: 'Iike', 455: 'Ikr', 456: 'Ill', 457: 'Im', 458: 'Imagine', 459: 'In', 460: 'Insecurities', 461: 'InshAllah', 462: 'Instagram', 463: 'Institute', 464: 'Interesting', 465: 'Intergul', 466: 'Irish', 467: 'Is', 468: 'Island', 469: 'It', 470: 'Its', 471: 'JOB', 472: 'Jabba', 473: 'January', 474: 'Japanese', 475: 'Jedi', 476: 'Jogfrey', 477: 'Judiasm', 478: 'Just', 479: 'Juul', 480: 'K', 481: 'KILL', 482: 'KING', 483: 'KNOWS', 484: 'KOTOR', 485: 'KUwtK', 486: 'Keep', 487: 'Kemba', 488: 'Ken', 489: 'Kids', 490: 'Killers', 491: 'Kinda', 492: 'Klokslag', 493: 'Korean', 494: 'L', 495: 'LAMZY', 496: 'LAY', 497: 'LIBTARD', 498: 'LIGHT', 499: 'LMAO', 500: 'LMFAO', 501: 'LOL', 502: 'LOUD', 503: 'LOVE', 504: 'LaPorte', 505: 'Labour', 506: 'Lady', 507: 'Lancaster', 508: 'Land', 509: 'Large', 510: 'Last', 511: 'Lauder', 512: 'Laugh', 513: 'Layg', 514: 'Legs', 515: 'Let', 516: 'Lets', 517: 'Licence', 518: 'Life', 519: 'Light', 520: 'Like', 521: 'Lin', 522: 'Lined', 523: 'Literally', 524: 'Living', 525: 'Lma', 526: 'Lmao', 527: 'Lmaoooo', 528: 'Lmfao', 529: 'Lol', 530: 'London', 531: 'Long', 532: 'Look', 533: 'Looking', 534: 'Looks', 535: 'Lord', 536: 'Lost', 537: 'Lots', 538: 'Love', 539: 'Luck', 540: 'Lucky', 541: 'Luv', 542: 'MA', 543: 'MAKE', 544: 'MAN', 545: 'MC', 546: 'ME', 547: 'MEDICAL', 548: 'MEEEEEEEEE', 549: 'MIL', 550: 'MLs', 551: 'MY', 552: 'Ma', 553: 'Mah', 554: 'Main', 555: 'Make', 556: 'Makes', 557: 'Man', 558: 'Manchester', 559: 'Mark', 560: 'Mate', 561: 'May', 562: 'Maybe', 563: 'McAllen', 564: 'McDonald', 565: 'McDonalds', 566: 'Me', 567: 'Mean', 568: 'Meant', 569: 'Medley', 570: 'Michelin', 571: 'Michigan', 572: 'Midwest', 573: 'Mifflin', 574: 'Might', 575: 'Mikans', 576: 'Millport', 577: 'Millsbury', 578: 'Mine', 579: 'Minnesota', 580: 'Miskatonic', 581: 'Miss', 582: 'Missing', 583: 'Mmm', 584: 'Mmmmmm', 585: 'Mom', 586: 'Monday', 587: 'Monster', 588: 'Monte', 589: 'More', 590: 'Most', 591: 'Mostly', 592: 'Mountain', 593: 'Mr', 594: 'Mrs', 595: 'Ms', 596: 'Much', 597: 'Music', 598: 'Must', 599: 'My', 600: 'NAP', 601: 'NEED', 602: 'NERVE', 603: 'NEVER', 604: 'NJ', 605: 'NO', 606: 'NOT', 607: 'NOTHING', 608: 'NT', 609: 'Nah', 610: 'Nature', 611: 'Needs', 612: 'Nemo', 613: 'Netflix', 614: 'Never', 615: 'New', 616: 'NewTubers', 617: 'News', 618: 'Next', 619: 'Nice', 620: 'No', 621: 'Nobody', 622: 'Noooo', 623: 'Nooooo', 624: 'Nope', 625: 'Not', 626: 'Nothing', 627: 'November', 628: 'Now', 629: 'O', 630: 'OG', 631: 'OH', 632: 'OK', 633: 'OLD', 634: 'OMG', 635: 'ON', 636: 'ONLY', 637: 'OP', 638: 'OPEN', 639: 'OR', 640: 'OTHER', 641: 'OUT', 642: 'OWL', 643: 'Obviously', 644: 'Of', 645: 'Ofc', 646: 'Offense', 647: 'Oh', 648: 'Ohhh', 649: 'Oilers', 650: 'Ok', 651: 'Okay', 652: 'Olympics', 653: 'OmG', 654: 'Omg', 655: 'On', 656: 'One', 657: 'Only', 658: 'Ontario', 659: 'Ooh', 660: 'Oohhooo', 661: 'Oooff', 662: 'Ooohhh', 663: 'Ooooh', 664: 'Ooooooo', 665: 'Oops', 666: 'Or', 667: 'Other', 668: 'Ouch', 669: 'Out', 670: 'Outlaws', 671: 'Outrageous', 672: 'Overpriced', 673: 'Oww', 674: 'Oy', 675: 'PARENTS', 676: 'PASS', 677: 'PAT', 678: 'PAY', 679: 'PERFECT', 680: 'PK', 681: 'PLACE', 682: 'PM', 683: 'POLICE', 684: 'PR', 685: 'PUNISHER', 686: 'PUNISHING', 687: 'Packers', 688: 'Panic', 689: 'Pansexual', 690: 'Parents', 691: 'Parliament', 692: 'Party', 693: 'Pats', 694: 'Pay', 695: 'Pentagon', 696: 'People', 697: 'Per', 698: 'Perhaps', 699: 'Personally', 700: 'Peru', 701: 'PhD', 702: 'Photoshop', 703: 'Pig', 704: 'Pine', 705: 'PlAyOfFs', 706: 'Plagueis', 707: 'Planning', 708: 'Please', 709: 'Plot', 710: 'Plus', 711: 'Plz', 712: 'Poeling', 713: 'Polarizing', 714: 'Police', 715: 'Polygamy', 716: 'Poopels', 717: 'Poor', 718: 'Poverty', 719: 'Ppl', 720: 'Praise', 721: 'Praying', 722: 'Prestigious', 723: 'Pretend', 724: 'Pretty', 725: 'Probably', 726: 'Problem', 727: 'Prospect', 728: 'Puerto', 729: 'Pulling', 730: 'QB', 731: 'QUARANTINE', 732: 'Questions', 733: 'R', 734: 'RADIANCE', 735: 'RAGE', 736: 'RCIA', 737: 'REALLY', 738: 'RIGHT', 739: 'RIP', 740: 'RISE', 741: 'RL', 742: 'Ranch', 743: 'Rare', 744: 'Reacted', 745: 'Read', 746: 'Reality', 747: 'Really', 748: 'Rebloodicans', 749: 'Recipe', 750: 'Recover', 751: 'Recovery', 752: 'Reddit', 753: 'Refrigerators', 754: 'Remain', 755: 'Remainer', 756: 'Repost', 757: 'Republican', 758: 'Resistance', 759: 'Respect', 760: 'Rest', 761: 'Rican', 762: 'Ridiculously', 763: 'Right', 764: 'Ripping', 765: 'Rocket', 766: 'Rowan', 767: 'Rumor', 768: 'Rupple', 769: 'S', 770: 'SAME', 771: 'SB', 772: 'SC', 773: 'SCUM', 774: 'SEEMS', 775: 'SHARK', 776: 'SHE', 777: 'SHOOT', 778: 'SHOULD', 779: 'SILVER', 780: 'SMILING', 781: 'SNP', 782: 'SO', 783: 'SOLIDARITY', 784: 'STILL', 785: 'SUBREDDITDRAMA', 786: 'SUPPORTIVE', 787: 'Sack', 788: 'Sad', 789: 'Sadly', 790: 'Same', 791: 'Samsung', 792: 'Santa', 793: 'Savior', 794: 'Say', 795: 'Saying', 796: 'Says', 797: 'Scrambled', 798: 'Scripted', 799: 'Season', 800: 'See', 801: 'Seeing', 802: 'Seems', 803: 'Seinfeld', 804: 'Sending', 805: 'Seoul', 806: 'Seriously', 807: 'Set', 808: 'Shades', 809: 'Shame', 810: 'Sharpton', 811: 'She', 812: 'Shit', 813: 'Shock', 814: 'Shooooulderrrrr', 815: 'Shot', 816: 'Should', 817: 'Shouldn', 818: 'Show', 819: 'Sigh', 820: 'Sigma', 821: 'Simultaneously', 822: 'Since', 823: 'Singapore', 824: 'Sippinthatminttea', 825: 'Skynet', 826: 'Slowing', 827: 'Smh', 828: 'Smurfs', 829: 'So', 830: 'Some', 831: 'Someone', 832: 'Sometimes', 833: 'Son', 834: 'Sony', 835: 'Soon', 836: 'Sooo', 837: 'Sorry', 838: 'Sounds', 839: 'Source', 840: 'South', 841: 'Southern', 842: 'Spanish', 843: 'Special', 844: 'Spend', 845: 'Spending', 846: 'Spent', 847: 'Spotify', 848: 'Star', 849: 'Stay', 850: 'Steelers', 851: 'Still', 852: 'StirS', 853: 'Stole', 854: 'Stop', 855: 'Stuff', 856: 'Stupidly', 857: 'Success', 858: 'Such', 859: 'Sucks', 860: 'Suiderstrand', 861: 'Super', 862: 'Sure', 863: 'Surprising', 864: 'Switch', 865: 'T', 866: 'TEAM', 867: 'TED', 868: 'TEXT', 869: 'THAT', 870: 'THE', 871: 'THEN', 872: 'THERE', 873: 'THIS', 874: 'TIHI', 875: 'TIME', 876: 'TIMES', 877: 'TL', 878: 'TLJ', 879: 'TNG', 880: 'TO', 881: 'TOO', 882: 'TSN', 883: 'TTT', 884: 'TURTLES', 885: 'TV', 886: 'TY', 887: 'Taco', 888: 'Tail', 889: 'Take', 890: 'Talked', 891: 'Tamaki', 892: 'Tbh', 893: 'Team', 894: 'Technically', 895: 'Tekken', 896: 'Thank', 897: 'Thanks', 898: 'That', 899: 'Thats', 900: 'The', 901: 'TheQTVain', 902: 'Their', 903: 'Then', 904: 'There', 905: 'These', 906: 'They', 907: 'Think', 908: 'This', 909: 'Those', 910: 'ThotAudit', 911: 'Three', 912: 'Thrive', 913: 'Thx', 914: 'Ties', 915: 'Tiger', 916: 'Times', 917: 'Tire', 918: 'Tis', 919: 'To', 920: 'Today', 921: 'Tomlin', 922: 'Top', 923: 'Toronto', 924: 'Totally', 925: 'Tournament', 926: 'Trilogy', 927: 'Troll', 928: 'Troo', 929: 'Trouser', 930: 'True', 931: 'Truth', 932: 'Try', 933: 'Tuesdays', 934: 'Tv', 935: 'Twas', 936: 'Twilight', 937: 'Twin', 938: 'Twitter', 939: 'U', 940: 'UK', 941: 'UP', 942: 'US', 943: 'USA', 944: 'USC', 945: 'Ugh', 946: 'Uh', 947: 'Umm', 948: 'Uncle', 949: 'Under', 950: 'Underrated', 951: 'Understandable', 952: 'Underwater', 953: 'Unfortunately', 954: 'UnicORn', 955: 'United', 956: 'Universities', 957: 'Unleash', 958: 'Unless', 959: 'Until', 960: 'Up', 961: 'Updooted', 962: 'Use', 963: 'Useless', 964: 'Utah', 965: 'VOLCEL', 966: 'Vampire', 967: 'Venti', 968: 'Very', 969: 'View', 970: 'WALL', 971: 'WAS', 972: 'WE', 973: 'WHAT', 974: 'WHERE', 975: 'WHO', 976: 'WHY', 977: 'WITH', 978: 'WOW', 979: 'WTFuckery', 980: 'Wait', 981: 'Walk', 982: 'WallStreetBets', 983: 'Wankers', 984: 'Want', 985: 'Wars', 986: 'Was', 987: 'Wash', 988: 'Wat', 989: 'Way', 990: 'We', 991: 'Weather', 992: 'Wednesday', 993: 'Weird', 994: 'Welcome', 995: 'Well', 996: 'What', 997: 'Whatever', 998: 'Whats', 999: 'When', 1000: 'Whenever', 1001: 'Where', 1002: 'Which', 1003: 'Whisper', 1004: 'White', 1005: 'Who', 1006: 'Wholesome', 1007: 'Whoops', 1008: 'Why', 1009: 'Wild', 1010: 'Will', 1011: 'Windbreakers', 1012: 'Windows', 1013: 'Wish', 1014: 'With', 1015: 'Wizards', 1016: 'Wolf', 1017: 'Woman', 1018: 'Won', 1019: 'Wonder', 1020: 'Working', 1021: 'Would', 1022: 'Wouldn', 1023: 'Wow', 1024: 'Wtf', 1025: 'Wu', 1026: 'XIV', 1027: 'XL', 1028: 'YA', 1029: 'YELLOW', 1030: 'YES', 1031: 'YOU', 1032: 'Ya', 1033: 'Yea', 1034: 'Yeah', 1035: 'Yeahhhh', 1036: 'Year', 1037: 'Years', 1038: 'Yellowstone', 1039: 'Yep', 1040: 'Yes', 1041: 'Yet', 1042: 'Yikes', 1043: 'Yo', 1044: 'You', 1045: 'Your', 1046: 'Yum', 1047: 'Yup', 1048: 'Zion', 1049: 'a', 1050: 'abandoned', 1051: 'abby', 1052: 'able', 1053: 'about', 1054: 'above', 1055: 'absolute', 1056: 'absolutely', 1057: 'abstract', 1058: 'abt', 1059: 'abused', 1060: 'abuses', 1061: 'abusive', 1062: 'ac', 1063: 'accent', 1064: 'accept', 1065: 'accepted', 1066: 'access', 1067: 'accident', 1068: 'accidentally', 1069: 'according', 1070: 'account', 1071: 'accurate', 1072: 'accurately', 1073: 'achievements', 1074: 'acknowledge', 1075: 'across', 1076: 'acting', 1077: 'action', 1078: 'active', 1079: 'actress', 1080: 'acts', 1081: 'actual', 1082: 'actually', 1083: 'ad', 1084: 'add', 1085: 'added', 1086: 'addiction', 1087: 'additional', 1088: 'additions', 1089: 'address', 1090: 'adjustments', 1091: 'admin', 1092: 'admit', 1093: 'adorable', 1094: 'adore', 1095: 'advantage', 1096: 'advertised', 1097: 'advertising', 1098: 'advice', 1099: 'advocate', 1100: 'af', 1101: 'afford', 1102: 'afraid', 1103: 'after', 1104: 'again', 1105: 'against', 1106: 'age', 1107: 'agencies', 1108: 'aggressive', 1109: 'ago', 1110: 'agree', 1111: 'agreed', 1112: 'ahead', 1113: 'ahhh', 1114: 'ahrar', 1115: 'aht', 1116: 'ain', 1117: 'air', 1118: 'aired', 1119: 'akhi', 1120: 'al', 1121: 'alaykum', 1122: 'album', 1123: 'albums', 1124: 'alcohol', 1125: 'alerted', 1126: 'alive', 1127: 'all', 1128: 'allowed', 1129: 'allstar', 1130: 'almond', 1131: 'almost', 1132: 'alone', 1133: 'along', 1134: 'alp', 1135: 'alphabet', 1136: 'already', 1137: 'alright', 1138: 'also', 1139: 'alt', 1140: 'alternative', 1141: 'although', 1142: 'always', 1143: 'am', 1144: 'amazed', 1145: 'amazing', 1146: 'ambulance', 1147: 'amigo', 1148: 'among', 1149: 'amount', 1150: 'an', 1151: 'anabolic', 1152: 'analogies', 1153: 'analogy', 1154: 'analysis', 1155: 'and', 1156: 'angels', 1157: 'angry', 1158: 'animal', 1159: 'animals', 1160: 'anniversary', 1161: 'announced', 1162: 'announcing', 1163: 'annoyed', 1164: 'annoying', 1165: 'another', 1166: 'ant', 1167: 'anti', 1168: 'antivaxxers', 1169: 'antsy', 1170: 'anxiety', 1171: 'anxious', 1172: 'anxiously', 1173: 'any', 1174: 'anybody', 1175: 'anymore', 1176: 'anyone', 1177: 'anything', 1178: 'anyway', 1179: 'apart', 1180: 'aperol', 1181: 'apologies', 1182: 'apologize', 1183: 'app', 1184: 'apparently', 1185: 'appearance', 1186: 'applaud', 1187: 'apple', 1188: 'applies', 1189: 'appreciate', 1190: 'appreciated', 1191: 'approaching', 1192: 'appropriate', 1193: 'appropriately', 1194: 'appropriations', 1195: 'approval', 1196: 'approve', 1197: 'approximately', 1198: 'architect', 1199: 'are', 1200: 'area', 1201: 'areas', 1202: 'aren', 1203: 'arent', 1204: 'arguing', 1205: 'argument', 1206: 'arms', 1207: 'around', 1208: 'arrest', 1209: 'arrested', 1210: 'arrive', 1211: 'arse', 1212: 'arsehole', 1213: 'art', 1214: 'article', 1215: 'artistic', 1216: 'as', 1217: 'asf', 1218: 'ashamed', 1219: 'aside', 1220: 'asinine', 1221: 'ask', 1222: 'asked', 1223: 'asking', 1224: 'asleep', 1225: 'asm', 1226: 'aspergers', 1227: 'ass', 1228: 'assalamu', 1229: 'asshole', 1230: 'assholes', 1231: 'asst', 1232: 'assume', 1233: 'assuming', 1234: 'assumption', 1235: 'assured', 1236: 'at', 1237: 'ate', 1238: 'atheist', 1239: 'atmosphere', 1240: 'attacks', 1241: 'attention', 1242: 'attorney', 1243: 'attractive', 1244: 'audience', 1245: 'audio', 1246: 'auld', 1247: 'aunt', 1248: 'author', 1249: 'authorities', 1250: 'autism', 1251: 'autistic', 1252: 'autocorrect', 1253: 'autograt', 1254: 'automatically', 1255: 'autonomy', 1256: 'available', 1257: 'avatar', 1258: 'avatars', 1259: 'average', 1260: 'avoid', 1261: 'avoided', 1262: 'aw', 1263: 'awake', 1264: 'awareness', 1265: 'away', 1266: 'awe', 1267: 'awesome', 1268: 'awful', 1269: 'awkward', 1270: 'awoke', 1271: 'b', 1272: 'babcuck', 1273: 'baby', 1274: 'back', 1275: 'background', 1276: 'backstabbing', 1277: 'bad', 1278: 'badass', 1279: 'badboy', 1280: 'baffles', 1281: 'bag', 1282: 'bahaha', 1283: 'baking', 1284: 'balance', 1285: 'bald', 1286: 'ball', 1287: 'band', 1288: 'bango', 1289: 'bank', 1290: 'banked', 1291: 'banned', 1292: 'bar', 1293: 'bare', 1294: 'barely', 1295: 'barreling', 1296: 'bars', 1297: 'bartenders', 1298: 'base', 1299: 'based', 1300: 'bashing', 1301: 'basic', 1302: 'basically', 1303: 'basing', 1304: 'basket', 1305: 'bastard', 1306: 'bathroom', 1307: 'battery', 1308: 'battlefront', 1309: 'bby', 1310: 'bc', 1311: 'be', 1312: 'beach', 1313: 'beard', 1314: 'beat', 1315: 'beautiful', 1316: 'beauty', 1317: 'became', 1318: 'because', 1319: 'become', 1320: 'becomes', 1321: 'bed', 1322: 'bedroom', 1323: 'been', 1324: 'beer', 1325: 'before', 1326: 'behind', 1327: 'being', 1328: 'beings', 1329: 'belief', 1330: 'believable', 1331: 'believe', 1332: 'below', 1333: 'bench', 1334: 'best', 1335: 'bet', 1336: 'betray', 1337: 'betrayed', 1338: 'better', 1339: 'betting', 1340: 'between', 1341: 'bew', 1342: 'beyond', 1343: 'bible', 1344: 'bid', 1345: 'big', 1346: 'biggest', 1347: 'bill', 1348: 'billions', 1349: 'binged', 1350: 'bio', 1351: 'birthday', 1352: 'bisexual', 1353: 'bison', 1354: 'bit', 1355: 'bitch', 1356: 'bitcoin', 1357: 'bitcoins', 1358: 'bite', 1359: 'bitter', 1360: 'bizarre', 1361: 'black', 1362: 'bladder', 1363: 'blame', 1364: 'blamed', 1365: 'bland', 1366: 'blasphemous', 1367: 'blast', 1368: 'bleeding', 1369: 'blessing', 1370: 'blindfolds', 1371: 'blindness', 1372: 'block', 1373: 'blocked', 1374: 'blocks', 1375: 'bloke', 1376: 'blonde', 1377: 'blood', 1378: 'blooded', 1379: 'bloody', 1380: 'blows', 1381: 'blue', 1382: 'blunt', 1383: 'blurred', 1384: 'board', 1385: 'boards', 1386: 'boat', 1387: 'bodily', 1388: 'body', 1389: 'boggling', 1390: 'boiled', 1391: 'bollocks', 1392: 'bolt', 1393: 'bomb', 1394: 'bombs', 1395: 'bonkers', 1396: 'bonus', 1397: 'book', 1398: 'books', 1399: 'booming', 1400: 'boots', 1401: 'booze', 1402: 'bore', 1403: 'bored', 1404: 'boring', 1405: 'bot', 1406: 'both', 1407: 'bother', 1408: 'bothers', 1409: 'bottle', 1410: 'bottom', 1411: 'bought', 1412: 'bout', 1413: 'bowler', 1414: 'box', 1415: 'boxing', 1416: 'boy', 1417: 'boycotting', 1418: 'boyfriend', 1419: 'boys', 1420: 'brah', 1421: 'brain', 1422: 'brainless', 1423: 'brainwash', 1424: 'branch', 1425: 'brave', 1426: 'break', 1427: 'breaking', 1428: 'breaks', 1429: 'breath', 1430: 'breed', 1431: 'bridesmaids', 1432: 'bridges', 1433: 'brig', 1434: 'brilliant', 1435: 'brimming', 1436: 'bring', 1437: 'bringing', 1438: 'bro', 1439: 'broadcaster', 1440: 'broke', 1441: 'broken', 1442: 'brother', 1443: 'brought', 1444: 'brownie', 1445: 'brows', 1446: 'brush', 1447: 'brushing', 1448: 'btw', 1449: 'buckaroo', 1450: 'buddy', 1451: 'bug', 1452: 'build', 1453: 'building', 1454: 'built', 1455: 'bull', 1456: 'bullied', 1457: 'bump', 1458: 'bunch', 1459: 'bunk', 1460: 'bunnies', 1461: 'burden', 1462: 'burdening', 1463: 'burn', 1464: 'burned', 1465: 'burner', 1466: 'burns', 1467: 'burnt', 1468: 'bus', 1469: 'business', 1470: 'busy', 1471: 'but', 1472: 'butchers', 1473: 'buttcoin', 1474: 'butter', 1475: 'button', 1476: 'butts', 1477: 'buy', 1478: 'buying', 1479: 'buzzkill', 1480: 'by', 1481: 'bye', 1482: 'byfar', 1483: 'cable', 1484: 'cake', 1485: 'cakeday', 1486: 'call', 1487: 'called', 1488: 'calling', 1489: 'calorie', 1490: 'came', 1491: 'camera', 1492: 'cameraman', 1493: 'campaign', 1494: 'can', 1495: 'candidates', 1496: 'candles', 1497: 'canister', 1498: 'cannon', 1499: 'cannot', 1500: 'cant', 1501: 'cape', 1502: 'car', 1503: 'carbs', 1504: 'care', 1505: 'career', 1506: 'careful', 1507: 'carried', 1508: 'cartoon', 1509: 'case', 1510: 'cash', 1511: 'casino', 1512: 'cast', 1513: 'cat', 1514: 'catch', 1515: 'catching', 1516: 'caters', 1517: 'catgirl', 1518: 'cats', 1519: 'catsup', 1520: 'cattle', 1521: 'caught', 1522: 'cause', 1523: 'causes', 1524: 'cave', 1525: 'celebrity', 1526: 'center', 1527: 'centrists', 1528: 'cents', 1529: 'certain', 1530: 'cesspool', 1531: 'cha', 1532: 'challenge', 1533: 'champion', 1534: 'chance', 1535: 'chances', 1536: 'change', 1537: 'changed', 1538: 'chanting', 1539: 'character', 1540: 'characters', 1541: 'charas', 1542: 'charge', 1543: 'charger', 1544: 'charges', 1545: 'charitable', 1546: 'charming', 1547: 'charts', 1548: 'chased', 1549: 'chat', 1550: 'chatbox', 1551: 'chatty', 1552: 'cheap', 1553: 'cheat', 1554: 'check', 1555: 'checking', 1556: 'cheeky', 1557: 'cheer', 1558: 'cheered', 1559: 'cheerleader', 1560: 'cheese', 1561: 'cheesecake', 1562: 'cheesy', 1563: 'chef', 1564: 'chest', 1565: 'chevre', 1566: 'chick', 1567: 'chicken', 1568: 'chicks', 1569: 'chiefs', 1570: 'child', 1571: 'children', 1572: 'chills', 1573: 'china', 1574: 'chinook', 1575: 'chips', 1576: 'choice', 1577: 'choke', 1578: 'choose', 1579: 'chorizo', 1580: 'chosen', 1581: 'chuckle', 1582: 'chucklefuck', 1583: 'church', 1584: 'ciao', 1585: 'circa', 1586: 'circle', 1587: 'citizen', 1588: 'city', 1589: 'ck', 1590: 'claim', 1591: 'claiming', 1592: 'clap', 1593: 'clapped', 1594: 'claps', 1595: 'clarifying', 1596: 'class', 1597: 'classes', 1598: 'clean', 1599: 'clear', 1600: 'clearly', 1601: 'clever', 1602: 'clicked', 1603: 'clinically', 1604: 'clone', 1605: 'close', 1606: 'closest', 1607: 'cloudy', 1608: 'clown', 1609: 'club', 1610: 'cmmon', 1611: 'cnn', 1612: 'co', 1613: 'coaching', 1614: 'coastal', 1615: 'coerces', 1616: 'coffee', 1617: 'coincidence', 1618: 'coke', 1619: 'cold', 1620: 'collabed', 1621: 'collars', 1622: 'collected', 1623: 'college', 1624: 'colliding', 1625: 'collors', 1626: 'color', 1627: 'colors', 1628: 'colour', 1629: 'come', 1630: 'comeback', 1631: 'comes', 1632: 'coming', 1633: 'command', 1634: 'comment', 1635: 'comments', 1636: 'commies', 1637: 'committing', 1638: 'common', 1639: 'communists', 1640: 'community', 1641: 'commute', 1642: 'comp', 1643: 'company', 1644: 'compares', 1645: 'compassionate', 1646: 'compete', 1647: 'competitive', 1648: 'complain', 1649: 'complete', 1650: 'completely', 1651: 'comrade', 1652: 'concede', 1653: 'concept', 1654: 'concern', 1655: 'concerned', 1656: 'concerning', 1657: 'concur', 1658: 'condition', 1659: 'conditions', 1660: 'condolences', 1661: 'confidence', 1662: 'confirm', 1663: 'confirmed', 1664: 'confirming', 1665: 'conflating', 1666: 'conforming', 1667: 'confusing', 1668: 'congrats', 1669: 'congratulation', 1670: 'connoisseur', 1671: 'consent', 1672: 'consequences', 1673: 'conservative', 1674: 'consider', 1675: 'considered', 1676: 'considering', 1677: 'consists', 1678: 'console', 1679: 'conspiracies', 1680: 'conspiracy', 1681: 'constantly', 1682: 'constellations', 1683: 'constituencies', 1684: 'constructive', 1685: 'contact', 1686: 'contacts', 1687: 'contempt', 1688: 'contender', 1689: 'context', 1690: 'continuous', 1691: 'contract', 1692: 'contractors', 1693: 'control', 1694: 'controlled', 1695: 'controller', 1696: 'conversation', 1697: 'convinced', 1698: 'convincing', 1699: 'convo', 1700: 'cook', 1701: 'cooked', 1702: 'cooking', 1703: 'cooks', 1704: 'cool', 1705: 'cop', 1706: 'cops', 1707: 'copy', 1708: 'corgis', 1709: 'corporations', 1710: 'correct', 1711: 'corrected', 1712: 'correcting', 1713: 'correlation', 1714: 'cosmos', 1715: 'costs', 1716: 'could', 1717: 'couldn', 1718: 'couldnt', 1719: 'count', 1720: 'countries', 1721: 'country', 1722: 'couple', 1723: 'couples', 1724: 'course', 1725: 'court', 1726: 'cow', 1727: 'coward', 1728: 'coworkers', 1729: 'crack', 1730: 'cracked', 1731: 'cradle', 1732: 'crafty', 1733: 'crash', 1734: 'crashing', 1735: 'crave', 1736: 'craving', 1737: 'crazy', 1738: 'cream', 1739: 'create', 1740: 'created', 1741: 'creates', 1742: 'creative', 1743: 'creativity', 1744: 'creature', 1745: 'creatures', 1746: 'creepy', 1747: 'creme', 1748: 'crime', 1749: 'cringe', 1750: 'cringes', 1751: 'criticised', 1752: 'cronies', 1753: 'crooks', 1754: 'cross', 1755: 'crossover', 1756: 'crossposts', 1757: 'crown', 1758: 'crucified', 1759: 'cry', 1760: 'crying', 1761: 'cucked', 1762: 'cuddle', 1763: 'cultural', 1764: 'cup', 1765: 'curated', 1766: 'curb', 1767: 'cured', 1768: 'curiosity', 1769: 'curious', 1770: 'cus', 1771: 'custard', 1772: 'customer', 1773: 'cut', 1774: 'cute', 1775: 'cutie', 1776: 'cuz', 1777: 'cynical', 1778: 'd', 1779: 'dad', 1780: 'daily', 1781: 'damage', 1782: 'damn', 1783: 'damned', 1784: 'damp', 1785: 'dan', 1786: 'dancers', 1787: 'dances', 1788: 'dancing', 1789: 'dangerous', 1790: 'dare', 1791: 'dark', 1792: 'darkness', 1793: 'dashers', 1794: 'data', 1795: 'date', 1796: 'dating', 1797: 'daughter', 1798: 'day', 1799: 'days', 1800: 'dayz', 1801: 'daze', 1802: 'dead', 1803: 'deadpan', 1804: 'deagle', 1805: 'deal', 1806: 'dealing', 1807: 'dear', 1808: 'death', 1809: 'debacle', 1810: 'debate', 1811: 'debating', 1812: 'debt', 1813: 'debunked', 1814: 'decent', 1815: 'decide', 1816: 'decides', 1817: 'deciding', 1818: 'decision', 1819: 'decisions', 1820: 'deck', 1821: 'declaration', 1822: 'declare', 1823: 'declined', 1824: 'declutter', 1825: 'deep', 1826: 'deeply', 1827: 'deer', 1828: 'def', 1829: 'defect', 1830: 'defective', 1831: 'defence', 1832: 'defended', 1833: 'defending', 1834: 'defense', 1835: 'defensive', 1836: 'definitely', 1837: 'definition', 1838: 'definitive', 1839: 'deflator', 1840: 'deja', 1841: 'delete', 1842: 'deleting', 1843: 'deliberately', 1844: 'deliriously', 1845: 'delirium', 1846: 'delivered', 1847: 'delusion', 1848: 'delusional', 1849: 'demanding', 1850: 'denial', 1851: 'denotation', 1852: 'dense', 1853: 'deny', 1854: 'depends', 1855: 'depressed', 1856: 'depressing', 1857: 'depth', 1858: 'deride', 1859: 'described', 1860: 'desert', 1861: 'deserve', 1862: 'deserved', 1863: 'deserves', 1864: 'designers', 1865: 'desire', 1866: 'desk', 1867: 'desperately', 1868: 'desperation', 1869: 'despite', 1870: 'destination', 1871: 'destroy', 1872: 'destroyed', 1873: 'destruction', 1874: 'detail', 1875: 'determination', 1876: 'determined', 1877: 'devastating', 1878: 'develop', 1879: 'development', 1880: 'devil', 1881: 'devoid', 1882: 'dialogue', 1883: 'dictate', 1884: 'did', 1885: 'didn', 1886: 'didnt', 1887: 'die', 1888: 'died', 1889: 'difference', 1890: 'differences', 1891: 'different', 1892: 'difficult', 1893: 'digestive', 1894: 'diggah', 1895: 'digital', 1896: 'dignified', 1897: 'dinosaur', 1898: 'direct', 1899: 'directly', 1900: 'director', 1901: 'disagrees', 1902: 'disappointed', 1903: 'disappointing', 1904: 'disappoints', 1905: 'disc', 1906: 'disco', 1907: 'discovered', 1908: 'discovering', 1909: 'discrepancy', 1910: 'discriminated', 1911: 'discussing', 1912: 'discussions', 1913: 'diseases', 1914: 'disgrace', 1915: 'disgusted', 1916: 'disgusting', 1917: 'dishes', 1918: 'dislike', 1919: 'disorder', 1920: 'dispenser', 1921: 'disrespect', 1922: 'disrespected', 1923: 'distress', 1924: 'distributed', 1925: 'disturbing', 1926: 'diverse', 1927: 'diversity', 1928: 'divorced', 1929: 'dizzy', 1930: 'do', 1931: 'doctor', 1932: 'doctored', 1933: 'documentary', 1934: 'docuseries', 1935: 'does', 1936: 'doesn', 1937: 'dog', 1938: 'doggie', 1939: 'doggos', 1940: 'dogs', 1941: 'doing', 1942: 'dominatrix', 1943: 'don', 1944: 'done', 1945: 'dont', 1946: 'door', 1947: 'doorbell', 1948: 'double', 1949: 'doubt', 1950: 'doubts', 1951: 'down', 1952: 'downvote', 1953: 'downvoted', 1954: 'downvotes', 1955: 'dr', 1956: 'draft', 1957: 'drama', 1958: 'draws', 1959: 'dream', 1960: 'dreams', 1961: 'dressed', 1962: 'drink', 1963: 'drive', 1964: 'driver', 1965: 'drives', 1966: 'drop', 1967: 'dropped', 1968: 'drugs', 1969: 'drunk', 1970: 'dude', 1971: 'dudes', 1972: 'due', 1973: 'dui', 1974: 'dumb', 1975: 'dumbass', 1976: 'dumbest', 1977: 'dumped', 1978: 'dumpster', 1979: 'dunno', 1980: 'duped', 1981: 'during', 1982: 'dying', 1983: 'dysmorphia', 1984: 'e', 1985: 'eNoUgH', 1986: 'each', 1987: 'earlier', 1988: 'early', 1989: 'ears', 1990: 'easier', 1991: 'easily', 1992: 'easy', 1993: 'eat', 1994: 'eaters', 1995: 'eating', 1996: 'eban', 1997: 'economics', 1998: 'edge', 1999: 'educated', 2000: 'education', 2001: 'eels', 2002: 'effect', 2003: 'effort', 2004: 'efforts', 2005: 'eggs', 2006: 'eh', 2007: 'either', 2008: 'elated', 2009: 'elbows', 2010: 'elected', 2011: 'elevator', 2012: 'elitists', 2013: 'else', 2014: 'em', 2015: 'email', 2016: 'embarrassed', 2017: 'embarrassing', 2018: 'embarrassment', 2019: 'embrace', 2020: 'embracing', 2021: 'emergency', 2022: 'emoji', 2023: 'emotional', 2024: 'emotionally', 2025: 'emotions', 2026: 'empathy', 2027: 'employee', 2028: 'employment', 2029: 'empty', 2030: 'enamoured', 2031: 'encountered', 2032: 'encourage', 2033: 'encouragement', 2034: 'end', 2035: 'ended', 2036: 'endies', 2037: 'ending', 2038: 'endings', 2039: 'ends', 2040: 'energy', 2041: 'engaged', 2042: 'engineering', 2043: 'english', 2044: 'enjoy', 2045: 'enjoyable', 2046: 'enjoyed', 2047: 'enjoying', 2048: 'enlighten', 2049: 'enlightening', 2050: 'enough', 2051: 'enquiring', 2052: 'entered', 2053: 'entertaining', 2054: 'enthusiasm', 2055: 'entire', 2056: 'entitled', 2057: 'epic', 2058: 'episode', 2059: 'episodes', 2060: 'episoode', 2061: 'equally', 2062: 'erased', 2063: 'especially', 2064: 'essentially', 2065: 'etc', 2066: 'ethics', 2067: 'ethos', 2068: 'eugh', 2069: 'eve', 2070: 'even', 2071: 'evening', 2072: 'eventually', 2073: 'ever', 2074: 'every', 2075: 'everybody', 2076: 'everyday', 2077: 'everyone', 2078: 'everything', 2079: 'everythingggggg', 2080: 'everywhere', 2081: 'evidence', 2082: 'ex', 2083: 'exact', 2084: 'exactly', 2085: 'exaggeration', 2086: 'exam', 2087: 'example', 2088: 'examples', 2089: 'exceedingly', 2090: 'excellent', 2091: 'except', 2092: 'exception', 2093: 'exchanging', 2094: 'excited', 2095: 'exciting', 2096: 'excuse', 2097: 'execution', 2098: 'exercise', 2099: 'exhausting', 2100: 'exist', 2101: 'existed', 2102: 'existent', 2103: 'exit', 2104: 'exited', 2105: 'expect', 2106: 'expecting', 2107: 'expeditious', 2108: 'expensive', 2109: 'experience', 2110: 'experts', 2111: 'expired', 2112: 'explain', 2113: 'explained', 2114: 'explaining', 2115: 'explanation', 2116: 'explode', 2117: 'exploiting', 2118: 'explore', 2119: 'explorers', 2120: 'exposing', 2121: 'expressions', 2122: 'extinct', 2123: 'extra', 2124: 'extreme', 2125: 'extremely', 2126: 'eye', 2127: 'eyes', 2128: 'f', 2129: 'face', 2130: 'facemask', 2131: 'faces', 2132: 'facetime', 2133: 'facial', 2134: 'fact', 2135: 'factor', 2136: 'factory', 2137: 'facts', 2138: 'failed', 2139: 'failing', 2140: 'failure', 2141: 'fair', 2142: 'fairly', 2143: 'faith', 2144: 'fake', 2145: 'fall', 2146: 'fallen', 2147: 'falling', 2148: 'false', 2149: 'fam', 2150: 'family', 2151: 'famous', 2152: 'fan', 2153: 'fanfics', 2154: 'fans', 2155: 'far', 2156: 'farm', 2157: 'fart', 2158: 'fascinated', 2159: 'fascists', 2160: 'fast', 2161: 'faster', 2162: 'father', 2163: 'fatness', 2164: 'fault', 2165: 'fave', 2166: 'favorite', 2167: 'favorites', 2168: 'favourite', 2169: 'fear', 2170: 'feature', 2171: 'fed', 2172: 'feedback', 2173: 'feel', 2174: 'feeling', 2175: 'feelings', 2176: 'feels', 2177: 'feet', 2178: 'fell', 2179: 'fella', 2180: 'fellow', 2181: 'felt', 2182: 'fence', 2183: 'ferals', 2184: 'ferk', 2185: 'fest', 2186: 'festival', 2187: 'fetish', 2188: 'fever', 2189: 'few', 2190: 'fibre', 2191: 'fifteen', 2192: 'fight', 2193: 'fighter', 2194: 'fighting', 2195: 'fights', 2196: 'figure', 2197: 'files', 2198: 'film', 2199: 'filter', 2200: 'filters', 2201: 'filth', 2202: 'filthy', 2203: 'final', 2204: 'finally', 2205: 'financial', 2206: 'find', 2207: 'finding', 2208: 'finds', 2209: 'fine', 2210: 'finish', 2211: 'finished', 2212: 'finishing', 2213: 'fire', 2214: 'fired', 2215: 'first', 2216: 'fishing', 2217: 'fit', 2218: 'fix', 2219: 'fixing', 2220: 'fkn', 2221: 'flair', 2222: 'flaming', 2223: 'flash', 2224: 'flashbacks', 2225: 'flat', 2226: 'flavors', 2227: 'flavours', 2228: 'flew', 2229: 'flex', 2230: 'flight', 2231: 'flipping', 2232: 'floor', 2233: 'flop', 2234: 'flower', 2235: 'flowers', 2236: 'flu', 2237: 'fly', 2238: 'focus', 2239: 'focusing', 2240: 'folks', 2241: 'follow', 2242: 'follower', 2243: 'food', 2244: 'fool', 2245: 'foolish', 2246: 'foot', 2247: 'football', 2248: 'for', 2249: 'force', 2250: 'forced', 2251: 'foreigners', 2252: 'forever', 2253: 'forex', 2254: 'forget', 2255: 'forgettable', 2256: 'forgive', 2257: 'forgot', 2258: 'forgotten', 2259: 'form', 2260: 'forms', 2261: 'forth', 2262: 'fortunately', 2263: 'forum', 2264: 'forward', 2265: 'forwards', 2266: 'fotos', 2267: 'foul', 2268: 'found', 2269: 'four', 2270: 'frame', 2271: 'franchise', 2272: 'freakin', 2273: 'freaking', 2274: 'free', 2275: 'freezes', 2276: 'freezing', 2277: 'fresh', 2278: 'friend', 2279: 'friends', 2280: 'from', 2281: 'front', 2282: 'fruit', 2283: 'frustrating', 2284: 'frustrations', 2285: 'fry', 2286: 'fuck', 2287: 'fucking', 2288: 'fueles', 2289: 'full', 2290: 'fun', 2291: 'funky', 2292: 'funniest', 2293: 'funny', 2294: 'furry', 2295: 'future', 2296: 'fyi', 2297: 'gOoD', 2298: 'gain', 2299: 'galaxy', 2300: 'game', 2301: 'gameplay', 2302: 'gamer', 2303: 'games', 2304: 'gang', 2305: 'gangs', 2306: 'gangster', 2307: 'gapping', 2308: 'gatekeeping', 2309: 'gave', 2310: 'gemologist', 2311: 'gender', 2312: 'generalization', 2313: 'generally', 2314: 'generates', 2315: 'generation', 2316: 'generations', 2317: 'genius', 2318: 'genocide', 2319: 'gentle', 2320: 'genuine', 2321: 'genuinely', 2322: 'geometric', 2323: 'germs', 2324: 'gesture', 2325: 'get', 2326: 'gets', 2327: 'getting', 2328: 'gf', 2329: 'ghosted', 2330: 'ghoul', 2331: 'giant', 2332: 'gifs', 2333: 'gig', 2334: 'giggles', 2335: 'gimme', 2336: 'girl', 2337: 'girls', 2338: 'give', 2339: 'given', 2340: 'gives', 2341: 'giving', 2342: 'gl', 2343: 'glad', 2344: 'glam', 2345: 'glass', 2346: 'glasses', 2347: 'glitch', 2348: 'glow', 2349: 'go', 2350: 'goal', 2351: 'goals', 2352: 'god', 2353: 'goddamn', 2354: 'gods', 2355: 'goes', 2356: 'going', 2357: 'gold', 2358: 'golden', 2359: 'golf', 2360: 'gone', 2361: 'gonna', 2362: 'good', 2363: 'goodness', 2364: 'goodnewsforwomen', 2365: 'gooferton', 2366: 'goofy', 2367: 'googling', 2368: 'gorgeous', 2369: 'gorgeousss', 2370: 'gosh', 2371: 'got', 2372: 'gotcha', 2373: 'gotta', 2374: 'gotten', 2375: 'government', 2376: 'grade', 2377: 'grades', 2378: 'grandma', 2379: 'grandparent', 2380: 'granted', 2381: 'grateful', 2382: 'grazed', 2383: 'greasy', 2384: 'great', 2385: 'greedy', 2386: 'greyhounds', 2387: 'gritty', 2388: 'grooming', 2389: 'gross', 2390: 'grossed', 2391: 'grossest', 2392: 'ground', 2393: 'group', 2394: 'growing', 2395: 'grown', 2396: 'grungy', 2397: 'gtfo', 2398: 'guarantee', 2399: 'guess', 2400: 'guest', 2401: 'guilt', 2402: 'gun', 2403: 'guns', 2404: 'gurl', 2405: 'guts', 2406: 'guy', 2407: 'guys', 2408: 'gym', 2409: 'hElP', 2410: 'ha', 2411: 'habit', 2412: 'hacker', 2413: 'had', 2414: 'haha', 2415: 'hahaha', 2416: 'hair', 2417: 'haircut', 2418: 'haired', 2419: 'hairs', 2420: 'half', 2421: 'hall', 2422: 'hand', 2423: 'handed', 2424: 'handheld', 2425: 'handle', 2426: 'handout', 2427: 'hands', 2428: 'handsome', 2429: 'hang', 2430: 'hanging', 2431: 'hangover', 2432: 'happen', 2433: 'happened', 2434: 'happening', 2435: 'happens', 2436: 'happiness', 2437: 'happinesses', 2438: 'happy', 2439: 'harassed', 2440: 'harassing', 2441: 'hard', 2442: 'harder', 2443: 'hardly', 2444: 'hardware', 2445: 'harmful', 2446: 'harness', 2447: 'has', 2448: 'hat', 2449: 'hate', 2450: 'hated', 2451: 'hateful', 2452: 'hates', 2453: 'hav', 2454: 'have', 2455: 'haven', 2456: 'havin', 2457: 'having', 2458: 'hazmat', 2459: 'he', 2460: 'head', 2461: 'headbutt', 2462: 'headed', 2463: 'heads', 2464: 'healing', 2465: 'heals', 2466: 'health', 2467: 'healthcare', 2468: 'hear', 2469: 'heard', 2470: 'hearing', 2471: 'heart', 2472: 'heat', 2473: 'heck', 2474: 'hectic', 2475: 'heed', 2476: 'heels', 2477: 'hehe', 2478: 'hell', 2479: 'help', 2480: 'helped', 2481: 'helpful', 2482: 'helps', 2483: 'her', 2484: 'here', 2485: 'heresy', 2486: 'hero', 2487: 'herself', 2488: 'hershey', 2489: 'hes', 2490: 'hey', 2491: 'hid', 2492: 'hidden', 2493: 'hide', 2494: 'high', 2495: 'highest', 2496: 'highkey', 2497: 'highly', 2498: 'highs', 2499: 'hilarious', 2500: 'him', 2501: 'himself', 2502: 'hip', 2503: 'hippies', 2504: 'hire', 2505: 'his', 2506: 'historical', 2507: 'hit', 2508: 'hitter', 2509: 'hitting', 2510: 'hive', 2511: 'hmm', 2512: 'hmmm', 2513: 'hmmmmm', 2514: 'hmr', 2515: 'hobby', 2516: 'hockey', 2517: 'hold', 2518: 'holdem', 2519: 'holding', 2520: 'hole', 2521: 'holes', 2522: 'holiday', 2523: 'holy', 2524: 'home', 2525: 'homecourt', 2526: 'homeless', 2527: 'homes', 2528: 'hometown', 2529: 'honor', 2530: 'hook', 2531: 'hooked', 2532: 'hooking', 2533: 'hooters', 2534: 'hop', 2535: 'hope', 2536: 'hoped', 2537: 'hopeful', 2538: 'hopefully', 2539: 'hoping', 2540: 'horny', 2541: 'horrible', 2542: 'horror', 2543: 'horse', 2544: 'hospitalised', 2545: 'hot', 2546: 'hotspots', 2547: 'hour', 2548: 'hours', 2549: 'house', 2550: 'how', 2551: 'however', 2552: 'howl', 2553: 'hrs', 2554: 'hubby', 2555: 'hug', 2556: 'huge', 2557: 'hugely', 2558: 'hugs', 2559: 'huh', 2560: 'human', 2561: 'humans', 2562: 'humor', 2563: 'humour', 2564: 'hundreds', 2565: 'hunter', 2566: 'hunting', 2567: 'hurling', 2568: 'hurt', 2569: 'hurts', 2570: 'husband', 2571: 'hustles', 2572: 'hybrid', 2573: 'hydrocortisone', 2574: 'hymn', 2575: 'hype', 2576: 'hyped', 2577: 'hyperbolic', 2578: 'hypocrisy', 2579: 'i', 2580: 'iBiteYou', 2581: 'iN', 2582: 'iPhone', 2583: 'iSn', 2584: 'ice', 2585: 'icecream', 2586: 'ick', 2587: 'id', 2588: 'idea', 2589: 'identifiable', 2590: 'idiot', 2591: 'idk', 2592: 'if', 2593: 'ig', 2594: 'ignorance', 2595: 'ignore', 2596: 'iii', 2597: 'ill', 2598: 'illegal', 2599: 'illustrator', 2600: 'im', 2601: 'image', 2602: 'imagination', 2603: 'imagine', 2604: 'imagining', 2605: 'immediate', 2606: 'imo', 2607: 'impact', 2608: 'imperialism', 2609: 'important', 2610: 'impossible', 2611: 'impregnate', 2612: 'impressed', 2613: 'impressive', 2614: 'improve', 2615: 'in', 2616: 'incel', 2617: 'incels', 2618: 'incentive', 2619: 'incentives', 2620: 'inception', 2621: 'increases', 2622: 'incredibly', 2623: 'indecent', 2624: 'indeed', 2625: 'indestructible', 2626: 'indicate', 2627: 'individual', 2628: 'inertial', 2629: 'inevitably', 2630: 'infected', 2631: 'infiltrated', 2632: 'info', 2633: 'information', 2634: 'informative', 2635: 'ingest', 2636: 'inherent', 2637: 'initial', 2638: 'initials', 2639: 'injuries', 2640: 'injustices', 2641: 'input', 2642: 'insane', 2643: 'inside', 2644: 'instagram', 2645: 'installing', 2646: 'instantly', 2647: 'instead', 2648: 'instinctive', 2649: 'institutions', 2650: 'insult', 2651: 'insulting', 2652: 'insults', 2653: 'insurance', 2654: 'intellectual', 2655: 'intelligence', 2656: 'intelligent', 2657: 'intense', 2658: 'intensifies', 2659: 'intentionally', 2660: 'interaction', 2661: 'interest', 2662: 'interested', 2663: 'interesting', 2664: 'interfere', 2665: 'internal', 2666: 'international', 2667: 'internationalist', 2668: 'internet', 2669: 'interpreted', 2670: 'interview', 2671: 'interviews', 2672: 'into', 2673: 'intro', 2674: 'introduce', 2675: 'invested', 2676: 'investigate', 2677: 'invited', 2678: 'involve', 2679: 'involving', 2680: 'irk', 2681: 'irl', 2682: 'ironic', 2683: 'irony', 2684: 'irrelevant', 2685: 'is', 2686: 'ish', 2687: 'isla', 2688: 'isn', 2689: 'isnt', 2690: 'issue', 2691: 'issues', 2692: 'it', 2693: 'its', 2694: 'itself', 2695: 'jacket', 2696: 'jan', 2697: 'jango', 2698: 'jealous', 2699: 'jealousy', 2700: 'jedi', 2701: 'jello', 2702: 'jelly', 2703: 'jellyfish', 2704: 'jerk', 2705: 'jersey', 2706: 'jian', 2707: 'jinxed', 2708: 'job', 2709: 'jobs', 2710: 'joining', 2711: 'joke', 2712: 'joking', 2713: 'joy', 2714: 'judged', 2715: 'judges', 2716: 'juicy', 2717: 'jump', 2718: 'jumped', 2719: 'just', 2720: 'justice', 2721: 'k', 2722: 'karma', 2723: 'keep', 2724: 'keeps', 2725: 'ken', 2726: 'kept', 2727: 'key', 2728: 'kicked', 2729: 'kicker', 2730: 'kid', 2731: 'kiddan', 2732: 'kidding', 2733: 'kiddo', 2734: 'kids', 2735: 'kill', 2736: 'killed', 2737: 'killers', 2738: 'killing', 2739: 'kills', 2740: 'kind', 2741: 'kinda', 2742: 'kindly', 2743: 'kindness', 2744: 'kindred', 2745: 'kinds', 2746: 'king', 2747: 'kinks', 2748: 'kiss', 2749: 'kisses', 2750: 'kitchen', 2751: 'kitty', 2752: 'kmt', 2753: 'kneel', 2754: 'knew', 2755: 'knife', 2756: 'knocked', 2757: 'knocking', 2758: 'know', 2759: 'knowing', 2760: 'known', 2761: 'knows', 2762: 'kombatants', 2763: 'kuss', 2764: 'la', 2765: 'labor', 2766: 'labour', 2767: 'labyrinth', 2768: 'lack', 2769: 'lacked', 2770: 'lacks', 2771: 'ladies', 2772: 'lady', 2773: 'laid', 2774: 'lambasted', 2775: 'land', 2776: 'landlady', 2777: 'language', 2778: 'lap', 2779: 'largely', 2780: 'lashes', 2781: 'lassie', 2782: 'last', 2783: 'lasted', 2784: 'late', 2785: 'lately', 2786: 'latency', 2787: 'later', 2788: 'latest', 2789: 'laugh', 2790: 'laughable', 2791: 'laughed', 2792: 'laughing', 2793: 'launch', 2794: 'lausd', 2795: 'law', 2796: 'lawn', 2797: 'laws', 2798: 'lay', 2799: 'laying', 2800: 'laziness', 2801: 'lazy', 2802: 'lead', 2803: 'league', 2804: 'leaning', 2805: 'leans', 2806: 'learn', 2807: 'learned', 2808: 'least', 2809: 'leather', 2810: 'leave', 2811: 'leaving', 2812: 'left', 2813: 'leftie', 2814: 'leftists', 2815: 'legally', 2816: 'legit', 2817: 'legs', 2818: 'lemon', 2819: 'lemons', 2820: 'length', 2821: 'leo', 2822: 'less', 2823: 'lesson', 2824: 'let', 2825: 'level', 2826: 'libertarian', 2827: 'librals', 2828: 'library', 2829: 'libs', 2830: 'lice', 2831: 'lick', 2832: 'life', 2833: 'lifetime', 2834: 'light', 2835: 'lightning', 2836: 'like', 2837: 'liked', 2838: 'likely', 2839: 'likes', 2840: 'lil', 2841: 'lime', 2842: 'limit', 2843: 'line', 2844: 'lines', 2845: 'link', 2846: 'linked', 2847: 'links', 2848: 'list', 2849: 'listed', 2850: 'listen', 2851: 'listening', 2852: 'listing', 2853: 'lists', 2854: 'lit', 2855: 'literal', 2856: 'literally', 2857: 'lithium', 2858: 'little', 2859: 'live', 2860: 'lives', 2861: 'living', 2862: 'll', 2863: 'lmao', 2864: 'lmaooo', 2865: 'lmfao', 2866: 'local', 2867: 'location', 2868: 'locked', 2869: 'locker', 2870: 'logic', 2871: 'logical', 2872: 'lol', 2873: 'lonely', 2874: 'long', 2875: 'longer', 2876: 'look', 2877: 'looked', 2878: 'looking', 2879: 'looks', 2880: 'loop', 2881: 'lose', 2882: 'loser', 2883: 'losing', 2884: 'loss', 2885: 'lost', 2886: 'lot', 2887: 'lots', 2888: 'loud', 2889: 'love', 2890: 'loved', 2891: 'lovely', 2892: 'loves', 2893: 'loving', 2894: 'low', 2895: 'luck', 2896: 'lucky', 2897: 'lucrative', 2898: 'lunatic', 2899: 'm', 2900: 'machine', 2901: 'machines', 2902: 'mad', 2903: 'made', 2904: 'magic', 2905: 'magnetism', 2906: 'magnum', 2907: 'maidens', 2908: 'main', 2909: 'maintain', 2910: 'major', 2911: 'majority', 2912: 'make', 2913: 'makes', 2914: 'makeup', 2915: 'making', 2916: 'male', 2917: 'males', 2918: 'man', 2919: 'manger', 2920: 'mans', 2921: 'many', 2922: 'market', 2923: 'marriage', 2924: 'married', 2925: 'mask', 2926: 'mass', 2927: 'master', 2928: 'masturbating', 2929: 'match', 2930: 'mate', 2931: 'material', 2932: 'math', 2933: 'matter', 2934: 'matters', 2935: 'mattress', 2936: 'maximize', 2937: 'may', 2938: 'maybe', 2939: 'me', 2940: 'mean', 2941: 'meaning', 2942: 'means', 2943: 'meant', 2944: 'measles', 2945: 'meat', 2946: 'meatcycling', 2947: 'meatless', 2948: 'media', 2949: 'medical', 2950: 'mediocrity', 2951: 'meet', 2952: 'meeting', 2953: 'meh', 2954: 'member', 2955: 'meme', 2956: 'memes', 2957: 'memories', 2958: 'men', 2959: 'mental', 2960: 'mention', 2961: 'mentioned', 2962: 'menu', 2963: 'mess', 2964: 'message', 2965: 'met', 2966: 'metric', 2967: 'mic', 2968: 'middle', 2969: 'midichlorian', 2970: 'might', 2971: 'miles', 2972: 'military', 2973: 'milk', 2974: 'millenials', 2975: 'million', 2976: 'min', 2977: 'mind', 2978: 'mindfulness', 2979: 'minds', 2980: 'mine', 2981: 'minimum', 2982: 'minor', 2983: 'mint', 2984: 'minute', 2985: 'minutes', 2986: 'miracle', 2987: 'miserable', 2988: 'misfortune', 2989: 'mishap', 2990: 'misinformation', 2991: 'miss', 2992: 'missed', 2993: 'mission', 2994: 'missions', 2995: 'misspell', 2996: 'mistake', 2997: 'mistaking', 2998: 'misunderstood', 2999: 'mix', 3000: 'mixed', 3001: 'mixup', 3002: 'mm', 3003: 'mobile', 3004: 'mod', 3005: 'model', 3006: 'modern', 3007: 'modes', 3008: 'mods', 3009: 'mog', 3010: 'mom', 3011: 'moment', 3012: 'momentum', 3013: 'momma', 3014: 'mommy', 3015: 'moms', 3016: 'money', 3017: 'monitor', 3018: 'month', 3019: 'months', 3020: 'moon', 3021: 'moose', 3022: 'morbid', 3023: 'more', 3024: 'morning', 3025: 'moron', 3026: 'mosquito', 3027: 'most', 3028: 'mostly', 3029: 'mother', 3030: 'motherfucker', 3031: 'motherfucking', 3032: 'mouth', 3033: 'move', 3034: 'moved', 3035: 'movement', 3036: 'moves', 3037: 'movie', 3038: 'movies', 3039: 'moving', 3040: 'ms', 3041: 'much', 3042: 'muggings', 3043: 'mum', 3044: 'mummy', 3045: 'murder', 3046: 'murdering', 3047: 'murderino', 3048: 'music', 3049: 'must', 3050: 'mutual', 3051: 'my', 3052: 'myself', 3053: 'n', 3054: 'na', 3055: 'nah', 3056: 'nailed', 3057: 'name', 3058: 'named', 3059: 'names', 3060: 'nan', 3061: 'nationalism', 3062: 'nations', 3063: 'native', 3064: 'natural', 3065: 'naturally', 3066: 'nature', 3067: 'naughty', 3068: 'nba', 3069: 'nd', 3070: 'near', 3071: 'neat', 3072: 'necessarily', 3073: 'neck', 3074: 'necrophilia', 3075: 'need', 3076: 'needed', 3077: 'needs', 3078: 'negativity', 3079: 'neighbor', 3080: 'nerf', 3081: 'nerfs', 3082: 'nerve', 3083: 'nervous', 3084: 'ness', 3085: 'net', 3086: 'netti', 3087: 'neurotypical', 3088: 'never', 3089: 'new', 3090: 'news', 3091: 'next', 3092: 'ngl', 3093: 'nice', 3094: 'night', 3095: 'nightmare', 3096: 'nights', 3097: 'nightstand', 3098: 'nineties', 3099: 'nipples', 3100: 'nit', 3101: 'no', 3102: 'nobody', 3103: 'non', 3104: 'none', 3105: 'nonsense', 3106: 'normal', 3107: 'normalized', 3108: 'normies', 3109: 'north', 3110: 'northern', 3111: 'nos', 3112: 'nostrils', 3113: 'not', 3114: 'nothing', 3115: 'notice', 3116: 'noticed', 3117: 'notif', 3118: 'now', 3119: 'nuance', 3120: 'numb', 3121: 'number', 3122: 'nut', 3123: 'nutrient', 3124: 'nutritional', 3125: 'nuts', 3126: 'o', 3127: 'obesity', 3128: 'objective', 3129: 'observing', 3130: 'obsess', 3131: 'obsessed', 3132: 'obsessing', 3133: 'obsessive', 3134: 'obsessively', 3135: 'obtain', 3136: 'obtuse', 3137: 'obvious', 3138: 'obviously', 3139: 'obvs', 3140: 'occasionally', 3141: 'occurred', 3142: 'odd', 3143: 'oddly', 3144: 'of', 3145: 'off', 3146: 'offended', 3147: 'offense', 3148: 'offer', 3149: 'offered', 3150: 'office', 3151: 'officiant', 3152: 'often', 3153: 'oh', 3154: 'ohmygawd', 3155: 'oj', 3156: 'ok', 3157: 'okay', 3158: 'ol', 3159: 'old', 3160: 'older', 3161: 'oldpeoplereddit', 3162: 'omelette', 3163: 'omg', 3164: 'on', 3165: 'once', 3166: 'one', 3167: 'ones', 3168: 'online', 3169: 'only', 3170: 'onto', 3171: 'oops', 3172: 'open', 3173: 'opening', 3174: 'openings', 3175: 'opera', 3176: 'operators', 3177: 'opinion', 3178: 'opportunity', 3179: 'opposite', 3180: 'oppress', 3181: 'oppressed', 3182: 'oppression', 3183: 'optimist', 3184: 'option', 3185: 'options', 3186: 'or', 3187: 'oracle', 3188: 'orange', 3189: 'ordained', 3190: 'order', 3191: 'ordering', 3192: 'organized', 3193: 'orgasm', 3194: 'originally', 3195: 'other', 3196: 'others', 3197: 'otherwise', 3198: 'our', 3199: 'ourselves', 3200: 'out', 3201: 'outrage', 3202: 'outside', 3203: 'outta', 3204: 'oven', 3205: 'over', 3206: 'overall', 3207: 'overpriced', 3208: 'oversharing', 3209: 'overwatch', 3210: 'overwrite', 3211: 'own', 3212: 'owned', 3213: 'owner', 3214: 'owo', 3215: 'oxford', 3216: 'p', 3217: 'pEyToN', 3218: 'packet', 3219: 'paid', 3220: 'pain', 3221: 'painful', 3222: 'painted', 3223: 'pal', 3224: 'pale', 3225: 'palette', 3226: 'pan', 3227: 'pancake', 3228: 'panic', 3229: 'panicked', 3230: 'pans', 3231: 'pants', 3232: 'paper', 3233: 'parents', 3234: 'park', 3235: 'part', 3236: 'parties', 3237: 'partisan', 3238: 'partner', 3239: 'party', 3240: 'pass', 3241: 'passed', 3242: 'passes', 3243: 'passing', 3244: 'passion', 3245: 'past', 3246: 'pasta', 3247: 'patch', 3248: 'pathetic', 3249: 'patience', 3250: 'pats', 3251: 'pattern', 3252: 'patters', 3253: 'pay', 3254: 'paying', 3255: 'pays', 3256: 'peace', 3257: 'peach', 3258: 'peaked', 3259: 'pear', 3260: 'pedestal', 3261: 'peer', 3262: 'penetrated', 3263: 'peng', 3264: 'penguin', 3265: 'people', 3266: 'peoples', 3267: 'pepper', 3268: 'per', 3269: 'perfect', 3270: 'period', 3271: 'perpetrator', 3272: 'persistent', 3273: 'person', 3274: 'personal', 3275: 'perspective', 3276: 'perverse', 3277: 'pervert', 3278: 'pet', 3279: 'pets', 3280: 'pettiness', 3281: 'petty', 3282: 'phantom', 3283: 'philly', 3284: 'phone', 3285: 'photo', 3286: 'photographer', 3287: 'photos', 3288: 'phrase', 3289: 'phrasing', 3290: 'physical', 3291: 'physically', 3292: 'physics', 3293: 'pic', 3294: 'pick', 3295: 'pickle', 3296: 'pics', 3297: 'picture', 3298: 'pictured', 3299: 'pictures', 3300: 'piece', 3301: 'pieces', 3302: 'pigs', 3303: 'pills', 3304: 'pimples', 3305: 'pinch', 3306: 'ping', 3307: 'pisces', 3308: 'pisco', 3309: 'piss', 3310: 'pissed', 3311: 'pit', 3312: 'pizza', 3313: 'pj', 3314: 'place', 3315: 'placed', 3316: 'places', 3317: 'plague', 3318: 'plain', 3319: 'plan', 3320: 'planet', 3321: 'plastic', 3322: 'platinum', 3323: 'play', 3324: 'played', 3325: 'players', 3326: 'playful', 3327: 'playing', 3328: 'plays', 3329: 'pleasantly', 3330: 'please', 3331: 'pleased', 3332: 'pleasure', 3333: 'plenty', 3334: 'plot', 3335: 'ploy', 3336: 'plug', 3337: 'plunger', 3338: 'pm', 3339: 'podcast', 3340: 'poems', 3341: 'point', 3342: 'pointing', 3343: 'pointless', 3344: 'poison', 3345: 'pole', 3346: 'polite', 3347: 'politician', 3348: 'politics', 3349: 'polling', 3350: 'ponder', 3351: 'poor', 3352: 'popped', 3353: 'population', 3354: 'porn', 3355: 'portal', 3356: 'posion', 3357: 'position', 3358: 'positive', 3359: 'posse', 3360: 'possible', 3361: 'possibly', 3362: 'post', 3363: 'posted', 3364: 'posting', 3365: 'posts', 3366: 'pot', 3367: 'potato', 3368: 'potential', 3369: 'potentially', 3370: 'pounds', 3371: 'powered', 3372: 'powerful', 3373: 'practically', 3374: 'pranks', 3375: 'pray', 3376: 'prayer', 3377: 'prayers', 3378: 'praying', 3379: 'precious', 3380: 'predicament', 3381: 'pregnant', 3382: 'prejudice', 3383: 'prepared', 3384: 'presents', 3385: 'press', 3386: 'pretty', 3387: 'previous', 3388: 'price', 3389: 'prices', 3390: 'pricing', 3391: 'princess', 3392: 'principle', 3393: 'prison', 3394: 'private', 3395: 'privilege', 3396: 'privileges', 3397: 'pro', 3398: 'probably', 3399: 'problem', 3400: 'problems', 3401: 'proceed', 3402: 'process', 3403: 'produce', 3404: 'products', 3405: 'profile', 3406: 'projecting', 3407: 'promoting', 3408: 'propaganda', 3409: 'proper', 3410: 'properly', 3411: 'props', 3412: 'prospects', 3413: 'protection', 3414: 'proud', 3415: 'prove', 3416: 'proverbial', 3417: 'providers', 3418: 'proving', 3419: 'psychos', 3420: 'pubes', 3421: 'public', 3422: 'pull', 3423: 'punch', 3424: 'punching', 3425: 'punish', 3426: 'punishment', 3427: 'punt', 3428: 'pup', 3429: 'pupper', 3430: 'puppets', 3431: 'puppy', 3432: 'pure', 3433: 'purgatory', 3434: 'purple', 3435: 'purposely', 3436: 'pursue', 3437: 'pursuit', 3438: 'pushy', 3439: 'put', 3440: 'puts', 3441: 'pwoud', 3442: 'qaida', 3443: 'qualified', 3444: 'qualify', 3445: 'quality', 3446: 'quarter', 3447: 'queasy', 3448: 'queen', 3449: 'queer', 3450: 'question', 3451: 'questions', 3452: 'quick', 3453: 'quickest', 3454: 'quickly', 3455: 'quirky', 3456: 'quit', 3457: 'quite', 3458: 'quota', 3459: 'quote', 3460: 'r', 3461: 'racism', 3462: 'racist', 3463: 'radar', 3464: 'radical', 3465: 'radio', 3466: 'rage', 3467: 'raise', 3468: 'ramdom', 3469: 'rancid', 3470: 'random', 3471: 'randoms', 3472: 'range', 3473: 'rant', 3474: 'rapaidh', 3475: 'rape', 3476: 'rappers', 3477: 'rare', 3478: 'rarely', 3479: 'rates', 3480: 'rather', 3481: 'rational', 3482: 'ravens', 3483: 'ray', 3484: 're', 3485: 'reach', 3486: 'react', 3487: 'reactable', 3488: 'reaction', 3489: 'read', 3490: 'reading', 3491: 'reads', 3492: 'ready', 3493: 'real', 3494: 'reality', 3495: 'realize', 3496: 'realized', 3497: 'really', 3498: 'reason', 3499: 'reasonable', 3500: 'reasons', 3501: 'rebel', 3502: 'reckons', 3503: 'recommend', 3504: 'reconsider', 3505: 'record', 3506: 'recover', 3507: 'recovery', 3508: 'recruit', 3509: 'recruiting', 3510: 'red', 3511: 'reddit', 3512: 'redditor', 3513: 'redhead', 3514: 'redo', 3515: 'ref', 3516: 'reference', 3517: 'referendum', 3518: 'referring', 3519: 'reflective', 3520: 'reflexive', 3521: 'refusing', 3522: 'register', 3523: 'regular', 3524: 'regularly', 3525: 'regulations', 3526: 'rehabilitating', 3527: 'reigned', 3528: 'rejoining', 3529: 'relatable', 3530: 'relate', 3531: 'related', 3532: 'relationship', 3533: 'relationships', 3534: 'relatively', 3535: 'relaxing', 3536: 'release', 3537: 'released', 3538: 'relief', 3539: 'religious', 3540: 'rely', 3541: 'remain', 3542: 'remake', 3543: 'remarkable', 3544: 'remember', 3545: 'reminding', 3546: 'reminds', 3547: 'remotely', 3548: 'removed', 3549: 'renaissance', 3550: 'renovate', 3551: 'rent', 3552: 'repacked', 3553: 'repaid', 3554: 'repairing', 3555: 'replace', 3556: 'replacement', 3557: 'replies', 3558: 'reply', 3559: 'replying', 3560: 'representation', 3561: 'representing', 3562: 'reproduce', 3563: 'republican', 3564: 'republicans', 3565: 'request', 3566: 'requiem', 3567: 'required', 3568: 'rescind', 3569: 'research', 3570: 'resell', 3571: 'resentment', 3572: 'residents', 3573: 'resisting', 3574: 'responding', 3575: 'responds', 3576: 'response', 3577: 'responsibility', 3578: 'rest', 3579: 'restaurant', 3580: 'result', 3581: 'results', 3582: 'retains', 3583: 'retardation', 3584: 'retirement', 3585: 'retreat', 3586: 'retreats', 3587: 'return', 3588: 'revenge', 3589: 'review', 3590: 'rex', 3591: 'rice', 3592: 'rich', 3593: 'ricotta', 3594: 'rid', 3595: 'ride', 3596: 'ridiculous', 3597: 'right', 3598: 'rights', 3599: 'ring', 3600: 'rip', 3601: 'ripped', 3602: 'rippled', 3603: 'rise', 3604: 'risk', 3605: 'rivalry', 3606: 'river', 3607: 'rn', 3608: 'road', 3609: 'rock', 3610: 'rocket', 3611: 'rockets', 3612: 'role', 3613: 'roll', 3614: 'room', 3615: 'roommate', 3616: 'roommates', 3617: 'rooting', 3618: 'roster', 3619: 'round', 3620: 'route', 3621: 'royal', 3622: 'rubbing', 3623: 'rubies', 3624: 'ruin', 3625: 'ruins', 3626: 'rule', 3627: 'rules', 3628: 'rum', 3629: 'run', 3630: 'running', 3631: 'rush', 3632: 'rushed', 3633: 's', 3634: 'sacrifice', 3635: 'sacrifices', 3636: 'sad', 3637: 'sadder', 3638: 'saddest', 3639: 'sadly', 3640: 'sadness', 3641: 'safe', 3642: 'safety', 3643: 'said', 3644: 'saints', 3645: 'sake', 3646: 'salarian', 3647: 'sales', 3648: 'same', 3649: 'sandy', 3650: 'sanitizer', 3651: 'sarcasm', 3652: 'sarcastic', 3653: 'saturday', 3654: 'sauerkraut', 3655: 'savants', 3656: 'save', 3657: 'saved', 3658: 'saving', 3659: 'savings', 3660: 'savvy', 3661: 'saw', 3662: 'say', 3663: 'saying', 3664: 'says', 3665: 'scam', 3666: 'scammed', 3667: 'scammers', 3668: 'scared', 3669: 'scary', 3670: 'scenarios', 3671: 'schadenfreude', 3672: 'school', 3673: 'science', 3674: 'scousers', 3675: 'scratch', 3676: 'screens', 3677: 'screw', 3678: 'screwing', 3679: 'script', 3680: 'scripts', 3681: 'scrub', 3682: 'scumbags', 3683: 'search', 3684: 'season', 3685: 'seat', 3686: 'sec', 3687: 'second', 3688: 'seconds', 3689: 'secrecy', 3690: 'secret', 3691: 'section', 3692: 'secure', 3693: 'see', 3694: 'seeing', 3695: 'seem', 3696: 'seemingly', 3697: 'seems', 3698: 'seen', 3699: 'sees', 3700: 'seeya', 3701: 'self', 3702: 'selfie', 3703: 'semen', 3704: 'semester', 3705: 'send', 3706: 'sending', 3707: 'sense', 3708: 'sensing', 3709: 'sensitive', 3710: 'sentence', 3711: 'serious', 3712: 'seriously', 3713: 'served', 3714: 'service', 3715: 'setting', 3716: 'several', 3717: 'severe', 3718: 'severely', 3719: 'sex', 3720: 'sexist', 3721: 'sexual', 3722: 'sexually', 3723: 'sexy', 3724: 'sha', 3725: 'shaft', 3726: 'shaking', 3727: 'sham', 3728: 'shape', 3729: 'share', 3730: 'shared', 3731: 'sharing', 3732: 'shark', 3733: 'sharp', 3734: 'sharply', 3735: 'she', 3736: 'shelf', 3737: 'shell', 3738: 'shirt', 3739: 'shit', 3740: 'shits', 3741: 'shitty', 3742: 'shock', 3743: 'shoes', 3744: 'shook', 3745: 'shoot', 3746: 'shooting', 3747: 'shopping', 3748: 'short', 3749: 'shortly', 3750: 'shot', 3751: 'shotgun', 3752: 'shots', 3753: 'should', 3754: 'shouldn', 3755: 'shoveling', 3756: 'show', 3757: 'showing', 3758: 'shows', 3759: 'shut', 3760: 'siblings', 3761: 'sick', 3762: 'sickest', 3763: 'sickness', 3764: 'side', 3765: 'sides', 3766: 'sign', 3767: 'signature', 3768: 'signed', 3769: 'significant', 3770: 'signing', 3771: 'signs', 3772: 'silly', 3773: 'silver', 3774: 'similar', 3775: 'simple', 3776: 'sin', 3777: 'since', 3778: 'single', 3779: 'sink', 3780: 'sinner', 3781: 'sir', 3782: 'site', 3783: 'sitting', 3784: 'situation', 3785: 'size', 3786: 'skates', 3787: 'skills', 3788: 'skin', 3789: 'skip', 3790: 'skull', 3791: 'slaughtered', 3792: 'sleep', 3793: 'sleeptrain', 3794: 'sleeve', 3795: 'slept', 3796: 'slice', 3797: 'slightly', 3798: 'slob', 3799: 'slop', 3800: 'slow', 3801: 'small', 3802: 'smaller', 3803: 'smarter', 3804: 'smartly', 3805: 'smeared', 3806: 'smell', 3807: 'smells', 3808: 'smelly', 3809: 'smile', 3810: 'smooth', 3811: 'snack', 3812: 'snagging', 3813: 'snapchats', 3814: 'snapped', 3815: 'snow', 3816: 'snowflake', 3817: 'snuggled', 3818: 'so', 3819: 'soap', 3820: 'sobriety', 3821: 'society', 3822: 'soft', 3823: 'soil', 3824: 'solar', 3825: 'solid', 3826: 'solo', 3827: 'sololander', 3828: 'solve', 3829: 'solves', 3830: 'some', 3831: 'somebody', 3832: 'someday', 3833: 'somehow', 3834: 'someone', 3835: 'something', 3836: 'sometime', 3837: 'sometimes', 3838: 'son', 3839: 'song', 3840: 'songs', 3841: 'sons', 3842: 'soon', 3843: 'soooo', 3844: 'sorry', 3845: 'sort', 3846: 'sorts', 3847: 'soul', 3848: 'soulread', 3849: 'sound', 3850: 'sounds', 3851: 'source', 3852: 'sours', 3853: 'south', 3854: 'space', 3855: 'spam', 3856: 'speak', 3857: 'speaking', 3858: 'special', 3859: 'specific', 3860: 'specifically', 3861: 'speed', 3862: 'spell', 3863: 'spelling', 3864: 'spent', 3865: 'spiderman', 3866: 'spin', 3867: 'spirit', 3868: 'spirits', 3869: 'spit', 3870: 'split', 3871: 'spoil', 3872: 'spoke', 3873: 'sponsors', 3874: 'spot', 3875: 'spouse', 3876: 'spray', 3877: 'spreadsheeters', 3878: 'spritz', 3879: 'squeamish', 3880: 'sry', 3881: 'sssssssssssssssssssssssssssss', 3882: 'stabbed', 3883: 'stabbings', 3884: 'stadium', 3885: 'staff', 3886: 'stain', 3887: 'stains', 3888: 'stamp', 3889: 'stamps', 3890: 'stan', 3891: 'stand', 3892: 'standard', 3893: 'standards', 3894: 'standing', 3895: 'stands', 3896: 'stans', 3897: 'star', 3898: 'stars', 3899: 'start', 3900: 'started', 3901: 'starts', 3902: 'starving', 3903: 'state', 3904: 'statements', 3905: 'states', 3906: 'stating', 3907: 'station', 3908: 'statistic', 3909: 'stay', 3910: 'stayed', 3911: 'steal', 3912: 'stealing', 3913: 'steam', 3914: 'steel', 3915: 'step', 3916: 'steps', 3917: 'stereotype', 3918: 'stick', 3919: 'sticks', 3920: 'stickshift', 3921: 'still', 3922: 'stink', 3923: 'stitches', 3924: 'stock', 3925: 'stolen', 3926: 'stomping', 3927: 'stone', 3928: 'stoned', 3929: 'stood', 3930: 'stop', 3931: 'stopped', 3932: 'stopping', 3933: 'stops', 3934: 'store', 3935: 'stores', 3936: 'story', 3937: 'straight', 3938: 'stranger', 3939: 'strangers', 3940: 'strategy', 3941: 'stream', 3942: 'stressed', 3943: 'stresses', 3944: 'stripper', 3945: 'strippers', 3946: 'strong', 3947: 'structural', 3948: 'structure', 3949: 'stubborn', 3950: 'stubbornly', 3951: 'stuck', 3952: 'stud', 3953: 'student', 3954: 'study', 3955: 'stuff', 3956: 'stung', 3957: 'stunt', 3958: 'stupid', 3959: 'stupidly', 3960: 'style', 3961: 'stylist', 3962: 'sub', 3963: 'subreddit', 3964: 'subs', 3965: 'subtitles', 3966: 'subtlety', 3967: 'succinct', 3968: 'such', 3969: 'suck', 3970: 'sucked', 3971: 'sucks', 3972: 'suddenly', 3973: 'sued', 3974: 'suffering', 3975: 'suggestion', 3976: 'suggests', 3977: 'suit', 3978: 'summer', 3979: 'sunburn', 3980: 'sundae', 3981: 'sunk', 3982: 'sunny', 3983: 'sunrise', 3984: 'sunshine', 3985: 'super', 3986: 'support', 3987: 'supported', 3988: 'supporters', 3989: 'supporting', 3990: 'supposed', 3991: 'suprise', 3992: 'sure', 3993: 'surely', 3994: 'surface', 3995: 'surgery', 3996: 'surprise', 3997: 'surprised', 3998: 'surrogacy', 3999: 'survive', 4000: 'svu', 4001: 'sweatie', 4002: 'sweating', 4003: 'sweet', 4004: 'swimmer', 4005: 'swing', 4006: 'swings', 4007: 'swiping', 4008: 'swollen', 4009: 'symptom', 4010: 'synopsis', 4011: 'system', 4012: 'systematic', 4013: 't', 4014: 'tHe', 4015: 'tO', 4016: 'taco', 4017: 'tacos', 4018: 'tae', 4019: 'tag', 4020: 'take', 4021: 'taken', 4022: 'takes', 4023: 'taking', 4024: 'tale', 4025: 'talk', 4026: 'talking', 4027: 'talks', 4028: 'tall', 4029: 'tank', 4030: 'tanks', 4031: 'target', 4032: 'tart', 4033: 'task', 4034: 'taste', 4035: 'tati', 4036: 'taught', 4037: 'tbh', 4038: 'tea', 4039: 'teach', 4040: 'team', 4041: 'teammates', 4042: 'teams', 4043: 'tear', 4044: 'tears', 4045: 'teen', 4046: 'tehehehehehehe', 4047: 'tell', 4048: 'telling', 4049: 'temple', 4050: 'tempting', 4051: 'ten', 4052: 'teriyaki', 4053: 'term', 4054: 'terminal', 4055: 'terminology', 4056: 'terms', 4057: 'terrible', 4058: 'terrified', 4059: 'terrify', 4060: 'terrifying', 4061: 'text', 4062: 'th', 4063: 'than', 4064: 'thank', 4065: 'thankful', 4066: 'thanks', 4067: 'that', 4068: 'thats', 4069: 'the', 4070: 'theater', 4071: 'their', 4072: 'them', 4073: 'theme', 4074: 'themselves', 4075: 'then', 4076: 'theorists', 4077: 'theory', 4078: 'therapist', 4079: 'therapy', 4080: 'there', 4081: 'these', 4082: 'they', 4083: 'thick', 4084: 'thin', 4085: 'thing', 4086: 'things', 4087: 'think', 4088: 'thinking', 4089: 'thinks', 4090: 'third', 4091: 'thirsty', 4092: 'this', 4093: 'tho', 4094: 'thoroughly', 4095: 'thos', 4096: 'those', 4097: 'thou', 4098: 'though', 4099: 'thought', 4100: 'thoughts', 4101: 'thoughy', 4102: 'thread', 4103: 'threads', 4104: 'threatened', 4105: 'three', 4106: 'threw', 4107: 'through', 4108: 'throw', 4109: 'throwing', 4110: 'thrown', 4111: 'thus', 4112: 'thyroid', 4113: 'ti', 4114: 'tier', 4115: 'tik', 4116: 'till', 4117: 'time', 4118: 'timeless', 4119: 'times', 4120: 'timing', 4121: 'tiniest', 4122: 'tiny', 4123: 'tip', 4124: 'tipped', 4125: 'titanic', 4126: 'title', 4127: 'to', 4128: 'today', 4129: 'toddler', 4130: 'toe', 4131: 'toenails', 4132: 'tofu', 4133: 'together', 4134: 'toilet', 4135: 'toilets', 4136: 'tok', 4137: 'told', 4138: 'tomorow', 4139: 'tomorrow', 4140: 'tone', 4141: 'tongue', 4142: 'tonight', 4143: 'too', 4144: 'took', 4145: 'tool', 4146: 'tooth', 4147: 'top', 4148: 'topic', 4149: 'tops', 4150: 'tortilla', 4151: 'tortillas', 4152: 'totally', 4153: 'touch', 4154: 'tough', 4155: 'tourist', 4156: 'tousles', 4157: 'toward', 4158: 'towards', 4159: 'town', 4160: 'toxic', 4161: 'tracer', 4162: 'track', 4163: 'tracking', 4164: 'tracks', 4165: 'trade', 4166: 'traffic', 4167: 'tragic', 4168: 'training', 4169: 'transfer', 4170: 'transit', 4171: 'transition', 4172: 'translation', 4173: 'translations', 4174: 'translucent', 4175: 'transparent', 4176: 'traps', 4177: 'trash', 4178: 'travels', 4179: 'treasure', 4180: 'treat', 4181: 'treated', 4182: 'treatment', 4183: 'trees', 4184: 'tremble', 4185: 'trend', 4186: 'trendy', 4187: 'tribalism', 4188: 'trickiest', 4189: 'tried', 4190: 'trifecta', 4191: 'trillion', 4192: 'trip', 4193: 'triumphant', 4194: 'troll', 4195: 'trollGC', 4196: 'trolls', 4197: 'troo', 4198: 'troops', 4199: 'trouble', 4200: 'troubles', 4201: 'truck', 4202: 'trucks', 4203: 'true', 4204: 'truly', 4205: 'trust', 4206: 'truth', 4207: 'try', 4208: 'trying', 4209: 'tuck', 4210: 'tummy', 4211: 'turds', 4212: 'turned', 4213: 'turning', 4214: 'turns', 4215: 'tutorial', 4216: 'tv', 4217: 'tweet', 4218: 'twice', 4219: 'twin', 4220: 'twist', 4221: 'twitter', 4222: 'two', 4223: 'type', 4224: 'typed', 4225: 'types', 4226: 'typing', 4227: 'u', 4228: 'uS', 4229: 'ugly', 4230: 'uh', 4231: 'uk', 4232: 'unable', 4233: 'uncle', 4234: 'uncommon', 4235: 'under', 4236: 'underground', 4237: 'underpaid', 4238: 'undersold', 4239: 'understand', 4240: 'understanding', 4241: 'understated', 4242: 'unethical', 4243: 'unfortunate', 4244: 'unfortunately', 4245: 'unfunny', 4246: 'uniform', 4247: 'unique', 4248: 'unit', 4249: 'universally', 4250: 'university', 4251: 'unless', 4252: 'unnecessary', 4253: 'unpopular', 4254: 'until', 4255: 'up', 4256: 'updoots', 4257: 'upfront', 4258: 'uplifting', 4259: 'upload', 4260: 'upon', 4261: 'upper', 4262: 'ups', 4263: 'upset', 4264: 'upvote', 4265: 'upvotes', 4266: 'upvoting', 4267: 'ur', 4268: 'us', 4269: 'use', 4270: 'used', 4271: 'useful', 4272: 'user', 4273: 'username', 4274: 'uses', 4275: 'using', 4276: 'usual', 4277: 'usually', 4278: 'v', 4279: 'vaccinations', 4280: 'vaccine', 4281: 'vague', 4282: 'valid', 4283: 'valuable', 4284: 'value', 4285: 'vanguardism', 4286: 'vanilla', 4287: 'vault', 4288: 've', 4289: 'veggies', 4290: 'veins', 4291: 'vent', 4292: 'version', 4293: 'very', 4294: 'vewy', 4295: 'vey', 4296: 'vibe', 4297: 'vibes', 4298: 'victims', 4299: 'victory', 4300: 'video', 4301: 'videos', 4302: 'view', 4303: 'viewers', 4304: 'viewing', 4305: 'vindication', 4306: 'violate', 4307: 'visible', 4308: 'visit', 4309: 'visiting', 4310: 'vite', 4311: 'vodka', 4312: 'voice', 4313: 'vomiting', 4314: 'vote', 4315: 'voted', 4316: 'vulnerable', 4317: 'wabbies', 4318: 'waffles', 4319: 'wage', 4320: 'wait', 4321: 'waiter', 4322: 'waiting', 4323: 'waitress', 4324: 'wake', 4325: 'walk', 4326: 'walked', 4327: 'walking', 4328: 'wallow', 4329: 'wankfest', 4330: 'wanna', 4331: 'want', 4332: 'wanted', 4333: 'wanting', 4334: 'wants', 4335: 'war', 4336: 'warm', 4337: 'warmth', 4338: 'warning', 4339: 'wary', 4340: 'was', 4341: 'wash', 4342: 'washed', 4343: 'wasn', 4344: 'wasnt', 4345: 'waste', 4346: 'wastebasket', 4347: 'wasting', 4348: 'watch', 4349: 'watched', 4350: 'watching', 4351: 'water', 4352: 'waving', 4353: 'way', 4354: 'ways', 4355: 'we', 4356: 'weak', 4357: 'wealth', 4358: 'weapon', 4359: 'wear', 4360: 'wearing', 4361: 'wears', 4362: 'wedding', 4363: 'wee', 4364: 'week', 4365: 'weekend', 4366: 'weeks', 4367: 'weep', 4368: 'weigh', 4369: 'weight', 4370: 'weird', 4371: 'weirdest', 4372: 'welcome', 4373: 'welded', 4374: 'well', 4375: 'welp', 4376: 'went', 4377: 'were', 4378: 'weren', 4379: 'west', 4380: 'wha', 4381: 'what', 4382: 'whatapp', 4383: 'whatever', 4384: 'whats', 4385: 'when', 4386: 'whenever', 4387: 'where', 4388: 'which', 4389: 'whiff', 4390: 'while', 4391: 'whining', 4392: 'whippersnappers', 4393: 'whispering', 4394: 'white', 4395: 'who', 4396: 'whoever', 4397: 'whole', 4398: 'wholeheartedly', 4399: 'wholesome', 4400: 'whoppers', 4401: 'why', 4402: 'widow', 4403: 'wield', 4404: 'wif', 4405: 'wife', 4406: 'wild', 4407: 'will', 4408: 'willing', 4409: 'win', 4410: 'window', 4411: 'windshield', 4412: 'wine', 4413: 'wings', 4414: 'winter', 4415: 'wise', 4416: 'wish', 4417: 'wishing', 4418: 'with', 4419: 'without', 4420: 'witness', 4421: 'witnessing', 4422: 'wives', 4423: 'woke', 4424: 'woman', 4425: 'women', 4426: 'won', 4427: 'wonder', 4428: 'wonderful', 4429: 'wondering', 4430: 'woods', 4431: 'word', 4432: 'words', 4433: 'wore', 4434: 'work', 4435: 'worked', 4436: 'worker', 4437: 'workers', 4438: 'workforce', 4439: 'working', 4440: 'works', 4441: 'world', 4442: 'worried', 4443: 'worry', 4444: 'worrying', 4445: 'worse', 4446: 'worship', 4447: 'worst', 4448: 'worth', 4449: 'worthless', 4450: 'worthy', 4451: 'would', 4452: 'wouldn', 4453: 'wow', 4454: 'woww', 4455: 'wrap', 4456: 'wrists', 4457: 'write', 4458: 'writing', 4459: 'written', 4460: 'wrong', 4461: 'wrote', 4462: 'wtf', 4463: 'x', 4464: 'xd', 4465: 'y', 4466: 'ya', 4467: 'yah', 4468: 'yea', 4469: 'yeah', 4470: 'yeahno', 4471: 'year', 4472: 'years', 4473: 'yeast', 4474: 'yeh', 4475: 'yelled', 4476: 'yellow', 4477: 'yes', 4478: 'yesss', 4479: 'yesterday', 4480: 'yet', 4481: 'yoga', 4482: 'yoooouuuuu', 4483: 'you', 4484: 'young', 4485: 'younger', 4486: 'your', 4487: 'youre', 4488: 'yours', 4489: 'yourself', 4490: 'youtube', 4491: 'youuuuuuu', 4492: 'yr', 4493: 'zero', 4494: 'zoo', 4495: '\\u200d', 4496: '️', 4497: '🇦', 4498: '🇫', 4499: '🇲', 4500: '🇵', 4501: '🇷', 4502: '🇺'}\n",
      "word_to_idx:  {'A': 0, 'AA': 1, 'AB': 2, 'ABH': 3, 'AHAHA': 4, 'AM': 5, 'AMA': 6, 'AND': 7, 'ANGEL': 8, 'ANYONE': 9, 'APPROVE': 10, 'AR': 11, 'ARE': 12, 'AROUND': 13, 'AS': 14, 'ASAP': 15, 'ASD': 16, 'ATF': 17, 'ATM': 18, 'Aaahahahha': 19, 'Ab': 20, 'Absolutely': 21, 'Actually': 22, 'Acura': 23, 'Addison': 24, 'After': 25, 'Again': 26, 'Aggieopoly': 27, 'Aghulas': 28, 'Agreed': 29, 'Ah': 30, 'Ahem': 31, 'Ahh': 32, 'Ahhh': 33, 'Ahhhh': 34, 'AiG': 35, 'Al': 36, 'Alarming': 37, 'Alert': 38, 'All': 39, 'Allow': 40, 'Alright': 41, 'Also': 42, 'Although': 43, 'Alvalade': 44, 'Always': 45, 'Am': 46, 'Amateurs': 47, 'Amazing': 48, 'Amazon': 49, 'Ameen': 50, 'America': 51, 'American': 52, 'And': 53, 'Angel': 54, 'Animal': 55, 'Animation': 56, 'Another': 57, 'Any': 58, 'Anymore': 59, 'Anything': 60, 'Anytime': 61, 'Anyway': 62, 'Apologies': 63, 'Appalachia': 64, 'Apple': 65, 'Applying': 66, 'Are': 67, 'Aren': 68, 'Argh': 69, 'Argue': 70, 'Arizona': 71, 'Arm': 72, 'Arsenal': 73, 'As': 74, 'Ask': 75, 'At': 76, 'Au': 77, 'Austin': 78, 'Austinfred': 79, 'Australia': 80, 'Avocado': 81, 'Awesome': 82, 'Aww': 83, 'Ayyy': 84, 'Azusa': 85, 'B': 86, 'BACK': 87, 'BAYLESS': 88, 'BBC': 89, 'BIG': 90, 'BLADE': 91, 'BO': 92, 'BOMB': 93, 'BOTTOM': 94, 'BS': 95, 'BTS': 96, 'BURN': 97, 'Back': 98, 'Bae': 99, 'Barf': 100, 'Bc': 101, 'Be': 102, 'Beauty': 103, 'Because': 104, 'Being': 105, 'Belgian': 106, 'Believe': 107, 'Bellevue': 108, 'Ben': 109, 'Bengals': 110, 'Berlin': 111, 'Best': 112, 'Bet': 113, 'Big': 114, 'Bills': 115, 'Bingo': 116, 'Birthday': 117, 'Bit': 118, 'Bitch': 119, 'BlOod': 120, 'Black': 121, 'Blasted': 122, 'Block': 123, 'Blockbusters': 124, 'Bo': 125, 'Body': 126, 'Bold': 127, 'Bolts': 128, 'Bort': 129, 'Bowl': 130, 'Bowral': 131, 'Boys': 132, 'Brass': 133, 'Brave': 134, 'Bravo': 135, 'Bro': 136, 'Broncos': 137, 'Broncs': 138, 'Bruh': 139, 'Brussels': 140, 'Brutal': 141, 'Btw': 142, 'Bud': 143, 'Buddy': 144, 'Buff': 145, 'Bulls': 146, 'But': 147, 'Buying': 148, 'By': 149, 'C': 150, 'CANTTTT': 151, 'CARE': 152, 'CHAD': 153, 'CHOICE': 154, 'COOL': 155, 'Cake': 156, 'Cakeday': 157, 'Calling': 158, 'Came': 159, 'Can': 160, 'Canada': 161, 'Canadian': 162, 'Canon': 163, 'Capitalism': 164, 'Cardinals': 165, 'Casino': 166, 'Cat': 167, 'Catcher': 168, 'Change': 169, 'Check': 170, 'Cheers': 171, 'Chelsea': 172, 'China': 173, 'Cholent': 174, 'Christmas': 175, 'Cities': 176, 'Classic': 177, 'Clean': 178, 'Cleavage': 179, 'Clouds': 180, 'College': 181, 'Colts': 182, 'Come': 183, 'Comments': 184, 'Communication': 185, 'Community': 186, 'Company': 187, 'Con': 188, 'Concussions': 189, 'Congrats': 190, 'Congratulations': 191, 'Consider': 192, 'Contenders': 193, 'Convenient': 194, 'Corgis': 195, 'Corinthians': 196, 'Corsi': 197, 'Could': 198, 'Covington': 199, 'Crazy': 200, 'Crickets': 201, 'Crocodile': 202, 'Crossing': 203, 'Cruelty': 204, 'Cry': 205, 'Cute': 206, 'D': 207, 'DAMN': 208, 'DB': 209, 'DEVICE': 210, 'DEVOTED': 211, 'DICE': 212, 'DIE': 213, 'DIG': 214, 'DIVE': 215, 'DM': 216, 'DO': 217, 'DOIN': 218, 'DON': 219, 'DOPE': 220, 'DR': 221, 'DREAM': 222, 'DSJ': 223, 'Dachshund': 224, 'Dad': 225, 'Damn': 226, 'Danganronpa': 227, 'Darth': 228, 'Day': 229, 'Deal': 230, 'December': 231, 'Defense': 232, 'Define': 233, 'Definitely': 234, 'Degrees': 235, 'Del': 236, 'Deluxe': 237, 'Democrips': 238, 'Demographics': 239, 'Despite': 240, 'Detective': 241, 'Detroit': 242, 'Did': 243, 'Didn': 244, 'Didnt': 245, 'Ding': 246, 'Dirty': 247, 'Disagree': 248, 'Disco': 249, 'Discord': 250, 'Discovery': 251, 'Disease': 252, 'Do': 253, 'Does': 254, 'Doesn': 255, 'Don': 256, 'Done': 257, 'Dont': 258, 'Donut': 259, 'Doordash': 260, 'Dornish': 261, 'Dosing': 262, 'Down': 263, 'Dragonpit': 264, 'Drive': 265, 'Dude': 266, 'Dumbass': 267, 'Dunder': 268, 'Dv': 269, 'E': 270, 'ED': 271, 'EDIT': 272, 'ENGLAND': 273, 'ERA': 274, 'ESPN': 275, 'EST': 276, 'EU': 277, 'EVERYONE': 278, 'EXO': 279, 'Earth': 280, 'Easy': 281, 'Eat': 282, 'Edit': 283, 'Edited': 284, 'Either': 285, 'Ellsworth': 286, 'Embarrassing': 287, 'Emotes': 288, 'Enchanted': 289, 'English': 290, 'Enjoy': 291, 'Esp': 292, 'Especially': 293, 'Estee': 294, 'Europe': 295, 'Even': 296, 'Eventually': 297, 'Every': 298, 'Everyday': 299, 'Everyone': 300, 'Everywhere': 301, 'Exactly': 302, 'Excellent': 303, 'Except': 304, 'Executive': 305, 'F': 306, 'FBI': 307, 'FIGHT': 308, 'FINISH': 309, 'FIRE': 310, 'FOR': 311, 'FPS': 312, 'FPTP': 313, 'FUCK': 314, 'FURRIES': 315, 'FURRY': 316, 'Fab': 317, 'Fake': 318, 'Fall': 319, 'Family': 320, 'Famous': 321, 'Fantasy': 322, 'Fcuk': 323, 'Feel': 324, 'Fiddish': 325, 'Film': 326, 'Final': 327, 'Finale': 328, 'Finally': 329, 'Fine': 330, 'Fk': 331, 'Florence': 332, 'Focus': 333, 'Food': 334, 'For': 335, 'Forgive': 336, 'Found': 337, 'Frankly': 338, 'Friends': 339, 'From': 340, 'Fruit': 341, 'Fuck': 342, 'Fucking': 343, 'Funny': 344, 'G': 345, 'GAMERS': 346, 'GG': 347, 'GIRL': 348, 'GO': 349, 'GOD': 350, 'GOING': 351, 'GT': 352, 'Galaxy': 353, 'Gamers': 354, 'Gap': 355, 'Gather': 356, 'Genius': 357, 'Gentle': 358, 'Genuinely': 359, 'Germans': 360, 'Germany': 361, 'Get': 362, 'Getting': 363, 'Girl': 364, 'Girls': 365, 'Give': 366, 'Glad': 367, 'Glucose': 368, 'Go': 369, 'God': 370, 'Godlish': 371, 'Good': 372, 'Google': 373, 'Got': 374, 'Gotta': 375, 'Government': 376, 'Granville': 377, 'Great': 378, 'Greetings': 379, 'Gross': 380, 'Growing': 381, 'Guadalupe': 382, 'Guardian': 383, 'Guess': 384, 'Guy': 385, 'HA': 386, 'HAD': 387, 'HAHAHAHHA': 388, 'HATE': 389, 'HEAD': 390, 'HER': 391, 'HIGHS': 392, 'HIT': 393, 'HOPE': 394, 'HR': 395, 'Ha': 396, 'Haha': 397, 'Hahaha': 398, 'Hanoi': 399, 'Happy': 400, 'HappyFriendlyBot': 401, 'Hard': 402, 'Harris': 403, 'Has': 404, 'Hate': 405, 'Have': 406, 'Having': 407, 'Hawks': 408, 'He': 409, 'Hearts': 410, 'Hell': 411, 'Hello': 412, 'Her': 413, 'Here': 414, 'Hey': 415, 'Hi': 416, 'His': 417, 'Hitting': 418, 'Hiya': 419, 'Hm': 420, 'Hmm': 421, 'Hmmm': 422, 'Hollywood': 423, 'Holy': 424, 'Honestly': 425, 'Honey': 426, 'Hope': 427, 'Hopefully': 428, 'Horns': 429, 'House': 430, 'Houston': 431, 'How': 432, 'Hugs': 433, 'Huh': 434, 'Hun': 435, 'Hungover': 436, 'Hut': 437, 'HvV': 438, 'Hypocrisy': 439, 'I': 440, 'IIRC': 441, 'IMAX': 442, 'INTO': 443, 'IQ': 444, 'IRL': 445, 'IS': 446, 'ISO': 447, 'ISOING': 448, 'IT': 449, 'ITS': 450, 'Ice': 451, 'Idk': 452, 'If': 453, 'Iike': 454, 'Ikr': 455, 'Ill': 456, 'Im': 457, 'Imagine': 458, 'In': 459, 'Insecurities': 460, 'InshAllah': 461, 'Instagram': 462, 'Institute': 463, 'Interesting': 464, 'Intergul': 465, 'Irish': 466, 'Is': 467, 'Island': 468, 'It': 469, 'Its': 470, 'JOB': 471, 'Jabba': 472, 'January': 473, 'Japanese': 474, 'Jedi': 475, 'Jogfrey': 476, 'Judiasm': 477, 'Just': 478, 'Juul': 479, 'K': 480, 'KILL': 481, 'KING': 482, 'KNOWS': 483, 'KOTOR': 484, 'KUwtK': 485, 'Keep': 486, 'Kemba': 487, 'Ken': 488, 'Kids': 489, 'Killers': 490, 'Kinda': 491, 'Klokslag': 492, 'Korean': 493, 'L': 494, 'LAMZY': 495, 'LAY': 496, 'LIBTARD': 497, 'LIGHT': 498, 'LMAO': 499, 'LMFAO': 500, 'LOL': 501, 'LOUD': 502, 'LOVE': 503, 'LaPorte': 504, 'Labour': 505, 'Lady': 506, 'Lancaster': 507, 'Land': 508, 'Large': 509, 'Last': 510, 'Lauder': 511, 'Laugh': 512, 'Layg': 513, 'Legs': 514, 'Let': 515, 'Lets': 516, 'Licence': 517, 'Life': 518, 'Light': 519, 'Like': 520, 'Lin': 521, 'Lined': 522, 'Literally': 523, 'Living': 524, 'Lma': 525, 'Lmao': 526, 'Lmaoooo': 527, 'Lmfao': 528, 'Lol': 529, 'London': 530, 'Long': 531, 'Look': 532, 'Looking': 533, 'Looks': 534, 'Lord': 535, 'Lost': 536, 'Lots': 537, 'Love': 538, 'Luck': 539, 'Lucky': 540, 'Luv': 541, 'MA': 542, 'MAKE': 543, 'MAN': 544, 'MC': 545, 'ME': 546, 'MEDICAL': 547, 'MEEEEEEEEE': 548, 'MIL': 549, 'MLs': 550, 'MY': 551, 'Ma': 552, 'Mah': 553, 'Main': 554, 'Make': 555, 'Makes': 556, 'Man': 557, 'Manchester': 558, 'Mark': 559, 'Mate': 560, 'May': 561, 'Maybe': 562, 'McAllen': 563, 'McDonald': 564, 'McDonalds': 565, 'Me': 566, 'Mean': 567, 'Meant': 568, 'Medley': 569, 'Michelin': 570, 'Michigan': 571, 'Midwest': 572, 'Mifflin': 573, 'Might': 574, 'Mikans': 575, 'Millport': 576, 'Millsbury': 577, 'Mine': 578, 'Minnesota': 579, 'Miskatonic': 580, 'Miss': 581, 'Missing': 582, 'Mmm': 583, 'Mmmmmm': 584, 'Mom': 585, 'Monday': 586, 'Monster': 587, 'Monte': 588, 'More': 589, 'Most': 590, 'Mostly': 591, 'Mountain': 592, 'Mr': 593, 'Mrs': 594, 'Ms': 595, 'Much': 596, 'Music': 597, 'Must': 598, 'My': 599, 'NAP': 600, 'NEED': 601, 'NERVE': 602, 'NEVER': 603, 'NJ': 604, 'NO': 605, 'NOT': 606, 'NOTHING': 607, 'NT': 608, 'Nah': 609, 'Nature': 610, 'Needs': 611, 'Nemo': 612, 'Netflix': 613, 'Never': 614, 'New': 615, 'NewTubers': 616, 'News': 617, 'Next': 618, 'Nice': 619, 'No': 620, 'Nobody': 621, 'Noooo': 622, 'Nooooo': 623, 'Nope': 624, 'Not': 625, 'Nothing': 626, 'November': 627, 'Now': 628, 'O': 629, 'OG': 630, 'OH': 631, 'OK': 632, 'OLD': 633, 'OMG': 634, 'ON': 635, 'ONLY': 636, 'OP': 637, 'OPEN': 638, 'OR': 639, 'OTHER': 640, 'OUT': 641, 'OWL': 642, 'Obviously': 643, 'Of': 644, 'Ofc': 645, 'Offense': 646, 'Oh': 647, 'Ohhh': 648, 'Oilers': 649, 'Ok': 650, 'Okay': 651, 'Olympics': 652, 'OmG': 653, 'Omg': 654, 'On': 655, 'One': 656, 'Only': 657, 'Ontario': 658, 'Ooh': 659, 'Oohhooo': 660, 'Oooff': 661, 'Ooohhh': 662, 'Ooooh': 663, 'Ooooooo': 664, 'Oops': 665, 'Or': 666, 'Other': 667, 'Ouch': 668, 'Out': 669, 'Outlaws': 670, 'Outrageous': 671, 'Overpriced': 672, 'Oww': 673, 'Oy': 674, 'PARENTS': 675, 'PASS': 676, 'PAT': 677, 'PAY': 678, 'PERFECT': 679, 'PK': 680, 'PLACE': 681, 'PM': 682, 'POLICE': 683, 'PR': 684, 'PUNISHER': 685, 'PUNISHING': 686, 'Packers': 687, 'Panic': 688, 'Pansexual': 689, 'Parents': 690, 'Parliament': 691, 'Party': 692, 'Pats': 693, 'Pay': 694, 'Pentagon': 695, 'People': 696, 'Per': 697, 'Perhaps': 698, 'Personally': 699, 'Peru': 700, 'PhD': 701, 'Photoshop': 702, 'Pig': 703, 'Pine': 704, 'PlAyOfFs': 705, 'Plagueis': 706, 'Planning': 707, 'Please': 708, 'Plot': 709, 'Plus': 710, 'Plz': 711, 'Poeling': 712, 'Polarizing': 713, 'Police': 714, 'Polygamy': 715, 'Poopels': 716, 'Poor': 717, 'Poverty': 718, 'Ppl': 719, 'Praise': 720, 'Praying': 721, 'Prestigious': 722, 'Pretend': 723, 'Pretty': 724, 'Probably': 725, 'Problem': 726, 'Prospect': 727, 'Puerto': 728, 'Pulling': 729, 'QB': 730, 'QUARANTINE': 731, 'Questions': 732, 'R': 733, 'RADIANCE': 734, 'RAGE': 735, 'RCIA': 736, 'REALLY': 737, 'RIGHT': 738, 'RIP': 739, 'RISE': 740, 'RL': 741, 'Ranch': 742, 'Rare': 743, 'Reacted': 744, 'Read': 745, 'Reality': 746, 'Really': 747, 'Rebloodicans': 748, 'Recipe': 749, 'Recover': 750, 'Recovery': 751, 'Reddit': 752, 'Refrigerators': 753, 'Remain': 754, 'Remainer': 755, 'Repost': 756, 'Republican': 757, 'Resistance': 758, 'Respect': 759, 'Rest': 760, 'Rican': 761, 'Ridiculously': 762, 'Right': 763, 'Ripping': 764, 'Rocket': 765, 'Rowan': 766, 'Rumor': 767, 'Rupple': 768, 'S': 769, 'SAME': 770, 'SB': 771, 'SC': 772, 'SCUM': 773, 'SEEMS': 774, 'SHARK': 775, 'SHE': 776, 'SHOOT': 777, 'SHOULD': 778, 'SILVER': 779, 'SMILING': 780, 'SNP': 781, 'SO': 782, 'SOLIDARITY': 783, 'STILL': 784, 'SUBREDDITDRAMA': 785, 'SUPPORTIVE': 786, 'Sack': 787, 'Sad': 788, 'Sadly': 789, 'Same': 790, 'Samsung': 791, 'Santa': 792, 'Savior': 793, 'Say': 794, 'Saying': 795, 'Says': 796, 'Scrambled': 797, 'Scripted': 798, 'Season': 799, 'See': 800, 'Seeing': 801, 'Seems': 802, 'Seinfeld': 803, 'Sending': 804, 'Seoul': 805, 'Seriously': 806, 'Set': 807, 'Shades': 808, 'Shame': 809, 'Sharpton': 810, 'She': 811, 'Shit': 812, 'Shock': 813, 'Shooooulderrrrr': 814, 'Shot': 815, 'Should': 816, 'Shouldn': 817, 'Show': 818, 'Sigh': 819, 'Sigma': 820, 'Simultaneously': 821, 'Since': 822, 'Singapore': 823, 'Sippinthatminttea': 824, 'Skynet': 825, 'Slowing': 826, 'Smh': 827, 'Smurfs': 828, 'So': 829, 'Some': 830, 'Someone': 831, 'Sometimes': 832, 'Son': 833, 'Sony': 834, 'Soon': 835, 'Sooo': 836, 'Sorry': 837, 'Sounds': 838, 'Source': 839, 'South': 840, 'Southern': 841, 'Spanish': 842, 'Special': 843, 'Spend': 844, 'Spending': 845, 'Spent': 846, 'Spotify': 847, 'Star': 848, 'Stay': 849, 'Steelers': 850, 'Still': 851, 'StirS': 852, 'Stole': 853, 'Stop': 854, 'Stuff': 855, 'Stupidly': 856, 'Success': 857, 'Such': 858, 'Sucks': 859, 'Suiderstrand': 860, 'Super': 861, 'Sure': 862, 'Surprising': 863, 'Switch': 864, 'T': 865, 'TEAM': 866, 'TED': 867, 'TEXT': 868, 'THAT': 869, 'THE': 870, 'THEN': 871, 'THERE': 872, 'THIS': 873, 'TIHI': 874, 'TIME': 875, 'TIMES': 876, 'TL': 877, 'TLJ': 878, 'TNG': 879, 'TO': 880, 'TOO': 881, 'TSN': 882, 'TTT': 883, 'TURTLES': 884, 'TV': 885, 'TY': 886, 'Taco': 887, 'Tail': 888, 'Take': 889, 'Talked': 890, 'Tamaki': 891, 'Tbh': 892, 'Team': 893, 'Technically': 894, 'Tekken': 895, 'Thank': 896, 'Thanks': 897, 'That': 898, 'Thats': 899, 'The': 900, 'TheQTVain': 901, 'Their': 902, 'Then': 903, 'There': 904, 'These': 905, 'They': 906, 'Think': 907, 'This': 908, 'Those': 909, 'ThotAudit': 910, 'Three': 911, 'Thrive': 912, 'Thx': 913, 'Ties': 914, 'Tiger': 915, 'Times': 916, 'Tire': 917, 'Tis': 918, 'To': 919, 'Today': 920, 'Tomlin': 921, 'Top': 922, 'Toronto': 923, 'Totally': 924, 'Tournament': 925, 'Trilogy': 926, 'Troll': 927, 'Troo': 928, 'Trouser': 929, 'True': 930, 'Truth': 931, 'Try': 932, 'Tuesdays': 933, 'Tv': 934, 'Twas': 935, 'Twilight': 936, 'Twin': 937, 'Twitter': 938, 'U': 939, 'UK': 940, 'UP': 941, 'US': 942, 'USA': 943, 'USC': 944, 'Ugh': 945, 'Uh': 946, 'Umm': 947, 'Uncle': 948, 'Under': 949, 'Underrated': 950, 'Understandable': 951, 'Underwater': 952, 'Unfortunately': 953, 'UnicORn': 954, 'United': 955, 'Universities': 956, 'Unleash': 957, 'Unless': 958, 'Until': 959, 'Up': 960, 'Updooted': 961, 'Use': 962, 'Useless': 963, 'Utah': 964, 'VOLCEL': 965, 'Vampire': 966, 'Venti': 967, 'Very': 968, 'View': 969, 'WALL': 970, 'WAS': 971, 'WE': 972, 'WHAT': 973, 'WHERE': 974, 'WHO': 975, 'WHY': 976, 'WITH': 977, 'WOW': 978, 'WTFuckery': 979, 'Wait': 980, 'Walk': 981, 'WallStreetBets': 982, 'Wankers': 983, 'Want': 984, 'Wars': 985, 'Was': 986, 'Wash': 987, 'Wat': 988, 'Way': 989, 'We': 990, 'Weather': 991, 'Wednesday': 992, 'Weird': 993, 'Welcome': 994, 'Well': 995, 'What': 996, 'Whatever': 997, 'Whats': 998, 'When': 999, 'Whenever': 1000, 'Where': 1001, 'Which': 1002, 'Whisper': 1003, 'White': 1004, 'Who': 1005, 'Wholesome': 1006, 'Whoops': 1007, 'Why': 1008, 'Wild': 1009, 'Will': 1010, 'Windbreakers': 1011, 'Windows': 1012, 'Wish': 1013, 'With': 1014, 'Wizards': 1015, 'Wolf': 1016, 'Woman': 1017, 'Won': 1018, 'Wonder': 1019, 'Working': 1020, 'Would': 1021, 'Wouldn': 1022, 'Wow': 1023, 'Wtf': 1024, 'Wu': 1025, 'XIV': 1026, 'XL': 1027, 'YA': 1028, 'YELLOW': 1029, 'YES': 1030, 'YOU': 1031, 'Ya': 1032, 'Yea': 1033, 'Yeah': 1034, 'Yeahhhh': 1035, 'Year': 1036, 'Years': 1037, 'Yellowstone': 1038, 'Yep': 1039, 'Yes': 1040, 'Yet': 1041, 'Yikes': 1042, 'Yo': 1043, 'You': 1044, 'Your': 1045, 'Yum': 1046, 'Yup': 1047, 'Zion': 1048, 'a': 1049, 'abandoned': 1050, 'abby': 1051, 'able': 1052, 'about': 1053, 'above': 1054, 'absolute': 1055, 'absolutely': 1056, 'abstract': 1057, 'abt': 1058, 'abused': 1059, 'abuses': 1060, 'abusive': 1061, 'ac': 1062, 'accent': 1063, 'accept': 1064, 'accepted': 1065, 'access': 1066, 'accident': 1067, 'accidentally': 1068, 'according': 1069, 'account': 1070, 'accurate': 1071, 'accurately': 1072, 'achievements': 1073, 'acknowledge': 1074, 'across': 1075, 'acting': 1076, 'action': 1077, 'active': 1078, 'actress': 1079, 'acts': 1080, 'actual': 1081, 'actually': 1082, 'ad': 1083, 'add': 1084, 'added': 1085, 'addiction': 1086, 'additional': 1087, 'additions': 1088, 'address': 1089, 'adjustments': 1090, 'admin': 1091, 'admit': 1092, 'adorable': 1093, 'adore': 1094, 'advantage': 1095, 'advertised': 1096, 'advertising': 1097, 'advice': 1098, 'advocate': 1099, 'af': 1100, 'afford': 1101, 'afraid': 1102, 'after': 1103, 'again': 1104, 'against': 1105, 'age': 1106, 'agencies': 1107, 'aggressive': 1108, 'ago': 1109, 'agree': 1110, 'agreed': 1111, 'ahead': 1112, 'ahhh': 1113, 'ahrar': 1114, 'aht': 1115, 'ain': 1116, 'air': 1117, 'aired': 1118, 'akhi': 1119, 'al': 1120, 'alaykum': 1121, 'album': 1122, 'albums': 1123, 'alcohol': 1124, 'alerted': 1125, 'alive': 1126, 'all': 1127, 'allowed': 1128, 'allstar': 1129, 'almond': 1130, 'almost': 1131, 'alone': 1132, 'along': 1133, 'alp': 1134, 'alphabet': 1135, 'already': 1136, 'alright': 1137, 'also': 1138, 'alt': 1139, 'alternative': 1140, 'although': 1141, 'always': 1142, 'am': 1143, 'amazed': 1144, 'amazing': 1145, 'ambulance': 1146, 'amigo': 1147, 'among': 1148, 'amount': 1149, 'an': 1150, 'anabolic': 1151, 'analogies': 1152, 'analogy': 1153, 'analysis': 1154, 'and': 1155, 'angels': 1156, 'angry': 1157, 'animal': 1158, 'animals': 1159, 'anniversary': 1160, 'announced': 1161, 'announcing': 1162, 'annoyed': 1163, 'annoying': 1164, 'another': 1165, 'ant': 1166, 'anti': 1167, 'antivaxxers': 1168, 'antsy': 1169, 'anxiety': 1170, 'anxious': 1171, 'anxiously': 1172, 'any': 1173, 'anybody': 1174, 'anymore': 1175, 'anyone': 1176, 'anything': 1177, 'anyway': 1178, 'apart': 1179, 'aperol': 1180, 'apologies': 1181, 'apologize': 1182, 'app': 1183, 'apparently': 1184, 'appearance': 1185, 'applaud': 1186, 'apple': 1187, 'applies': 1188, 'appreciate': 1189, 'appreciated': 1190, 'approaching': 1191, 'appropriate': 1192, 'appropriately': 1193, 'appropriations': 1194, 'approval': 1195, 'approve': 1196, 'approximately': 1197, 'architect': 1198, 'are': 1199, 'area': 1200, 'areas': 1201, 'aren': 1202, 'arent': 1203, 'arguing': 1204, 'argument': 1205, 'arms': 1206, 'around': 1207, 'arrest': 1208, 'arrested': 1209, 'arrive': 1210, 'arse': 1211, 'arsehole': 1212, 'art': 1213, 'article': 1214, 'artistic': 1215, 'as': 1216, 'asf': 1217, 'ashamed': 1218, 'aside': 1219, 'asinine': 1220, 'ask': 1221, 'asked': 1222, 'asking': 1223, 'asleep': 1224, 'asm': 1225, 'aspergers': 1226, 'ass': 1227, 'assalamu': 1228, 'asshole': 1229, 'assholes': 1230, 'asst': 1231, 'assume': 1232, 'assuming': 1233, 'assumption': 1234, 'assured': 1235, 'at': 1236, 'ate': 1237, 'atheist': 1238, 'atmosphere': 1239, 'attacks': 1240, 'attention': 1241, 'attorney': 1242, 'attractive': 1243, 'audience': 1244, 'audio': 1245, 'auld': 1246, 'aunt': 1247, 'author': 1248, 'authorities': 1249, 'autism': 1250, 'autistic': 1251, 'autocorrect': 1252, 'autograt': 1253, 'automatically': 1254, 'autonomy': 1255, 'available': 1256, 'avatar': 1257, 'avatars': 1258, 'average': 1259, 'avoid': 1260, 'avoided': 1261, 'aw': 1262, 'awake': 1263, 'awareness': 1264, 'away': 1265, 'awe': 1266, 'awesome': 1267, 'awful': 1268, 'awkward': 1269, 'awoke': 1270, 'b': 1271, 'babcuck': 1272, 'baby': 1273, 'back': 1274, 'background': 1275, 'backstabbing': 1276, 'bad': 1277, 'badass': 1278, 'badboy': 1279, 'baffles': 1280, 'bag': 1281, 'bahaha': 1282, 'baking': 1283, 'balance': 1284, 'bald': 1285, 'ball': 1286, 'band': 1287, 'bango': 1288, 'bank': 1289, 'banked': 1290, 'banned': 1291, 'bar': 1292, 'bare': 1293, 'barely': 1294, 'barreling': 1295, 'bars': 1296, 'bartenders': 1297, 'base': 1298, 'based': 1299, 'bashing': 1300, 'basic': 1301, 'basically': 1302, 'basing': 1303, 'basket': 1304, 'bastard': 1305, 'bathroom': 1306, 'battery': 1307, 'battlefront': 1308, 'bby': 1309, 'bc': 1310, 'be': 1311, 'beach': 1312, 'beard': 1313, 'beat': 1314, 'beautiful': 1315, 'beauty': 1316, 'became': 1317, 'because': 1318, 'become': 1319, 'becomes': 1320, 'bed': 1321, 'bedroom': 1322, 'been': 1323, 'beer': 1324, 'before': 1325, 'behind': 1326, 'being': 1327, 'beings': 1328, 'belief': 1329, 'believable': 1330, 'believe': 1331, 'below': 1332, 'bench': 1333, 'best': 1334, 'bet': 1335, 'betray': 1336, 'betrayed': 1337, 'better': 1338, 'betting': 1339, 'between': 1340, 'bew': 1341, 'beyond': 1342, 'bible': 1343, 'bid': 1344, 'big': 1345, 'biggest': 1346, 'bill': 1347, 'billions': 1348, 'binged': 1349, 'bio': 1350, 'birthday': 1351, 'bisexual': 1352, 'bison': 1353, 'bit': 1354, 'bitch': 1355, 'bitcoin': 1356, 'bitcoins': 1357, 'bite': 1358, 'bitter': 1359, 'bizarre': 1360, 'black': 1361, 'bladder': 1362, 'blame': 1363, 'blamed': 1364, 'bland': 1365, 'blasphemous': 1366, 'blast': 1367, 'bleeding': 1368, 'blessing': 1369, 'blindfolds': 1370, 'blindness': 1371, 'block': 1372, 'blocked': 1373, 'blocks': 1374, 'bloke': 1375, 'blonde': 1376, 'blood': 1377, 'blooded': 1378, 'bloody': 1379, 'blows': 1380, 'blue': 1381, 'blunt': 1382, 'blurred': 1383, 'board': 1384, 'boards': 1385, 'boat': 1386, 'bodily': 1387, 'body': 1388, 'boggling': 1389, 'boiled': 1390, 'bollocks': 1391, 'bolt': 1392, 'bomb': 1393, 'bombs': 1394, 'bonkers': 1395, 'bonus': 1396, 'book': 1397, 'books': 1398, 'booming': 1399, 'boots': 1400, 'booze': 1401, 'bore': 1402, 'bored': 1403, 'boring': 1404, 'bot': 1405, 'both': 1406, 'bother': 1407, 'bothers': 1408, 'bottle': 1409, 'bottom': 1410, 'bought': 1411, 'bout': 1412, 'bowler': 1413, 'box': 1414, 'boxing': 1415, 'boy': 1416, 'boycotting': 1417, 'boyfriend': 1418, 'boys': 1419, 'brah': 1420, 'brain': 1421, 'brainless': 1422, 'brainwash': 1423, 'branch': 1424, 'brave': 1425, 'break': 1426, 'breaking': 1427, 'breaks': 1428, 'breath': 1429, 'breed': 1430, 'bridesmaids': 1431, 'bridges': 1432, 'brig': 1433, 'brilliant': 1434, 'brimming': 1435, 'bring': 1436, 'bringing': 1437, 'bro': 1438, 'broadcaster': 1439, 'broke': 1440, 'broken': 1441, 'brother': 1442, 'brought': 1443, 'brownie': 1444, 'brows': 1445, 'brush': 1446, 'brushing': 1447, 'btw': 1448, 'buckaroo': 1449, 'buddy': 1450, 'bug': 1451, 'build': 1452, 'building': 1453, 'built': 1454, 'bull': 1455, 'bullied': 1456, 'bump': 1457, 'bunch': 1458, 'bunk': 1459, 'bunnies': 1460, 'burden': 1461, 'burdening': 1462, 'burn': 1463, 'burned': 1464, 'burner': 1465, 'burns': 1466, 'burnt': 1467, 'bus': 1468, 'business': 1469, 'busy': 1470, 'but': 1471, 'butchers': 1472, 'buttcoin': 1473, 'butter': 1474, 'button': 1475, 'butts': 1476, 'buy': 1477, 'buying': 1478, 'buzzkill': 1479, 'by': 1480, 'bye': 1481, 'byfar': 1482, 'cable': 1483, 'cake': 1484, 'cakeday': 1485, 'call': 1486, 'called': 1487, 'calling': 1488, 'calorie': 1489, 'came': 1490, 'camera': 1491, 'cameraman': 1492, 'campaign': 1493, 'can': 1494, 'candidates': 1495, 'candles': 1496, 'canister': 1497, 'cannon': 1498, 'cannot': 1499, 'cant': 1500, 'cape': 1501, 'car': 1502, 'carbs': 1503, 'care': 1504, 'career': 1505, 'careful': 1506, 'carried': 1507, 'cartoon': 1508, 'case': 1509, 'cash': 1510, 'casino': 1511, 'cast': 1512, 'cat': 1513, 'catch': 1514, 'catching': 1515, 'caters': 1516, 'catgirl': 1517, 'cats': 1518, 'catsup': 1519, 'cattle': 1520, 'caught': 1521, 'cause': 1522, 'causes': 1523, 'cave': 1524, 'celebrity': 1525, 'center': 1526, 'centrists': 1527, 'cents': 1528, 'certain': 1529, 'cesspool': 1530, 'cha': 1531, 'challenge': 1532, 'champion': 1533, 'chance': 1534, 'chances': 1535, 'change': 1536, 'changed': 1537, 'chanting': 1538, 'character': 1539, 'characters': 1540, 'charas': 1541, 'charge': 1542, 'charger': 1543, 'charges': 1544, 'charitable': 1545, 'charming': 1546, 'charts': 1547, 'chased': 1548, 'chat': 1549, 'chatbox': 1550, 'chatty': 1551, 'cheap': 1552, 'cheat': 1553, 'check': 1554, 'checking': 1555, 'cheeky': 1556, 'cheer': 1557, 'cheered': 1558, 'cheerleader': 1559, 'cheese': 1560, 'cheesecake': 1561, 'cheesy': 1562, 'chef': 1563, 'chest': 1564, 'chevre': 1565, 'chick': 1566, 'chicken': 1567, 'chicks': 1568, 'chiefs': 1569, 'child': 1570, 'children': 1571, 'chills': 1572, 'china': 1573, 'chinook': 1574, 'chips': 1575, 'choice': 1576, 'choke': 1577, 'choose': 1578, 'chorizo': 1579, 'chosen': 1580, 'chuckle': 1581, 'chucklefuck': 1582, 'church': 1583, 'ciao': 1584, 'circa': 1585, 'circle': 1586, 'citizen': 1587, 'city': 1588, 'ck': 1589, 'claim': 1590, 'claiming': 1591, 'clap': 1592, 'clapped': 1593, 'claps': 1594, 'clarifying': 1595, 'class': 1596, 'classes': 1597, 'clean': 1598, 'clear': 1599, 'clearly': 1600, 'clever': 1601, 'clicked': 1602, 'clinically': 1603, 'clone': 1604, 'close': 1605, 'closest': 1606, 'cloudy': 1607, 'clown': 1608, 'club': 1609, 'cmmon': 1610, 'cnn': 1611, 'co': 1612, 'coaching': 1613, 'coastal': 1614, 'coerces': 1615, 'coffee': 1616, 'coincidence': 1617, 'coke': 1618, 'cold': 1619, 'collabed': 1620, 'collars': 1621, 'collected': 1622, 'college': 1623, 'colliding': 1624, 'collors': 1625, 'color': 1626, 'colors': 1627, 'colour': 1628, 'come': 1629, 'comeback': 1630, 'comes': 1631, 'coming': 1632, 'command': 1633, 'comment': 1634, 'comments': 1635, 'commies': 1636, 'committing': 1637, 'common': 1638, 'communists': 1639, 'community': 1640, 'commute': 1641, 'comp': 1642, 'company': 1643, 'compares': 1644, 'compassionate': 1645, 'compete': 1646, 'competitive': 1647, 'complain': 1648, 'complete': 1649, 'completely': 1650, 'comrade': 1651, 'concede': 1652, 'concept': 1653, 'concern': 1654, 'concerned': 1655, 'concerning': 1656, 'concur': 1657, 'condition': 1658, 'conditions': 1659, 'condolences': 1660, 'confidence': 1661, 'confirm': 1662, 'confirmed': 1663, 'confirming': 1664, 'conflating': 1665, 'conforming': 1666, 'confusing': 1667, 'congrats': 1668, 'congratulation': 1669, 'connoisseur': 1670, 'consent': 1671, 'consequences': 1672, 'conservative': 1673, 'consider': 1674, 'considered': 1675, 'considering': 1676, 'consists': 1677, 'console': 1678, 'conspiracies': 1679, 'conspiracy': 1680, 'constantly': 1681, 'constellations': 1682, 'constituencies': 1683, 'constructive': 1684, 'contact': 1685, 'contacts': 1686, 'contempt': 1687, 'contender': 1688, 'context': 1689, 'continuous': 1690, 'contract': 1691, 'contractors': 1692, 'control': 1693, 'controlled': 1694, 'controller': 1695, 'conversation': 1696, 'convinced': 1697, 'convincing': 1698, 'convo': 1699, 'cook': 1700, 'cooked': 1701, 'cooking': 1702, 'cooks': 1703, 'cool': 1704, 'cop': 1705, 'cops': 1706, 'copy': 1707, 'corgis': 1708, 'corporations': 1709, 'correct': 1710, 'corrected': 1711, 'correcting': 1712, 'correlation': 1713, 'cosmos': 1714, 'costs': 1715, 'could': 1716, 'couldn': 1717, 'couldnt': 1718, 'count': 1719, 'countries': 1720, 'country': 1721, 'couple': 1722, 'couples': 1723, 'course': 1724, 'court': 1725, 'cow': 1726, 'coward': 1727, 'coworkers': 1728, 'crack': 1729, 'cracked': 1730, 'cradle': 1731, 'crafty': 1732, 'crash': 1733, 'crashing': 1734, 'crave': 1735, 'craving': 1736, 'crazy': 1737, 'cream': 1738, 'create': 1739, 'created': 1740, 'creates': 1741, 'creative': 1742, 'creativity': 1743, 'creature': 1744, 'creatures': 1745, 'creepy': 1746, 'creme': 1747, 'crime': 1748, 'cringe': 1749, 'cringes': 1750, 'criticised': 1751, 'cronies': 1752, 'crooks': 1753, 'cross': 1754, 'crossover': 1755, 'crossposts': 1756, 'crown': 1757, 'crucified': 1758, 'cry': 1759, 'crying': 1760, 'cucked': 1761, 'cuddle': 1762, 'cultural': 1763, 'cup': 1764, 'curated': 1765, 'curb': 1766, 'cured': 1767, 'curiosity': 1768, 'curious': 1769, 'cus': 1770, 'custard': 1771, 'customer': 1772, 'cut': 1773, 'cute': 1774, 'cutie': 1775, 'cuz': 1776, 'cynical': 1777, 'd': 1778, 'dad': 1779, 'daily': 1780, 'damage': 1781, 'damn': 1782, 'damned': 1783, 'damp': 1784, 'dan': 1785, 'dancers': 1786, 'dances': 1787, 'dancing': 1788, 'dangerous': 1789, 'dare': 1790, 'dark': 1791, 'darkness': 1792, 'dashers': 1793, 'data': 1794, 'date': 1795, 'dating': 1796, 'daughter': 1797, 'day': 1798, 'days': 1799, 'dayz': 1800, 'daze': 1801, 'dead': 1802, 'deadpan': 1803, 'deagle': 1804, 'deal': 1805, 'dealing': 1806, 'dear': 1807, 'death': 1808, 'debacle': 1809, 'debate': 1810, 'debating': 1811, 'debt': 1812, 'debunked': 1813, 'decent': 1814, 'decide': 1815, 'decides': 1816, 'deciding': 1817, 'decision': 1818, 'decisions': 1819, 'deck': 1820, 'declaration': 1821, 'declare': 1822, 'declined': 1823, 'declutter': 1824, 'deep': 1825, 'deeply': 1826, 'deer': 1827, 'def': 1828, 'defect': 1829, 'defective': 1830, 'defence': 1831, 'defended': 1832, 'defending': 1833, 'defense': 1834, 'defensive': 1835, 'definitely': 1836, 'definition': 1837, 'definitive': 1838, 'deflator': 1839, 'deja': 1840, 'delete': 1841, 'deleting': 1842, 'deliberately': 1843, 'deliriously': 1844, 'delirium': 1845, 'delivered': 1846, 'delusion': 1847, 'delusional': 1848, 'demanding': 1849, 'denial': 1850, 'denotation': 1851, 'dense': 1852, 'deny': 1853, 'depends': 1854, 'depressed': 1855, 'depressing': 1856, 'depth': 1857, 'deride': 1858, 'described': 1859, 'desert': 1860, 'deserve': 1861, 'deserved': 1862, 'deserves': 1863, 'designers': 1864, 'desire': 1865, 'desk': 1866, 'desperately': 1867, 'desperation': 1868, 'despite': 1869, 'destination': 1870, 'destroy': 1871, 'destroyed': 1872, 'destruction': 1873, 'detail': 1874, 'determination': 1875, 'determined': 1876, 'devastating': 1877, 'develop': 1878, 'development': 1879, 'devil': 1880, 'devoid': 1881, 'dialogue': 1882, 'dictate': 1883, 'did': 1884, 'didn': 1885, 'didnt': 1886, 'die': 1887, 'died': 1888, 'difference': 1889, 'differences': 1890, 'different': 1891, 'difficult': 1892, 'digestive': 1893, 'diggah': 1894, 'digital': 1895, 'dignified': 1896, 'dinosaur': 1897, 'direct': 1898, 'directly': 1899, 'director': 1900, 'disagrees': 1901, 'disappointed': 1902, 'disappointing': 1903, 'disappoints': 1904, 'disc': 1905, 'disco': 1906, 'discovered': 1907, 'discovering': 1908, 'discrepancy': 1909, 'discriminated': 1910, 'discussing': 1911, 'discussions': 1912, 'diseases': 1913, 'disgrace': 1914, 'disgusted': 1915, 'disgusting': 1916, 'dishes': 1917, 'dislike': 1918, 'disorder': 1919, 'dispenser': 1920, 'disrespect': 1921, 'disrespected': 1922, 'distress': 1923, 'distributed': 1924, 'disturbing': 1925, 'diverse': 1926, 'diversity': 1927, 'divorced': 1928, 'dizzy': 1929, 'do': 1930, 'doctor': 1931, 'doctored': 1932, 'documentary': 1933, 'docuseries': 1934, 'does': 1935, 'doesn': 1936, 'dog': 1937, 'doggie': 1938, 'doggos': 1939, 'dogs': 1940, 'doing': 1941, 'dominatrix': 1942, 'don': 1943, 'done': 1944, 'dont': 1945, 'door': 1946, 'doorbell': 1947, 'double': 1948, 'doubt': 1949, 'doubts': 1950, 'down': 1951, 'downvote': 1952, 'downvoted': 1953, 'downvotes': 1954, 'dr': 1955, 'draft': 1956, 'drama': 1957, 'draws': 1958, 'dream': 1959, 'dreams': 1960, 'dressed': 1961, 'drink': 1962, 'drive': 1963, 'driver': 1964, 'drives': 1965, 'drop': 1966, 'dropped': 1967, 'drugs': 1968, 'drunk': 1969, 'dude': 1970, 'dudes': 1971, 'due': 1972, 'dui': 1973, 'dumb': 1974, 'dumbass': 1975, 'dumbest': 1976, 'dumped': 1977, 'dumpster': 1978, 'dunno': 1979, 'duped': 1980, 'during': 1981, 'dying': 1982, 'dysmorphia': 1983, 'e': 1984, 'eNoUgH': 1985, 'each': 1986, 'earlier': 1987, 'early': 1988, 'ears': 1989, 'easier': 1990, 'easily': 1991, 'easy': 1992, 'eat': 1993, 'eaters': 1994, 'eating': 1995, 'eban': 1996, 'economics': 1997, 'edge': 1998, 'educated': 1999, 'education': 2000, 'eels': 2001, 'effect': 2002, 'effort': 2003, 'efforts': 2004, 'eggs': 2005, 'eh': 2006, 'either': 2007, 'elated': 2008, 'elbows': 2009, 'elected': 2010, 'elevator': 2011, 'elitists': 2012, 'else': 2013, 'em': 2014, 'email': 2015, 'embarrassed': 2016, 'embarrassing': 2017, 'embarrassment': 2018, 'embrace': 2019, 'embracing': 2020, 'emergency': 2021, 'emoji': 2022, 'emotional': 2023, 'emotionally': 2024, 'emotions': 2025, 'empathy': 2026, 'employee': 2027, 'employment': 2028, 'empty': 2029, 'enamoured': 2030, 'encountered': 2031, 'encourage': 2032, 'encouragement': 2033, 'end': 2034, 'ended': 2035, 'endies': 2036, 'ending': 2037, 'endings': 2038, 'ends': 2039, 'energy': 2040, 'engaged': 2041, 'engineering': 2042, 'english': 2043, 'enjoy': 2044, 'enjoyable': 2045, 'enjoyed': 2046, 'enjoying': 2047, 'enlighten': 2048, 'enlightening': 2049, 'enough': 2050, 'enquiring': 2051, 'entered': 2052, 'entertaining': 2053, 'enthusiasm': 2054, 'entire': 2055, 'entitled': 2056, 'epic': 2057, 'episode': 2058, 'episodes': 2059, 'episoode': 2060, 'equally': 2061, 'erased': 2062, 'especially': 2063, 'essentially': 2064, 'etc': 2065, 'ethics': 2066, 'ethos': 2067, 'eugh': 2068, 'eve': 2069, 'even': 2070, 'evening': 2071, 'eventually': 2072, 'ever': 2073, 'every': 2074, 'everybody': 2075, 'everyday': 2076, 'everyone': 2077, 'everything': 2078, 'everythingggggg': 2079, 'everywhere': 2080, 'evidence': 2081, 'ex': 2082, 'exact': 2083, 'exactly': 2084, 'exaggeration': 2085, 'exam': 2086, 'example': 2087, 'examples': 2088, 'exceedingly': 2089, 'excellent': 2090, 'except': 2091, 'exception': 2092, 'exchanging': 2093, 'excited': 2094, 'exciting': 2095, 'excuse': 2096, 'execution': 2097, 'exercise': 2098, 'exhausting': 2099, 'exist': 2100, 'existed': 2101, 'existent': 2102, 'exit': 2103, 'exited': 2104, 'expect': 2105, 'expecting': 2106, 'expeditious': 2107, 'expensive': 2108, 'experience': 2109, 'experts': 2110, 'expired': 2111, 'explain': 2112, 'explained': 2113, 'explaining': 2114, 'explanation': 2115, 'explode': 2116, 'exploiting': 2117, 'explore': 2118, 'explorers': 2119, 'exposing': 2120, 'expressions': 2121, 'extinct': 2122, 'extra': 2123, 'extreme': 2124, 'extremely': 2125, 'eye': 2126, 'eyes': 2127, 'f': 2128, 'face': 2129, 'facemask': 2130, 'faces': 2131, 'facetime': 2132, 'facial': 2133, 'fact': 2134, 'factor': 2135, 'factory': 2136, 'facts': 2137, 'failed': 2138, 'failing': 2139, 'failure': 2140, 'fair': 2141, 'fairly': 2142, 'faith': 2143, 'fake': 2144, 'fall': 2145, 'fallen': 2146, 'falling': 2147, 'false': 2148, 'fam': 2149, 'family': 2150, 'famous': 2151, 'fan': 2152, 'fanfics': 2153, 'fans': 2154, 'far': 2155, 'farm': 2156, 'fart': 2157, 'fascinated': 2158, 'fascists': 2159, 'fast': 2160, 'faster': 2161, 'father': 2162, 'fatness': 2163, 'fault': 2164, 'fave': 2165, 'favorite': 2166, 'favorites': 2167, 'favourite': 2168, 'fear': 2169, 'feature': 2170, 'fed': 2171, 'feedback': 2172, 'feel': 2173, 'feeling': 2174, 'feelings': 2175, 'feels': 2176, 'feet': 2177, 'fell': 2178, 'fella': 2179, 'fellow': 2180, 'felt': 2181, 'fence': 2182, 'ferals': 2183, 'ferk': 2184, 'fest': 2185, 'festival': 2186, 'fetish': 2187, 'fever': 2188, 'few': 2189, 'fibre': 2190, 'fifteen': 2191, 'fight': 2192, 'fighter': 2193, 'fighting': 2194, 'fights': 2195, 'figure': 2196, 'files': 2197, 'film': 2198, 'filter': 2199, 'filters': 2200, 'filth': 2201, 'filthy': 2202, 'final': 2203, 'finally': 2204, 'financial': 2205, 'find': 2206, 'finding': 2207, 'finds': 2208, 'fine': 2209, 'finish': 2210, 'finished': 2211, 'finishing': 2212, 'fire': 2213, 'fired': 2214, 'first': 2215, 'fishing': 2216, 'fit': 2217, 'fix': 2218, 'fixing': 2219, 'fkn': 2220, 'flair': 2221, 'flaming': 2222, 'flash': 2223, 'flashbacks': 2224, 'flat': 2225, 'flavors': 2226, 'flavours': 2227, 'flew': 2228, 'flex': 2229, 'flight': 2230, 'flipping': 2231, 'floor': 2232, 'flop': 2233, 'flower': 2234, 'flowers': 2235, 'flu': 2236, 'fly': 2237, 'focus': 2238, 'focusing': 2239, 'folks': 2240, 'follow': 2241, 'follower': 2242, 'food': 2243, 'fool': 2244, 'foolish': 2245, 'foot': 2246, 'football': 2247, 'for': 2248, 'force': 2249, 'forced': 2250, 'foreigners': 2251, 'forever': 2252, 'forex': 2253, 'forget': 2254, 'forgettable': 2255, 'forgive': 2256, 'forgot': 2257, 'forgotten': 2258, 'form': 2259, 'forms': 2260, 'forth': 2261, 'fortunately': 2262, 'forum': 2263, 'forward': 2264, 'forwards': 2265, 'fotos': 2266, 'foul': 2267, 'found': 2268, 'four': 2269, 'frame': 2270, 'franchise': 2271, 'freakin': 2272, 'freaking': 2273, 'free': 2274, 'freezes': 2275, 'freezing': 2276, 'fresh': 2277, 'friend': 2278, 'friends': 2279, 'from': 2280, 'front': 2281, 'fruit': 2282, 'frustrating': 2283, 'frustrations': 2284, 'fry': 2285, 'fuck': 2286, 'fucking': 2287, 'fueles': 2288, 'full': 2289, 'fun': 2290, 'funky': 2291, 'funniest': 2292, 'funny': 2293, 'furry': 2294, 'future': 2295, 'fyi': 2296, 'gOoD': 2297, 'gain': 2298, 'galaxy': 2299, 'game': 2300, 'gameplay': 2301, 'gamer': 2302, 'games': 2303, 'gang': 2304, 'gangs': 2305, 'gangster': 2306, 'gapping': 2307, 'gatekeeping': 2308, 'gave': 2309, 'gemologist': 2310, 'gender': 2311, 'generalization': 2312, 'generally': 2313, 'generates': 2314, 'generation': 2315, 'generations': 2316, 'genius': 2317, 'genocide': 2318, 'gentle': 2319, 'genuine': 2320, 'genuinely': 2321, 'geometric': 2322, 'germs': 2323, 'gesture': 2324, 'get': 2325, 'gets': 2326, 'getting': 2327, 'gf': 2328, 'ghosted': 2329, 'ghoul': 2330, 'giant': 2331, 'gifs': 2332, 'gig': 2333, 'giggles': 2334, 'gimme': 2335, 'girl': 2336, 'girls': 2337, 'give': 2338, 'given': 2339, 'gives': 2340, 'giving': 2341, 'gl': 2342, 'glad': 2343, 'glam': 2344, 'glass': 2345, 'glasses': 2346, 'glitch': 2347, 'glow': 2348, 'go': 2349, 'goal': 2350, 'goals': 2351, 'god': 2352, 'goddamn': 2353, 'gods': 2354, 'goes': 2355, 'going': 2356, 'gold': 2357, 'golden': 2358, 'golf': 2359, 'gone': 2360, 'gonna': 2361, 'good': 2362, 'goodness': 2363, 'goodnewsforwomen': 2364, 'gooferton': 2365, 'goofy': 2366, 'googling': 2367, 'gorgeous': 2368, 'gorgeousss': 2369, 'gosh': 2370, 'got': 2371, 'gotcha': 2372, 'gotta': 2373, 'gotten': 2374, 'government': 2375, 'grade': 2376, 'grades': 2377, 'grandma': 2378, 'grandparent': 2379, 'granted': 2380, 'grateful': 2381, 'grazed': 2382, 'greasy': 2383, 'great': 2384, 'greedy': 2385, 'greyhounds': 2386, 'gritty': 2387, 'grooming': 2388, 'gross': 2389, 'grossed': 2390, 'grossest': 2391, 'ground': 2392, 'group': 2393, 'growing': 2394, 'grown': 2395, 'grungy': 2396, 'gtfo': 2397, 'guarantee': 2398, 'guess': 2399, 'guest': 2400, 'guilt': 2401, 'gun': 2402, 'guns': 2403, 'gurl': 2404, 'guts': 2405, 'guy': 2406, 'guys': 2407, 'gym': 2408, 'hElP': 2409, 'ha': 2410, 'habit': 2411, 'hacker': 2412, 'had': 2413, 'haha': 2414, 'hahaha': 2415, 'hair': 2416, 'haircut': 2417, 'haired': 2418, 'hairs': 2419, 'half': 2420, 'hall': 2421, 'hand': 2422, 'handed': 2423, 'handheld': 2424, 'handle': 2425, 'handout': 2426, 'hands': 2427, 'handsome': 2428, 'hang': 2429, 'hanging': 2430, 'hangover': 2431, 'happen': 2432, 'happened': 2433, 'happening': 2434, 'happens': 2435, 'happiness': 2436, 'happinesses': 2437, 'happy': 2438, 'harassed': 2439, 'harassing': 2440, 'hard': 2441, 'harder': 2442, 'hardly': 2443, 'hardware': 2444, 'harmful': 2445, 'harness': 2446, 'has': 2447, 'hat': 2448, 'hate': 2449, 'hated': 2450, 'hateful': 2451, 'hates': 2452, 'hav': 2453, 'have': 2454, 'haven': 2455, 'havin': 2456, 'having': 2457, 'hazmat': 2458, 'he': 2459, 'head': 2460, 'headbutt': 2461, 'headed': 2462, 'heads': 2463, 'healing': 2464, 'heals': 2465, 'health': 2466, 'healthcare': 2467, 'hear': 2468, 'heard': 2469, 'hearing': 2470, 'heart': 2471, 'heat': 2472, 'heck': 2473, 'hectic': 2474, 'heed': 2475, 'heels': 2476, 'hehe': 2477, 'hell': 2478, 'help': 2479, 'helped': 2480, 'helpful': 2481, 'helps': 2482, 'her': 2483, 'here': 2484, 'heresy': 2485, 'hero': 2486, 'herself': 2487, 'hershey': 2488, 'hes': 2489, 'hey': 2490, 'hid': 2491, 'hidden': 2492, 'hide': 2493, 'high': 2494, 'highest': 2495, 'highkey': 2496, 'highly': 2497, 'highs': 2498, 'hilarious': 2499, 'him': 2500, 'himself': 2501, 'hip': 2502, 'hippies': 2503, 'hire': 2504, 'his': 2505, 'historical': 2506, 'hit': 2507, 'hitter': 2508, 'hitting': 2509, 'hive': 2510, 'hmm': 2511, 'hmmm': 2512, 'hmmmmm': 2513, 'hmr': 2514, 'hobby': 2515, 'hockey': 2516, 'hold': 2517, 'holdem': 2518, 'holding': 2519, 'hole': 2520, 'holes': 2521, 'holiday': 2522, 'holy': 2523, 'home': 2524, 'homecourt': 2525, 'homeless': 2526, 'homes': 2527, 'hometown': 2528, 'honor': 2529, 'hook': 2530, 'hooked': 2531, 'hooking': 2532, 'hooters': 2533, 'hop': 2534, 'hope': 2535, 'hoped': 2536, 'hopeful': 2537, 'hopefully': 2538, 'hoping': 2539, 'horny': 2540, 'horrible': 2541, 'horror': 2542, 'horse': 2543, 'hospitalised': 2544, 'hot': 2545, 'hotspots': 2546, 'hour': 2547, 'hours': 2548, 'house': 2549, 'how': 2550, 'however': 2551, 'howl': 2552, 'hrs': 2553, 'hubby': 2554, 'hug': 2555, 'huge': 2556, 'hugely': 2557, 'hugs': 2558, 'huh': 2559, 'human': 2560, 'humans': 2561, 'humor': 2562, 'humour': 2563, 'hundreds': 2564, 'hunter': 2565, 'hunting': 2566, 'hurling': 2567, 'hurt': 2568, 'hurts': 2569, 'husband': 2570, 'hustles': 2571, 'hybrid': 2572, 'hydrocortisone': 2573, 'hymn': 2574, 'hype': 2575, 'hyped': 2576, 'hyperbolic': 2577, 'hypocrisy': 2578, 'i': 2579, 'iBiteYou': 2580, 'iN': 2581, 'iPhone': 2582, 'iSn': 2583, 'ice': 2584, 'icecream': 2585, 'ick': 2586, 'id': 2587, 'idea': 2588, 'identifiable': 2589, 'idiot': 2590, 'idk': 2591, 'if': 2592, 'ig': 2593, 'ignorance': 2594, 'ignore': 2595, 'iii': 2596, 'ill': 2597, 'illegal': 2598, 'illustrator': 2599, 'im': 2600, 'image': 2601, 'imagination': 2602, 'imagine': 2603, 'imagining': 2604, 'immediate': 2605, 'imo': 2606, 'impact': 2607, 'imperialism': 2608, 'important': 2609, 'impossible': 2610, 'impregnate': 2611, 'impressed': 2612, 'impressive': 2613, 'improve': 2614, 'in': 2615, 'incel': 2616, 'incels': 2617, 'incentive': 2618, 'incentives': 2619, 'inception': 2620, 'increases': 2621, 'incredibly': 2622, 'indecent': 2623, 'indeed': 2624, 'indestructible': 2625, 'indicate': 2626, 'individual': 2627, 'inertial': 2628, 'inevitably': 2629, 'infected': 2630, 'infiltrated': 2631, 'info': 2632, 'information': 2633, 'informative': 2634, 'ingest': 2635, 'inherent': 2636, 'initial': 2637, 'initials': 2638, 'injuries': 2639, 'injustices': 2640, 'input': 2641, 'insane': 2642, 'inside': 2643, 'instagram': 2644, 'installing': 2645, 'instantly': 2646, 'instead': 2647, 'instinctive': 2648, 'institutions': 2649, 'insult': 2650, 'insulting': 2651, 'insults': 2652, 'insurance': 2653, 'intellectual': 2654, 'intelligence': 2655, 'intelligent': 2656, 'intense': 2657, 'intensifies': 2658, 'intentionally': 2659, 'interaction': 2660, 'interest': 2661, 'interested': 2662, 'interesting': 2663, 'interfere': 2664, 'internal': 2665, 'international': 2666, 'internationalist': 2667, 'internet': 2668, 'interpreted': 2669, 'interview': 2670, 'interviews': 2671, 'into': 2672, 'intro': 2673, 'introduce': 2674, 'invested': 2675, 'investigate': 2676, 'invited': 2677, 'involve': 2678, 'involving': 2679, 'irk': 2680, 'irl': 2681, 'ironic': 2682, 'irony': 2683, 'irrelevant': 2684, 'is': 2685, 'ish': 2686, 'isla': 2687, 'isn': 2688, 'isnt': 2689, 'issue': 2690, 'issues': 2691, 'it': 2692, 'its': 2693, 'itself': 2694, 'jacket': 2695, 'jan': 2696, 'jango': 2697, 'jealous': 2698, 'jealousy': 2699, 'jedi': 2700, 'jello': 2701, 'jelly': 2702, 'jellyfish': 2703, 'jerk': 2704, 'jersey': 2705, 'jian': 2706, 'jinxed': 2707, 'job': 2708, 'jobs': 2709, 'joining': 2710, 'joke': 2711, 'joking': 2712, 'joy': 2713, 'judged': 2714, 'judges': 2715, 'juicy': 2716, 'jump': 2717, 'jumped': 2718, 'just': 2719, 'justice': 2720, 'k': 2721, 'karma': 2722, 'keep': 2723, 'keeps': 2724, 'ken': 2725, 'kept': 2726, 'key': 2727, 'kicked': 2728, 'kicker': 2729, 'kid': 2730, 'kiddan': 2731, 'kidding': 2732, 'kiddo': 2733, 'kids': 2734, 'kill': 2735, 'killed': 2736, 'killers': 2737, 'killing': 2738, 'kills': 2739, 'kind': 2740, 'kinda': 2741, 'kindly': 2742, 'kindness': 2743, 'kindred': 2744, 'kinds': 2745, 'king': 2746, 'kinks': 2747, 'kiss': 2748, 'kisses': 2749, 'kitchen': 2750, 'kitty': 2751, 'kmt': 2752, 'kneel': 2753, 'knew': 2754, 'knife': 2755, 'knocked': 2756, 'knocking': 2757, 'know': 2758, 'knowing': 2759, 'known': 2760, 'knows': 2761, 'kombatants': 2762, 'kuss': 2763, 'la': 2764, 'labor': 2765, 'labour': 2766, 'labyrinth': 2767, 'lack': 2768, 'lacked': 2769, 'lacks': 2770, 'ladies': 2771, 'lady': 2772, 'laid': 2773, 'lambasted': 2774, 'land': 2775, 'landlady': 2776, 'language': 2777, 'lap': 2778, 'largely': 2779, 'lashes': 2780, 'lassie': 2781, 'last': 2782, 'lasted': 2783, 'late': 2784, 'lately': 2785, 'latency': 2786, 'later': 2787, 'latest': 2788, 'laugh': 2789, 'laughable': 2790, 'laughed': 2791, 'laughing': 2792, 'launch': 2793, 'lausd': 2794, 'law': 2795, 'lawn': 2796, 'laws': 2797, 'lay': 2798, 'laying': 2799, 'laziness': 2800, 'lazy': 2801, 'lead': 2802, 'league': 2803, 'leaning': 2804, 'leans': 2805, 'learn': 2806, 'learned': 2807, 'least': 2808, 'leather': 2809, 'leave': 2810, 'leaving': 2811, 'left': 2812, 'leftie': 2813, 'leftists': 2814, 'legally': 2815, 'legit': 2816, 'legs': 2817, 'lemon': 2818, 'lemons': 2819, 'length': 2820, 'leo': 2821, 'less': 2822, 'lesson': 2823, 'let': 2824, 'level': 2825, 'libertarian': 2826, 'librals': 2827, 'library': 2828, 'libs': 2829, 'lice': 2830, 'lick': 2831, 'life': 2832, 'lifetime': 2833, 'light': 2834, 'lightning': 2835, 'like': 2836, 'liked': 2837, 'likely': 2838, 'likes': 2839, 'lil': 2840, 'lime': 2841, 'limit': 2842, 'line': 2843, 'lines': 2844, 'link': 2845, 'linked': 2846, 'links': 2847, 'list': 2848, 'listed': 2849, 'listen': 2850, 'listening': 2851, 'listing': 2852, 'lists': 2853, 'lit': 2854, 'literal': 2855, 'literally': 2856, 'lithium': 2857, 'little': 2858, 'live': 2859, 'lives': 2860, 'living': 2861, 'll': 2862, 'lmao': 2863, 'lmaooo': 2864, 'lmfao': 2865, 'local': 2866, 'location': 2867, 'locked': 2868, 'locker': 2869, 'logic': 2870, 'logical': 2871, 'lol': 2872, 'lonely': 2873, 'long': 2874, 'longer': 2875, 'look': 2876, 'looked': 2877, 'looking': 2878, 'looks': 2879, 'loop': 2880, 'lose': 2881, 'loser': 2882, 'losing': 2883, 'loss': 2884, 'lost': 2885, 'lot': 2886, 'lots': 2887, 'loud': 2888, 'love': 2889, 'loved': 2890, 'lovely': 2891, 'loves': 2892, 'loving': 2893, 'low': 2894, 'luck': 2895, 'lucky': 2896, 'lucrative': 2897, 'lunatic': 2898, 'm': 2899, 'machine': 2900, 'machines': 2901, 'mad': 2902, 'made': 2903, 'magic': 2904, 'magnetism': 2905, 'magnum': 2906, 'maidens': 2907, 'main': 2908, 'maintain': 2909, 'major': 2910, 'majority': 2911, 'make': 2912, 'makes': 2913, 'makeup': 2914, 'making': 2915, 'male': 2916, 'males': 2917, 'man': 2918, 'manger': 2919, 'mans': 2920, 'many': 2921, 'market': 2922, 'marriage': 2923, 'married': 2924, 'mask': 2925, 'mass': 2926, 'master': 2927, 'masturbating': 2928, 'match': 2929, 'mate': 2930, 'material': 2931, 'math': 2932, 'matter': 2933, 'matters': 2934, 'mattress': 2935, 'maximize': 2936, 'may': 2937, 'maybe': 2938, 'me': 2939, 'mean': 2940, 'meaning': 2941, 'means': 2942, 'meant': 2943, 'measles': 2944, 'meat': 2945, 'meatcycling': 2946, 'meatless': 2947, 'media': 2948, 'medical': 2949, 'mediocrity': 2950, 'meet': 2951, 'meeting': 2952, 'meh': 2953, 'member': 2954, 'meme': 2955, 'memes': 2956, 'memories': 2957, 'men': 2958, 'mental': 2959, 'mention': 2960, 'mentioned': 2961, 'menu': 2962, 'mess': 2963, 'message': 2964, 'met': 2965, 'metric': 2966, 'mic': 2967, 'middle': 2968, 'midichlorian': 2969, 'might': 2970, 'miles': 2971, 'military': 2972, 'milk': 2973, 'millenials': 2974, 'million': 2975, 'min': 2976, 'mind': 2977, 'mindfulness': 2978, 'minds': 2979, 'mine': 2980, 'minimum': 2981, 'minor': 2982, 'mint': 2983, 'minute': 2984, 'minutes': 2985, 'miracle': 2986, 'miserable': 2987, 'misfortune': 2988, 'mishap': 2989, 'misinformation': 2990, 'miss': 2991, 'missed': 2992, 'mission': 2993, 'missions': 2994, 'misspell': 2995, 'mistake': 2996, 'mistaking': 2997, 'misunderstood': 2998, 'mix': 2999, 'mixed': 3000, 'mixup': 3001, 'mm': 3002, 'mobile': 3003, 'mod': 3004, 'model': 3005, 'modern': 3006, 'modes': 3007, 'mods': 3008, 'mog': 3009, 'mom': 3010, 'moment': 3011, 'momentum': 3012, 'momma': 3013, 'mommy': 3014, 'moms': 3015, 'money': 3016, 'monitor': 3017, 'month': 3018, 'months': 3019, 'moon': 3020, 'moose': 3021, 'morbid': 3022, 'more': 3023, 'morning': 3024, 'moron': 3025, 'mosquito': 3026, 'most': 3027, 'mostly': 3028, 'mother': 3029, 'motherfucker': 3030, 'motherfucking': 3031, 'mouth': 3032, 'move': 3033, 'moved': 3034, 'movement': 3035, 'moves': 3036, 'movie': 3037, 'movies': 3038, 'moving': 3039, 'ms': 3040, 'much': 3041, 'muggings': 3042, 'mum': 3043, 'mummy': 3044, 'murder': 3045, 'murdering': 3046, 'murderino': 3047, 'music': 3048, 'must': 3049, 'mutual': 3050, 'my': 3051, 'myself': 3052, 'n': 3053, 'na': 3054, 'nah': 3055, 'nailed': 3056, 'name': 3057, 'named': 3058, 'names': 3059, 'nan': 3060, 'nationalism': 3061, 'nations': 3062, 'native': 3063, 'natural': 3064, 'naturally': 3065, 'nature': 3066, 'naughty': 3067, 'nba': 3068, 'nd': 3069, 'near': 3070, 'neat': 3071, 'necessarily': 3072, 'neck': 3073, 'necrophilia': 3074, 'need': 3075, 'needed': 3076, 'needs': 3077, 'negativity': 3078, 'neighbor': 3079, 'nerf': 3080, 'nerfs': 3081, 'nerve': 3082, 'nervous': 3083, 'ness': 3084, 'net': 3085, 'netti': 3086, 'neurotypical': 3087, 'never': 3088, 'new': 3089, 'news': 3090, 'next': 3091, 'ngl': 3092, 'nice': 3093, 'night': 3094, 'nightmare': 3095, 'nights': 3096, 'nightstand': 3097, 'nineties': 3098, 'nipples': 3099, 'nit': 3100, 'no': 3101, 'nobody': 3102, 'non': 3103, 'none': 3104, 'nonsense': 3105, 'normal': 3106, 'normalized': 3107, 'normies': 3108, 'north': 3109, 'northern': 3110, 'nos': 3111, 'nostrils': 3112, 'not': 3113, 'nothing': 3114, 'notice': 3115, 'noticed': 3116, 'notif': 3117, 'now': 3118, 'nuance': 3119, 'numb': 3120, 'number': 3121, 'nut': 3122, 'nutrient': 3123, 'nutritional': 3124, 'nuts': 3125, 'o': 3126, 'obesity': 3127, 'objective': 3128, 'observing': 3129, 'obsess': 3130, 'obsessed': 3131, 'obsessing': 3132, 'obsessive': 3133, 'obsessively': 3134, 'obtain': 3135, 'obtuse': 3136, 'obvious': 3137, 'obviously': 3138, 'obvs': 3139, 'occasionally': 3140, 'occurred': 3141, 'odd': 3142, 'oddly': 3143, 'of': 3144, 'off': 3145, 'offended': 3146, 'offense': 3147, 'offer': 3148, 'offered': 3149, 'office': 3150, 'officiant': 3151, 'often': 3152, 'oh': 3153, 'ohmygawd': 3154, 'oj': 3155, 'ok': 3156, 'okay': 3157, 'ol': 3158, 'old': 3159, 'older': 3160, 'oldpeoplereddit': 3161, 'omelette': 3162, 'omg': 3163, 'on': 3164, 'once': 3165, 'one': 3166, 'ones': 3167, 'online': 3168, 'only': 3169, 'onto': 3170, 'oops': 3171, 'open': 3172, 'opening': 3173, 'openings': 3174, 'opera': 3175, 'operators': 3176, 'opinion': 3177, 'opportunity': 3178, 'opposite': 3179, 'oppress': 3180, 'oppressed': 3181, 'oppression': 3182, 'optimist': 3183, 'option': 3184, 'options': 3185, 'or': 3186, 'oracle': 3187, 'orange': 3188, 'ordained': 3189, 'order': 3190, 'ordering': 3191, 'organized': 3192, 'orgasm': 3193, 'originally': 3194, 'other': 3195, 'others': 3196, 'otherwise': 3197, 'our': 3198, 'ourselves': 3199, 'out': 3200, 'outrage': 3201, 'outside': 3202, 'outta': 3203, 'oven': 3204, 'over': 3205, 'overall': 3206, 'overpriced': 3207, 'oversharing': 3208, 'overwatch': 3209, 'overwrite': 3210, 'own': 3211, 'owned': 3212, 'owner': 3213, 'owo': 3214, 'oxford': 3215, 'p': 3216, 'pEyToN': 3217, 'packet': 3218, 'paid': 3219, 'pain': 3220, 'painful': 3221, 'painted': 3222, 'pal': 3223, 'pale': 3224, 'palette': 3225, 'pan': 3226, 'pancake': 3227, 'panic': 3228, 'panicked': 3229, 'pans': 3230, 'pants': 3231, 'paper': 3232, 'parents': 3233, 'park': 3234, 'part': 3235, 'parties': 3236, 'partisan': 3237, 'partner': 3238, 'party': 3239, 'pass': 3240, 'passed': 3241, 'passes': 3242, 'passing': 3243, 'passion': 3244, 'past': 3245, 'pasta': 3246, 'patch': 3247, 'pathetic': 3248, 'patience': 3249, 'pats': 3250, 'pattern': 3251, 'patters': 3252, 'pay': 3253, 'paying': 3254, 'pays': 3255, 'peace': 3256, 'peach': 3257, 'peaked': 3258, 'pear': 3259, 'pedestal': 3260, 'peer': 3261, 'penetrated': 3262, 'peng': 3263, 'penguin': 3264, 'people': 3265, 'peoples': 3266, 'pepper': 3267, 'per': 3268, 'perfect': 3269, 'period': 3270, 'perpetrator': 3271, 'persistent': 3272, 'person': 3273, 'personal': 3274, 'perspective': 3275, 'perverse': 3276, 'pervert': 3277, 'pet': 3278, 'pets': 3279, 'pettiness': 3280, 'petty': 3281, 'phantom': 3282, 'philly': 3283, 'phone': 3284, 'photo': 3285, 'photographer': 3286, 'photos': 3287, 'phrase': 3288, 'phrasing': 3289, 'physical': 3290, 'physically': 3291, 'physics': 3292, 'pic': 3293, 'pick': 3294, 'pickle': 3295, 'pics': 3296, 'picture': 3297, 'pictured': 3298, 'pictures': 3299, 'piece': 3300, 'pieces': 3301, 'pigs': 3302, 'pills': 3303, 'pimples': 3304, 'pinch': 3305, 'ping': 3306, 'pisces': 3307, 'pisco': 3308, 'piss': 3309, 'pissed': 3310, 'pit': 3311, 'pizza': 3312, 'pj': 3313, 'place': 3314, 'placed': 3315, 'places': 3316, 'plague': 3317, 'plain': 3318, 'plan': 3319, 'planet': 3320, 'plastic': 3321, 'platinum': 3322, 'play': 3323, 'played': 3324, 'players': 3325, 'playful': 3326, 'playing': 3327, 'plays': 3328, 'pleasantly': 3329, 'please': 3330, 'pleased': 3331, 'pleasure': 3332, 'plenty': 3333, 'plot': 3334, 'ploy': 3335, 'plug': 3336, 'plunger': 3337, 'pm': 3338, 'podcast': 3339, 'poems': 3340, 'point': 3341, 'pointing': 3342, 'pointless': 3343, 'poison': 3344, 'pole': 3345, 'polite': 3346, 'politician': 3347, 'politics': 3348, 'polling': 3349, 'ponder': 3350, 'poor': 3351, 'popped': 3352, 'population': 3353, 'porn': 3354, 'portal': 3355, 'posion': 3356, 'position': 3357, 'positive': 3358, 'posse': 3359, 'possible': 3360, 'possibly': 3361, 'post': 3362, 'posted': 3363, 'posting': 3364, 'posts': 3365, 'pot': 3366, 'potato': 3367, 'potential': 3368, 'potentially': 3369, 'pounds': 3370, 'powered': 3371, 'powerful': 3372, 'practically': 3373, 'pranks': 3374, 'pray': 3375, 'prayer': 3376, 'prayers': 3377, 'praying': 3378, 'precious': 3379, 'predicament': 3380, 'pregnant': 3381, 'prejudice': 3382, 'prepared': 3383, 'presents': 3384, 'press': 3385, 'pretty': 3386, 'previous': 3387, 'price': 3388, 'prices': 3389, 'pricing': 3390, 'princess': 3391, 'principle': 3392, 'prison': 3393, 'private': 3394, 'privilege': 3395, 'privileges': 3396, 'pro': 3397, 'probably': 3398, 'problem': 3399, 'problems': 3400, 'proceed': 3401, 'process': 3402, 'produce': 3403, 'products': 3404, 'profile': 3405, 'projecting': 3406, 'promoting': 3407, 'propaganda': 3408, 'proper': 3409, 'properly': 3410, 'props': 3411, 'prospects': 3412, 'protection': 3413, 'proud': 3414, 'prove': 3415, 'proverbial': 3416, 'providers': 3417, 'proving': 3418, 'psychos': 3419, 'pubes': 3420, 'public': 3421, 'pull': 3422, 'punch': 3423, 'punching': 3424, 'punish': 3425, 'punishment': 3426, 'punt': 3427, 'pup': 3428, 'pupper': 3429, 'puppets': 3430, 'puppy': 3431, 'pure': 3432, 'purgatory': 3433, 'purple': 3434, 'purposely': 3435, 'pursue': 3436, 'pursuit': 3437, 'pushy': 3438, 'put': 3439, 'puts': 3440, 'pwoud': 3441, 'qaida': 3442, 'qualified': 3443, 'qualify': 3444, 'quality': 3445, 'quarter': 3446, 'queasy': 3447, 'queen': 3448, 'queer': 3449, 'question': 3450, 'questions': 3451, 'quick': 3452, 'quickest': 3453, 'quickly': 3454, 'quirky': 3455, 'quit': 3456, 'quite': 3457, 'quota': 3458, 'quote': 3459, 'r': 3460, 'racism': 3461, 'racist': 3462, 'radar': 3463, 'radical': 3464, 'radio': 3465, 'rage': 3466, 'raise': 3467, 'ramdom': 3468, 'rancid': 3469, 'random': 3470, 'randoms': 3471, 'range': 3472, 'rant': 3473, 'rapaidh': 3474, 'rape': 3475, 'rappers': 3476, 'rare': 3477, 'rarely': 3478, 'rates': 3479, 'rather': 3480, 'rational': 3481, 'ravens': 3482, 'ray': 3483, 're': 3484, 'reach': 3485, 'react': 3486, 'reactable': 3487, 'reaction': 3488, 'read': 3489, 'reading': 3490, 'reads': 3491, 'ready': 3492, 'real': 3493, 'reality': 3494, 'realize': 3495, 'realized': 3496, 'really': 3497, 'reason': 3498, 'reasonable': 3499, 'reasons': 3500, 'rebel': 3501, 'reckons': 3502, 'recommend': 3503, 'reconsider': 3504, 'record': 3505, 'recover': 3506, 'recovery': 3507, 'recruit': 3508, 'recruiting': 3509, 'red': 3510, 'reddit': 3511, 'redditor': 3512, 'redhead': 3513, 'redo': 3514, 'ref': 3515, 'reference': 3516, 'referendum': 3517, 'referring': 3518, 'reflective': 3519, 'reflexive': 3520, 'refusing': 3521, 'register': 3522, 'regular': 3523, 'regularly': 3524, 'regulations': 3525, 'rehabilitating': 3526, 'reigned': 3527, 'rejoining': 3528, 'relatable': 3529, 'relate': 3530, 'related': 3531, 'relationship': 3532, 'relationships': 3533, 'relatively': 3534, 'relaxing': 3535, 'release': 3536, 'released': 3537, 'relief': 3538, 'religious': 3539, 'rely': 3540, 'remain': 3541, 'remake': 3542, 'remarkable': 3543, 'remember': 3544, 'reminding': 3545, 'reminds': 3546, 'remotely': 3547, 'removed': 3548, 'renaissance': 3549, 'renovate': 3550, 'rent': 3551, 'repacked': 3552, 'repaid': 3553, 'repairing': 3554, 'replace': 3555, 'replacement': 3556, 'replies': 3557, 'reply': 3558, 'replying': 3559, 'representation': 3560, 'representing': 3561, 'reproduce': 3562, 'republican': 3563, 'republicans': 3564, 'request': 3565, 'requiem': 3566, 'required': 3567, 'rescind': 3568, 'research': 3569, 'resell': 3570, 'resentment': 3571, 'residents': 3572, 'resisting': 3573, 'responding': 3574, 'responds': 3575, 'response': 3576, 'responsibility': 3577, 'rest': 3578, 'restaurant': 3579, 'result': 3580, 'results': 3581, 'retains': 3582, 'retardation': 3583, 'retirement': 3584, 'retreat': 3585, 'retreats': 3586, 'return': 3587, 'revenge': 3588, 'review': 3589, 'rex': 3590, 'rice': 3591, 'rich': 3592, 'ricotta': 3593, 'rid': 3594, 'ride': 3595, 'ridiculous': 3596, 'right': 3597, 'rights': 3598, 'ring': 3599, 'rip': 3600, 'ripped': 3601, 'rippled': 3602, 'rise': 3603, 'risk': 3604, 'rivalry': 3605, 'river': 3606, 'rn': 3607, 'road': 3608, 'rock': 3609, 'rocket': 3610, 'rockets': 3611, 'role': 3612, 'roll': 3613, 'room': 3614, 'roommate': 3615, 'roommates': 3616, 'rooting': 3617, 'roster': 3618, 'round': 3619, 'route': 3620, 'royal': 3621, 'rubbing': 3622, 'rubies': 3623, 'ruin': 3624, 'ruins': 3625, 'rule': 3626, 'rules': 3627, 'rum': 3628, 'run': 3629, 'running': 3630, 'rush': 3631, 'rushed': 3632, 's': 3633, 'sacrifice': 3634, 'sacrifices': 3635, 'sad': 3636, 'sadder': 3637, 'saddest': 3638, 'sadly': 3639, 'sadness': 3640, 'safe': 3641, 'safety': 3642, 'said': 3643, 'saints': 3644, 'sake': 3645, 'salarian': 3646, 'sales': 3647, 'same': 3648, 'sandy': 3649, 'sanitizer': 3650, 'sarcasm': 3651, 'sarcastic': 3652, 'saturday': 3653, 'sauerkraut': 3654, 'savants': 3655, 'save': 3656, 'saved': 3657, 'saving': 3658, 'savings': 3659, 'savvy': 3660, 'saw': 3661, 'say': 3662, 'saying': 3663, 'says': 3664, 'scam': 3665, 'scammed': 3666, 'scammers': 3667, 'scared': 3668, 'scary': 3669, 'scenarios': 3670, 'schadenfreude': 3671, 'school': 3672, 'science': 3673, 'scousers': 3674, 'scratch': 3675, 'screens': 3676, 'screw': 3677, 'screwing': 3678, 'script': 3679, 'scripts': 3680, 'scrub': 3681, 'scumbags': 3682, 'search': 3683, 'season': 3684, 'seat': 3685, 'sec': 3686, 'second': 3687, 'seconds': 3688, 'secrecy': 3689, 'secret': 3690, 'section': 3691, 'secure': 3692, 'see': 3693, 'seeing': 3694, 'seem': 3695, 'seemingly': 3696, 'seems': 3697, 'seen': 3698, 'sees': 3699, 'seeya': 3700, 'self': 3701, 'selfie': 3702, 'semen': 3703, 'semester': 3704, 'send': 3705, 'sending': 3706, 'sense': 3707, 'sensing': 3708, 'sensitive': 3709, 'sentence': 3710, 'serious': 3711, 'seriously': 3712, 'served': 3713, 'service': 3714, 'setting': 3715, 'several': 3716, 'severe': 3717, 'severely': 3718, 'sex': 3719, 'sexist': 3720, 'sexual': 3721, 'sexually': 3722, 'sexy': 3723, 'sha': 3724, 'shaft': 3725, 'shaking': 3726, 'sham': 3727, 'shape': 3728, 'share': 3729, 'shared': 3730, 'sharing': 3731, 'shark': 3732, 'sharp': 3733, 'sharply': 3734, 'she': 3735, 'shelf': 3736, 'shell': 3737, 'shirt': 3738, 'shit': 3739, 'shits': 3740, 'shitty': 3741, 'shock': 3742, 'shoes': 3743, 'shook': 3744, 'shoot': 3745, 'shooting': 3746, 'shopping': 3747, 'short': 3748, 'shortly': 3749, 'shot': 3750, 'shotgun': 3751, 'shots': 3752, 'should': 3753, 'shouldn': 3754, 'shoveling': 3755, 'show': 3756, 'showing': 3757, 'shows': 3758, 'shut': 3759, 'siblings': 3760, 'sick': 3761, 'sickest': 3762, 'sickness': 3763, 'side': 3764, 'sides': 3765, 'sign': 3766, 'signature': 3767, 'signed': 3768, 'significant': 3769, 'signing': 3770, 'signs': 3771, 'silly': 3772, 'silver': 3773, 'similar': 3774, 'simple': 3775, 'sin': 3776, 'since': 3777, 'single': 3778, 'sink': 3779, 'sinner': 3780, 'sir': 3781, 'site': 3782, 'sitting': 3783, 'situation': 3784, 'size': 3785, 'skates': 3786, 'skills': 3787, 'skin': 3788, 'skip': 3789, 'skull': 3790, 'slaughtered': 3791, 'sleep': 3792, 'sleeptrain': 3793, 'sleeve': 3794, 'slept': 3795, 'slice': 3796, 'slightly': 3797, 'slob': 3798, 'slop': 3799, 'slow': 3800, 'small': 3801, 'smaller': 3802, 'smarter': 3803, 'smartly': 3804, 'smeared': 3805, 'smell': 3806, 'smells': 3807, 'smelly': 3808, 'smile': 3809, 'smooth': 3810, 'snack': 3811, 'snagging': 3812, 'snapchats': 3813, 'snapped': 3814, 'snow': 3815, 'snowflake': 3816, 'snuggled': 3817, 'so': 3818, 'soap': 3819, 'sobriety': 3820, 'society': 3821, 'soft': 3822, 'soil': 3823, 'solar': 3824, 'solid': 3825, 'solo': 3826, 'sololander': 3827, 'solve': 3828, 'solves': 3829, 'some': 3830, 'somebody': 3831, 'someday': 3832, 'somehow': 3833, 'someone': 3834, 'something': 3835, 'sometime': 3836, 'sometimes': 3837, 'son': 3838, 'song': 3839, 'songs': 3840, 'sons': 3841, 'soon': 3842, 'soooo': 3843, 'sorry': 3844, 'sort': 3845, 'sorts': 3846, 'soul': 3847, 'soulread': 3848, 'sound': 3849, 'sounds': 3850, 'source': 3851, 'sours': 3852, 'south': 3853, 'space': 3854, 'spam': 3855, 'speak': 3856, 'speaking': 3857, 'special': 3858, 'specific': 3859, 'specifically': 3860, 'speed': 3861, 'spell': 3862, 'spelling': 3863, 'spent': 3864, 'spiderman': 3865, 'spin': 3866, 'spirit': 3867, 'spirits': 3868, 'spit': 3869, 'split': 3870, 'spoil': 3871, 'spoke': 3872, 'sponsors': 3873, 'spot': 3874, 'spouse': 3875, 'spray': 3876, 'spreadsheeters': 3877, 'spritz': 3878, 'squeamish': 3879, 'sry': 3880, 'sssssssssssssssssssssssssssss': 3881, 'stabbed': 3882, 'stabbings': 3883, 'stadium': 3884, 'staff': 3885, 'stain': 3886, 'stains': 3887, 'stamp': 3888, 'stamps': 3889, 'stan': 3890, 'stand': 3891, 'standard': 3892, 'standards': 3893, 'standing': 3894, 'stands': 3895, 'stans': 3896, 'star': 3897, 'stars': 3898, 'start': 3899, 'started': 3900, 'starts': 3901, 'starving': 3902, 'state': 3903, 'statements': 3904, 'states': 3905, 'stating': 3906, 'station': 3907, 'statistic': 3908, 'stay': 3909, 'stayed': 3910, 'steal': 3911, 'stealing': 3912, 'steam': 3913, 'steel': 3914, 'step': 3915, 'steps': 3916, 'stereotype': 3917, 'stick': 3918, 'sticks': 3919, 'stickshift': 3920, 'still': 3921, 'stink': 3922, 'stitches': 3923, 'stock': 3924, 'stolen': 3925, 'stomping': 3926, 'stone': 3927, 'stoned': 3928, 'stood': 3929, 'stop': 3930, 'stopped': 3931, 'stopping': 3932, 'stops': 3933, 'store': 3934, 'stores': 3935, 'story': 3936, 'straight': 3937, 'stranger': 3938, 'strangers': 3939, 'strategy': 3940, 'stream': 3941, 'stressed': 3942, 'stresses': 3943, 'stripper': 3944, 'strippers': 3945, 'strong': 3946, 'structural': 3947, 'structure': 3948, 'stubborn': 3949, 'stubbornly': 3950, 'stuck': 3951, 'stud': 3952, 'student': 3953, 'study': 3954, 'stuff': 3955, 'stung': 3956, 'stunt': 3957, 'stupid': 3958, 'stupidly': 3959, 'style': 3960, 'stylist': 3961, 'sub': 3962, 'subreddit': 3963, 'subs': 3964, 'subtitles': 3965, 'subtlety': 3966, 'succinct': 3967, 'such': 3968, 'suck': 3969, 'sucked': 3970, 'sucks': 3971, 'suddenly': 3972, 'sued': 3973, 'suffering': 3974, 'suggestion': 3975, 'suggests': 3976, 'suit': 3977, 'summer': 3978, 'sunburn': 3979, 'sundae': 3980, 'sunk': 3981, 'sunny': 3982, 'sunrise': 3983, 'sunshine': 3984, 'super': 3985, 'support': 3986, 'supported': 3987, 'supporters': 3988, 'supporting': 3989, 'supposed': 3990, 'suprise': 3991, 'sure': 3992, 'surely': 3993, 'surface': 3994, 'surgery': 3995, 'surprise': 3996, 'surprised': 3997, 'surrogacy': 3998, 'survive': 3999, 'svu': 4000, 'sweatie': 4001, 'sweating': 4002, 'sweet': 4003, 'swimmer': 4004, 'swing': 4005, 'swings': 4006, 'swiping': 4007, 'swollen': 4008, 'symptom': 4009, 'synopsis': 4010, 'system': 4011, 'systematic': 4012, 't': 4013, 'tHe': 4014, 'tO': 4015, 'taco': 4016, 'tacos': 4017, 'tae': 4018, 'tag': 4019, 'take': 4020, 'taken': 4021, 'takes': 4022, 'taking': 4023, 'tale': 4024, 'talk': 4025, 'talking': 4026, 'talks': 4027, 'tall': 4028, 'tank': 4029, 'tanks': 4030, 'target': 4031, 'tart': 4032, 'task': 4033, 'taste': 4034, 'tati': 4035, 'taught': 4036, 'tbh': 4037, 'tea': 4038, 'teach': 4039, 'team': 4040, 'teammates': 4041, 'teams': 4042, 'tear': 4043, 'tears': 4044, 'teen': 4045, 'tehehehehehehe': 4046, 'tell': 4047, 'telling': 4048, 'temple': 4049, 'tempting': 4050, 'ten': 4051, 'teriyaki': 4052, 'term': 4053, 'terminal': 4054, 'terminology': 4055, 'terms': 4056, 'terrible': 4057, 'terrified': 4058, 'terrify': 4059, 'terrifying': 4060, 'text': 4061, 'th': 4062, 'than': 4063, 'thank': 4064, 'thankful': 4065, 'thanks': 4066, 'that': 4067, 'thats': 4068, 'the': 4069, 'theater': 4070, 'their': 4071, 'them': 4072, 'theme': 4073, 'themselves': 4074, 'then': 4075, 'theorists': 4076, 'theory': 4077, 'therapist': 4078, 'therapy': 4079, 'there': 4080, 'these': 4081, 'they': 4082, 'thick': 4083, 'thin': 4084, 'thing': 4085, 'things': 4086, 'think': 4087, 'thinking': 4088, 'thinks': 4089, 'third': 4090, 'thirsty': 4091, 'this': 4092, 'tho': 4093, 'thoroughly': 4094, 'thos': 4095, 'those': 4096, 'thou': 4097, 'though': 4098, 'thought': 4099, 'thoughts': 4100, 'thoughy': 4101, 'thread': 4102, 'threads': 4103, 'threatened': 4104, 'three': 4105, 'threw': 4106, 'through': 4107, 'throw': 4108, 'throwing': 4109, 'thrown': 4110, 'thus': 4111, 'thyroid': 4112, 'ti': 4113, 'tier': 4114, 'tik': 4115, 'till': 4116, 'time': 4117, 'timeless': 4118, 'times': 4119, 'timing': 4120, 'tiniest': 4121, 'tiny': 4122, 'tip': 4123, 'tipped': 4124, 'titanic': 4125, 'title': 4126, 'to': 4127, 'today': 4128, 'toddler': 4129, 'toe': 4130, 'toenails': 4131, 'tofu': 4132, 'together': 4133, 'toilet': 4134, 'toilets': 4135, 'tok': 4136, 'told': 4137, 'tomorow': 4138, 'tomorrow': 4139, 'tone': 4140, 'tongue': 4141, 'tonight': 4142, 'too': 4143, 'took': 4144, 'tool': 4145, 'tooth': 4146, 'top': 4147, 'topic': 4148, 'tops': 4149, 'tortilla': 4150, 'tortillas': 4151, 'totally': 4152, 'touch': 4153, 'tough': 4154, 'tourist': 4155, 'tousles': 4156, 'toward': 4157, 'towards': 4158, 'town': 4159, 'toxic': 4160, 'tracer': 4161, 'track': 4162, 'tracking': 4163, 'tracks': 4164, 'trade': 4165, 'traffic': 4166, 'tragic': 4167, 'training': 4168, 'transfer': 4169, 'transit': 4170, 'transition': 4171, 'translation': 4172, 'translations': 4173, 'translucent': 4174, 'transparent': 4175, 'traps': 4176, 'trash': 4177, 'travels': 4178, 'treasure': 4179, 'treat': 4180, 'treated': 4181, 'treatment': 4182, 'trees': 4183, 'tremble': 4184, 'trend': 4185, 'trendy': 4186, 'tribalism': 4187, 'trickiest': 4188, 'tried': 4189, 'trifecta': 4190, 'trillion': 4191, 'trip': 4192, 'triumphant': 4193, 'troll': 4194, 'trollGC': 4195, 'trolls': 4196, 'troo': 4197, 'troops': 4198, 'trouble': 4199, 'troubles': 4200, 'truck': 4201, 'trucks': 4202, 'true': 4203, 'truly': 4204, 'trust': 4205, 'truth': 4206, 'try': 4207, 'trying': 4208, 'tuck': 4209, 'tummy': 4210, 'turds': 4211, 'turned': 4212, 'turning': 4213, 'turns': 4214, 'tutorial': 4215, 'tv': 4216, 'tweet': 4217, 'twice': 4218, 'twin': 4219, 'twist': 4220, 'twitter': 4221, 'two': 4222, 'type': 4223, 'typed': 4224, 'types': 4225, 'typing': 4226, 'u': 4227, 'uS': 4228, 'ugly': 4229, 'uh': 4230, 'uk': 4231, 'unable': 4232, 'uncle': 4233, 'uncommon': 4234, 'under': 4235, 'underground': 4236, 'underpaid': 4237, 'undersold': 4238, 'understand': 4239, 'understanding': 4240, 'understated': 4241, 'unethical': 4242, 'unfortunate': 4243, 'unfortunately': 4244, 'unfunny': 4245, 'uniform': 4246, 'unique': 4247, 'unit': 4248, 'universally': 4249, 'university': 4250, 'unless': 4251, 'unnecessary': 4252, 'unpopular': 4253, 'until': 4254, 'up': 4255, 'updoots': 4256, 'upfront': 4257, 'uplifting': 4258, 'upload': 4259, 'upon': 4260, 'upper': 4261, 'ups': 4262, 'upset': 4263, 'upvote': 4264, 'upvotes': 4265, 'upvoting': 4266, 'ur': 4267, 'us': 4268, 'use': 4269, 'used': 4270, 'useful': 4271, 'user': 4272, 'username': 4273, 'uses': 4274, 'using': 4275, 'usual': 4276, 'usually': 4277, 'v': 4278, 'vaccinations': 4279, 'vaccine': 4280, 'vague': 4281, 'valid': 4282, 'valuable': 4283, 'value': 4284, 'vanguardism': 4285, 'vanilla': 4286, 'vault': 4287, 've': 4288, 'veggies': 4289, 'veins': 4290, 'vent': 4291, 'version': 4292, 'very': 4293, 'vewy': 4294, 'vey': 4295, 'vibe': 4296, 'vibes': 4297, 'victims': 4298, 'victory': 4299, 'video': 4300, 'videos': 4301, 'view': 4302, 'viewers': 4303, 'viewing': 4304, 'vindication': 4305, 'violate': 4306, 'visible': 4307, 'visit': 4308, 'visiting': 4309, 'vite': 4310, 'vodka': 4311, 'voice': 4312, 'vomiting': 4313, 'vote': 4314, 'voted': 4315, 'vulnerable': 4316, 'wabbies': 4317, 'waffles': 4318, 'wage': 4319, 'wait': 4320, 'waiter': 4321, 'waiting': 4322, 'waitress': 4323, 'wake': 4324, 'walk': 4325, 'walked': 4326, 'walking': 4327, 'wallow': 4328, 'wankfest': 4329, 'wanna': 4330, 'want': 4331, 'wanted': 4332, 'wanting': 4333, 'wants': 4334, 'war': 4335, 'warm': 4336, 'warmth': 4337, 'warning': 4338, 'wary': 4339, 'was': 4340, 'wash': 4341, 'washed': 4342, 'wasn': 4343, 'wasnt': 4344, 'waste': 4345, 'wastebasket': 4346, 'wasting': 4347, 'watch': 4348, 'watched': 4349, 'watching': 4350, 'water': 4351, 'waving': 4352, 'way': 4353, 'ways': 4354, 'we': 4355, 'weak': 4356, 'wealth': 4357, 'weapon': 4358, 'wear': 4359, 'wearing': 4360, 'wears': 4361, 'wedding': 4362, 'wee': 4363, 'week': 4364, 'weekend': 4365, 'weeks': 4366, 'weep': 4367, 'weigh': 4368, 'weight': 4369, 'weird': 4370, 'weirdest': 4371, 'welcome': 4372, 'welded': 4373, 'well': 4374, 'welp': 4375, 'went': 4376, 'were': 4377, 'weren': 4378, 'west': 4379, 'wha': 4380, 'what': 4381, 'whatapp': 4382, 'whatever': 4383, 'whats': 4384, 'when': 4385, 'whenever': 4386, 'where': 4387, 'which': 4388, 'whiff': 4389, 'while': 4390, 'whining': 4391, 'whippersnappers': 4392, 'whispering': 4393, 'white': 4394, 'who': 4395, 'whoever': 4396, 'whole': 4397, 'wholeheartedly': 4398, 'wholesome': 4399, 'whoppers': 4400, 'why': 4401, 'widow': 4402, 'wield': 4403, 'wif': 4404, 'wife': 4405, 'wild': 4406, 'will': 4407, 'willing': 4408, 'win': 4409, 'window': 4410, 'windshield': 4411, 'wine': 4412, 'wings': 4413, 'winter': 4414, 'wise': 4415, 'wish': 4416, 'wishing': 4417, 'with': 4418, 'without': 4419, 'witness': 4420, 'witnessing': 4421, 'wives': 4422, 'woke': 4423, 'woman': 4424, 'women': 4425, 'won': 4426, 'wonder': 4427, 'wonderful': 4428, 'wondering': 4429, 'woods': 4430, 'word': 4431, 'words': 4432, 'wore': 4433, 'work': 4434, 'worked': 4435, 'worker': 4436, 'workers': 4437, 'workforce': 4438, 'working': 4439, 'works': 4440, 'world': 4441, 'worried': 4442, 'worry': 4443, 'worrying': 4444, 'worse': 4445, 'worship': 4446, 'worst': 4447, 'worth': 4448, 'worthless': 4449, 'worthy': 4450, 'would': 4451, 'wouldn': 4452, 'wow': 4453, 'woww': 4454, 'wrap': 4455, 'wrists': 4456, 'write': 4457, 'writing': 4458, 'written': 4459, 'wrong': 4460, 'wrote': 4461, 'wtf': 4462, 'x': 4463, 'xd': 4464, 'y': 4465, 'ya': 4466, 'yah': 4467, 'yea': 4468, 'yeah': 4469, 'yeahno': 4470, 'year': 4471, 'years': 4472, 'yeast': 4473, 'yeh': 4474, 'yelled': 4475, 'yellow': 4476, 'yes': 4477, 'yesss': 4478, 'yesterday': 4479, 'yet': 4480, 'yoga': 4481, 'yoooouuuuu': 4482, 'you': 4483, 'young': 4484, 'younger': 4485, 'your': 4486, 'youre': 4487, 'yours': 4488, 'yourself': 4489, 'youtube': 4490, 'youuuuuuu': 4491, 'yr': 4492, 'zero': 4493, 'zoo': 4494, '\\u200d': 4495, '️': 4496, '🇦': 4497, '🇫': 4498, '🇲': 4499, '🇵': 4500, '🇷': 4501, '🇺': 4502}\n"
     ]
    }
   ],
   "source": [
    "# word classes (final output)\n",
    "\n",
    "flattened_word_list = [word for word_list in dataset['tokenized_text'] for word in word_list if emoji.emoji_count(word) == 0]\n",
    "unique_word_list = sorted(list(set(flattened_word_list)))\n",
    "\n",
    "word_to_idx = {word: idx for idx, word in enumerate(unique_word_list)}\n",
    "idx_to_word = {idx: word for idx, word in enumerate(unique_word_list)}\n",
    "\n",
    "print('the number of words: ', len(idx_to_word))\n",
    "print(\"idx_to_word: \", idx_to_word)\n",
    "print(\"word_to_idx: \", word_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{tensor([1389,  315, 1483,   96, 1183,  296,  573,  152,  699, 1186,  454,  983,\n",
       "         1090, 1213,   94,  914,  205,  814,  304, 1037,   13, 1017,  229,  698,\n",
       "          171, 1769,  522,  885, 1777,   14,  856,  151]): tensor([[0.1158, 0.2528, 0.0378,  ..., 0.2255, 0.1758, 0.0000],\n",
       "         [0.0886, 0.1335, 0.1508,  ..., 0.1249, 0.0891, 0.0000],\n",
       "         [0.2391, 0.0000, 0.3805,  ..., 0.1559, 0.1945, 0.0000],\n",
       "         ...,\n",
       "         [0.0753, 0.1029, 0.0438,  ..., 0.1978, 0.0529, 0.0000],\n",
       "         [0.1144, 0.1958, 0.1020,  ..., 0.1424, 0.0959, 0.0000],\n",
       "         [0.1308, 0.0431, 0.1764,  ..., 0.0362, 0.1899, 0.0000]]),\n",
       " tensor([1735,   85, 1538, 1117, 1373, 1288,  345,  114,  750,   36, 1531,  193,\n",
       "          646, 1530,  579,  132, 1316,  340, 1134,  993, 1433, 1522, 1216,  683,\n",
       "          878, 1391,  409,  858, 1695, 1499,  969, 1644]): tensor([[0.2569, 0.1662, 0.0722,  ..., 0.1924, 0.3354, 0.0000],\n",
       "         [0.0827, 0.0987, 0.1177,  ..., 0.0887, 0.0175, 0.0000],\n",
       "         [0.1618, 0.1571, 0.3044,  ..., 0.1489, 0.2262, 0.0000],\n",
       "         ...,\n",
       "         [0.2099, 0.2253, 0.0989,  ..., 0.0791, 0.1139, 0.0000],\n",
       "         [0.1107, 0.0990, 0.0814,  ..., 0.1014, 0.1139, 0.0000],\n",
       "         [0.1555, 0.2402, 0.3746,  ..., 0.0000, 0.1983, 0.0000]]),\n",
       " tensor([1261,  473, 1076,  156,  262,  278, 1180, 1162, 1069, 1594,  830,  451,\n",
       "          232,  569,  789, 1390, 1247,  895,  338, 1733, 1603,  884,  882,  377,\n",
       "           81, 1153, 1749, 1680, 1544, 1586, 1804,  139]): tensor([[0.1020, 0.1646, 0.1476,  ..., 0.1568, 0.1027, 0.0000],\n",
       "         [0.1237, 0.1224, 0.1402,  ..., 0.0610, 0.0485, 0.0000],\n",
       "         [0.0997, 0.1322, 0.1128,  ..., 0.0835, 0.0937, 0.0000],\n",
       "         ...,\n",
       "         [0.0855, 0.1287, 0.1330,  ..., 0.0888, 0.0614, 0.0000],\n",
       "         [0.2038, 0.1454, 0.2512,  ..., 0.0005, 0.0567, 0.0000],\n",
       "         [0.2377, 0.1264, 0.1168,  ..., 0.0054, 0.0000, 0.0000]]),\n",
       " tensor([1171,  458, 1823, 1276,  140, 1244,  474, 1361,  713, 1111, 1158, 1643,\n",
       "          952,  747,  930, 1218,  778,  667, 1353, 1615,  578, 1110, 1188, 1825,\n",
       "          803, 1297, 1764, 1789, 1518,  217,  663,  739]): tensor([[0.0791, 0.1180, 0.2456,  ..., 0.1193, 0.2566, 0.0000],\n",
       "         [0.1301, 0.1631, 0.0847,  ..., 0.0996, 0.0561, 0.0000],\n",
       "         [0.1095, 0.2391, 0.1493,  ..., 0.0000, 0.3103, 0.0000],\n",
       "         ...,\n",
       "         [0.0000, 0.3287, 0.1986,  ..., 0.0000, 0.1860, 0.0000],\n",
       "         [0.0887, 0.1085, 0.1368,  ..., 0.2880, 0.1541, 0.0000],\n",
       "         [0.1132, 0.1917, 0.0966,  ..., 0.1437, 0.0992, 0.0000]]),\n",
       " tensor([   0,  662,  291, 1813,  455,  647, 1174,  276, 1067,  201, 1766,  403,\n",
       "         1303,    1,  865,  230,  531, 1482, 1115,  258, 1610,  729, 1693,  834,\n",
       "          204,  788, 1127,  299, 1059, 1121,  157, 1051]): tensor([[0.1944, 0.1073, 0.1463,  ..., 0.2191, 0.1429, 0.0000],\n",
       "         [0.0974, 0.2308, 0.1889,  ..., 0.0000, 0.0980, 0.0000],\n",
       "         [0.2876, 0.2711, 0.3366,  ..., 0.0000, 0.2499, 0.0000],\n",
       "         ...,\n",
       "         [0.2417, 0.1098, 0.1707,  ..., 0.1044, 0.4851, 0.0000],\n",
       "         [0.1637, 0.2451, 0.0343,  ..., 0.3012, 0.3033, 0.0000],\n",
       "         [0.1051, 0.0392, 0.1582,  ..., 0.1081, 0.0000, 0.0000]]),\n",
       " tensor([1166,  285,  195, 1750, 1126,  871,  989,  246, 1799, 1754,  501, 1042,\n",
       "          153,  191, 1464,  321, 1621,  391, 1114,   95, 1209,  131,  864,  287,\n",
       "          452, 1574,  658,  143, 1682,  442,  991, 1019]): tensor([[0.0772, 0.1451, 0.0422,  ..., 0.2034, 0.0932, 0.0000],\n",
       "         [0.1654, 0.3928, 0.1030,  ..., 0.1908, 0.4272, 0.0000],\n",
       "         [0.1388, 0.1693, 0.1813,  ..., 0.0444, 0.1589, 0.0000],\n",
       "         ...,\n",
       "         [0.1033, 0.1200, 0.1356,  ..., 0.0898, 0.0299, 0.0000],\n",
       "         [0.0824, 0.1057, 0.1176,  ..., 0.0895, 0.0257, 0.0000],\n",
       "         [0.0881, 0.1412, 0.1194,  ..., 0.0166, 0.0000, 0.0000]]),\n",
       " tensor([ 687, 1430,  475,  489, 1833,  329, 1388,  691,   20,  448, 1028, 1275,\n",
       "          520,  279, 1337, 1306, 1184,  384, 1580, 1007,  546,  126, 1685, 1332,\n",
       "          359, 1312, 1046, 1694,  776, 1504,  606,  676]): tensor([[0.0608, 0.0963, 0.3082,  ..., 0.0000, 0.1706, 0.0000],\n",
       "         [0.0907, 0.1390, 0.1068,  ..., 0.0731, 0.0556, 0.0000],\n",
       "         [0.0400, 0.1805, 0.0701,  ..., 0.2934, 0.3196, 0.0000],\n",
       "         ...,\n",
       "         [0.0889, 0.0412, 0.2392,  ..., 0.0392, 0.1562, 0.0000],\n",
       "         [0.0850, 0.1282, 0.1402,  ..., 0.1052, 0.0747, 0.0000],\n",
       "         [0.1191, 0.1885, 0.0981,  ..., 0.1412, 0.1065, 0.0000]]),\n",
       " tensor([ 822,  962, 1335, 1622, 1148, 1195,  176,  393, 1101,  313,   39, 1567,\n",
       "          189, 1663,  467, 1377,  319, 1410,  549, 1714,  944,  423,  227,  206,\n",
       "         1326,  801,  328,   33,  703, 1401, 1229,  228]): tensor([[0.0848, 0.1267, 0.1350,  ..., 0.0871, 0.0564, 0.0000],\n",
       "         [0.0684, 0.1468, 0.1399,  ..., 0.1277, 0.0652, 0.0000],\n",
       "         [0.1067, 0.1672, 0.0693,  ..., 0.1778, 0.1850, 0.0000],\n",
       "         ...,\n",
       "         [0.1472, 0.1810, 0.0680,  ..., 0.1615, 0.2407, 0.0000],\n",
       "         [0.1065, 0.1804, 0.0809,  ..., 0.0662, 0.1992, 0.0000],\n",
       "         [0.0904, 0.1891, 0.1975,  ..., 0.0000, 0.0899, 0.0000]]),\n",
       " tensor([1434,  784, 1576,  840, 1015, 1020, 1737,  496, 1755,  594, 1639, 1592,\n",
       "         1780, 1287, 1141,   40,  893,   93,  260, 1411, 1334,  516,  919,  136,\n",
       "          117, 1196,  487, 1095,  600,  911, 1362, 1485]): tensor([[0.0594, 0.2006, 0.0953,  ..., 0.2396, 0.0000, 0.0000],\n",
       "         [0.1553, 0.3192, 0.0655,  ..., 0.2705, 0.1104, 0.0000],\n",
       "         [0.2519, 0.1736, 0.0436,  ..., 0.1702, 0.1164, 0.0000],\n",
       "         ...,\n",
       "         [0.0931, 0.0350, 0.1712,  ..., 0.0656, 0.1549, 0.0000],\n",
       "         [0.0859, 0.1409, 0.0450,  ..., 0.1918, 0.0991, 0.0000],\n",
       "         [0.1218, 0.1937, 0.0980,  ..., 0.1565, 0.1159, 0.0000]]),\n",
       " tensor([ 743,   22,  372, 1185,  510,  119,   61,  430, 1207,  797, 1104, 1096,\n",
       "         1264,  207, 1651, 1383,  932,   98,  842, 1672, 1679, 1009, 1626,    4,\n",
       "          161, 1350,  302,  160,  956, 1739, 1579, 1646]): tensor([[0.0277, 0.1462, 0.1351,  ..., 0.1928, 0.0611, 0.0000],\n",
       "         [0.0865, 0.1310, 0.1481,  ..., 0.1244, 0.0904, 0.0000],\n",
       "         [0.0082, 0.2342, 0.1022,  ..., 0.1641, 0.1727, 0.0000],\n",
       "         ...,\n",
       "         [0.1365, 0.2212, 0.1235,  ..., 0.0861, 0.3391, 0.0000],\n",
       "         [0.0641, 0.4033, 0.1121,  ..., 0.0000, 0.4645, 0.0000],\n",
       "         [0.1431, 0.0305, 0.0237,  ..., 0.1298, 0.3682, 0.0000]]),\n",
       " tensor([ 783, 1647, 1190,  314,  211, 1566,  308,  407, 1770,  341,  437, 1745,\n",
       "          891,  695,  364,   46,  197,  112,  762,  404,  509,  977,  542,  934,\n",
       "           27, 1699, 1589,  615,  933,  417, 1199, 1548]): tensor([[0.0719, 0.1476, 0.1373,  ..., 0.1267, 0.0834, 0.0000],\n",
       "         [0.0861, 0.1296, 0.1349,  ..., 0.0879, 0.0684, 0.0000],\n",
       "         [0.1537, 0.0906, 0.2197,  ..., 0.1903, 0.2151, 0.0000],\n",
       "         ...,\n",
       "         [0.1110, 0.1658, 0.2509,  ..., 0.0000, 0.0920, 0.0000],\n",
       "         [0.0937, 0.1410, 0.1042,  ..., 0.0800, 0.0641, 0.0000],\n",
       "         [0.2071, 0.1818, 0.1948,  ..., 0.0782, 0.3154, 0.0000]]),\n",
       " tensor([1258,  268, 1301,  754, 1342,  410,  508, 1094,  129, 1031, 1645,  469,\n",
       "         1125, 1070, 1364,   34,  861,  395,  626,  172, 1133, 1150, 1035,  491,\n",
       "          441, 1517,   42,  269,  559, 1135,  796, 1123]): tensor([[0.1471, 0.1256, 0.1294,  ..., 0.0141, 0.1326, 0.0000],\n",
       "         [0.1224, 0.1098, 0.1122,  ..., 0.0628, 0.0701, 0.0000],\n",
       "         [0.1338, 0.2318, 0.0633,  ..., 0.1949, 0.1742, 0.0000],\n",
       "         ...,\n",
       "         [0.0643, 0.1770, 0.1507,  ..., 0.2306, 0.0852, 0.0000],\n",
       "         [0.1324, 0.1124, 0.0455,  ..., 0.1929, 0.0079, 0.0000],\n",
       "         [0.1416, 0.0000, 0.1285,  ..., 0.2336, 0.0000, 0.0000]]),\n",
       " tensor([ 562,  870, 1746, 1595,  623,  166,  999, 1056,  120,  253, 1442, 1649,\n",
       "         1163, 1459, 1524,   45,  512,  786,  850, 1140,  794, 1443,  902, 1397,\n",
       "         1149, 1491, 1670, 1834, 1294,   19,  634, 1618]): tensor([[0.0559, 0.2075, 0.2749,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.1428, 0.1699, 0.1717,  ..., 0.0389, 0.3319, 0.0000],\n",
       "         [0.1099, 0.0285, 0.2433,  ..., 0.0383, 0.1183, 0.0000],\n",
       "         ...,\n",
       "         [0.2042, 0.1266, 0.2819,  ..., 0.2055, 0.0802, 0.0000],\n",
       "         [0.1179, 0.2056, 0.0477,  ..., 0.1034, 0.1305, 0.0000],\n",
       "         [0.2066, 0.2493, 0.2379,  ..., 0.0756, 0.2440, 0.0000]]),\n",
       " tensor([1686, 1280, 1452, 1360,  653,  242,  648, 1368,  264,  288, 1203, 1723,\n",
       "         1278, 1677,  982,   88,  737, 1669, 1382,  436, 1408,  293,  202,  696,\n",
       "          831, 1152, 1454,  964,  896, 1761, 1311,  470]): tensor([[0.0000, 0.2759, 0.0164,  ..., 0.0697, 0.3209, 0.0000],\n",
       "         [0.1212, 0.1099, 0.1162,  ..., 0.0636, 0.0599, 0.0000],\n",
       "         [0.1076, 0.1881, 0.1803,  ..., 0.2208, 0.1827, 0.0000],\n",
       "         ...,\n",
       "         [0.1051, 0.1293, 0.1192,  ..., 0.0938, 0.2139, 0.0000],\n",
       "         [0.2685, 0.2879, 0.2882,  ..., 0.0000, 0.2674, 0.0000],\n",
       "         [0.1168, 0.1908, 0.0579,  ..., 0.0879, 0.1237, 0.0000]]),\n",
       " tensor([ 400,  908, 1638, 1520, 1139, 1254, 1543, 1725,  818,  685, 1772, 1431,\n",
       "         1327,  472,  169,    5, 1457, 1681, 1506,  679, 1495, 1426,  577, 1765,\n",
       "         1807, 1758,  894,  877,  734, 1363, 1653, 1260]): tensor([[0.1233, 0.1087, 0.1146,  ..., 0.0644, 0.0571, 0.0000],\n",
       "         [0.1269, 0.0000, 0.2254,  ..., 0.2157, 0.2655, 0.0000],\n",
       "         [0.2102, 0.0616, 0.1350,  ..., 0.2687, 0.1401, 0.0000],\n",
       "         ...,\n",
       "         [0.1458, 0.1548, 0.1072,  ..., 0.1545, 0.0699, 0.0000],\n",
       "         [0.2324, 0.0254, 0.1244,  ..., 0.1168, 0.2976, 0.0000],\n",
       "         [0.2433, 0.2759, 0.2298,  ..., 0.0293, 0.1415, 0.0000]]),\n",
       " tensor([ 256, 1783,  968,  970,  735,  447,  363,  686, 1041, 1409, 1661, 1118,\n",
       "         1449,  468,  823,  791,  913,  612, 1659, 1785, 1729, 1376, 1462,  245,\n",
       "           17,  323,  511,  249, 1809, 1160,  177, 1722]): tensor([[0.1636, 0.1076, 0.0962,  ..., 0.0309, 0.1137, 0.0000],\n",
       "         [0.1196, 0.1565, 0.0336,  ..., 0.1791, 0.1780, 0.0000],\n",
       "         [0.0834, 0.1070, 0.2268,  ..., 0.1559, 0.0033, 0.0000],\n",
       "         ...,\n",
       "         [0.0449, 0.1695, 0.1716,  ..., 0.3029, 0.6636, 0.0000],\n",
       "         [0.1041, 0.1706, 0.1709,  ..., 0.1503, 0.0356, 0.0000],\n",
       "         [0.1216, 0.1100, 0.1170,  ..., 0.0627, 0.0562, 0.0000]]),\n",
       " tensor([ 726,  521,  399,  357,  431, 1667, 1285,  133, 1194, 1010, 1652, 1336,\n",
       "         1724,  556,  874,  668,  912,  281, 1193,  853,   31,  805, 1604,  758,\n",
       "           35,   66, 1341, 1167,  257,  449,  396,  102]): tensor([[0.0000, 0.3028, 0.1386,  ..., 0.0326, 0.0086, 0.0000],\n",
       "         [0.0626, 0.1489, 0.1363,  ..., 0.1304, 0.0688, 0.0000],\n",
       "         [0.0323, 0.0048, 0.0598,  ..., 0.1966, 0.0000, 0.0000],\n",
       "         ...,\n",
       "         [0.0310, 0.2585, 0.0678,  ..., 0.0000, 0.3694, 0.0000],\n",
       "         [0.1608, 0.0826, 0.0284,  ..., 0.1213, 0.0000, 0.0000],\n",
       "         [0.0994, 0.1276, 0.1357,  ..., 0.0985, 0.0211, 0.0000]]),\n",
       " tensor([ 892, 1608, 1598, 1351,  915,  589, 1584, 1636,  446, 1048,  863, 1219,\n",
       "         1773,  728, 1836, 1743,  524,   10,  770,   53, 1582, 1832, 1439, 1554,\n",
       "         1422,  571, 1025,  267,  581, 1267,  477,  154]): tensor([[0.0834, 0.0980, 0.1165,  ..., 0.0872, 0.0213, 0.0000],\n",
       "         [0.1039, 0.1194, 0.1350,  ..., 0.0908, 0.0305, 0.0000],\n",
       "         [0.0482, 0.1075, 0.0872,  ..., 0.1350, 0.0291, 0.0000],\n",
       "         ...,\n",
       "         [0.2993, 0.2757, 0.0721,  ..., 0.0231, 0.0072, 0.0000],\n",
       "         [0.0939, 0.1473, 0.1258,  ..., 0.1258, 0.1687, 0.0000],\n",
       "         [0.1028, 0.1538, 0.1319,  ..., 0.1137, 0.1132, 0.0000]]),\n",
       " tensor([ 875,  456,    7,  402,  827, 1614,  221,  290, 1396, 1262, 1788, 1415,\n",
       "          992,  327,  890,  601, 1521, 1687,  795, 1560,  927,   50, 1751,  637,\n",
       "         1593, 1717,  723,  499,  187,  935,  671,  809]): tensor([[0.0330, 0.1672, 0.1011,  ..., 0.0914, 0.0000, 0.0000],\n",
       "         [0.1068, 0.2257, 0.1550,  ..., 0.1343, 0.0723, 0.0000],\n",
       "         [0.0301, 0.0631, 0.1260,  ..., 0.1476, 0.2312, 0.0000],\n",
       "         ...,\n",
       "         [0.2578, 0.1259, 0.0563,  ..., 0.2016, 0.5684, 0.0000],\n",
       "         [0.0290, 0.1281, 0.1483,  ..., 0.1480, 0.0782, 0.0000],\n",
       "         [0.0879, 0.1302, 0.1535,  ..., 0.1221, 0.0872, 0.0000]]),\n",
       " tensor([1122,  639,  106, 1129, 1692,   79,  779, 1369,  346,  880,  147,    6,\n",
       "         1660,  424, 1493, 1597, 1407, 1002, 1147,  716,  280,  234,   18,  108,\n",
       "         1436,  507, 1824,  443, 1796, 1228, 1304, 1130]): tensor([[0.1648, 0.1723, 0.0000,  ..., 0.5007, 0.3207, 0.0000],\n",
       "         [0.0818, 0.0959, 0.2222,  ..., 0.1296, 0.0000, 0.0000],\n",
       "         [0.0654, 0.1488, 0.1368,  ..., 0.1329, 0.0724, 0.0000],\n",
       "         ...,\n",
       "         [0.0769, 0.1199, 0.0942,  ..., 0.4725, 0.6120, 0.0000],\n",
       "         [0.0126, 0.0575, 0.1002,  ..., 0.2253, 0.2266, 0.0000],\n",
       "         [0.0192, 0.2015, 0.0336,  ..., 0.1251, 0.1909, 0.0000]]),\n",
       " tensor([1704,  564,  215,  134,   54, 1282,  392, 1339, 1233,  465,  666, 1588,\n",
       "          609,  851,  672,  714, 1612, 1461,  563, 1378,  457,  121,  859, 1138,\n",
       "         1092,   89,  183, 1837, 1354, 1021,  356, 1501]): tensor([[0.2148, 0.2299, 0.2950,  ..., 0.1131, 0.2242, 0.0000],\n",
       "         [0.2095, 0.1453, 0.1486,  ..., 0.1142, 0.0145, 0.0000],\n",
       "         [0.0906, 0.2309, 0.1424,  ..., 0.0961, 0.3616, 0.0000],\n",
       "         ...,\n",
       "         [0.1817, 0.1381, 0.2444,  ..., 0.0423, 0.1235, 0.0000],\n",
       "         [0.0102, 0.2666, 0.1246,  ..., 0.0020, 0.0776, 0.0000],\n",
       "         [0.2569, 0.1465, 0.4345,  ..., 0.0466, 0.3252, 0.0000]]),\n",
       " tensor([1224,  772,  829,  375,  180, 1690,  580,   97,  560, 1488,  389,  604,\n",
       "         1082, 1344, 1030,  178,  181,  130,  872, 1585,  704, 1535,  252, 1085,\n",
       "          528, 1473,   26,  697,   75,  665, 1300,  284]): tensor([[0.1894, 0.1011, 0.0962,  ..., 0.2046, 0.3250, 0.0000],\n",
       "         [0.0953, 0.2848, 0.1399,  ..., 0.3100, 0.0349, 0.0000],\n",
       "         [0.0629, 0.2671, 0.2159,  ..., 0.0184, 0.1146, 0.0000],\n",
       "         ...,\n",
       "         [0.0000, 0.0293, 0.0021,  ..., 0.0100, 0.1560, 0.0000],\n",
       "         [0.1214, 0.1133, 0.1126,  ..., 0.0780, 0.0775, 0.0000],\n",
       "         [0.2396, 0.2616, 0.1826,  ..., 0.0060, 0.3030, 0.0000]]),\n",
       " tensor([1460,  800, 1024,  505, 1083, 1550,  669,  751, 1283, 1634,  967, 1536,\n",
       "         1202, 1302, 1432,  222,  825,  815,  418,  706, 1779,  727,  167, 1438,\n",
       "         1561,    9,  773,  421,  608, 1819,  385,  835]): tensor([[0.2960, 0.1013, 0.3941,  ..., 0.0000, 0.4752, 0.0000],\n",
       "         [0.1208, 0.1649, 0.1333,  ..., 0.1197, 0.0646, 0.0000],\n",
       "         [0.1018, 0.2164, 0.0917,  ..., 0.0501, 0.1097, 0.0000],\n",
       "         ...,\n",
       "         [0.0994, 0.2016, 0.0674,  ..., 0.1527, 0.1433, 0.0000],\n",
       "         [0.0541, 0.0347, 0.0590,  ..., 0.0580, 0.0599, 0.0000],\n",
       "         [0.1012, 0.1500, 0.1982,  ..., 0.1660, 0.1070, 0.0000]]),\n",
       " tensor([ 920,  945,  488, 1045, 1540, 1742,  138,  731, 1500,  343,  318, 1496,\n",
       "          975,  397, 1767, 1519,  149,  981, 1762,  461,  811,  690,  684,  659,\n",
       "         1204, 1417,  821, 1293, 1674, 1290, 1814,  732]): tensor([[0.2516, 0.2767, 0.1764,  ..., 0.1230, 0.4878, 0.0000],\n",
       "         [0.1115, 0.2639, 0.1415,  ..., 0.2307, 0.1313, 0.0000],\n",
       "         [0.0439, 0.1319, 0.2162,  ..., 0.1564, 0.0869, 0.0000],\n",
       "         ...,\n",
       "         [0.2040, 0.0885, 0.1628,  ..., 0.0597, 0.0539, 0.0000],\n",
       "         [0.2954, 0.3633, 0.0000,  ..., 0.3784, 0.7232, 0.0000],\n",
       "         [0.0221, 0.1177, 0.0791,  ..., 0.1580, 0.0751, 0.0000]]),\n",
       " tensor([ 368, 1458,  888,   25, 1565, 1445, 1617, 1358,   60,  216, 1575,  793,\n",
       "         1169, 1155,   86, 1470,  142,   38,   37,   90, 1367,  241,  597, 1534,\n",
       "          326,  360,  587, 1427,  150, 1578,  630,  664]): tensor([[0.2201, 0.2766, 0.0451,  ..., 0.3188, 0.1009, 0.0000],\n",
       "         [0.1100, 0.1971, 0.1588,  ..., 0.0526, 0.3335, 0.0000],\n",
       "         [0.1034, 0.1159, 0.1309,  ..., 0.1301, 0.2624, 0.0000],\n",
       "         ...,\n",
       "         [0.0379, 0.1255, 0.1638,  ..., 0.0000, 0.2223, 0.0000],\n",
       "         [0.0933, 0.1209, 0.1110,  ..., 0.1013, 0.0000, 0.0000],\n",
       "         [0.0989, 0.1202, 0.1161,  ..., 0.2285, 0.0789, 0.0000]]),\n",
       " tensor([1320,  476,  186,  498, 1099,  349, 1346,  586,  899,  174,   28, 1602,\n",
       "         1277,  709,  428,  541,  574,  759,  103, 1740, 1259,  145,  243, 1062,\n",
       "          656, 1066,  740, 1240, 1815, 1508, 1691, 1071]): tensor([[0.2739, 0.1305, 0.1955,  ..., 0.0514, 0.0670, 0.0000],\n",
       "         [0.0827, 0.3100, 0.0492,  ..., 0.0000, 0.0034, 0.0000],\n",
       "         [0.0790, 0.1678, 0.0978,  ..., 0.1032, 0.0359, 0.0000],\n",
       "         ...,\n",
       "         [0.1074, 0.1628, 0.0277,  ..., 0.1534, 0.1066, 0.0000],\n",
       "         [0.2594, 0.1712, 0.0455,  ..., 0.1371, 0.1236, 0.0000],\n",
       "         [0.1462, 0.2222, 0.0000,  ..., 0.0018, 0.4420, 0.0000]]),\n",
       " tensor([1757,  844, 1533,  765, 1063, 1313, 1406, 1291,  537, 1191, 1702,  550,\n",
       "         1077,  110, 1050,  848,  849,  627,  444,  775,  847,  828,  657, 1057,\n",
       "           52,  792, 1243, 1505,  769,  116, 1709,   84]): tensor([[0.0336, 0.1455, 0.1074,  ..., 0.2377, 0.1470, 0.0000],\n",
       "         [0.0505, 0.3419, 0.0417,  ..., 0.0697, 0.0000, 0.0000],\n",
       "         [0.1224, 0.0105, 0.0951,  ..., 0.0000, 0.1924, 0.0000],\n",
       "         ...,\n",
       "         [0.0940, 0.0871, 0.0887,  ..., 0.1026, 0.0000, 0.0000],\n",
       "         [0.1436, 0.0339, 0.0271,  ..., 0.1307, 0.3707, 0.0000],\n",
       "         [0.1276, 0.1763, 0.0678,  ..., 0.1637, 0.1124, 0.0000]]),\n",
       " tensor([1012, 1423,  105, 1490, 1657,  255, 1546, 1515,  724, 1563,  768, 1478,\n",
       "          655, 1370,  638, 1109,   80,  330,  771, 1044,  761, 1154, 1136,  502,\n",
       "          566, 1003,  622,   68, 1248, 1165,  883,   55]): tensor([[0.0632, 0.1138, 0.2084,  ..., 0.0551, 0.0405, 0.0000],\n",
       "         [0.0906, 0.0000, 0.0662,  ..., 0.2564, 0.0000, 0.0000],\n",
       "         [0.0938, 0.1892, 0.1926,  ..., 0.0000, 0.1790, 0.0000],\n",
       "         ...,\n",
       "         [0.0679, 0.1494, 0.1427,  ..., 0.1200, 0.0711, 0.0000],\n",
       "         [0.0828, 0.1322, 0.1411,  ..., 0.0858, 0.0583, 0.0000],\n",
       "         [0.1213, 0.1072, 0.1146,  ..., 0.0641, 0.0581, 0.0000]]),\n",
       " tensor([ 990, 1263, 1385,  958,  605,  320,  972, 1016,  225,  347,  641,  681,\n",
       "            8,  200, 1215, 1665,   91, 1577,  127,   12,  336, 1380,  954,  837,\n",
       "          540, 1542, 1347, 1212, 1210,  979,  179, 1227]): tensor([[0.1279, 0.2164, 0.0097,  ..., 0.2456, 0.1350, 0.0000],\n",
       "         [0.1011, 0.1509, 0.1333,  ..., 0.1156, 0.1066, 0.0000],\n",
       "         [0.0835, 0.0307, 0.1412,  ..., 0.3473, 0.1591, 0.0000],\n",
       "         ...,\n",
       "         [0.1181, 0.2582, 0.0000,  ..., 0.0453, 0.1167, 0.0000],\n",
       "         [0.0910, 0.1694, 0.1330,  ..., 0.1307, 0.0395, 0.0000],\n",
       "         [0.1004, 0.1503, 0.1373,  ..., 0.1176, 0.1076, 0.0000]]),\n",
       " tensor([1208,  248, 1124,  957,  635, 1416, 1102, 1456, 1790,   11,  629, 1400,\n",
       "         1570, 1529,  545,  953,  386, 1791,  610,  380,  918, 1840, 1441,   92,\n",
       "         1137,  887,  337, 1730, 1451, 1502, 1198, 1055]): tensor([[0.3321, 0.2369, 0.2043,  ..., 0.1726, 0.6950, 0.0000],\n",
       "         [0.1027, 0.1483, 0.1372,  ..., 0.1167, 0.1073, 0.0000],\n",
       "         [0.1061, 0.0986, 0.0898,  ..., 0.3616, 0.3003, 0.0000],\n",
       "         ...,\n",
       "         [0.2686, 0.0701, 0.0885,  ..., 0.2097, 0.3022, 0.0000],\n",
       "         [0.0318, 0.1666, 0.0922,  ..., 0.0000, 0.2512, 0.0000],\n",
       "         [0.0657, 0.1159, 0.1132,  ..., 0.0756, 0.0334, 0.0000]]),\n",
       " tensor([1014, 1398,  624, 1238,  273, 1465,  929, 1088, 1113, 1484,  718,  910,\n",
       "         1703, 1826, 1480, 1805,  755, 1033,  388,  523,  652, 1666,   82,  503,\n",
       "         1060,  283,  753, 1800, 1801,  378,   83,  876]): tensor([[0.0790, 0.1684, 0.0986,  ..., 0.0974, 0.0471, 0.0000],\n",
       "         [0.1539, 0.2298, 0.0898,  ..., 0.1703, 0.4191, 0.0000],\n",
       "         [0.0000, 0.2859, 0.3096,  ..., 0.1799, 0.1204, 0.0000],\n",
       "         ...,\n",
       "         [0.1597, 0.2179, 0.1250,  ..., 0.1443, 0.3658, 0.0000],\n",
       "         [0.0000, 0.1811, 0.0861,  ..., 0.0830, 0.1180, 0.0000],\n",
       "         [0.1096, 0.1978, 0.1253,  ..., 0.0786, 0.2215, 0.0000]]),\n",
       " tensor([1463, 1503,  460,  565,   77,  725, 1514, 1256, 1648, 1455, 1421,  766,\n",
       "          777,  390,  434, 1097, 1741, 1372, 1732, 1156, 1309,  738, 1558,  214,\n",
       "         1119,  879, 1620, 1726, 1161,  463,  144,  682]): tensor([[0.1029, 0.1515, 0.1376,  ..., 0.1173, 0.1104, 0.0000],\n",
       "         [0.2273, 0.0074, 0.3312,  ..., 0.0000, 0.3470, 0.0000],\n",
       "         [0.1497, 0.1287, 0.3671,  ..., 0.0203, 0.0729, 0.0000],\n",
       "         ...,\n",
       "         [0.0374, 0.1653, 0.1631,  ..., 0.1644, 0.0622, 0.0000],\n",
       "         [0.2037, 0.0974, 0.2015,  ..., 0.0386, 0.4474, 0.0000],\n",
       "         [0.1134, 0.2655, 0.1925,  ..., 0.0000, 0.2378, 0.0000]]),\n",
       " tensor([ 645, 1635, 1697,  137, 1330,  843, 1000, 1468,  960,  860,  370,  897,\n",
       "          165, 1748,   72,  317,  419,  500,  568,  688, 1759,  459, 1197,  616,\n",
       "         1328,   41,  603,  760, 1798, 1241,  445, 1523]): tensor([[0.1066, 0.1397, 0.1096,  ..., 0.0583, 0.0910, 0.0000],\n",
       "         [0.2694, 0.0292, 0.2223,  ..., 0.2652, 0.4302, 0.0000],\n",
       "         [0.1347, 0.1708, 0.0836,  ..., 0.1646, 0.0974, 0.0000],\n",
       "         ...,\n",
       "         [0.0350, 0.1294, 0.1472,  ..., 0.1494, 0.0913, 0.0000],\n",
       "         [0.2177, 0.2587, 0.0494,  ..., 0.2998, 0.0824, 0.0000],\n",
       "         [0.1436, 0.1779, 0.3199,  ..., 0.1664, 0.0000, 0.0000]]),\n",
       " tensor([1587,  490, 1274,  219, 1004, 1279, 1008, 1349, 1731, 1820, 1257, 1265,\n",
       "         1242,  376,  866, 1471,   64,  633,  642,  435,   74, 1359,  988,  971,\n",
       "          209, 1098,  553,  966,  947,   48,  504,  146]): tensor([[0.1671, 0.2513, 0.2257,  ..., 0.0112, 0.3416, 0.0000],\n",
       "         [0.2391, 0.0000, 0.1324,  ..., 0.1234, 0.2184, 0.0000],\n",
       "         [0.1452, 0.4330, 0.0000,  ..., 0.5708, 0.5579, 0.0000],\n",
       "         ...,\n",
       "         [0.0911, 0.1392, 0.1037,  ..., 0.0763, 0.0473, 0.0000],\n",
       "         [0.2959, 0.0758, 0.0847,  ..., 0.1817, 0.4455, 0.0000],\n",
       "         [0.0790, 0.2650, 0.1222,  ..., 0.2113, 0.2132, 0.0000]]),\n",
       " tensor([ 675,   21, 1072,  995,  412,  492,  742,  190, 1708,  294, 1413,  164,\n",
       "          515,  572,   87,  717,  466, 1507,  854, 1706, 1032, 1601, 1178, 1752,\n",
       "         1630, 1808,  401, 1641, 1093, 1655,  636, 1698]): tensor([[0.0075, 0.1487, 0.1816,  ..., 0.1653, 0.0488, 0.0000],\n",
       "         [0.0736, 0.2115, 0.1141,  ..., 0.1206, 0.0873, 0.0000],\n",
       "         [0.1169, 0.2100, 0.1864,  ..., 0.1194, 0.4336, 0.0000],\n",
       "         ...,\n",
       "         [0.0912, 0.1826, 0.2306,  ..., 0.1391, 0.3638, 0.0000],\n",
       "         [0.0849, 0.1194, 0.2088,  ..., 0.0612, 0.1068, 0.0000],\n",
       "         [0.3936, 0.0029, 0.0000,  ..., 0.1780, 0.5952, 0.0000]]),\n",
       " tensor([1656,  369,  852, 1545, 1810,  660, 1795,  904,  301, 1246, 1001, 1583,\n",
       "         1053,  387,  625,  224,  826, 1444,  924, 1569,  125,  644, 1497,  640,\n",
       "          223, 1029, 1168,  295,  955,  335, 1250, 1419]): tensor([[0.1234, 0.1201, 0.1146,  ..., 0.0692, 0.0480, 0.0000],\n",
       "         [0.2053, 0.0940, 0.0796,  ..., 0.1742, 0.3436, 0.0000],\n",
       "         [0.1384, 0.1638, 0.0887,  ..., 0.1552, 0.1092, 0.0000],\n",
       "         ...,\n",
       "         [0.1467, 0.3193, 0.0377,  ..., 0.1282, 0.2716, 0.0000],\n",
       "         [0.0000, 0.1337, 0.0000,  ..., 0.0375, 0.3264, 0.0000],\n",
       "         [0.1074, 0.3669, 0.2022,  ..., 0.0182, 0.0000, 0.0000]]),\n",
       " tensor([ 846,  373,   57, 1399,   16,  272, 1446, 1793, 1086, 1266,    3, 1065,\n",
       "         1556, 1064, 1707,  595,  632,  325, 1600,  748, 1371,  158, 1716,  159,\n",
       "          282,  763, 1151, 1683,  104,  235,  312,  238]): tensor([[0.1339, 0.0385, 0.0499,  ..., 0.2116, 0.0310, 0.0000],\n",
       "         [0.0874, 0.1725, 0.1366,  ..., 0.1896, 0.0160, 0.0000],\n",
       "         [0.0815, 0.2151, 0.1162,  ..., 0.2274, 0.0318, 0.0000],\n",
       "         ...,\n",
       "         [0.1122, 0.2058, 0.0445,  ..., 0.1683, 0.2224, 0.0000],\n",
       "         [0.0558, 0.1999, 0.1671,  ..., 0.1199, 0.0426, 0.0000],\n",
       "         [0.0898, 0.0803, 0.1751,  ..., 0.1034, 0.0000, 0.0000]]),\n",
       " tensor([1352, 1006, 1437,  790, 1528,  996,  406,  355,  113, 1479, 1711,  833,\n",
       "          533,  961,  513,  741, 1425,  558,  122,  661, 1664,   47,  362, 1143,\n",
       "         1728,  868,  673, 1039, 1753,  525,  547,  689]): tensor([[0.1250, 0.0793, 0.2450,  ..., 0.0643, 0.1500, 0.0000],\n",
       "         [0.0878, 0.1298, 0.1513,  ..., 0.1272, 0.0907, 0.0000],\n",
       "         [0.0384, 0.1813, 0.0748,  ..., 0.2922, 0.3046, 0.0000],\n",
       "         ...,\n",
       "         [0.0773, 0.2692, 0.3311,  ..., 0.2414, 0.0000, 0.0000],\n",
       "         [0.1333, 0.2774, 0.0618,  ..., 0.2154, 0.1933, 0.0000],\n",
       "         [0.3003, 0.2699, 0.0665,  ..., 0.0207, 0.2731, 0.0000]]),\n",
       " tensor([ 621,  440,   24,  213, 1089,  959,  539,  708,  155, 1074, 1537, 1590,\n",
       "         1689, 1011,  836,  517, 1474,    2, 1532,  951,  592,  928,  936,  118,\n",
       "          965, 1513,  948, 1100, 1555,  702,  749,  980]): tensor([[0.0799, 0.1030, 0.1158,  ..., 0.0934, 0.0168, 0.0000],\n",
       "         [0.0718, 0.2941, 0.2365,  ..., 0.0000, 0.0598, 0.0000],\n",
       "         [0.1296, 0.1621, 0.0713,  ..., 0.1640, 0.0934, 0.0000],\n",
       "         ...,\n",
       "         [0.1729, 0.0158, 0.1741,  ..., 0.3227, 0.1629, 0.0000],\n",
       "         [0.1876, 0.0375, 0.0610,  ..., 0.1265, 0.0451, 0.0000],\n",
       "         [0.1073, 0.1980, 0.0927,  ..., 0.1117, 0.0600, 0.0000]]),\n",
       " tensor([ 839,  804, 1271,  649, 1469, 1811,  379, 1632, 1838,  333,  931,  812,\n",
       "         1251,  263, 1182, 1295,  719,   62,  348, 1812, 1705,  311,  922, 1747,\n",
       "         1081, 1038, 1794, 1321, 1308, 1200, 1176,  746]): tensor([[0.0858, 0.1283, 0.1326,  ..., 0.0894, 0.0652, 0.0000],\n",
       "         [0.1895, 0.0979, 0.0983,  ..., 0.2076, 0.3217, 0.0000],\n",
       "         [0.2228, 0.0000, 0.1901,  ..., 0.2868, 0.4050, 0.0000],\n",
       "         ...,\n",
       "         [0.0784, 0.1704, 0.0920,  ..., 0.1075, 0.0423, 0.0000],\n",
       "         [0.2040, 0.1363, 0.0319,  ..., 0.1335, 0.4147, 0.0000],\n",
       "         [0.0802, 0.1062, 0.2096,  ..., 0.0765, 0.0497, 0.0000]]),\n",
       " tensor([ 536, 1365, 1525, 1221,  938, 1564, 1591,  484]): tensor([[0.0872, 0.1342, 0.1496,  ..., 0.1260, 0.0922, 0.0000],\n",
       "         [0.0546, 0.1524, 0.1388,  ..., 0.2454, 0.0528, 0.0000],\n",
       "         [0.1166, 0.1887, 0.0966,  ..., 0.1409, 0.1003, 0.0000],\n",
       "         ...,\n",
       "         [0.0659, 0.1160, 0.1126,  ..., 0.0747, 0.0374, 0.0000],\n",
       "         [0.1594, 0.0583, 0.3464,  ..., 0.1336, 0.1930, 0.0000],\n",
       "         [0.0752, 0.1020, 0.2077,  ..., 0.0908, 0.0620, 0.0000]]),\n",
       " tensor([1607,  841, 1323,  598, 1128, 1510,  168,  422, 1132,  305,  534, 1386,\n",
       "          538, 1668,  270, 1317, 1159,  744,  941,   78,  576, 1340,  100, 1782,\n",
       "         1721, 1348, 1498,  787,  813, 1249, 1049, 1778]): tensor([[0.2491, 0.0465, 0.1747,  ..., 0.0187, 0.1856, 0.0000],\n",
       "         [0.2274, 0.1908, 0.1116,  ..., 0.0432, 0.4153, 0.0000],\n",
       "         [0.1149, 0.1872, 0.0929,  ..., 0.1417, 0.0938, 0.0000],\n",
       "         ...,\n",
       "         [0.1957, 0.3146, 0.0841,  ..., 0.4433, 0.4831, 0.0000],\n",
       "         [0.2037, 0.3724, 0.1180,  ..., 0.1341, 0.3334, 0.0000],\n",
       "         [0.2696, 0.2333, 0.1331,  ..., 0.2235, 0.2621, 0.0000]]),\n",
       " tensor([1023,  916,  433,  596, 1379, 1509,   73,   99, 1623,  310,  277,  244,\n",
       "          101,   51,  416, 1629, 1760,  862,  464,  670, 1552, 1596, 1013, 1310,\n",
       "          366,  921,  383,  584, 1492,  614,  141, 1331]): tensor([[0.0198, 0.3789, 0.1935,  ..., 0.1304, 0.4420, 0.0000],\n",
       "         [0.1234, 0.1171, 0.2051,  ..., 0.0497, 0.1701, 0.0000],\n",
       "         [0.4804, 0.4046, 0.1284,  ..., 0.0000, 0.3503, 0.0000],\n",
       "         ...,\n",
       "         [0.0862, 0.0578, 0.2560,  ..., 0.1255, 0.0000, 0.0000],\n",
       "         [0.0879, 0.2395, 0.0955,  ..., 0.1214, 0.2926, 0.0000],\n",
       "         [0.2272, 0.1832, 0.1233,  ..., 0.0000, 0.9199, 0.0000]]),\n",
       " tensor([ 425,  339,  873, 1142,  261, 1710, 1404, 1043, 1839,  271,  306,  705,\n",
       "         1387, 1403,  567,  297, 1325,   70, 1393, 1541, 1061, 1830,  527, 1781,\n",
       "         1700,  194, 1329, 1230, 1539, 1627, 1084,  619]): tensor([[0.2125, 0.2814, 0.0000,  ..., 0.2105, 0.4169, 0.0000],\n",
       "         [0.0902, 0.1419, 0.1360,  ..., 0.0857, 0.0829, 0.0000],\n",
       "         [0.1952, 0.2392, 0.2735,  ..., 0.1149, 0.1885, 0.0000],\n",
       "         ...,\n",
       "         [0.0867, 0.0111, 0.2261,  ..., 0.0351, 0.1028, 0.0000],\n",
       "         [0.1269, 0.1027, 0.0169,  ..., 0.2225, 0.4709, 0.0000],\n",
       "         [0.1054, 0.2183, 0.0990,  ..., 0.0472, 0.1089, 0.0000]]),\n",
       " tensor([ 198, 1211,  923,  218,  898,  745, 1611,  233,  973, 1187,  303, 1701,\n",
       "          643,  203, 1676,  107, 1727,  220, 1322,  767,  654,  869,  781,  757,\n",
       "         1466, 1763, 1315,  701,  613,  518,  162, 1116]): tensor([[0.0836, 0.1404, 0.1061,  ..., 0.1026, 0.0807, 0.0000],\n",
       "         [0.1203, 0.1506, 0.1522,  ..., 0.0995, 0.1344, 0.0000],\n",
       "         [0.0835, 0.0984, 0.1165,  ..., 0.0868, 0.0228, 0.0000],\n",
       "         ...,\n",
       "         [0.0507, 0.2179, 0.0238,  ..., 0.2542, 0.1095, 0.0000],\n",
       "         [0.1342, 0.1200, 0.0122,  ..., 0.0036, 0.0000, 0.0000],\n",
       "         [0.0961, 0.1849, 0.0690,  ..., 0.0000, 0.3003, 0.0000]]),\n",
       " tensor([ 307,  583, 1284,  985, 1179, 1394, 1654,  692, 1175, 1298,  405,  582,\n",
       "         1255,  557,  415,   67, 1073,   29,  438,  677,  940, 1736, 1112,  259,\n",
       "         1307, 1559,  756, 1734,  994, 1289, 1715, 1802]): tensor([[0.1575, 0.2112, 0.1758,  ..., 0.2491, 0.0811, 0.0000],\n",
       "         [0.2129, 0.1701, 0.0581,  ..., 0.2034, 0.3028, 0.0000],\n",
       "         [0.1342, 0.1614, 0.1247,  ..., 0.1361, 0.1186, 0.0000],\n",
       "         ...,\n",
       "         [0.0616, 0.2182, 0.1048,  ..., 0.0000, 0.2633, 0.0000],\n",
       "         [0.0948, 0.1385, 0.1464,  ..., 0.0865, 0.0769, 0.0000],\n",
       "         [0.1462, 0.2051, 0.0872,  ..., 0.2294, 0.2250, 0.0000]]),\n",
       " tensor([1562, 1599,  292, 1475,  607, 1624,   23, 1225,  997,  620,  674,  453,\n",
       "          495, 1305,  479,  115, 1131, 1245,  394, 1181, 1381,  175,  485, 1688,\n",
       "          309, 1650,   30, 1818, 1549, 1144, 1075,  820]): tensor([[0.1072, 0.1132, 0.1334,  ..., 0.0917, 0.0384, 0.0000],\n",
       "         [0.0730, 0.1291, 0.2407,  ..., 0.2268, 0.2006, 0.0000],\n",
       "         [0.0876, 0.1327, 0.1533,  ..., 0.1232, 0.0876, 0.0000],\n",
       "         ...,\n",
       "         [0.1318, 0.2047, 0.1682,  ..., 0.1064, 0.0717, 0.0000],\n",
       "         [0.0900, 0.2461, 0.0710,  ..., 0.1463, 0.0000, 0.0000],\n",
       "         [0.0562, 0.1783, 0.1993,  ..., 0.1524, 0.1654, 0.0000]]),\n",
       " tensor([ 358,  942,   43, 1273, 1314, 1333,  845, 1786,  350, 1173, 1214,  976,\n",
       "         1222, 1375,  832,  420, 1616, 1384,  212,  182, 1157, 1420,  903, 1658,\n",
       "          905,  544,   69, 1170,  552,  978,  855, 1516]): tensor([[0.1034, 0.1078, 0.0564,  ..., 0.1309, 0.2590, 0.0000],\n",
       "         [0.0603, 0.1201, 0.2023,  ..., 0.1070, 0.0363, 0.0000],\n",
       "         [0.0000, 0.2309, 0.0272,  ..., 0.1811, 0.2479, 0.0000],\n",
       "         ...,\n",
       "         [0.1444, 0.2268, 0.1979,  ..., 0.0971, 0.3443, 0.0000],\n",
       "         [0.0721, 0.2286, 0.1788,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.2177, 0.2008, 0.0663,  ..., 0.0840, 0.2158, 0.0000]]),\n",
       " tensor([1637, 1269, 1571, 1551,  551, 1829,  478, 1146, 1489, 1268, 1205, 1787,\n",
       "         1678,  838,  881, 1720,  886, 1827,  231, 1052,  611, 1642, 1494,  817,\n",
       "          128,  824,  721, 1357,  353, 1771, 1487,  382]): tensor([[0.0845, 0.1587, 0.1662,  ..., 0.1367, 0.0821, 0.0000],\n",
       "         [0.2560, 0.3154, 0.0386,  ..., 0.0000, 0.1825, 0.0000],\n",
       "         [0.0762, 0.1097, 0.2025,  ..., 0.0502, 0.0627, 0.0000],\n",
       "         ...,\n",
       "         [0.1255, 0.2313, 0.1500,  ..., 0.1811, 0.1490, 0.0000],\n",
       "         [0.2274, 0.2534, 0.1599,  ..., 0.1308, 0.1786, 0.0000],\n",
       "         [0.1143, 0.1696, 0.1334,  ..., 0.1190, 0.0785, 0.0000]]),\n",
       " tensor([ 806,  752, 1414, 1817,  354, 1234,  254, 1719, 1226, 1286, 1172,  950,\n",
       "         1744,  733, 1034, 1231, 1713,  439,  199, 1252]): tensor([[0.1681, 0.2096, 0.0721,  ..., 0.1249, 0.1366, 0.0000],\n",
       "         [0.1752, 0.1766, 0.0303,  ..., 0.3105, 0.2231, 0.0000],\n",
       "         [0.1670, 0.0826, 0.0814,  ..., 0.1969, 0.3008, 0.0000],\n",
       "         ...,\n",
       "         [0.1348, 0.1732, 0.0838,  ..., 0.1601, 0.0933, 0.0000],\n",
       "         [0.1208, 0.1925, 0.2635,  ..., 0.1000, 0.1896, 0.0000],\n",
       "         [0.1960, 0.0690, 0.1013,  ..., 0.1318, 0.2136, 0.0000]]),\n",
       " tensor([1472, 1605,  286,  332, 1206, 1803,  946,  529, 1232,   59, 1027, 1640,\n",
       "         1792, 1429,  680, 1718, 1481,  239,  867, 1568, 1270, 1673,  493, 1054,\n",
       "          289,  494, 1395, 1343,  526,   44,  266,  432]): tensor([[0.0588, 0.1732, 0.1494,  ..., 0.0000, 0.0790, 0.0000],\n",
       "         [0.2670, 0.2414, 0.0818,  ..., 0.0000, 0.2000, 0.0000],\n",
       "         [0.1005, 0.1489, 0.1344,  ..., 0.1173, 0.1076, 0.0000],\n",
       "         ...,\n",
       "         [0.1347, 0.2123, 0.0761,  ..., 0.1433, 0.2173, 0.0000],\n",
       "         [0.1013, 0.1618, 0.1511,  ..., 0.1184, 0.1005, 0.0000],\n",
       "         [0.1114, 0.2565, 0.0392,  ..., 0.1277, 0.2362, 0.0000]]),\n",
       " tensor([ 555,  300,  530,  628,  937, 1217,  352,  173,  148, 1768,   63, 1164,\n",
       "           15, 1581, 1189,  163, 1784,  170,  590,  799, 1040,  570,  462,  532,\n",
       "          250,   49, 1675,  429,  519,  316,  774,   76]): tensor([[0.1364, 0.1704, 0.0832,  ..., 0.1622, 0.0897, 0.0000],\n",
       "         [0.1200, 0.1921, 0.1283,  ..., 0.0170, 0.2482, 0.0000],\n",
       "         [0.1058, 0.1158, 0.1202,  ..., 0.0677, 0.0829, 0.0000],\n",
       "         ...,\n",
       "         [0.0832, 0.0982, 0.1163,  ..., 0.0880, 0.0213, 0.0000],\n",
       "         [0.1140, 0.2045, 0.1076,  ..., 0.0349, 0.0771, 0.0000],\n",
       "         [0.0578, 0.2433, 0.0211,  ..., 0.1464, 0.4833, 0.0000]]),\n",
       " tensor([ 184,  548, 1797,  720,  943, 1775,  427, 1467,  381, 1756, 1236,  236,\n",
       "         1633,  694,  857, 1281, 1662, 1619,  974,  591,  196,  710, 1324,  344,\n",
       "         1036,  331,  371, 1774, 1374,  274, 1628, 1299]): tensor([[0.2786, 0.0274, 0.0005,  ..., 0.1892, 0.4640, 0.0000],\n",
       "         [0.1057, 0.2113, 0.1737,  ..., 0.0214, 0.1023, 0.0000],\n",
       "         [0.1146, 0.1875, 0.2002,  ..., 0.1038, 0.3837, 0.0000],\n",
       "         ...,\n",
       "         [0.1211, 0.1118, 0.1172,  ..., 0.0617, 0.0534, 0.0000],\n",
       "         [0.1803, 0.0899, 0.1341,  ..., 0.1571, 0.0000, 0.0000],\n",
       "         [0.2163, 0.0863, 0.0639,  ..., 0.2097, 0.4092, 0.0000]]),\n",
       " tensor([ 208, 1557,  998,  471,  486, 1338,  497, 1318,  575, 1573,  939, 1572,\n",
       "         1526, 1684,  711, 1355,   71, 1145, 1511, 1835,  650, 1345,  408,   65,\n",
       "         1103,  917, 1319, 1447,  963,  251, 1087, 1613]): tensor([[0.1320, 0.1640, 0.0784,  ..., 0.1495, 0.0745, 0.0000],\n",
       "         [0.0052, 0.1771, 0.2347,  ..., 0.1564, 0.0753, 0.0000],\n",
       "         [0.0509, 0.1690, 0.0765,  ..., 0.0746, 0.2679, 0.0000],\n",
       "         ...,\n",
       "         [0.0887, 0.1300, 0.1514,  ..., 0.1242, 0.0874, 0.0000],\n",
       "         [0.1051, 0.2424, 0.2290,  ..., 0.1621, 0.4285, 0.0000],\n",
       "         [0.0760, 0.2476, 0.3651,  ..., 0.0000, 0.0649, 0.0000]]),\n",
       " tensor([  58,  514,  588,  730, 1476, 1235, 1816, 1609,  780,  111,  889, 1091,\n",
       "         1527, 1356,  785,  901,  808,  124,  506, 1201,  722,  226, 1047,  275,\n",
       "          185,  365,  367,   56, 1831, 1448, 1828,  240]): tensor([[0.0463, 0.1376, 0.1254,  ..., 0.1003, 0.0316, 0.0000],\n",
       "         [0.0723, 0.1690, 0.1210,  ..., 0.2223, 0.0339, 0.0000],\n",
       "         [0.1390, 0.1821, 0.0596,  ..., 0.1745, 0.1257, 0.0000],\n",
       "         ...,\n",
       "         [0.1161, 0.1266, 0.0000,  ..., 0.2658, 0.2913, 0.0000],\n",
       "         [0.0825, 0.2754, 0.1075,  ..., 0.2420, 0.2341, 0.0000],\n",
       "         [0.1787, 0.0000, 0.2051,  ..., 0.2268, 0.0700, 0.0000]]),\n",
       " tensor([ 764,  816,  617,  802, 1080,  700, 1239,  819,  322, 1292, 1821,  543,\n",
       "         1553, 1068,  907,  599,  925, 1440, 1402, 1625,  554,  482,   32, 1435,\n",
       "         1712, 1776, 1253,  693,  926, 1237,  618,  986]): tensor([[0.1879, 0.0267, 0.0632,  ..., 0.2827, 0.1141, 0.0000],\n",
       "         [0.1416, 0.1405, 0.1479,  ..., 0.1082, 0.1245, 0.0000],\n",
       "         [0.1889, 0.2673, 0.0726,  ..., 0.0970, 0.2069, 0.0000],\n",
       "         ...,\n",
       "         [0.0474, 0.0000, 0.2003,  ..., 0.1354, 0.3268, 0.0000],\n",
       "         [0.1557, 0.2811, 0.2027,  ..., 0.1802, 0.2683, 0.0000],\n",
       "         [0.0676, 0.1556, 0.1227,  ..., 0.1222, 0.1343, 0.0000]]),\n",
       " tensor([1106,  481, 1120,  426, 1486,  712, 1272,  807,  414,  984,  900, 1192,\n",
       "         1105, 1392, 1177,  413,  247,  987,  736,  109,  483, 1107, 1018, 1405,\n",
       "         1696, 1671, 1806,  782,  342,  949, 1412,  798]): tensor([[0.1423, 0.1732, 0.0444,  ..., 0.0000, 0.1145, 0.0000],\n",
       "         [0.0140, 0.1376, 0.1053,  ..., 0.0328, 0.2590, 0.0000],\n",
       "         [0.1228, 0.1663, 0.1337,  ..., 0.1187, 0.0746, 0.0000],\n",
       "         ...,\n",
       "         [0.0330, 0.1893, 0.2025,  ..., 0.0712, 0.0938, 0.0000],\n",
       "         [0.1363, 0.2476, 0.1480,  ..., 0.1270, 0.3974, 0.0000],\n",
       "         [0.0370, 0.2619, 0.2252,  ..., 0.1197, 0.2705, 0.0000]]),\n",
       " tensor([ 906, 1078,  398, 1079,  810, 1428, 1450, 1005,  351, 1418,  535, 1512,\n",
       "          715, 1022,  135,  602,  450,  651,  561, 1453,  480,  324, 1424, 1058,\n",
       "         1026, 1477, 1296,  265,  707,  678,  585, 1547]): tensor([[0.1023, 0.1498, 0.1381,  ..., 0.1160, 0.1011, 0.0000],\n",
       "         [0.1324, 0.2068, 0.2062,  ..., 0.0515, 0.3599, 0.0000],\n",
       "         [0.1304, 0.2037, 0.1775,  ..., 0.2365, 0.3201, 0.0000],\n",
       "         ...,\n",
       "         [0.0838, 0.1098, 0.2254,  ..., 0.0559, 0.0482, 0.0000],\n",
       "         [0.0713, 0.1123, 0.1584,  ..., 0.1075, 0.1179, 0.0000],\n",
       "         [0.1898, 0.4549, 0.1640,  ..., 0.0000, 0.4768, 0.0000]]),\n",
       " tensor([1738,  237,  374,  631, 1366,  361,  123,  411,  334, 1631,  210, 1223,\n",
       "          188,  909, 1606,  298, 1108,  192, 1220,  593, 1822]): tensor([[0.1468, 0.1755, 0.1327,  ..., 0.0833, 0.2242, 0.0000],\n",
       "         [0.0882, 0.1613, 0.1158,  ..., 0.1569, 0.1521, 0.0000],\n",
       "         [0.0770, 0.1759, 0.0918,  ..., 0.2628, 0.0259, 0.0000],\n",
       "         ...,\n",
       "         [0.1339, 0.1884, 0.1001,  ..., 0.0855, 0.0622, 0.0000],\n",
       "         [0.2063, 0.1092, 0.2056,  ..., 0.1041, 0.3148, 0.0000],\n",
       "         [0.1036, 0.1919, 0.2453,  ..., 0.2085, 0.2897, 0.0000]])}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_embedding_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_embedding_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델2 데이터 페어 구성\n",
    "model2_dataset = dict()\n",
    "for i in range(len(word_embedding_dict)):\n",
    "    key = list(word_embedding_dict.keys())[i]\n",
    "    value = word_embedding_dict[key]\n",
    "    for j in range(len(key)):\n",
    "        data_idx = key[j].item()\n",
    "        words = list(dataset[dataset['index'] == data_idx]['tokenized_text'])[0]\n",
    "        embeddings = value[j]\n",
    "        for k in range(len(words)):\n",
    "            word = words[k]\n",
    "            if emoji.emoji_count(word) == 0:\n",
    "                embedding = embeddings[k*28:(k+1)*28]\n",
    "                word_idx = word_to_idx[word]\n",
    "                model2_dataset[word_idx] = embedding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{440: tensor([0.0000, 0.0000, 0.1642, 0.1316, 0.1667, 0.0903, 0.1326, 0.1784, 0.1796,\n",
       "         0.1138, 0.0957, 0.1733, 0.1667, 0.0896, 0.0958, 0.2662, 0.0000, 0.1755,\n",
       "         0.0817, 0.1010, 0.0000, 0.1683, 0.2049, 0.0000, 0.1333, 0.1344, 0.1394,\n",
       "         0.1411]),\n",
       " 4099: tensor([0.0000, 0.2034, 0.1185, 0.0000, 0.1733, 0.2139, 0.1182, 0.1245, 0.0691,\n",
       "         0.0916, 0.0439, 0.1237, 0.0966, 0.1697, 0.0866, 0.2224, 0.0670, 0.0970,\n",
       "         0.1348, 0.1937, 0.0824, 0.1234, 0.1816, 0.1389, 0.0000, 0.1316, 0.0683,\n",
       "         0.1195]),\n",
       " 2692: tensor([0.0000, 0.0000, 0.2732, 0.3842, 0.1081, 0.0838, 0.0000, 0.0000, 0.4043,\n",
       "         0.3638, 0.1368, 0.2273, 0.0000, 0.2130, 0.1201, 0.3150, 0.2690, 0.0000,\n",
       "         0.5215, 0.1329, 0.0000, 0.0932, 0.0000, 0.0000, 0.1842, 0.0000, 0.2663,\n",
       "         0.0000]),\n",
       " 4340: tensor([0.1701, 0.0646, 0.1650, 0.0000, 0.3537, 0.1411, 0.2893, 0.0000, 0.0000,\n",
       "         0.0000, 0.2170, 0.3072, 0.1426, 0.3665, 0.0000, 0.1701, 0.3447, 0.0000,\n",
       "         0.1246, 0.2363, 0.0229, 0.0872, 0.3074, 0.2420, 0.0094, 0.3243, 0.1618,\n",
       "         0.1679]),\n",
       " 2293: tensor([0.0000, 0.2226, 0.1284, 0.1411, 0.0000, 0.0000, 0.1106, 0.0000, 0.0569,\n",
       "         0.0682, 0.3758, 0.2142, 0.1658, 0.1834, 0.1996, 0.0545, 0.0547, 0.2637,\n",
       "         0.1114, 0.1719, 0.1273, 0.1352, 0.2746, 0.2234, 0.1854, 0.0000, 0.0000,\n",
       "         0.2236]),\n",
       " 4496: tensor([0.1451, 0.0000, 0.0752, 0.1382, 0.0000, 0.0973, 0.1443, 0.0987, 0.1345,\n",
       "         0.1081, 0.0948, 0.0000, 0.1207, 0.0732, 0.0000, 0.1633, 0.2368, 0.0000,\n",
       "         0.2045, 0.1536, 0.0682, 0.0000, 0.1594, 0.1407, 0.0000, 0.0000, 0.1675,\n",
       "         0.0844]),\n",
       " 795: tensor([0.0886, 0.1335, 0.1508, 0.0972, 0.0639, 0.0761, 0.1537, 0.1713, 0.1769,\n",
       "         0.1553, 0.1441, 0.0665, 0.0841, 0.0000, 0.0000, 0.0565, 0.1594, 0.0849,\n",
       "         0.1514, 0.0833, 0.0687, 0.0624, 0.1521, 0.0893, 0.1745, 0.1564, 0.1249,\n",
       "         0.1312]),\n",
       " 1272: tensor([0.0512, 0.1377, 0.1759, 0.1806, 0.0000, 0.0978, 0.1756, 0.1323, 0.1673,\n",
       "         0.1392, 0.1404, 0.1705, 0.0761, 0.0000, 0.1337, 0.1773, 0.0846, 0.1656,\n",
       "         0.0000, 0.1020, 0.1808, 0.2086, 0.1081, 0.1997, 0.1546, 0.1034, 0.1377,\n",
       "         0.1361]),\n",
       " 3753: tensor([0.2255, 0.0000, 0.0000, 0.0000, 0.1124, 0.1226, 0.0657, 0.0136, 0.0755,\n",
       "         0.0000, 0.1057, 0.0000, 0.1304, 0.2755, 0.0000, 0.1250, 0.1309, 0.0894,\n",
       "         0.0264, 0.0921, 0.1357, 0.2136, 0.1054, 0.1930, 0.0456, 0.0600, 0.0000,\n",
       "         0.0803]),\n",
       " 1311: tensor([0.2771, 0.0000, 0.0000, 0.2833, 0.0138, 0.1129, 0.1042, 0.4041, 0.1726,\n",
       "         0.0000, 0.2653, 0.0000, 0.1626, 0.2165, 0.0000, 0.2245, 0.1307, 0.0682,\n",
       "         0.0715, 0.1089, 0.1917, 0.3129, 0.3797, 0.4104, 0.1339, 0.1688, 0.0000,\n",
       "         0.2012]),\n",
       " 2214: tensor([0.3701, 0.1147, 0.1274, 0.1762, 0.1317, 0.0000, 0.0654, 0.1127, 0.1054,\n",
       "         0.0826, 0.0944, 0.1550, 0.1058, 0.0000, 0.1192, 0.1537, 0.1948, 0.0579,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.1611, 0.2132, 0.0161, 0.0598, 0.0000,\n",
       "         0.0642]),\n",
       " 4423: tensor([0.1688, 0.1447, 0.0602, 0.2353, 0.0000, 0.2830, 0.3547, 0.0000, 0.0410,\n",
       "         0.0536, 0.2410, 0.0438, 0.2522, 0.0000, 0.0000, 0.1101, 0.2501, 0.0439,\n",
       "         0.0000, 0.2257, 0.0187, 0.0573, 0.0000, 0.3526, 0.3036, 0.0332, 0.2969,\n",
       "         0.1912]),\n",
       " 2335: tensor([0.1335, 0.0000, 0.0000, 0.0000, 0.3875, 0.2194, 0.1439, 0.0000, 0.2649,\n",
       "         0.1185, 0.2113, 0.1791, 0.1793, 0.1291, 0.4751, 0.3123, 0.2888, 0.4598,\n",
       "         0.0243, 0.3998, 0.3174, 0.0000, 0.2897, 0.1351, 0.2444, 0.2806, 0.2433,\n",
       "         0.2984]),\n",
       " 4256: tensor([0.1862, 0.1143, 0.0581, 0.2113, 0.1721, 0.1297, 0.1502, 0.1586, 0.0709,\n",
       "         0.0589, 0.0757, 0.1591, 0.0648, 0.1053, 0.1115, 0.0958, 0.0930, 0.1253,\n",
       "         0.1286, 0.1620, 0.1541, 0.0624, 0.1323, 0.0914, 0.0820, 0.1393, 0.0000,\n",
       "         0.1370]),\n",
       " 806: tensor([0.0581, 0.0512, 0.1227, 0.2027, 0.1667, 0.0356, 0.1222, 0.1895, 0.1245,\n",
       "         0.0000, 0.2251, 0.1153, 0.3041, 0.2389, 0.1345, 0.0294, 0.0000, 0.0352,\n",
       "         0.0499, 0.2766, 0.0000, 0.0235, 0.1652, 0.1945, 0.0575, 0.0340, 0.1744,\n",
       "         0.0146]),\n",
       " 2592: tensor([0.0000, 0.1534, 0.1215, 0.1570, 0.1407, 0.1503, 0.0824, 0.1604, 0.1699,\n",
       "         0.1257, 0.0423, 0.0000, 0.2077, 0.1571, 0.0000, 0.1101, 0.0000, 0.1718,\n",
       "         0.1608, 0.1887, 0.0000, 0.0963, 0.0000, 0.0690, 0.1790, 0.1333, 0.2431,\n",
       "         0.1288]),\n",
       " 4483: tensor([0.2093, 0.2357, 0.4466, 0.1668, 0.4475, 0.1376, 0.1390, 0.3589, 0.2636,\n",
       "         0.0000, 0.1331, 0.1570, 0.0000, 0.0684, 0.1787, 0.0000, 0.0777, 0.0000,\n",
       "         0.2289, 0.1648, 0.1525, 0.0000, 0.2600, 0.1792, 0.0000, 0.1670, 0.0000,\n",
       "         0.1341]),\n",
       " 2432: tensor([0.0676, 0.1420, 0.0000, 0.3112, 0.1205, 0.5180, 0.0225, 0.2660, 0.2552,\n",
       "         0.1637, 0.4360, 0.0237, 0.0701, 0.1941, 0.1218, 0.0859, 0.1541, 0.0957,\n",
       "         0.1307, 0.0000, 0.3686, 0.4030, 0.1910, 0.2764, 0.2352, 0.2895, 0.0000,\n",
       "         0.0000]),\n",
       " 4127: tensor([1.4337e-01, 0.0000e+00, 0.0000e+00, 9.5781e-02, 0.0000e+00, 7.1349e-02,\n",
       "         2.5176e-04, 3.3748e-01, 7.3619e-02, 2.1136e-01, 1.4927e-01, 0.0000e+00,\n",
       "         5.7517e-02, 1.0046e-01, 0.0000e+00, 8.1444e-02, 2.6936e-01, 0.0000e+00,\n",
       "         2.9636e-01, 1.1751e-01, 2.3004e-01, 0.0000e+00, 0.0000e+00, 2.8253e-01,\n",
       "         0.0000e+00, 0.0000e+00, 1.1848e-01, 2.2113e-01]),\n",
       " 3693: tensor([0.1891, 0.2095, 0.1305, 0.0804, 0.0000, 0.0456, 0.1406, 0.0229, 0.2357,\n",
       "         0.2140, 0.1953, 0.1561, 0.1020, 0.1386, 0.1569, 0.1208, 0.0878, 0.1287,\n",
       "         0.1701, 0.1959, 0.1063, 0.1352, 0.1367, 0.0831, 0.1650, 0.0000, 0.0822,\n",
       "         0.1913]),\n",
       " 4092: tensor([0.1382, 0.0995, 0.0620, 0.0473, 0.1570, 0.1072, 0.1564, 0.0000, 0.0703,\n",
       "         0.1125, 0.1970, 0.1387, 0.0984, 0.2678, 0.1461, 0.1562, 0.0000, 0.2844,\n",
       "         0.1874, 0.3096, 0.0000, 0.1779, 0.0717, 0.1370, 0.1899, 0.1997, 0.0782,\n",
       "         0.0000]),\n",
       " 2889: tensor([0.3785, 0.0000, 0.0322, 0.0000, 0.0000, 0.0145, 0.0931, 0.0000, 0.0855,\n",
       "         0.4275, 0.4455, 0.2837, 0.0000, 0.0450, 0.2996, 0.1798, 0.0000, 0.1525,\n",
       "         0.0851, 0.1608, 0.2838, 0.0901, 0.1445, 0.0000, 0.0760, 0.4010, 0.0000,\n",
       "         0.0000]),\n",
       " 3113: tensor([0.4385, 0.2286, 0.2353, 0.0000, 0.0000, 0.1397, 0.0000, 0.2064, 0.2750,\n",
       "         0.0861, 0.1105, 0.1261, 0.1345, 0.1014, 0.2787, 0.2188, 0.0815, 0.0000,\n",
       "         0.0000, 0.2816, 0.0000, 0.0000, 0.2833, 0.2151, 0.0000, 0.1858, 0.1275,\n",
       "         0.0000]),\n",
       " 2719: tensor([0.1089, 0.2436, 0.0735, 0.0399, 0.0000, 0.0594, 0.0000, 0.1859, 0.2549,\n",
       "         0.0007, 0.2067, 0.0000, 0.0000, 0.2771, 0.0571, 0.0333, 0.0832, 0.2106,\n",
       "         0.0000, 0.1487, 0.0759, 0.0193, 0.0000, 0.0000, 0.1002, 0.0300, 0.2464,\n",
       "         0.1407]),\n",
       " 4486: tensor([0.2053, 0.0000, 0.3083, 0.0000, 0.0000, 0.0466, 0.1406, 0.1981, 0.0000,\n",
       "         0.0000, 0.0871, 0.0000, 0.3138, 0.3531, 0.0000, 0.2458, 0.2204, 0.0000,\n",
       "         0.1500, 0.2212, 0.1727, 0.2908, 0.1974, 0.3248, 0.0892, 0.0760, 0.0000,\n",
       "         0.2624]),\n",
       " 4434: tensor([0.1314, 0.1066, 0.1741, 0.1538, 0.0000, 0.1019, 0.1157, 0.1756, 0.0995,\n",
       "         0.1179, 0.1105, 0.0901, 0.1298, 0.1636, 0.1598, 0.0776, 0.1304, 0.1526,\n",
       "         0.0715, 0.1067, 0.1358, 0.1331, 0.0000, 0.1447, 0.1254, 0.1406, 0.0649,\n",
       "         0.0725]),\n",
       " 1471: tensor([0.0020, 0.1447, 0.0000, 0.0625, 0.0000, 0.2762, 0.3153, 0.1230, 0.0000,\n",
       "         0.0870, 0.1367, 0.1494, 0.2246, 0.0000, 0.2780, 0.1114, 0.0000, 0.2562,\n",
       "         0.0000, 0.2634, 0.2927, 0.0000, 0.0000, 0.1924, 0.1611, 0.2741, 0.1845,\n",
       "         0.0189]),\n",
       " 4395: tensor([0.0000, 0.1324, 0.2129, 0.0000, 0.2232, 0.0000, 0.2438, 0.1599, 0.2286,\n",
       "         0.0739, 0.1760, 0.0000, 0.1356, 0.3682, 0.0000, 0.0000, 0.0000, 0.2351,\n",
       "         0.3587, 0.1700, 0.0000, 0.0751, 0.1237, 0.1393, 0.0950, 0.3936, 0.1475,\n",
       "         0.1606]),\n",
       " 1199: tensor([0.3335, 0.0000, 0.0000, 0.0165, 0.2561, 0.0832, 0.1765, 0.0123, 0.2127,\n",
       "         0.0000, 0.2595, 0.0334, 0.1730, 0.1949, 0.2107, 0.0911, 0.1155, 0.2206,\n",
       "         0.1083, 0.2421, 0.0173, 0.3193, 0.2196, 0.0859, 0.0000, 0.1397, 0.0000,\n",
       "         0.2866]),\n",
       " 897: tensor([0.1860, 0.0000, 0.3461, 0.1334, 0.3319, 0.1368, 0.2542, 0.1483, 0.0000,\n",
       "         0.0979, 0.0000, 0.1841, 0.4138, 0.0000, 0.0000, 0.1543, 0.2023, 0.2357,\n",
       "         0.0000, 0.1866, 0.1072, 0.0855, 0.3306, 0.0000, 0.2250, 0.2235, 0.1549,\n",
       "         0.1313]),\n",
       " 2248: tensor([0.3799, 0.1677, 0.0000, 0.1948, 0.0000, 0.4001, 0.1805, 0.0424, 0.2478,\n",
       "         0.0982, 0.2167, 0.1591, 0.7033, 0.0000, 0.0171, 0.0000, 0.2404, 0.2757,\n",
       "         0.0000, 0.1244, 0.0000, 0.0221, 0.0000, 0.2336, 0.0089, 0.2151, 0.2658,\n",
       "         0.2655]),\n",
       " 1327: tensor([0.0000, 0.1878, 0.0000, 0.2016, 0.1975, 0.0000, 0.2278, 0.0000, 0.0000,\n",
       "         0.2269, 0.0000, 0.1135, 0.3375, 0.4762, 0.0000, 0.0799, 0.1888, 0.0785,\n",
       "         0.1216, 0.3429, 0.0000, 0.0000, 0.1715, 0.0000, 0.2105, 0.0000, 0.0866,\n",
       "         0.1601]),\n",
       " 1267: tensor([0.0844, 0.3462, 0.1504, 0.0000, 0.2098, 0.2281, 0.2327, 0.0347, 0.0000,\n",
       "         0.0000, 0.1219, 0.1969, 0.2153, 0.1228, 0.0000, 0.1745, 0.1415, 0.0000,\n",
       "         0.1279, 0.1655, 0.1985, 0.1387, 0.1432, 0.2243, 0.0764, 0.1931, 0.3443,\n",
       "         0.3429]),\n",
       " 4087: tensor([0.0000, 0.1623, 0.1094, 0.0000, 0.1439, 0.1660, 0.1421, 0.1124, 0.1404,\n",
       "         0.0922, 0.1201, 0.1291, 0.1272, 0.1324, 0.0478, 0.1622, 0.0321, 0.1245,\n",
       "         0.1883, 0.1395, 0.1207, 0.1725, 0.1758, 0.1771, 0.0000, 0.0654, 0.1062,\n",
       "         0.0937]),\n",
       " 4069: tensor([0.0011, 0.1137, 0.2253, 0.1942, 0.0000, 0.0270, 0.0000, 0.1217, 0.1209,\n",
       "         0.2458, 0.2155, 0.0000, 0.0000, 0.0272, 0.1428, 0.0085, 0.0000, 0.0452,\n",
       "         0.0000, 0.2708, 0.4622, 0.0000, 0.0000, 0.0000, 0.2750, 0.1782, 0.1199,\n",
       "         0.2712]),\n",
       " 1798: tensor([0.0174, 0.1161, 0.2678, 0.2402, 0.1542, 0.1237, 0.3026, 0.2185, 0.1074,\n",
       "         0.0904, 0.2582, 0.0526, 0.1304, 0.0908, 0.1686, 0.0000, 0.2300, 0.0000,\n",
       "         0.2251, 0.2405, 0.0446, 0.0000, 0.3131, 0.1256, 0.0000, 0.3068, 0.0000,\n",
       "         0.2196]),\n",
       " 3626: tensor([0.1468, 0.1324, 0.1460, 0.1281, 0.0000, 0.1222, 0.1539, 0.1746, 0.0877,\n",
       "         0.1319, 0.0990, 0.0889, 0.1181, 0.1820, 0.1518, 0.0868, 0.1208, 0.1647,\n",
       "         0.0711, 0.0941, 0.1340, 0.1297, 0.0000, 0.1283, 0.1095, 0.1367, 0.0973,\n",
       "         0.0725]),\n",
       " 1188: tensor([0.1512, 0.1426, 0.1379, 0.1284, 0.1593, 0.1566, 0.1666, 0.1401, 0.1226,\n",
       "         0.1248, 0.0848, 0.0872, 0.1617, 0.1715, 0.1187, 0.0864, 0.1329, 0.1072,\n",
       "         0.1790, 0.1531, 0.1390, 0.1231, 0.1013, 0.2024, 0.0000, 0.1363, 0.1480,\n",
       "         0.1386]),\n",
       " 2621: tensor([0.1902, 0.1332, 0.0591, 0.1683, 0.1397, 0.0792, 0.1770, 0.1968, 0.0845,\n",
       "         0.0662, 0.0766, 0.1630, 0.0618, 0.1425, 0.0624, 0.1305, 0.0981, 0.1523,\n",
       "         0.1234, 0.1874, 0.1271, 0.0816, 0.1265, 0.1096, 0.0966, 0.1224, 0.0000,\n",
       "         0.1823]),\n",
       " 3205: tensor([0.1470, 0.1244, 0.0360, 0.1668, 0.1263, 0.1281, 0.1565, 0.2005, 0.1097,\n",
       "         0.0486, 0.0620, 0.1764, 0.0740, 0.1525, 0.0548, 0.1685, 0.0521, 0.1912,\n",
       "         0.1380, 0.1533, 0.1411, 0.0857, 0.0969, 0.1398, 0.1383, 0.1542, 0.0000,\n",
       "         0.1641]),\n",
       " 794: tensor([0.0345, 0.0706, 0.1670, 0.1287, 0.2280, 0.1872, 0.0000, 0.2383, 0.0000,\n",
       "         0.1844, 0.2326, 0.1149, 0.1263, 0.0000, 0.0000, 0.0000, 0.1395, 0.2685,\n",
       "         0.0000, 0.0000, 0.0377, 0.1399, 0.0934, 0.0000, 0.0923, 0.0432, 0.0529,\n",
       "         0.0388]),\n",
       " 4418: tensor([0.1837, 0.0000, 0.0000, 0.0189, 0.0000, 0.1130, 0.1868, 0.2508, 0.2048,\n",
       "         0.2069, 0.0544, 0.1927, 0.1572, 0.0590, 0.1300, 0.0000, 0.2939, 0.1260,\n",
       "         0.0306, 0.0038, 0.2551, 0.1569, 0.0000, 0.0689, 0.2555, 0.2857, 0.2706,\n",
       "         0.1050]),\n",
       " 2939: tensor([0.1417, 0.0765, 0.0115, 0.2326, 0.0000, 0.2670, 0.0910, 0.1557, 0.1598,\n",
       "         0.1275, 0.2798, 0.0000, 0.0000, 0.1657, 0.0955, 0.1229, 0.1661, 0.1331,\n",
       "         0.0000, 0.2284, 0.1741, 0.0914, 0.0000, 0.0892, 0.1584, 0.1413, 0.1809,\n",
       "         0.1093]),\n",
       " 3118: tensor([0.0000, 0.3441, 0.2250, 0.1088, 0.0916, 0.0899, 0.0771, 0.0000, 0.0000,\n",
       "         0.2115, 0.2206, 0.1239, 0.0000, 0.1209, 0.2259, 0.1324, 0.0851, 0.0000,\n",
       "         0.2670, 0.1684, 0.2591, 0.0280, 0.0000, 0.1285, 0.0000, 0.1225, 0.1909,\n",
       "         0.1437]),\n",
       " 972: tensor([0.0000, 0.1620, 0.0000, 0.0670, 0.0059, 0.2378, 0.2201, 0.2172, 0.0077,\n",
       "         0.0871, 0.2158, 0.0733, 0.2413, 0.0680, 0.3131, 0.2694, 0.1829, 0.2346,\n",
       "         0.1311, 0.1904, 0.1412, 0.0000, 0.2021, 0.2888, 0.2161, 0.0000, 0.1198,\n",
       "         0.2049]),\n",
       " 503: tensor([0.1756, 0.1952, 0.0000, 0.2719, 0.0000, 0.6279, 0.8343, 0.2098, 0.0000,\n",
       "         0.0000, 0.3374, 0.0000, 0.2283, 0.0000, 0.2123, 0.0000, 0.3490, 0.3914,\n",
       "         0.0000, 0.3863, 0.4831, 0.1457, 0.0000, 0.5377, 0.3476, 0.2160, 0.4591,\n",
       "         0.2835]),\n",
       " 677: tensor([0.0373, 0.1879, 0.0173, 0.1266, 0.3728, 0.1944, 0.3145, 0.0658, 0.2169,\n",
       "         0.0000, 0.1097, 0.0934, 0.0000, 0.0000, 0.1222, 0.1214, 0.2280, 0.2993,\n",
       "         0.0000, 0.0635, 0.1095, 0.3148, 0.1028, 0.1678, 0.0000, 0.0328, 0.0947,\n",
       "         0.2187]),\n",
       " 150: tensor([0.2361, 0.0000, 0.1346, 0.1922, 0.0000, 0.0000, 0.0658, 0.0000, 0.1263,\n",
       "         0.1300, 0.1061, 0.1870, 0.1417, 0.1492, 0.1590, 0.3006, 0.0434, 0.1740,\n",
       "         0.0000, 0.1011, 0.2341, 0.0000, 0.1024, 0.0762, 0.1404, 0.0896, 0.0302,\n",
       "         0.1858]),\n",
       " 7: tensor([0.0000, 0.3031, 0.0000, 0.1066, 0.0000, 0.1516, 0.0894, 0.0152, 0.1175,\n",
       "         0.2506, 0.2419, 0.0467, 0.0640, 0.1729, 0.1087, 0.1104, 0.1601, 0.2162,\n",
       "         0.1286, 0.2071, 0.2156, 0.0861, 0.1956, 0.2089, 0.0913, 0.0000, 0.1333,\n",
       "         0.2310]),\n",
       " 219: tensor([0.1173, 0.0000, 0.0000, 0.0000, 0.6273, 0.1581, 0.0497, 0.0000, 0.0754,\n",
       "         0.1772, 0.1319, 0.2136, 0.1572, 0.0910, 0.1512, 0.1708, 0.4812, 0.3872,\n",
       "         0.0110, 0.1528, 0.1421, 0.0000, 0.1600, 0.2106, 0.3581, 0.1798, 0.1766,\n",
       "         0.1563]),\n",
       " 865: tensor([0.0000, 0.0000, 0.1856, 0.1143, 0.1516, 0.0672, 0.1368, 0.1672, 0.1801,\n",
       "         0.0718, 0.1022, 0.1215, 0.1645, 0.0931, 0.0996, 0.2409, 0.0000, 0.1399,\n",
       "         0.0746, 0.0796, 0.0000, 0.1482, 0.2266, 0.0000, 0.1147, 0.1260, 0.1799,\n",
       "         0.1430]),\n",
       " 152: tensor([0.0000, 0.0000, 0.1866, 0.0826, 0.0218, 0.1979, 0.0000, 0.0000, 0.0739,\n",
       "         0.2612, 0.0765, 0.0837, 0.0000, 0.0726, 0.0000, 0.2008, 0.4094, 0.0000,\n",
       "         0.2428, 0.0000, 0.1104, 0.1948, 0.0000, 0.0000, 0.0000, 0.0000, 0.1725,\n",
       "         0.0911]),\n",
       " 975: tensor([0.0000, 0.0000, 0.0000, 0.2061, 0.2477, 0.1927, 0.1306, 0.0000, 0.0000,\n",
       "         0.2345, 0.0000, 0.2427, 0.3287, 0.3770, 0.0000, 0.0482, 0.2072, 0.2724,\n",
       "         0.1597, 0.1094, 0.0000, 0.0000, 0.1777, 0.0000, 0.2227, 0.0000, 0.1202,\n",
       "         0.1514]),\n",
       " 483: tensor([0.1274, 0.2848, 0.0000, 0.1885, 0.0000, 0.1823, 0.1990, 0.4567, 0.0515,\n",
       "         0.0000, 0.0000, 0.0000, 0.1740, 0.0742, 0.0963, 0.1203, 0.0000, 0.2182,\n",
       "         0.2177, 0.0000, 0.1412, 0.0000, 0.0549, 0.0000, 0.0072, 0.0000, 0.0000,\n",
       "         0.1734]),\n",
       " 453: tensor([0.1393, 0.1790, 0.0696, 0.1450, 0.0637, 0.1047, 0.2149, 0.1964, 0.1195,\n",
       "         0.1610, 0.1127, 0.0584, 0.1809, 0.0000, 0.0000, 0.0706, 0.1705, 0.0819,\n",
       "         0.0000, 0.0108, 0.1546, 0.1078, 0.1161, 0.0000, 0.2517, 0.0951, 0.0909,\n",
       "         0.1294]),\n",
       " 2447: tensor([0.1279, 0.1074, 0.0000, 0.2643, 0.2609, 0.2324, 0.1717, 0.0576, 0.0319,\n",
       "         0.1435, 0.0736, 0.0387, 0.0195, 0.0701, 0.0029, 0.0000, 0.0000, 0.1018,\n",
       "         0.2931, 0.2050, 0.1570, 0.1331, 0.3376, 0.0000, 0.1730, 0.4423, 0.0616,\n",
       "         0.2442]),\n",
       " 3774: tensor([0.0000, 0.0971, 0.1559, 0.2371, 0.1401, 0.3962, 0.0869, 0.0832, 0.0729,\n",
       "         0.0073, 0.3015, 0.0000, 0.3636, 0.1359, 0.0000, 0.2067, 0.0000, 0.1949,\n",
       "         0.1833, 0.1105, 0.0000, 0.0000, 0.0000, 0.1491, 0.0935, 0.0953, 0.3021,\n",
       "         0.0064]),\n",
       " 3612: tensor([0.1126, 0.2444, 0.1119, 0.2079, 0.0000, 0.0076, 0.1674, 0.3159, 0.0679,\n",
       "         0.0445, 0.1655, 0.0904, 0.2199, 0.2580, 0.0000, 0.1373, 0.2377, 0.1268,\n",
       "         0.1280, 0.0000, 0.0412, 0.0588, 0.1328, 0.1936, 0.1747, 0.3120, 0.0000,\n",
       "         0.0000]),\n",
       " 2034: tensor([0.1083, 0.0000, 0.0317, 0.1236, 0.1548, 0.0000, 0.1375, 0.2826, 0.1117,\n",
       "         0.0000, 0.1637, 0.0000, 0.1778, 0.2209, 0.1151, 0.1659, 0.1873, 0.1331,\n",
       "         0.0673, 0.1909, 0.1690, 0.2859, 0.0000, 0.0000, 0.0775, 0.1813, 0.2268,\n",
       "         0.2041]),\n",
       " 4471: tensor([0.1481, 0.1335, 0.0473, 0.1412, 0.1939, 0.2738, 0.2365, 0.2347, 0.0429,\n",
       "         0.1125, 0.1232, 0.2252, 0.1179, 0.0463, 0.1836, 0.0000, 0.2611, 0.0000,\n",
       "         0.1617, 0.2029, 0.0560, 0.0000, 0.2371, 0.0365, 0.0000, 0.1896, 0.0000,\n",
       "         0.1769]),\n",
       " 4075: tensor([0.0282, 0.1739, 0.0085, 0.3141, 0.0000, 0.3173, 0.1641, 0.2721, 0.0608,\n",
       "         0.0472, 0.2092, 0.0530, 0.0817, 0.1573, 0.0000, 0.1373, 0.1508, 0.0578,\n",
       "         0.1261, 0.0109, 0.1771, 0.2068, 0.2154, 0.1448, 0.1290, 0.1338, 0.0000,\n",
       "         0.0000]),\n",
       " 3101: tensor([0.2268, 0.1039, 0.1772, 0.1634, 0.0000, 0.2664, 0.2830, 0.1249, 0.0931,\n",
       "         0.2032, 0.2355, 0.0000, 0.0000, 0.0984, 0.1591, 0.2375, 0.1967, 0.1588,\n",
       "         0.0000, 0.2063, 0.1414, 0.2932, 0.0000, 0.0000, 0.1848, 0.0918, 0.2343,\n",
       "         0.1338]),\n",
       " 4353: tensor([0.1370, 0.1439, 0.1215, 0.0462, 0.0000, 0.0710, 0.1647, 0.1024, 0.0667,\n",
       "         0.1317, 0.0687, 0.0647, 0.1556, 0.2501, 0.1242, 0.1690, 0.0679, 0.2249,\n",
       "         0.1136, 0.0905, 0.0883, 0.0782, 0.0000, 0.2056, 0.0743, 0.0159, 0.1799,\n",
       "         0.1090]),\n",
       " 1143: tensor([0.1432, 0.1695, 0.2271, 0.0951, 0.0988, 0.1035, 0.1680, 0.0406, 0.1138,\n",
       "         0.1499, 0.1206, 0.1222, 0.0243, 0.0000, 0.0662, 0.1910, 0.0881, 0.1288,\n",
       "         0.0000, 0.0898, 0.2719, 0.2619, 0.1705, 0.1190, 0.1556, 0.1580, 0.1622,\n",
       "         0.1017]),\n",
       " 4023: tensor([0.0493, 0.2697, 0.0000, 0.0896, 0.1649, 0.6481, 0.1428, 0.1523, 0.0000,\n",
       "         0.0203, 0.1777, 0.2436, 0.2473, 0.0000, 0.0000, 0.1925, 0.1452, 0.1685,\n",
       "         0.2556, 0.0645, 0.0000, 0.1931, 0.2860, 0.0703, 0.0256, 0.1049, 0.1517,\n",
       "         0.2476]),\n",
       " 4096: tensor([0.1417, 0.1276, 0.3255, 0.0866, 0.1820, 0.1187, 0.0690, 0.1651, 0.2465,\n",
       "         0.1966, 0.0849, 0.1294, 0.1242, 0.0000, 0.0754, 0.2254, 0.0129, 0.1613,\n",
       "         0.0000, 0.0774, 0.4301, 0.0695, 0.2192, 0.0689, 0.0322, 0.1896, 0.1252,\n",
       "         0.0603]),\n",
       " 2500: tensor([0.1125, 0.1138, 0.1147, 0.1407, 0.0000, 0.1673, 0.1518, 0.2008, 0.0602,\n",
       "         0.1277, 0.1437, 0.0776, 0.0898, 0.2129, 0.1786, 0.0659, 0.1449, 0.1871,\n",
       "         0.0553, 0.0729, 0.1222, 0.1078, 0.0000, 0.1711, 0.1418, 0.1002, 0.1505,\n",
       "         0.0432]),\n",
       " 2063: tensor([0.1545, 0.0661, 0.1404, 0.2431, 0.0000, 0.0591, 0.2422, 0.1275, 0.1313,\n",
       "         0.2023, 0.2470, 0.0000, 0.0000, 0.0000, 0.1609, 0.0000, 0.0000, 0.0762,\n",
       "         0.0000, 0.2856, 0.1271, 0.1527, 0.0000, 0.0397, 0.0914, 0.0000, 0.0914,\n",
       "         0.0393]),\n",
       " 834: tensor([0.1795, 0.0000, 0.0000, 0.0000, 0.3680, 0.1742, 0.0552, 0.0000, 0.0741,\n",
       "         0.1979, 0.1877, 0.0385, 0.1300, 0.2339, 0.5056, 0.1845, 0.3642, 0.3082,\n",
       "         0.2190, 0.1153, 0.1495, 0.0000, 0.2158, 0.0091, 0.2419, 0.1440, 0.1950,\n",
       "         0.2803]),\n",
       " 833: tensor([0.1035, 0.1285, 0.0000, 0.0000, 0.2043, 0.1384, 0.1680, 0.1520, 0.0862,\n",
       "         0.0003, 0.2306, 0.1384, 0.0236, 0.0000, 0.0000, 0.0171, 0.0302, 0.0251,\n",
       "         0.0000, 0.0237, 0.0367, 0.1341, 0.0946, 0.1013, 0.2261, 0.2486, 0.0366,\n",
       "         0.1173]),\n",
       " 3144: tensor([0.4254, 0.1754, 0.3096, 0.0000, 0.0000, 0.2726, 0.0000, 0.2831, 0.0000,\n",
       "         0.0000, 0.0640, 0.4479, 0.0232, 0.2815, 0.0000, 0.0503, 0.3395, 0.0000,\n",
       "         0.0695, 0.1439, 0.1874, 0.2088, 0.4375, 0.4012, 0.0000, 0.1809, 0.1596,\n",
       "         0.3824]),\n",
       " 1049: tensor([0.0100, 0.1523, 0.2986, 0.0493, 0.0822, 0.2449, 0.2371, 0.2584, 0.3216,\n",
       "         0.4711, 0.0000, 0.0000, 0.0167, 0.3516, 0.0000, 0.0000, 0.0000, 0.0478,\n",
       "         0.1097, 0.1319, 0.0000, 0.1178, 0.0000, 0.1238, 0.2979, 0.1832, 0.0000,\n",
       "         0.2486]),\n",
       " 1355: tensor([0.3414, 0.5235, 0.0000, 0.2790, 0.1386, 0.3080, 0.2899, 0.6219, 0.0000,\n",
       "         0.0000, 0.0000, 0.0983, 0.3328, 0.2166, 0.0000, 0.1271, 0.1486, 0.5332,\n",
       "         0.0000, 0.2587, 0.0000, 0.4938, 0.3569, 0.0000, 0.0000, 0.1573, 0.2315,\n",
       "         0.1484]),\n",
       " 2484: tensor([0.0046, 0.1513, 0.0000, 0.0898, 0.0000, 0.1164, 0.2452, 0.0446, 0.0263,\n",
       "         0.2247, 0.0325, 0.1575, 0.1314, 0.0000, 0.1979, 0.0000, 0.0000, 0.1821,\n",
       "         0.0000, 0.0000, 0.3327, 0.0000, 0.0000, 0.4058, 0.1441, 0.3366, 0.1471,\n",
       "         0.1815]),\n",
       " 4355: tensor([0.1570, 0.2107, 0.1771, 0.3218, 0.0000, 0.2347, 0.1136, 0.2715, 0.2398,\n",
       "         0.1157, 0.2759, 0.0000, 0.0000, 0.1402, 0.0573, 0.2927, 0.0717, 0.0514,\n",
       "         0.0000, 0.2982, 0.3000, 0.0285, 0.0000, 0.0000, 0.1586, 0.2040, 0.2111,\n",
       "         0.1862]),\n",
       " 2349: tensor([0.0000, 0.0539, 0.2857, 0.0952, 0.0364, 0.7181, 0.1709, 0.0689, 0.3923,\n",
       "         0.2180, 0.5579, 0.0000, 0.2431, 0.2911, 0.0000, 0.0592, 0.0000, 0.0000,\n",
       "         0.1436, 0.0000, 0.0000, 0.0803, 0.0000, 0.0625, 0.2160, 0.1572, 0.0000,\n",
       "         0.1769]),\n",
       " 160: tensor([0.0000, 0.0493, 0.0901, 0.1826, 0.3954, 0.0559, 0.1749, 0.0000, 0.0000,\n",
       "         0.1689, 0.1546, 0.1096, 0.0000, 0.0101, 0.3561, 0.1189, 0.0571, 0.0000,\n",
       "         0.3180, 0.4829, 0.2953, 0.0102, 0.0000, 0.1594, 0.0000, 0.1729, 0.1415,\n",
       "         0.0880]),\n",
       " 4013: tensor([0.1313, 0.1749, 0.1299, 0.0590, 0.0000, 0.1667, 0.2114, 0.1951, 0.0028,\n",
       "         0.0939, 0.0725, 0.1130, 0.1391, 0.1645, 0.1633, 0.3169, 0.0000, 0.1826,\n",
       "         0.1142, 0.2154, 0.0255, 0.1175, 0.0000, 0.2017, 0.0101, 0.0221, 0.0872,\n",
       "         0.1498]),\n",
       " 3891: tensor([0.0493, 0.0378, 0.0961, 0.0000, 0.1629, 0.1902, 0.2102, 0.0000, 0.1686,\n",
       "         0.1182, 0.3014, 0.0000, 0.1043, 0.3695, 0.0611, 0.2466, 0.0000, 0.2695,\n",
       "         0.0814, 0.1747, 0.0000, 0.3883, 0.1260, 0.2221, 0.1735, 0.2179, 0.0750,\n",
       "         0.0594]),\n",
       " 4080: tensor([0.1550, 0.1435, 0.0000, 0.2080, 0.1922, 0.1732, 0.1965, 0.1762, 0.0779,\n",
       "         0.0287, 0.1012, 0.0283, 0.1216, 0.1467, 0.0995, 0.1403, 0.2845, 0.1655,\n",
       "         0.0677, 0.1724, 0.1626, 0.0934, 0.1674, 0.1074, 0.0743, 0.0928, 0.0000,\n",
       "         0.1610]),\n",
       " 2407: tensor([0.0658, 0.2959, 0.0939, 0.0991, 0.0707, 0.0445, 0.0554, 0.1588, 0.3517,\n",
       "         0.0509, 0.0000, 0.0573, 0.0595, 0.2177, 0.3307, 0.1408, 0.0000, 0.0910,\n",
       "         0.2994, 0.3850, 0.2856, 0.1279, 0.0532, 0.2207, 0.0000, 0.0000, 0.3851,\n",
       "         0.1657]),\n",
       " 467: tensor([0.1753, 0.1732, 0.0864, 0.1406, 0.1432, 0.2329, 0.1739, 0.1906, 0.0702,\n",
       "         0.1396, 0.1377, 0.1218, 0.1842, 0.0000, 0.0000, 0.1987, 0.1369, 0.0939,\n",
       "         0.0000, 0.0287, 0.1440, 0.1400, 0.1174, 0.0000, 0.2939, 0.0998, 0.1070,\n",
       "         0.1019]),\n",
       " 3516: tensor([0.1858, 0.1642, 0.1106, 0.1178, 0.0000, 0.0736, 0.0684, 0.0219, 0.2157,\n",
       "         0.2483, 0.1056, 0.1211, 0.1117, 0.1276, 0.1310, 0.1255, 0.1086, 0.1815,\n",
       "         0.1443, 0.1829, 0.1101, 0.0858, 0.1871, 0.1289, 0.1718, 0.0000, 0.0311,\n",
       "         0.1437]),\n",
       " 2173: tensor([0.0000, 0.1414, 0.1878, 0.0966, 0.1398, 0.0665, 0.2115, 0.0000, 0.2749,\n",
       "         0.0384, 0.1585, 0.3429, 0.2100, 0.0000, 0.1198, 0.2719, 0.1751, 0.1973,\n",
       "         0.0000, 0.0201, 0.1968, 0.2126, 0.0532, 0.0000, 0.0000, 0.3167, 0.1588,\n",
       "         0.3298]),\n",
       " 2836: tensor([0.0000, 0.1285, 0.0996, 0.0990, 0.1627, 0.2145, 0.1349, 0.1185, 0.1361,\n",
       "         0.1074, 0.2114, 0.0000, 0.1271, 0.1124, 0.0000, 0.1459, 0.0000, 0.1254,\n",
       "         0.1499, 0.0963, 0.0000, 0.1219, 0.0000, 0.0896, 0.1112, 0.1386, 0.2096,\n",
       "         0.0477]),\n",
       " 2685: tensor([0.3519, 0.2346, 0.1546, 0.1269, 0.2006, 0.0000, 0.1708, 0.3443, 0.1636,\n",
       "         0.0373, 0.0000, 0.2317, 0.1245, 0.1875, 0.2568, 0.1907, 0.1169, 0.0000,\n",
       "         0.1439, 0.2552, 0.0816, 0.1857, 0.3919, 0.2405, 0.1130, 0.0000, 0.2273,\n",
       "         0.1776]),\n",
       " 995: tensor([0.1972, 0.0487, 0.2463, 0.1516, 0.0706, 0.0352, 0.0705, 0.1357, 0.1335,\n",
       "         0.0545, 0.0788, 0.2379, 0.2119, 0.0000, 0.0000, 0.1823, 0.0775, 0.1871,\n",
       "         0.0000, 0.1351, 0.1002, 0.0426, 0.2404, 0.1178, 0.1310, 0.1411, 0.1101,\n",
       "         0.1820]),\n",
       " 2940: tensor([0.3296, 0.0000, 0.1795, 0.2455, 0.0000, 0.0000, 0.1075, 0.0000, 0.1766,\n",
       "         0.0242, 0.0790, 0.0929, 0.0728, 0.1703, 0.1056, 0.3530, 0.0415, 0.1292,\n",
       "         0.1077, 0.0478, 0.1781, 0.0000, 0.0889, 0.1231, 0.0277, 0.0615, 0.1477,\n",
       "         0.1967]),\n",
       " 637: tensor([0.1440, 0.1510, 0.1417, 0.1161, 0.1481, 0.1806, 0.1970, 0.0000, 0.3031,\n",
       "         0.0698, 0.1498, 0.2056, 0.1789, 0.0826, 0.1839, 0.1493, 0.0876, 0.1416,\n",
       "         0.0000, 0.1933, 0.2039, 0.2383, 0.0854, 0.1063, 0.0000, 0.3278, 0.2892,\n",
       "         0.1437]),\n",
       " 3643: tensor([0.0000, 0.1059, 0.0915, 0.1831, 0.2068, 0.3945, 0.1350, 0.1171, 0.2345,\n",
       "         0.0000, 0.3173, 0.0000, 0.2500, 0.1376, 0.0000, 0.0970, 0.0000, 0.2300,\n",
       "         0.0911, 0.2085, 0.0000, 0.1058, 0.0000, 0.0881, 0.1308, 0.0000, 0.3268,\n",
       "         0.0246]),\n",
       " 1109: tensor([0.0000e+00, 1.0415e-01, 6.6822e-02, 0.0000e+00, 3.3174e-01, 0.0000e+00,\n",
       "         5.1895e-04, 1.1522e-01, 2.3743e-01, 2.9058e-01, 1.3096e-01, 1.6285e-01,\n",
       "         1.4073e-01, 3.0509e-01, 2.2250e-01, 6.1727e-01, 5.4714e-01, 1.0399e-01,\n",
       "         3.5578e-02, 7.3469e-02, 2.1327e-01, 1.1472e-01, 0.0000e+00, 0.0000e+00,\n",
       "         4.3218e-02, 6.6919e-02, 2.5988e-01, 4.6458e-02]),\n",
       " 2943: tensor([0.0888, 0.0800, 0.0585, 0.1533, 0.0000, 0.0330, 0.3425, 0.2178, 0.2126,\n",
       "         0.1666, 0.1213, 0.0000, 0.0000, 0.2071, 0.1793, 0.0878, 0.0042, 0.1999,\n",
       "         0.0000, 0.0938, 0.3146, 0.3204, 0.0000, 0.0583, 0.0000, 0.4414, 0.1746,\n",
       "         0.2515]),\n",
       " 4067: tensor([0.2002, 0.1887, 0.1001, 0.1535, 0.0000, 0.1184, 0.2008, 0.1481, 0.1323,\n",
       "         0.0365, 0.0686, 0.1233, 0.1106, 0.0000, 0.1882, 0.1099, 0.1258, 0.1592,\n",
       "         0.0000, 0.1676, 0.2030, 0.0000, 0.0000, 0.1725, 0.1890, 0.1896, 0.1607,\n",
       "         0.1083]),\n",
       " 4082: tensor([0.0000, 0.0000, 0.1673, 0.1341, 0.1753, 0.0942, 0.1404, 0.1847, 0.1755,\n",
       "         0.1137, 0.1018, 0.1764, 0.1655, 0.0929, 0.0887, 0.2772, 0.0000, 0.1697,\n",
       "         0.0780, 0.1005, 0.0000, 0.1690, 0.2022, 0.0000, 0.1332, 0.1381, 0.1412,\n",
       "         0.1320]),\n",
       " 1716: tensor([0.2918, 0.2375, 0.0848, 0.1975, 0.0000, 0.2537, 0.3409, 0.1674, 0.1699,\n",
       "         0.0000, 0.2601, 0.0269, 0.1060, 0.0000, 0.2042, 0.2423, 0.2259, 0.1696,\n",
       "         0.0000, 0.1775, 0.1898, 0.0000, 0.0000, 0.3373, 0.2746, 0.1405, 0.2603,\n",
       "         0.0607]),\n",
       " 784: tensor([0.1902, 0.0000, 0.1453, 0.0679, 0.0000, 0.0000, 0.2146, 0.0000, 0.1503,\n",
       "         0.1038, 0.1098, 0.2466, 0.2530, 0.1044, 0.0932, 0.4181, 0.0504, 0.2612,\n",
       "         0.0869, 0.1464, 0.2056, 0.0000, 0.2210, 0.0132, 0.1100, 0.2298, 0.0797,\n",
       "         0.1518]),\n",
       " 3385: tensor([0.0000, 0.0155, 0.2046, 0.0279, 0.1075, 0.1765, 0.2257, 0.0469, 0.1457,\n",
       "         0.1581, 0.2456, 0.1301, 0.0887, 0.1118, 0.0885, 0.0000, 0.0626, 0.0000,\n",
       "         0.2717, 0.1644, 0.0297, 0.0000, 0.2995, 0.1978, 0.0000, 0.3088, 0.0000,\n",
       "         0.2123]),\n",
       " 1544: tensor([0.1690, 0.0000, 0.0000, 0.0000, 0.2972, 0.1232, 0.0494, 0.0000, 0.0953,\n",
       "         0.1843, 0.1310, 0.1241, 0.1158, 0.1434, 0.3687, 0.1599, 0.2472, 0.2820,\n",
       "         0.2256, 0.1317, 0.1254, 0.0000, 0.1786, 0.0000, 0.2021, 0.1887, 0.1905,\n",
       "         0.2915]),\n",
       " 599: tensor([0.0000, 0.2308, 0.0000, 0.3693, 0.0000, 0.4861, 0.1184, 0.0837, 0.1115,\n",
       "         0.3269, 0.0000, 0.0842, 0.1783, 0.0461, 0.1331, 0.0449, 0.3721, 0.1265,\n",
       "         0.2231, 0.0338, 0.2509, 0.2246, 0.2692, 0.2022, 0.2667, 0.3884, 0.0000,\n",
       "         0.0000]),\n",
       " 1277: tensor([0.2334, 0.0000, 0.0120, 0.2388, 0.0000, 0.0000, 0.1378, 0.0000, 0.1689,\n",
       "         0.2874, 0.1226, 0.1979, 0.2212, 0.1857, 0.0839, 0.1107, 0.0468, 0.2271,\n",
       "         0.0820, 0.0423, 0.1715, 0.0000, 0.1173, 0.1697, 0.1421, 0.1352, 0.0992,\n",
       "         0.1944]),\n",
       " 986: tensor([0.0705, 0.1434, 0.1380, 0.0700, 0.1419, 0.1656, 0.0942, 0.2045, 0.0293,\n",
       "         0.1457, 0.1173, 0.0406, 0.1593, 0.0000, 0.0000, 0.1146, 0.0937, 0.1235,\n",
       "         0.0000, 0.0000, 0.1245, 0.0749, 0.1162, 0.0000, 0.2593, 0.1604, 0.0828,\n",
       "         0.0878]),\n",
       " 2420: tensor([0.1211, 0.1517, 0.3294, 0.0000, 0.1008, 0.0721, 0.2782, 0.0000, 0.0000,\n",
       "         0.0000, 0.2968, 0.0000, 0.4798, 0.0996, 0.0000, 0.3610, 0.0107, 0.0000,\n",
       "         0.2255, 0.1709, 0.0702, 0.1112, 0.0982, 0.3214, 0.0758, 0.1456, 0.2282,\n",
       "         0.0000]),\n",
       " 1224: tensor([0.0000, 0.2580, 0.0000, 0.0736, 0.0000, 0.2508, 0.1524, 0.0808, 0.0061,\n",
       "         0.2624, 0.1536, 0.0261, 0.0000, 0.1763, 0.2448, 0.0824, 0.2616, 0.1412,\n",
       "         0.1073, 0.3404, 0.1148, 0.0000, 0.1665, 0.3337, 0.2076, 0.0000, 0.1416,\n",
       "         0.3929]),\n",
       " 4390: tensor([0.0000, 0.0000, 0.2429, 0.2762, 0.2395, 0.0570, 0.2405, 0.4002, 0.1119,\n",
       "         0.0890, 0.3192, 0.0000, 0.1176, 0.0870, 0.2624, 0.1502, 0.0000, 0.1870,\n",
       "         0.1086, 0.0000, 0.0000, 0.1060, 0.2208, 0.0000, 0.1940, 0.2214, 0.2411,\n",
       "         0.0248]),\n",
       " 4226: tensor([0.0000, 0.2394, 0.3842, 0.1003, 0.0321, 0.1042, 0.1508, 0.2548, 0.4106,\n",
       "         0.3044, 0.2365, 0.0000, 0.2590, 0.3408, 0.0000, 0.2121, 0.0000, 0.0526,\n",
       "         0.4115, 0.0450, 0.0000, 0.0459, 0.0000, 0.1025, 0.1908, 0.0000, 0.1550,\n",
       "         0.2055]),\n",
       " 1155: tensor([0.2517, 0.0000, 0.2688, 0.3664, 0.0000, 0.0000, 0.3759, 0.0000, 0.0534,\n",
       "         0.0000, 0.2169, 0.0000, 0.0195, 0.1033, 0.1471, 0.4164, 0.3196, 0.1269,\n",
       "         0.1925, 0.3396, 0.2057, 0.0000, 0.1067, 0.3428, 0.0136, 0.0679, 0.2214,\n",
       "         0.0839]),\n",
       " 1717: tensor([0.0000, 0.2273, 0.1122, 0.1573, 0.0000, 0.3186, 0.0568, 0.1473, 0.1579,\n",
       "         0.1885, 0.2398, 0.0000, 0.0000, 0.2160, 0.1156, 0.1463, 0.2014, 0.1602,\n",
       "         0.0000, 0.0521, 0.2097, 0.0171, 0.0000, 0.0000, 0.2749, 0.1844, 0.2079,\n",
       "         0.1974]),\n",
       " 3544: tensor([0.0886, 0.1349, 0.1340, 0.1755, 0.0000, 0.1758, 0.1239, 0.1732, 0.0344,\n",
       "         0.1064, 0.1158, 0.1106, 0.1213, 0.1194, 0.1347, 0.1508, 0.0799, 0.1639,\n",
       "         0.0448, 0.1355, 0.1496, 0.1242, 0.0000, 0.1422, 0.1018, 0.1067, 0.1603,\n",
       "         0.1029]),\n",
       " 2550: tensor([0.1072, 0.1596, 0.1105, 0.1306, 0.0000, 0.1738, 0.0621, 0.1066, 0.1208,\n",
       "         0.1093, 0.2224, 0.0000, 0.0000, 0.1305, 0.0689, 0.1733, 0.1229, 0.1182,\n",
       "         0.0000, 0.1897, 0.1384, 0.1371, 0.0000, 0.0419, 0.1209, 0.0763, 0.1773,\n",
       "         0.1403]),\n",
       " 3862: tensor([0.1404, 0.0269, 0.3225, 0.1577, 0.2110, 0.0082, 0.1011, 0.2688, 0.2490,\n",
       "         0.0000, 0.0801, 0.1161, 0.1408, 0.1826, 0.2906, 0.0000, 0.1445, 0.0000,\n",
       "         0.1487, 0.1889, 0.2011, 0.0000, 0.0962, 0.3245, 0.0000, 0.3076, 0.0000,\n",
       "         0.1488]),\n",
       " 2824: tensor([0.0910, 0.1133, 0.1767, 0.2139, 0.2400, 0.3456, 0.0136, 0.1906, 0.2267,\n",
       "         0.0000, 0.1635, 0.0696, 0.1912, 0.1290, 0.1012, 0.0000, 0.1452, 0.0000,\n",
       "         0.1483, 0.1106, 0.0933, 0.0000, 0.2721, 0.2230, 0.0000, 0.0989, 0.0000,\n",
       "         0.3408]),\n",
       " 1252: tensor([0.2316, 0.0000, 0.0100, 0.2333, 0.0000, 0.2115, 0.1415, 0.4201, 0.1615,\n",
       "         0.3856, 0.0000, 0.0000, 0.0000, 0.0126, 0.0000, 0.2976, 0.0595, 0.0000,\n",
       "         0.1140, 0.1754, 0.1496, 0.0000, 0.1624, 0.5960, 0.0000, 0.0000, 0.0339,\n",
       "         0.2936]),\n",
       " 4020: tensor([0.0735, 0.2459, 0.2253, 0.0152, 0.2062, 0.1422, 0.2314, 0.0537, 0.0000,\n",
       "         0.3622, 0.1649, 0.0967, 0.1236, 0.3169, 0.2013, 0.1514, 0.1444, 0.1215,\n",
       "         0.0848, 0.0000, 0.0989, 0.4080, 0.2112, 0.4527, 0.0000, 0.1961, 0.1697,\n",
       "         0.0586]),\n",
       " 4066: tensor([0.1974, 0.2130, 0.1252, 0.0000, 0.1922, 0.0949, 0.1676, 0.1254, 0.0766,\n",
       "         0.2581, 0.0963, 0.0000, 0.2284, 0.0000, 0.1629, 0.0116, 0.1475, 0.1431,\n",
       "         0.0000, 0.0633, 0.2755, 0.2157, 0.0399, 0.1021, 0.0704, 0.1839, 0.2392,\n",
       "         0.2026]),\n",
       " 529: tensor([0.1304, 0.2037, 0.1775, 0.0883, 0.3372, 0.0996, 0.0776, 0.1427, 0.0000,\n",
       "         0.0877, 0.2108, 0.0000, 0.1802, 0.0000, 0.0000, 0.2294, 0.1455, 0.2221,\n",
       "         0.0000, 0.0000, 0.1906, 0.2041, 0.0000, 0.0000, 0.2779, 0.2758, 0.1470,\n",
       "         0.1036]),\n",
       " 1930: tensor([0.1115, 0.0832, 0.1098, 0.0676, 0.0925, 0.2589, 0.1359, 0.0680, 0.0868,\n",
       "         0.0000, 0.1289, 0.2091, 0.1743, 0.1314, 0.1481, 0.0000, 0.2226, 0.0000,\n",
       "         0.1397, 0.1186, 0.1264, 0.0000, 0.1698, 0.0475, 0.0000, 0.1388, 0.0000,\n",
       "         0.1371]),\n",
       " 3016: tensor([0.0000, 0.1466, 0.1310, 0.0861, 0.3365, 0.2772, 0.4047, 0.0000, 0.0859,\n",
       "         0.0000, 0.1699, 0.0054, 0.0000, 0.0088, 0.1959, 0.1337, 0.3424, 0.1357,\n",
       "         0.0000, 0.1886, 0.2300, 0.3901, 0.0000, 0.2828, 0.0000, 0.2255, 0.1874,\n",
       "         0.2301]),\n",
       " 1740: tensor([0.0000, 0.1634, 0.0817, 0.1342, 0.1624, 0.3281, 0.1174, 0.0789, 0.1849,\n",
       "         0.0350, 0.2697, 0.0000, 0.2929, 0.1354, 0.0000, 0.1286, 0.0000, 0.1893,\n",
       "         0.1047, 0.1955, 0.0000, 0.0514, 0.0000, 0.0828, 0.1054, 0.0000, 0.2998,\n",
       "         0.0095]),\n",
       " 2779: tensor([0.1299, 0.1252, 0.1840, 0.1442, 0.2411, 0.1159, 0.3500, 0.0605, 0.2089,\n",
       "         0.0000, 0.1358, 0.1405, 0.1082, 0.0888, 0.2009, 0.1972, 0.1373, 0.2245,\n",
       "         0.0000, 0.1432, 0.1212, 0.3085, 0.0000, 0.1014, 0.0000, 0.1795, 0.2036,\n",
       "         0.2030]),\n",
       " 1694: tensor([0.0000, 0.1824, 0.2023, 0.0000, 0.3256, 0.0000, 0.1745, 0.1925, 0.1009,\n",
       "         0.0691, 0.0880, 0.0000, 0.1312, 0.2777, 0.0976, 0.0000, 0.0000, 0.3261,\n",
       "         0.2115, 0.2167, 0.0000, 0.1193, 0.1120, 0.1603, 0.0893, 0.2745, 0.1112,\n",
       "         0.1559]),\n",
       " 1480: tensor([0.0000, 0.3010, 0.0000, 0.0695, 0.0000, 0.0399, 0.1675, 0.1152, 0.1490,\n",
       "         0.1998, 0.3377, 0.0704, 0.0359, 0.2867, 0.2051, 0.1730, 0.1150, 0.3062,\n",
       "         0.2568, 0.2548, 0.3181, 0.2146, 0.2647, 0.2335, 0.3458, 0.0000, 0.2233,\n",
       "         0.1527]),\n",
       " 2375: tensor([0.1417, 0.1803, 0.0904, 0.0731, 0.0000, 0.1559, 0.1127, 0.0987, 0.2262,\n",
       "         0.1085, 0.2001, 0.0000, 0.0000, 0.1603, 0.1422, 0.1469, 0.1657, 0.1857,\n",
       "         0.0000, 0.1216, 0.1916, 0.1328, 0.0000, 0.0000, 0.0616, 0.2010, 0.1834,\n",
       "         0.2148]),\n",
       " 1924: tensor([0.2373, 0.1567, 0.2555, 0.0000, 0.0000, 0.0424, 0.1690, 0.1353, 0.0000,\n",
       "         0.0000, 0.1698, 0.0643, 0.3197, 0.1785, 0.0000, 0.2066, 0.1930, 0.0000,\n",
       "         0.1707, 0.1830, 0.1135, 0.2698, 0.2226, 0.3079, 0.0000, 0.1598, 0.2021,\n",
       "         0.1377]),\n",
       " 1739: tensor([0.0000, 0.1415, 0.0829, 0.1338, 0.1441, 0.2686, 0.1629, 0.0801, 0.3313,\n",
       "         0.1652, 0.1405, 0.0000, 0.0999, 0.1301, 0.0000, 0.2078, 0.0000, 0.0967,\n",
       "         0.0745, 0.1230, 0.0000, 0.1911, 0.0000, 0.1234, 0.1774, 0.0680, 0.2428,\n",
       "         0.1271]),\n",
       " 1529: tensor([0.3668, 0.1558, 0.1682, 0.1780, 0.2853, 0.0000, 0.0839, 0.0491, 0.0831,\n",
       "         0.0780, 0.0000, 0.2664, 0.2022, 0.1128, 0.1492, 0.1318, 0.1631, 0.0980,\n",
       "         0.2405, 0.2117, 0.2080, 0.2564, 0.2757, 0.0367, 0.1750, 0.0000, 0.0527,\n",
       "         0.1866]),\n",
       " 3581: tensor([0.2779, 0.0000, 0.0000, 0.0000, 0.4151, 0.2623, 0.1973, 0.0000, 0.4311,\n",
       "         0.1193, 0.0376, 0.2951, 0.1360, 0.1571, 0.0982, 0.2176, 0.4127, 0.1528,\n",
       "         0.1128, 0.2429, 0.0000, 0.0000, 0.1276, 0.1578, 0.0726, 0.0913, 0.1821,\n",
       "         0.1035]),\n",
       " 2615: tensor([0.1487, 0.1555, 0.0875, 0.1141, 0.0000, 0.1891, 0.1473, 0.1315, 0.2443,\n",
       "         0.1338, 0.2004, 0.0000, 0.0000, 0.1791, 0.1671, 0.1557, 0.2270, 0.2118,\n",
       "         0.0000, 0.1223, 0.1822, 0.1386, 0.0000, 0.0000, 0.1723, 0.2546, 0.2263,\n",
       "         0.2328]),\n",
       " 3198: tensor([0.1269, 0.0000, 0.3032, 0.2382, 0.0000, 0.0000, 0.2792, 0.0000, 0.1072,\n",
       "         0.1311, 0.1632, 0.0946, 0.1279, 0.1156, 0.1954, 0.3443, 0.0958, 0.0874,\n",
       "         0.2199, 0.1657, 0.1424, 0.0000, 0.0711, 0.4142, 0.0060, 0.1187, 0.1300,\n",
       "         0.0711]),\n",
       " 3821: tensor([0.0000, 0.0730, 0.1511, 0.0000, 0.3472, 0.0000, 0.0981, 0.1705, 0.0786,\n",
       "         0.1439, 0.3047, 0.0000, 0.1812, 0.2683, 0.0000, 0.0000, 0.2938, 0.1694,\n",
       "         0.0961, 0.0927, 0.1264, 0.0841, 0.2174, 0.1907, 0.0103, 0.1649, 0.1186,\n",
       "         0.0176]),\n",
       " 996: tensor([0.0837, 0.1079, 0.2088, 0.0525, 0.1718, 0.1339, 0.0000, 0.1613, 0.0000,\n",
       "         0.1211, 0.1481, 0.0381, 0.1261, 0.0000, 0.0000, 0.1032, 0.0957, 0.2022,\n",
       "         0.0000, 0.0000, 0.1134, 0.1665, 0.0737, 0.0000, 0.2134, 0.1684, 0.0780,\n",
       "         0.0752]),\n",
       " 2384: tensor([0.3091, 0.1501, 0.3019, 0.2971, 0.0000, 0.3020, 0.3809, 0.2168, 0.2294,\n",
       "         0.2920, 0.2131, 0.0000, 0.0000, 0.0000, 0.2135, 0.3997, 0.0000, 0.0699,\n",
       "         0.0000, 0.3577, 0.2108, 0.4091, 0.0000, 0.0346, 0.0055, 0.0472, 0.1398,\n",
       "         0.1130]),\n",
       " 3285: tensor([0.0151, 0.0182, 0.1430, 0.0127, 0.2098, 0.1998, 0.1944, 0.0000, 0.2198,\n",
       "         0.1281, 0.3272, 0.1266, 0.2014, 0.2086, 0.0770, 0.0986, 0.0000, 0.1552,\n",
       "         0.1201, 0.1982, 0.0627, 0.3071, 0.2009, 0.1240, 0.0939, 0.1970, 0.0000,\n",
       "         0.0000]),\n",
       " 4222: tensor([0.2446, 0.1358, 0.0000, 0.3022, 0.0000, 0.2009, 0.1469, 0.2390, 0.3819,\n",
       "         0.2765, 0.1959, 0.0869, 0.2737, 0.0902, 0.2703, 0.1705, 0.1680, 0.1477,\n",
       "         0.2863, 0.2377, 0.2377, 0.1480, 0.1884, 0.0000, 0.2123, 0.4576, 0.0671,\n",
       "         0.1400]),\n",
       " 2876: tensor([0.1755, 0.0400, 0.0812, 0.2250, 0.1549, 0.1105, 0.3097, 0.0000, 0.2853,\n",
       "         0.0516, 0.1635, 0.3080, 0.2065, 0.0547, 0.1473, 0.1727, 0.2731, 0.3542,\n",
       "         0.0000, 0.1738, 0.0647, 0.1998, 0.0600, 0.0000, 0.0000, 0.3677, 0.3031,\n",
       "         0.4115]),\n",
       " 3818: tensor([0.1880, 0.0542, 0.0873, 0.1781, 0.0000, 0.1524, 0.1475, 0.1607, 0.1132,\n",
       "         0.1984, 0.1338, 0.1156, 0.1633, 0.0661, 0.1325, 0.1401, 0.1494, 0.1400,\n",
       "         0.1204, 0.1788, 0.1182, 0.1559, 0.0000, 0.1155, 0.0945, 0.1812, 0.1988,\n",
       "         0.1070]),\n",
       " 2438: tensor([0.2178, 0.1256, 0.0000, 0.3657, 0.0030, 0.6432, 0.0946, 0.0618, 0.0000,\n",
       "         0.2746, 0.0000, 0.1347, 0.1522, 0.0968, 0.1551, 0.0180, 0.0038, 0.0090,\n",
       "         0.4466, 0.0096, 0.0917, 0.4458, 0.3828, 0.0000, 0.1550, 0.2150, 0.0885,\n",
       "         0.1251]),\n",
       " 811: tensor([0.0143, 0.0000, 0.0000, 0.0000, 0.4860, 0.0944, 0.0000, 0.0000, 0.0212,\n",
       "         0.1742, 0.2581, 0.1811, 0.0905, 0.0317, 0.5001, 0.1621, 0.2062, 0.3194,\n",
       "         0.0000, 0.0879, 0.1456, 0.0000, 0.1044, 0.0763, 0.3541, 0.1443, 0.0256,\n",
       "         0.0805]),\n",
       " 3633: tensor([0.2211, 0.0000, 0.1579, 0.1826, 0.0000, 0.0000, 0.1274, 0.0000, 0.0811,\n",
       "         0.1976, 0.1175, 0.1582, 0.1940, 0.2053, 0.1498, 0.1812, 0.0411, 0.1828,\n",
       "         0.0403, 0.0898, 0.1675, 0.0000, 0.0944, 0.1140, 0.1794, 0.1104, 0.1218,\n",
       "         0.1578]),\n",
       " 3921: tensor([0.1724, 0.1360, 0.1135, 0.1206, 0.0000, 0.1860, 0.0612, 0.0845, 0.1570,\n",
       "         0.0951, 0.2440, 0.0000, 0.0000, 0.1110, 0.1020, 0.1626, 0.0930, 0.1264,\n",
       "         0.0000, 0.1785, 0.1222, 0.1654, 0.0000, 0.0185, 0.1055, 0.0281, 0.1857,\n",
       "         0.1468]),\n",
       " 2861: tensor([0.0000, 0.0000, 0.0459, 0.0829, 0.1622, 0.2067, 0.0153, 0.1553, 0.4349,\n",
       "         0.4342, 0.1287, 0.4456, 0.2801, 0.1241, 0.3623, 0.1811, 0.0000, 0.0000,\n",
       "         0.1814, 0.3009, 0.0000, 0.0802, 0.0826, 0.0000, 0.0688, 0.3417, 0.0144,\n",
       "         0.4431]),\n",
       " 3551: tensor([0.4711, 0.0000, 0.0000, 0.5559, 0.0000, 0.1543, 0.0215, 0.1278, 0.0466,\n",
       "         0.0546, 0.0821, 0.3328, 0.0000, 0.0000, 0.0457, 0.1239, 0.0000, 0.4446,\n",
       "         0.1894, 0.2482, 0.2389, 0.4401, 0.5167, 0.0000, 0.4577, 0.7029, 0.3199,\n",
       "         0.3495]),\n",
       " 2274: tensor([0.1539, 0.1611, 0.0000, 0.0000, 0.0793, 0.3201, 0.0723, 0.0294, 0.5196,\n",
       "         0.0380, 0.1384, 0.0453, 0.3278, 0.1941, 0.3514, 0.1798, 0.0553, 0.2131,\n",
       "         0.0118, 0.3667, 0.0953, 0.1561, 0.1205, 0.0000, 0.3157, 0.1112, 0.2439,\n",
       "         0.2779]),\n",
       " 2643: tensor([0.0000, 0.0000, 0.2623, 0.2340, 0.3914, 0.4224, 0.1592, 0.3050, 0.2545,\n",
       "         0.0716, 0.1504, 0.0000, 0.1609, 0.0790, 0.2265, 0.1009, 0.0000, 0.0000,\n",
       "         0.1971, 0.1272, 0.0000, 0.0000, 0.1297, 0.0000, 0.2490, 0.1371, 0.0000,\n",
       "         0.0000]),\n",
       " 2460: tensor([0.2141, 0.0000, 0.1513, 0.4261, 0.1576, 0.0000, 0.1672, 0.4200, 0.2584,\n",
       "         0.0000, 0.1497, 0.0000, 0.2842, 0.0492, 0.3159, 0.1699, 0.3175, 0.2780,\n",
       "         0.0000, 0.1155, 0.3454, 0.3593, 0.0000, 0.1342, 0.2359, 0.2588, 0.1933,\n",
       "         0.2861]),\n",
       " 3484: tensor([0.1173, 0.1811, 0.2609, 0.2680, 0.0000, 0.0867, 0.0895, 0.1103, 0.3508,\n",
       "         0.0321, 0.0877, 0.1896, 0.0025, 0.0000, 0.0956, 0.1360, 0.0000, 0.2969,\n",
       "         0.0000, 0.2073, 0.0000, 0.1009, 0.0000, 0.0320, 0.1204, 0.0000, 0.0000,\n",
       "         0.0727]),\n",
       " 2878: tensor([0.0000, 0.0000, 0.1806, 0.2666, 0.1006, 0.2740, 0.0382, 0.1728, 0.2129,\n",
       "         0.2161, 0.1572, 0.1143, 0.0657, 0.0249, 0.1362, 0.2706, 0.0000, 0.1513,\n",
       "         0.1902, 0.1168, 0.0000, 0.0822, 0.1890, 0.0000, 0.0967, 0.1141, 0.1302,\n",
       "         0.0371]),\n",
       " 2483: tensor([0.1249, 0.1415, 0.1679, 0.0811, 0.1272, 0.2938, 0.1184, 0.1619, 0.1514,\n",
       "         0.0000, 0.1642, 0.0947, 0.1115, 0.1795, 0.1388, 0.0000, 0.1834, 0.0000,\n",
       "         0.1724, 0.1321, 0.0528, 0.0000, 0.2403, 0.1676, 0.0000, 0.2707, 0.0000,\n",
       "         0.2339]),\n",
       " 4255: tensor([0.1836, 0.1082, 0.0000, 0.2643, 0.0621, 0.0000, 0.1800, 0.2786, 0.0000,\n",
       "         0.0927, 0.1365, 0.2121, 0.0000, 0.2332, 0.1387, 0.5235, 0.1057, 0.0000,\n",
       "         0.5389, 0.2249, 0.2071, 0.2653, 0.2497, 0.0000, 0.3026, 0.5021, 0.0471,\n",
       "         0.1960]),\n",
       " 283: tensor([0.1592, 0.0855, 0.0000, 0.2775, 0.1256, 0.0370, 0.1178, 0.2111, 0.1168,\n",
       "         0.1326, 0.1715, 0.2498, 0.1360, 0.0993, 0.0879, 0.3339, 0.0498, 0.2121,\n",
       "         0.2497, 0.0290, 0.2105, 0.2344, 0.1333, 0.0000, 0.1586, 0.2081, 0.0775,\n",
       "         0.2770]),\n",
       " 2357: tensor([0.1469, 0.1945, 0.0000, 0.2464, 0.2423, 0.1212, 0.2756, 0.2087, 0.0859,\n",
       "         0.0301, 0.1384, 0.0434, 0.0907, 0.1272, 0.1468, 0.1338, 0.0818, 0.1643,\n",
       "         0.0564, 0.1823, 0.1493, 0.2339, 0.1640, 0.1664, 0.0000, 0.1557, 0.0000,\n",
       "         0.2483]),\n",
       " 2740: tensor([0.2691, 0.0368, 0.1810, 0.1309, 0.0000, 0.0868, 0.2989, 0.1496, 0.0998,\n",
       "         0.1566, 0.1570, 0.0000, 0.0000, 0.0466, 0.1039, 0.1659, 0.1239, 0.1632,\n",
       "         0.0000, 0.2249, 0.0342, 0.2092, 0.0000, 0.0843, 0.1152, 0.0857, 0.1001,\n",
       "         0.0389]),\n",
       " 3512: tensor([0.0000e+00, 1.7285e-01, 8.9201e-02, 9.8297e-03, 1.2424e-01, 9.0887e-02,\n",
       "         2.1204e-01, 0.0000e+00, 0.0000e+00, 3.2601e-04, 1.2861e-02, 1.3713e-01,\n",
       "         0.0000e+00, 1.3066e-01, 3.3937e-01, 1.9416e-01, 0.0000e+00, 0.0000e+00,\n",
       "         1.7965e-01, 2.6532e-01, 2.2202e-01, 6.8068e-02, 0.0000e+00, 1.1944e-02,\n",
       "         0.0000e+00, 2.5994e-01, 7.8625e-02, 0.0000e+00]),\n",
       " 4046: tensor([0.0000, 0.1237, 0.1816, 0.1332, 0.1198, 0.4130, 0.0000, 0.0000, 0.0000,\n",
       "         0.2497, 0.0000, 0.2671, 0.3528, 0.3263, 0.0000, 0.3269, 0.2616, 0.1692,\n",
       "         0.2395, 0.2926, 0.0000, 0.0000, 0.2502, 0.0000, 0.1868, 0.0000, 0.0661,\n",
       "         0.0000]),\n",
       " 3497: tensor([0.1670, 0.1494, 0.1814, 0.1178, 0.1654, 0.2077, 0.1608, 0.1280, 0.1284,\n",
       "         0.0859, 0.0920, 0.0590, 0.1230, 0.1745, 0.1789, 0.1007, 0.0841, 0.0828,\n",
       "         0.1270, 0.0470, 0.1105, 0.1510, 0.0702, 0.1960, 0.0000, 0.1549, 0.1612,\n",
       "         0.1120]),\n",
       " 2535: tensor([0.1263, 0.0800, 0.0000, 0.1051, 0.2528, 0.1992, 0.1349, 0.0000, 0.4558,\n",
       "         0.1712, 0.0916, 0.0902, 0.2526, 0.1202, 0.2329, 0.0000, 0.2185, 0.3768,\n",
       "         0.0886, 0.2363, 0.1244, 0.1132, 0.2156, 0.0000, 0.5263, 0.0638, 0.1610,\n",
       "         0.0503]),\n",
       " 3186: tensor([0.2237, 0.0000, 0.1391, 0.0281, 0.0744, 0.1628, 0.0239, 0.0000, 0.3479,\n",
       "         0.1659, 0.3712, 0.1096, 0.1303, 0.1855, 0.0000, 0.0000, 0.0000, 0.1982,\n",
       "         0.0887, 0.2161, 0.0000, 0.2353, 0.0789, 0.1912, 0.1239, 0.2182, 0.0000,\n",
       "         0.0000]),\n",
       " 3831: tensor([0.2090, 0.2526, 0.1430, 0.3846, 0.1750, 0.1414, 0.1727, 0.0585, 0.0197,\n",
       "         0.1610, 0.1603, 0.1565, 0.1276, 0.1997, 0.0466, 0.0000, 0.0897, 0.0000,\n",
       "         0.3244, 0.1360, 0.0000, 0.0000, 0.1562, 0.1208, 0.0000, 0.1774, 0.0000,\n",
       "         0.2815]),\n",
       " 2280: tensor([0.0611, 0.3073, 0.0655, 0.1344, 0.0000, 0.0992, 0.1242, 0.1939, 0.2332,\n",
       "         0.1786, 0.1485, 0.0000, 0.0000, 0.1278, 0.1769, 0.1372, 0.0076, 0.1107,\n",
       "         0.0000, 0.1279, 0.3383, 0.0739, 0.0000, 0.0000, 0.1818, 0.2659, 0.1297,\n",
       "         0.2111]),\n",
       " 3756: tensor([0.1071, 0.1040, 0.0000, 0.0830, 0.1970, 0.1455, 0.1178, 0.1490, 0.1790,\n",
       "         0.0748, 0.1393, 0.1014, 0.2716, 0.1306, 0.1293, 0.1451, 0.1150, 0.1096,\n",
       "         0.0584, 0.1761, 0.1669, 0.1346, 0.0000, 0.0709, 0.1467, 0.1687, 0.1149,\n",
       "         0.1620]),\n",
       " 3699: tensor([0.0656, 0.1157, 0.1131, 0.0998, 0.1639, 0.1303, 0.0000, 0.1082, 0.1268,\n",
       "         0.0675, 0.0776, 0.1957, 0.0597, 0.0000, 0.0000, 0.0760, 0.1121, 0.0980,\n",
       "         0.1805, 0.1402, 0.0895, 0.0582, 0.0875, 0.1689, 0.0764, 0.0870, 0.0387,\n",
       "         0.0455]),\n",
       " 3157: tensor([0.0338, 0.0918, 0.2075, 0.0743, 0.0000, 0.3298, 0.0879, 0.2334, 0.0778,\n",
       "         0.1418, 0.0175, 0.0286, 0.2490, 0.0830, 0.0846, 0.0975, 0.1740, 0.1159,\n",
       "         0.1038, 0.1456, 0.0380, 0.0560, 0.1414, 0.0664, 0.2308, 0.0000, 0.0825,\n",
       "         0.0693]),\n",
       " 2600: tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.5536, 0.1836, 0.0487, 0.0000, 0.2950,\n",
       "         0.2351, 0.1650, 0.3127, 0.0411, 0.0724, 0.3674, 0.2918, 0.5263, 0.3087,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0246, 0.1334, 0.2716, 0.0921, 0.0484,\n",
       "         0.0904]),\n",
       " 2662: tensor([0.2129, 0.1428, 0.1210, 0.0000, 0.0635, 0.1148, 0.0451, 0.0000, 0.2271,\n",
       "         0.1712, 0.4286, 0.0044, 0.0000, 0.2459, 0.0189, 0.0855, 0.0000, 0.2563,\n",
       "         0.1401, 0.1702, 0.0000, 0.1593, 0.1305, 0.0000, 0.1999, 0.2995, 0.0000,\n",
       "         0.0000]),\n",
       " 2710: tensor([0.0540, 0.1485, 0.1458, 0.1598, 0.0000, 0.1493, 0.0892, 0.1551, 0.0000,\n",
       "         0.0810, 0.0671, 0.1070, 0.1468, 0.2618, 0.0948, 0.2442, 0.0248, 0.1365,\n",
       "         0.0420, 0.1293, 0.0511, 0.0896, 0.0000, 0.1140, 0.0649, 0.1844, 0.1913,\n",
       "         0.1026]),\n",
       " 1293: tensor([0.0557, 0.1076, 0.1121, 0.1432, 0.0369, 0.1697, 0.0859, 0.1093, 0.2732,\n",
       "         0.1889, 0.0609, 0.0663, 0.0572, 0.1712, 0.1334, 0.1403, 0.0000, 0.1779,\n",
       "         0.2174, 0.1151, 0.1131, 0.0189, 0.0406, 0.1268, 0.0671, 0.0000, 0.4389,\n",
       "         0.1278]),\n",
       " 2427: tensor([0.1851, 0.1616, 0.1125, 0.1173, 0.0000, 0.0747, 0.0661, 0.0175, 0.2125,\n",
       "         0.2453, 0.1093, 0.1202, 0.1110, 0.1272, 0.1313, 0.1261, 0.1089, 0.1818,\n",
       "         0.1435, 0.1838, 0.1092, 0.0823, 0.1866, 0.1302, 0.1712, 0.0000, 0.0293,\n",
       "         0.1438]),\n",
       " 2566: tensor([0.1843, 0.3223, 0.3925, 0.1771, 0.2929, 0.0000, 0.1205, 0.2218, 0.0912,\n",
       "         0.1357, 0.0000, 0.3200, 0.3153, 0.2415, 0.1220, 0.0384, 0.2108, 0.0996,\n",
       "         0.2920, 0.2682, 0.1154, 0.2166, 0.2072, 0.1061, 0.1070, 0.0000, 0.1226,\n",
       "         0.3233]),\n",
       " 3359: tensor([0.0000, 0.0000, 0.2522, 0.0750, 0.1150, 0.3838, 0.2282, 0.1658, 0.1566,\n",
       "         0.1540, 0.1644, 0.2114, 0.1552, 0.2440, 0.0380, 0.2514, 0.0000, 0.2073,\n",
       "         0.1767, 0.2029, 0.0000, 0.1772, 0.0390, 0.0000, 0.1116, 0.0785, 0.0000,\n",
       "         0.1076]),\n",
       " 696: tensor([0.0000, 0.1651, 0.1289, 0.1873, 0.1632, 0.1525, 0.1060, 0.1479, 0.1881,\n",
       "         0.0513, 0.0136, 0.0000, 0.2128, 0.1550, 0.0384, 0.1128, 0.0000, 0.1611,\n",
       "         0.2069, 0.2155, 0.0000, 0.0969, 0.0000, 0.1030, 0.1985, 0.1198, 0.2315,\n",
       "         0.1597]),\n",
       " 3495: tensor([0.1447, 0.1110, 0.0000, 0.2286, 0.3029, 0.0822, 0.2703, 0.1467, 0.1961,\n",
       "         0.2324, 0.0926, 0.1062, 0.1590, 0.1825, 0.1526, 0.2719, 0.0499, 0.0761,\n",
       "         0.2104, 0.0972, 0.2217, 0.0757, 0.0000, 0.0000, 0.0798, 0.2232, 0.0099,\n",
       "         0.1807]),\n",
       " 2327: tensor([0.0479, 0.2589, 0.0972, 0.0571, 0.0000, 0.3520, 0.0000, 0.3103, 0.3938,\n",
       "         0.1376, 0.1568, 0.0000, 0.0000, 0.2713, 0.1159, 0.2184, 0.3016, 0.2156,\n",
       "         0.0000, 0.3490, 0.0457, 0.0926, 0.0000, 0.0000, 0.2954, 0.3738, 0.2124,\n",
       "         0.1299]),\n",
       " 1150: tensor([0.0000, 0.3473, 0.0000, 0.0000, 0.0000, 0.0736, 0.2170, 0.2355, 0.0920,\n",
       "         0.0000, 0.3301, 0.2200, 0.0704, 0.2188, 0.2206, 0.2377, 0.1939, 0.0807,\n",
       "         0.1711, 0.0909, 0.0296, 0.2501, 0.0000, 0.1291, 0.2169, 0.3378, 0.0000,\n",
       "         0.0657]),\n",
       " 1083: tensor([0.1399, 0.2009, 0.0246, 0.0797, 0.0000, 0.1179, 0.3078, 0.2283, 0.0883,\n",
       "         0.1307, 0.1108, 0.0942, 0.1416, 0.0000, 0.2280, 0.1348, 0.1587, 0.1779,\n",
       "         0.0000, 0.0988, 0.3412, 0.0000, 0.0561, 0.1118, 0.1455, 0.2261, 0.1817,\n",
       "         0.2229]),\n",
       " 1823: tensor([0.2493, 0.0000, 0.0000, 0.1230, 0.2320, 0.1614, 0.1710, 0.0817, 0.1825,\n",
       "         0.0000, 0.1660, 0.0000, 0.1604, 0.2027, 0.0459, 0.2319, 0.1383, 0.2121,\n",
       "         0.0789, 0.1918, 0.0901, 0.2002, 0.1742, 0.1187, 0.0380, 0.0523, 0.0000,\n",
       "         0.1698]),\n",
       " 861: tensor([0.0000, 0.4818, 0.3507, 0.4982, 0.1245, 0.2384, 0.0892, 0.0000, 0.0000,\n",
       "         0.0000, 0.5131, 0.1505, 0.0000, 0.1692, 0.2583, 0.1341, 0.0302, 0.0000,\n",
       "         0.2581, 0.2443, 0.3237, 0.0733, 0.0000, 0.6088, 0.0000, 0.2778, 0.5110,\n",
       "         0.6684]),\n",
       " 130: tensor([0.0000, 0.0000, 0.1961, 0.1417, 0.1446, 0.2152, 0.1214, 0.1921, 0.1649,\n",
       "         0.2457, 0.1061, 0.2412, 0.1192, 0.1162, 0.1033, 0.2222, 0.0000, 0.2071,\n",
       "         0.1101, 0.1525, 0.0000, 0.0923, 0.1208, 0.0000, 0.0724, 0.1675, 0.0700,\n",
       "         0.1730]),\n",
       " 1081: tensor([0.0000, 0.0000, 0.4213, 0.2323, 0.1862, 0.3455, 0.0000, 0.0000, 0.1405,\n",
       "         0.2059, 0.3538, 0.0219, 0.0000, 0.2665, 0.1856, 0.2006, 0.3187, 0.3043,\n",
       "         0.1813, 0.1522, 0.2557, 0.1591, 0.0000, 0.0000, 0.0399, 0.0000, 0.1383,\n",
       "         0.2324]),\n",
       " 1097: tensor([0.1903, 0.1612, 0.0000, 0.0829, 0.0901, 0.3684, 0.2283, 0.2177, 0.0000,\n",
       "         0.0153, 0.1916, 0.2523, 0.0744, 0.1349, 0.0000, 0.2022, 0.0524, 0.2416,\n",
       "         0.1212, 0.1754, 0.1330, 0.1015, 0.1579, 0.1672, 0.0884, 0.0580, 0.0549,\n",
       "         0.1814]),\n",
       " 3940: tensor([0.1447, 0.1901, 0.1131, 0.0763, 0.0143, 0.3220, 0.0701, 0.0595, 0.1688,\n",
       "         0.1927, 0.1141, 0.1142, 0.1275, 0.1212, 0.0832, 0.0590, 0.1249, 0.1280,\n",
       "         0.1267, 0.1299, 0.0835, 0.0496, 0.1548, 0.1070, 0.1561, 0.0000, 0.0376,\n",
       "         0.1632]),\n",
       " 3597: tensor([0.2037, 0.1333, 0.0724, 0.1637, 0.1234, 0.0884, 0.1749, 0.1931, 0.0864,\n",
       "         0.0790, 0.0634, 0.1660, 0.0615, 0.1576, 0.0586, 0.1333, 0.1160, 0.1499,\n",
       "         0.1150, 0.1838, 0.1316, 0.0912, 0.1191, 0.1082, 0.1031, 0.1176, 0.0000,\n",
       "         0.1817]),\n",
       " 2899: tensor([0.1385, 0.1757, 0.2717, 0.1840, 0.0000, 0.1663, 0.1987, 0.1450, 0.1915,\n",
       "         0.1639, 0.1702, 0.1523, 0.1339, 0.0000, 0.1583, 0.1900, 0.0839, 0.2053,\n",
       "         0.0000, 0.1400, 0.1680, 0.0000, 0.0545, 0.1467, 0.1884, 0.1597, 0.1455,\n",
       "         0.1123]),\n",
       " 3663: tensor([0.1185, 0.0000, 0.1947, 0.0000, 0.1538, 0.2917, 0.1010, 0.0000, 0.1533,\n",
       "         0.0848, 0.2007, 0.1600, 0.0000, 0.0994, 0.0758, 0.1192, 0.0000, 0.1079,\n",
       "         0.0527, 0.2347, 0.2270, 0.2980, 0.1461, 0.0000, 0.0849, 0.1791, 0.0000,\n",
       "         0.0000]),\n",
       " 1154: tensor([0.4426, 0.2865, 0.0000, 0.3143, 0.3593, 0.1579, 0.1019, 0.3218, 0.2853,\n",
       "         0.1660, 0.1211, 0.4012, 0.3506, 0.0091, 0.3355, 0.0000, 0.2506, 0.1170,\n",
       "         0.0098, 0.1412, 0.2173, 0.0000, 0.1777, 0.0000, 0.0000, 0.5224, 0.3498,\n",
       "         0.1665]),\n",
       " 4460: tensor([0.0000, 0.2397, 0.0000, 0.1211, 0.0000, 0.0000, 0.0125, 0.0209, 0.0853,\n",
       "         0.1179, 0.2201, 0.0000, 0.2474, 0.1371, 0.2478, 0.1963, 0.0583, 0.1790,\n",
       "         0.0818, 0.3021, 0.2340, 0.0167, 0.1909, 0.1385, 0.0718, 0.0000, 0.0981,\n",
       "         0.1804]),\n",
       " 1299: tensor([0.0000, 0.2040, 0.2999, 0.0000, 0.4947, 0.0914, 0.2578, 0.1884, 0.3514,\n",
       "         0.1035, 0.0000, 0.0000, 0.3816, 0.2023, 0.3168, 0.0000, 0.0000, 0.2952,\n",
       "         0.1705, 0.2968, 0.0000, 0.1031, 0.0000, 0.0053, 0.0744, 0.2640, 0.1320,\n",
       "         0.0638]),\n",
       " 3164: tensor([0.1009, 0.0585, 0.1353, 0.0000, 0.1378, 0.1636, 0.1139, 0.0000, 0.1188,\n",
       "         0.1225, 0.2217, 0.1715, 0.0000, 0.2162, 0.0861, 0.1712, 0.0000, 0.1534,\n",
       "         0.0918, 0.1557, 0.1273, 0.2791, 0.1110, 0.0099, 0.0778, 0.1755, 0.0000,\n",
       "         0.0000]),\n",
       " 2081: tensor([0.2318, 0.0000, 0.3146, 0.0325, 0.0000, 0.0000, 0.0200, 0.0000, 0.0920,\n",
       "         0.0981, 0.0000, 0.0161, 0.0617, 0.2934, 0.3580, 0.2493, 0.1312, 0.1198,\n",
       "         0.0950, 0.2441, 0.0379, 0.0000, 0.0965, 0.0000, 0.3617, 0.1369, 0.1448,\n",
       "         0.2500]),\n",
       " 1794: tensor([0.0000, 0.0313, 0.5709, 0.0000, 0.1583, 0.0995, 0.1750, 0.0341, 0.0000,\n",
       "         0.0000, 0.1919, 0.0253, 0.4013, 0.2760, 0.0000, 0.1371, 0.3361, 0.0000,\n",
       "         0.1526, 0.1310, 0.0000, 0.0393, 0.0795, 0.3336, 0.1699, 0.2278, 0.1041,\n",
       "         0.1307]),\n",
       " 2314: tensor([0.3283, 0.0000, 0.0000, 0.3726, 0.0000, 0.0313, 0.0814, 0.0616, 0.3855,\n",
       "         0.0000, 0.2694, 0.0000, 0.0747, 0.1158, 0.0000, 0.0578, 0.3435, 0.0000,\n",
       "         0.4098, 0.0556, 0.0482, 0.0000, 0.1255, 0.1060, 0.0000, 0.0000, 0.2241,\n",
       "         0.2015]),\n",
       " 4271: tensor([0.0000, 0.0493, 0.0293, 0.4115, 0.4615, 0.0687, 0.2486, 0.0938, 0.0000,\n",
       "         0.2315, 0.4442, 0.0291, 0.0000, 0.1882, 0.2330, 0.1229, 0.3061, 0.0000,\n",
       "         0.3764, 0.5048, 0.0607, 0.1852, 0.0000, 0.3900, 0.0000, 0.2901, 0.0000,\n",
       "         0.0300]),\n",
       " 839: tensor([0.0987, 0.1381, 0.1283, 0.0934, 0.2851, 0.1828, 0.0493, 0.1039, 0.1787,\n",
       "         0.0193, 0.0567, 0.1554, 0.1101, 0.0000, 0.0000, 0.0708, 0.1243, 0.1156,\n",
       "         0.1271, 0.0679, 0.0655, 0.1064, 0.0332, 0.2916, 0.1121, 0.1702, 0.0261,\n",
       "         0.0000]),\n",
       " 2454: tensor([0.0485, 0.1154, 0.0000, 0.0877, 0.1816, 0.0355, 0.1048, 0.1256, 0.1568,\n",
       "         0.1722, 0.1271, 0.1498, 0.2717, 0.1233, 0.1194, 0.1986, 0.2794, 0.1371,\n",
       "         0.1817, 0.1829, 0.2065, 0.1470, 0.0869, 0.0000, 0.3157, 0.1576, 0.0405,\n",
       "         0.0788]),\n",
       " 2505: tensor([0.0043, 0.1580, 0.0336, 0.2387, 0.4075, 0.3178, 0.1594, 0.2666, 0.1336,\n",
       "         0.0000, 0.2761, 0.3012, 0.2254, 0.3630, 0.3243, 0.0000, 0.2171, 0.0000,\n",
       "         0.5257, 0.2353, 0.0525, 0.0470, 0.3622, 0.1074, 0.0000, 0.0000, 0.0000,\n",
       "         0.3418]),\n",
       " 3767: tensor([0.0000, 0.3639, 0.0000, 0.1415, 0.0000, 0.0658, 0.0939, 0.1517, 0.0000,\n",
       "         0.2681, 0.1337, 0.0000, 0.1078, 0.1690, 0.1613, 0.2507, 0.0850, 0.1895,\n",
       "         0.3002, 0.3860, 0.3429, 0.0991, 0.2446, 0.1848, 0.2452, 0.0000, 0.2398,\n",
       "         0.0964]),\n",
       " 3051: tensor([0.0601, 0.1120, 0.0359, 0.1789, 0.0542, 0.0870, 0.2021, 0.1056, 0.0811,\n",
       "         0.0685, 0.1015, 0.2264, 0.0975, 0.0000, 0.1440, 0.0368, 0.0736, 0.1332,\n",
       "         0.0000, 0.0000, 0.0380, 0.1758, 0.1173, 0.2983, 0.0997, 0.0596, 0.0000,\n",
       "         0.1146]),\n",
       " 2705: tensor([0.0000, 0.0558, 0.0669, 0.1331, 0.2218, 0.2062, 0.0857, 0.0000, 0.0000,\n",
       "         0.1568, 0.1425, 0.0000, 0.1892, 0.1009, 0.0000, 0.1807, 0.0000, 0.0846,\n",
       "         0.3162, 0.1213, 0.0000, 0.1278, 0.0000, 0.0528, 0.2709, 0.2991, 0.2760,\n",
       "         0.1464]),\n",
       " 522: tensor([0.1437, 0.0000, 0.0000, 0.3133, 0.1542, 0.2357, 0.0000, 0.2913, 0.1718,\n",
       "         0.0000, 0.4018, 0.0000, 0.2473, 0.1203, 0.0091, 0.1725, 0.1120, 0.1016,\n",
       "         0.2186, 0.0202, 0.1324, 0.1367, 0.2164, 0.1929, 0.1744, 0.1951, 0.0000,\n",
       "         0.1245]),\n",
       " 1236: tensor([0.0000, 0.0962, 0.1312, 0.1992, 0.1048, 0.1585, 0.0927, 0.1155, 0.1486,\n",
       "         0.1177, 0.0936, 0.0321, 0.0812, 0.1462, 0.0000, 0.0931, 0.0000, 0.1311,\n",
       "         0.1675, 0.2050, 0.0542, 0.0312, 0.0322, 0.1524, 0.1089, 0.1100, 0.3351,\n",
       "         0.0894]),\n",
       " 162: tensor([0.0000, 0.0000, 0.1788, 0.1702, 0.1591, 0.1524, 0.1215, 0.1063, 0.1371,\n",
       "         0.1184, 0.0127, 0.2810, 0.1610, 0.0980, 0.0573, 0.2094, 0.0000, 0.2081,\n",
       "         0.0907, 0.1081, 0.0000, 0.0770, 0.2226, 0.0000, 0.0796, 0.0859, 0.0697,\n",
       "         0.1951]),\n",
       " 917: tensor([0.0000, 0.0000, 0.2353, 0.2284, 0.2346, 0.2547, 0.2471, 0.2839, 0.0013,\n",
       "         0.1874, 0.0436, 0.0334, 0.0560, 0.1369, 0.0000, 0.1478, 0.0000, 0.1616,\n",
       "         0.1364, 0.1374, 0.0000, 0.0196, 0.2076, 0.0000, 0.1647, 0.2389, 0.2410,\n",
       "         0.0250]),\n",
       " 4385: tensor([0.1045, 0.1300, 0.0000, 0.0678, 0.2252, 0.1411, 0.0716, 0.1469, 0.2783,\n",
       "         0.2960, 0.0960, 0.1637, 0.2941, 0.1540, 0.1388, 0.0940, 0.1414, 0.1618,\n",
       "         0.0536, 0.2014, 0.2826, 0.2071, 0.0538, 0.0000, 0.2018, 0.2220, 0.0655,\n",
       "         0.2474]),\n",
       " 4485: tensor([0.0009, 0.0000, 0.0000, 0.0000, 0.5156, 0.1130, 0.0000, 0.0000, 0.1918,\n",
       "         0.2529, 0.3129, 0.1091, 0.1508, 0.0663, 0.5286, 0.3326, 0.3318, 0.4038,\n",
       "         0.3744, 0.1040, 0.2450, 0.0000, 0.0000, 0.0000, 0.2389, 0.1488, 0.1300,\n",
       "         0.2435]),\n",
       " 400: tensor([0.0219, 0.2187, 0.3343, 0.0000, 0.0663, 0.2680, 0.1829, 0.0421, 0.0000,\n",
       "         0.0000, 0.0000, 0.0307, 0.2163, 0.2829, 0.0000, 0.1555, 0.3051, 0.0000,\n",
       "         0.2058, 0.2015, 0.0969, 0.1463, 0.1262, 0.2953, 0.2148, 0.0718, 0.1910,\n",
       "         0.3134]),\n",
       " 3584: tensor([0.0000, 0.1084, 0.0395, 0.0000, 0.2652, 0.0408, 0.0709, 0.0547, 0.0000,\n",
       "         0.1018, 0.2862, 0.0980, 0.1884, 0.2552, 0.0000, 0.1798, 0.3114, 0.0496,\n",
       "         0.0123, 0.0799, 0.0741, 0.2951, 0.1316, 0.2155, 0.0000, 0.0000, 0.1118,\n",
       "         0.0000]),\n",
       " 478: tensor([0.0000, 0.1280, 0.0000, 0.0953, 0.3375, 0.2183, 0.0942, 0.2551, 0.1957,\n",
       "         0.0457, 0.1036, 0.3101, 0.0477, 0.0000, 0.0000, 0.2362, 0.0858, 0.0000,\n",
       "         0.0487, 0.0000, 0.0000, 0.1502, 0.1850, 0.2129, 0.2549, 0.3151, 0.0311,\n",
       "         0.1540]),\n",
       " 1455: tensor([0.0658, 0.1809, 0.1180, 0.2650, 0.0000, 0.0927, 0.2320, 0.3279, 0.1770,\n",
       "         0.1623, 0.2257, 0.2571, 0.1165, 0.0776, 0.2696, 0.0616, 0.0740, 0.1069,\n",
       "         0.0335, 0.0168, 0.0325, 0.0293, 0.0000, 0.2985, 0.0854, 0.2702, 0.0458,\n",
       "         0.1775]),\n",
       " 3629: tensor([0.0655, 0.0121, 0.0999, 0.0259, 0.1612, 0.2172, 0.1003, 0.0000, 0.2583,\n",
       "         0.1300, 0.3008, 0.1683, 0.1277, 0.2155, 0.0618, 0.1121, 0.0000, 0.1548,\n",
       "         0.1262, 0.1570, 0.0269, 0.3223, 0.1275, 0.0826, 0.1057, 0.1467, 0.0000,\n",
       "         0.0000]),\n",
       " 1136: tensor([0.1324, 0.1874, 0.0757, 0.1695, 0.0000, 0.0283, 0.0831, 0.1572, 0.1283,\n",
       "         0.2730, 0.1294, 0.0681, 0.1892, 0.1301, 0.1017, 0.1372, 0.1289, 0.1559,\n",
       "         0.1118, 0.1992, 0.1674, 0.1196, 0.1990, 0.0626, 0.2067, 0.0000, 0.0938,\n",
       "         0.1634]),\n",
       " 3900: tensor([0.0664, 0.3479, 0.0218, 0.3496, 0.0000, 0.2437, 0.2953, 0.0956, 0.3964,\n",
       "         0.0769, 0.1176, 0.0000, 0.0000, 0.4051, 0.1646, 0.0000, 0.3704, 0.2679,\n",
       "         0.0000, 0.1019, 0.2081, 0.0000, 0.0000, 0.0000, 0.3335, 0.4809, 0.3175,\n",
       "         0.2801]),\n",
       " 2893: tensor([0.0874, 0.1517, 0.2051, 0.0233, 0.0000, 0.1404, 0.0131, 0.0760, 0.1781,\n",
       "         0.1124, 0.0916, 0.0000, 0.0000, 0.1737, 0.0720, 0.0559, 0.1557, 0.1408,\n",
       "         0.0000, 0.0679, 0.0942, 0.0196, 0.0000, 0.0000, 0.1503, 0.2212, 0.1461,\n",
       "         0.2173]),\n",
       " 733: tensor([0.0891, 0.0000, 0.0000, 0.2859, 0.0000, 0.1342, 0.1544, 0.1422, 0.1589,\n",
       "         0.0000, 0.2545, 0.0000, 0.1707, 0.1112, 0.0000, 0.0000, 0.2331, 0.0000,\n",
       "         0.3200, 0.2842, 0.0946, 0.0000, 0.1762, 0.1703, 0.0000, 0.0000, 0.3082,\n",
       "         0.0682]),\n",
       " 3793: tensor([0.0562, 0.1934, 0.0000, 0.1691, 0.0000, 0.0314, 0.2274, 0.0601, 0.1176,\n",
       "         0.1800, 0.0615, 0.1949, 0.1499, 0.0000, 0.1791, 0.0000, 0.0762, 0.1552,\n",
       "         0.0000, 0.1269, 0.2248, 0.0000, 0.0000, 0.3037, 0.1969, 0.2456, 0.1657,\n",
       "         0.1945]),\n",
       " 574: tensor([0.0647, 0.1302, 0.0000, 0.1444, 0.1860, 0.5149, 0.1845, 0.1556, 0.0000,\n",
       "         0.0000, 0.1888, 0.1390, 0.1235, 0.1267, 0.0000, 0.2219, 0.3075, 0.0415,\n",
       "         0.3824, 0.1265, 0.0000, 0.0562, 0.2660, 0.0000, 0.0000, 0.1299, 0.1329,\n",
       "         0.1857]),\n",
       " 4117: tensor([0.1127, 0.0000, 0.1798, 0.1567, 0.2393, 0.1643, 0.0000, 0.0000, 0.1517,\n",
       "         0.0103, 0.1146, 0.2269, 0.2699, 0.2808, 0.2389, 0.0000, 0.1452, 0.0000,\n",
       "         0.3371, 0.0287, 0.0922, 0.0153, 0.3288, 0.0553, 0.0000, 0.0000, 0.0000,\n",
       "         0.3246]),\n",
       " 3830: tensor([0.2830, 0.1718, 0.2146, 0.2447, 0.2081, 0.3072, 0.2323, 0.0000, 0.2428,\n",
       "         0.2534, 0.0565, 0.1961, 0.2179, 0.0109, 0.1998, 0.0000, 0.1252, 0.0000,\n",
       "         0.1141, 0.0000, 0.1048, 0.0000, 0.2662, 0.0000, 0.0000, 0.2655, 0.0000,\n",
       "         0.3076]),\n",
       " 3792: tensor([0.0226, 0.1567, 0.0000, 0.2102, 0.2896, 0.2543, 0.0000, 0.0000, 0.1472,\n",
       "         0.0000, 0.1317, 0.2838, 0.0613, 0.1274, 0.1426, 0.0000, 0.2183, 0.0000,\n",
       "         0.3632, 0.0024, 0.1584, 0.0000, 0.2744, 0.0000, 0.0000, 0.1073, 0.0000,\n",
       "         0.1296]),\n",
       " 4168: tensor([0.2892, 0.0000, 0.2249, 0.2217, 0.0000, 0.0000, 0.0504, 0.0000, 0.0959,\n",
       "         0.0791, 0.0892, 0.0305, 0.0453, 0.1656, 0.1586, 0.3035, 0.0964, 0.1317,\n",
       "         0.0568, 0.1163, 0.1309, 0.0000, 0.0000, 0.1581, 0.0632, 0.0081, 0.1225,\n",
       "         0.2028]),\n",
       " 889: tensor([0.2287, 0.1555, 0.1734, 0.1237, 0.1455, 0.1874, 0.1268, 0.2225, 0.1561,\n",
       "         0.1431, 0.0565, 0.0800, 0.1582, 0.1823, 0.2126, 0.1294, 0.1144, 0.1047,\n",
       "         0.0000, 0.0199, 0.1276, 0.2278, 0.0640, 0.1742, 0.0000, 0.1734, 0.1484,\n",
       "         0.1321]),\n",
       " 4207: tensor([0.1037, 0.1299, 0.0735, 0.1794, 0.0000, 0.2380, 0.1214, 0.1155, 0.1369,\n",
       "         0.1665, 0.1856, 0.1976, 0.2480, 0.0000, 0.0458, 0.1682, 0.1049, 0.1305,\n",
       "         0.0000, 0.0000, 0.2538, 0.0000, 0.1397, 0.2071, 0.1252, 0.1129, 0.2552,\n",
       "         0.0882]),\n",
       " 3200: tensor([0.0399, 0.0591, 0.1122, 0.2060, 0.1297, 0.1668, 0.1383, 0.1048, 0.2272,\n",
       "         0.0468, 0.0848, 0.0456, 0.0777, 0.1199, 0.1382, 0.1627, 0.0000, 0.1080,\n",
       "         0.1661, 0.1519, 0.1255, 0.0205, 0.1162, 0.1801, 0.0894, 0.0801, 0.3500,\n",
       "         0.0937]),\n",
       " 4381: tensor([0.2227, 0.0000, 0.1444, 0.1833, 0.0000, 0.0000, 0.1256, 0.0000, 0.0832,\n",
       "         0.2034, 0.1118, 0.1646, 0.1865, 0.2054, 0.1520, 0.1667, 0.0435, 0.1768,\n",
       "         0.0359, 0.0984, 0.1705, 0.0000, 0.0974, 0.1210, 0.1733, 0.1116, 0.1264,\n",
       "         0.1529]),\n",
       " 2150: tensor([0.0000, 0.0000, 0.0642, 0.2707, 0.2081, 0.3470, 0.1066, 0.2360, 0.2231,\n",
       "         0.1265, 0.2047, 0.2399, 0.1135, 0.0960, 0.0849, 0.4006, 0.0000, 0.1944,\n",
       "         0.1784, 0.1040, 0.0000, 0.0338, 0.2037, 0.0000, 0.1338, 0.1170, 0.1725,\n",
       "         0.0000]),\n",
       " 822: tensor([0.0791, 0.1091, 0.2046, 0.0578, 0.1769, 0.1367, 0.0000, 0.1681, 0.0000,\n",
       "         0.1212, 0.1498, 0.0519, 0.1160, 0.0000, 0.0000, 0.0951, 0.1052, 0.2036,\n",
       "         0.0000, 0.0000, 0.1032, 0.1729, 0.0780, 0.0000, 0.2158, 0.1749, 0.0715,\n",
       "         0.0805]),\n",
       " 3735: tensor([0.0610, 0.0000, 0.0000, 0.1357, 0.2895, 0.2501, 0.2307, 0.2152, 0.2121,\n",
       "         0.0000, 0.2173, 0.0000, 0.1519, 0.1073, 0.1538, 0.2747, 0.0765, 0.2035,\n",
       "         0.0919, 0.1062, 0.0230, 0.2206, 0.1405, 0.1477, 0.0569, 0.0908, 0.0000,\n",
       "         0.1316]),\n",
       " 1237: tensor([0.1444, 0.1648, 0.0699, 0.1591, 0.0000, 0.2361, 0.1700, 0.1034, 0.3403,\n",
       "         0.0995, 0.1395, 0.0000, 0.0000, 0.1517, 0.1312, 0.2599, 0.2980, 0.1619,\n",
       "         0.0000, 0.1604, 0.1560, 0.0927, 0.0000, 0.0000, 0.2896, 0.2914, 0.2027,\n",
       "         0.2536]),\n",
       " 3195: tensor([0.0737, 0.0000, 0.0747, 0.0000, 0.1552, 0.1456, 0.1152, 0.0000, 0.1663,\n",
       "         0.1134, 0.1912, 0.0076, 0.0000, 0.2432, 0.0336, 0.2675, 0.0000, 0.2205,\n",
       "         0.0982, 0.2075, 0.0000, 0.3052, 0.0354, 0.0025, 0.1470, 0.1428, 0.0000,\n",
       "         0.0000]),\n",
       " 2243: tensor([0.1696, 0.1357, 0.1311, 0.1574, 0.0000, 0.1328, 0.1532, 0.1684, 0.0641,\n",
       "         0.1578, 0.0893, 0.0922, 0.1156, 0.1699, 0.1720, 0.0956, 0.1263, 0.1872,\n",
       "         0.0410, 0.0853, 0.1442, 0.0943, 0.0000, 0.1565, 0.1209, 0.1003, 0.1056,\n",
       "         0.0853]),\n",
       " 4451: tensor([0.1842, 0.1783, 0.0000, 0.2746, 0.0000, 0.1754, 0.1303, 0.0222, 0.1783,\n",
       "         0.0280, 0.0949, 0.1050, 0.3153, 0.0000, 0.0199, 0.0518, 0.0868, 0.1330,\n",
       "         0.0000, 0.0920, 0.2749, 0.0000, 0.0000, 0.2478, 0.0743, 0.0903, 0.2859,\n",
       "         0.1990]),\n",
       " 2399: tensor([0.0000, 0.1213, 0.0000, 0.3593, 0.0722, 0.3269, 0.0736, 0.3663, 0.1709,\n",
       "         0.0000, 0.2616, 0.0000, 0.1470, 0.2776, 0.1333, 0.2624, 0.1642, 0.1430,\n",
       "         0.1360, 0.0096, 0.3455, 0.1109, 0.2931, 0.3266, 0.3242, 0.1401, 0.0000,\n",
       "         0.0755]),\n",
       " 1207: tensor([0.0048, 0.2006, 0.4201, 0.0000, 0.2587, 0.0000, 0.1799, 0.1783, 0.0674,\n",
       "         0.1098, 0.0888, 0.0147, 0.2413, 0.0000, 0.2353, 0.0584, 0.0312, 0.0000,\n",
       "         0.0280, 0.1979, 0.1966, 0.0000, 0.1429, 0.1333, 0.0141, 0.4451, 0.0000,\n",
       "         0.0393]),\n",
       " 1893: tensor([0.1317, 0.0881, 0.2966, 0.0000, 0.0412, 0.0616, 0.1585, 0.0227, 0.0000,\n",
       "         0.0000, 0.1606, 0.1309, 0.3631, 0.1346, 0.0000, 0.1669, 0.1428, 0.0000,\n",
       "         0.1474, 0.1246, 0.0790, 0.1760, 0.1436, 0.1555, 0.0000, 0.1621, 0.1982,\n",
       "         0.0527]),\n",
       " 1919: tensor([0.1061, 0.0912, 0.0000, 0.0882, 0.1447, 0.1755, 0.0668, 0.0739, 0.1929,\n",
       "         0.1218, 0.0624, 0.1412, 0.1835, 0.0611, 0.1676, 0.0000, 0.1371, 0.1706,\n",
       "         0.0568, 0.1513, 0.1880, 0.1379, 0.1604, 0.0000, 0.2913, 0.2246, 0.0695,\n",
       "         0.0827]),\n",
       " 1503: tensor([0.3297, 0.1298, 0.2054, 0.1112, 0.1505, 0.0000, 0.1232, 0.1357, 0.2719,\n",
       "         0.0814, 0.0000, 0.1738, 0.1061, 0.1270, 0.1429, 0.1902, 0.1812, 0.2062,\n",
       "         0.1556, 0.1069, 0.1757, 0.3035, 0.1430, 0.0281, 0.1774, 0.0000, 0.1149,\n",
       "         0.0963]),\n",
       " 909: tensor([0.1104, 0.1323, 0.1658, 0.0007, 0.1780, 0.1689, 0.0000, 0.1827, 0.0000,\n",
       "         0.1071, 0.1621, 0.0098, 0.1206, 0.0000, 0.0000, 0.0841, 0.1572, 0.1411,\n",
       "         0.0000, 0.0000, 0.0808, 0.1345, 0.0621, 0.0000, 0.2585, 0.3020, 0.1081,\n",
       "         0.0319]),\n",
       " 2209: tensor([0.1752, 0.1578, 0.0994, 0.1581, 0.0000, 0.1682, 0.2999, 0.2046, 0.0000,\n",
       "         0.0722, 0.0587, 0.0156, 0.3579, 0.0000, 0.2492, 0.1784, 0.1805, 0.1284,\n",
       "         0.0000, 0.0959, 0.2897, 0.0000, 0.1203, 0.3134, 0.1031, 0.1765, 0.0656,\n",
       "         0.1824]),\n",
       " 3303: tensor([0.0646, 0.0546, 0.0000, 0.1288, 0.2229, 0.1094, 0.1332, 0.1207, 0.1465,\n",
       "         0.0844, 0.1464, 0.1097, 0.1858, 0.1241, 0.0653, 0.1179, 0.0954, 0.1146,\n",
       "         0.0746, 0.1085, 0.1465, 0.1000, 0.0390, 0.0400, 0.1127, 0.1394, 0.0928,\n",
       "         0.0628]),\n",
       " 1005: tensor([0.1130, 0.1451, 0.1467, 0.1315, 0.0203, 0.0694, 0.0846, 0.1897, 0.1457,\n",
       "         0.1670, 0.1236, 0.0616, 0.1188, 0.0000, 0.0000, 0.0769, 0.1886, 0.0940,\n",
       "         0.1012, 0.1146, 0.0841, 0.0943, 0.1500, 0.0425, 0.1904, 0.1110, 0.1236,\n",
       "         0.1137]),\n",
       " 2450: tensor([0.0307, 0.1054, 0.1364, 0.1185, 0.1054, 0.0976, 0.1546, 0.1074, 0.1443,\n",
       "         0.2932, 0.1812, 0.1162, 0.1549, 0.1975, 0.1657, 0.0296, 0.2076, 0.0841,\n",
       "         0.0000, 0.0963, 0.1657, 0.3009, 0.1080, 0.2049, 0.0000, 0.2908, 0.0958,\n",
       "         0.1561]),\n",
       " 1945: tensor([0.0000, 0.3154, 0.0000, 0.2307, 0.0000, 0.3002, 0.1283, 0.0000, 0.0588,\n",
       "         0.0906, 0.2972, 0.0949, 0.0000, 0.2926, 0.1870, 0.2332, 0.3362, 0.1967,\n",
       "         0.1526, 0.2632, 0.1426, 0.0000, 0.0948, 0.2709, 0.1121, 0.0000, 0.0609,\n",
       "         0.4096]),\n",
       " 2338: tensor([0.0000, 0.2012, 0.0000, 0.2630, 0.0000, 0.3413, 0.3947, 0.3997, 0.1047,\n",
       "         0.0211, 0.0000, 0.1307, 0.0000, 0.2327, 0.1029, 0.1132, 0.2435, 0.0880,\n",
       "         0.0851, 0.2605, 0.0872, 0.1827, 0.0876, 0.1644, 0.1108, 0.0000, 0.3328,\n",
       "         0.0568]),\n",
       " 1782: tensor([0.0680, 0.0510, 0.0922, 0.0886, 0.0000, 0.0686, 0.1042, 0.2233, 0.1565,\n",
       "         0.0283, 0.1665, 0.1298, 0.0833, 0.1861, 0.1679, 0.0811, 0.1395, 0.0834,\n",
       "         0.1237, 0.0887, 0.1320, 0.1544, 0.0000, 0.1128, 0.2121, 0.1530, 0.0000,\n",
       "         0.0483]),\n",
       " 1053: tensor([0.1135, 0.1197, 0.0134, 0.2982, 0.1362, 0.1839, 0.2488, 0.2934, 0.1260,\n",
       "         0.0000, 0.1262, 0.1267, 0.0772, 0.1775, 0.0808, 0.2042, 0.0853, 0.1296,\n",
       "         0.0756, 0.1367, 0.1343, 0.1675, 0.1571, 0.1526, 0.0657, 0.1012, 0.0000,\n",
       "         0.1346]),\n",
       " 2007: tensor([0.0000, 0.1942, 0.2565, 0.0000, 0.4150, 0.1575, 0.3232, 0.1556, 0.2461,\n",
       "         0.1527, 0.0000, 0.1389, 0.3051, 0.1976, 0.2197, 0.0363, 0.0000, 0.3025,\n",
       "         0.0199, 0.3943, 0.1480, 0.0686, 0.1123, 0.0551, 0.0000, 0.1071, 0.1549,\n",
       "         0.0529]),\n",
       " 1001: tensor([0.1108, 0.0875, 0.0000, 0.1232, 0.2428, 0.1065, 0.1408, 0.1762, 0.1312,\n",
       "         0.1045, 0.1109, 0.1168, 0.2449, 0.1064, 0.0835, 0.0937, 0.1401, 0.1091,\n",
       "         0.0899, 0.1471, 0.1763, 0.1382, 0.0000, 0.0495, 0.1360, 0.2000, 0.0782,\n",
       "         0.1432]),\n",
       " 810: tensor([0.1559, 0.1075, 0.1071, 0.1216, 0.0000, 0.1365, 0.1862, 0.0941, 0.0926,\n",
       "         0.1444, 0.1530, 0.0000, 0.0000, 0.1422, 0.0850, 0.1098, 0.2043, 0.1314,\n",
       "         0.0000, 0.1620, 0.0347, 0.1502, 0.0000, 0.0000, 0.2447, 0.0778, 0.1512,\n",
       "         0.1049]),\n",
       " 663: tensor([0.0553, 0.0835, 0.1464, 0.0272, 0.0482, 0.0000, 0.0000, 0.0054, 0.0718,\n",
       "         0.1929, 0.1773, 0.1540, 0.0000, 0.0000, 0.0000, 0.0000, 0.0992, 0.1537,\n",
       "         0.1591, 0.3107, 0.1679, 0.0000, 0.0000, 0.1350, 0.0364, 0.0000, 0.1768,\n",
       "         0.2348]),\n",
       " 4453: tensor([0.0000, 0.0376, 0.1200, 0.3499, 0.0000, 0.2182, 0.2026, 0.0650, 0.3830,\n",
       "         0.1098, 0.1767, 0.1447, 0.2958, 0.0000, 0.0687, 0.1566, 0.3669, 0.0000,\n",
       "         0.0000, 0.0288, 0.0000, 0.0000, 0.0000, 0.0125, 0.2480, 0.1650, 0.0798,\n",
       "         0.2449]),\n",
       " 4463: tensor([0.1384, 0.1589, 0.1675, 0.1297, 0.1702, 0.2915, 0.0624, 0.0912, 0.1330,\n",
       "         0.0000, 0.1989, 0.1290, 0.1066, 0.2174, 0.1646, 0.0000, 0.2003, 0.0000,\n",
       "         0.2223, 0.0973, 0.0370, 0.0000, 0.2288, 0.1537, 0.0000, 0.1819, 0.0000,\n",
       "         0.2788]),\n",
       " 3861: tensor([0.1219, 0.2671, 0.0641, 0.1977, 0.3059, 0.4124, 0.2234, 0.0695, 0.3579,\n",
       "         0.0753, 0.1933, 0.0461, 0.1244, 0.0000, 0.0000, 0.1797, 0.2472, 0.2649,\n",
       "         0.0633, 0.3421, 0.1106, 0.1390, 0.0000, 0.3835, 0.0738, 0.1481, 0.0921,\n",
       "         0.0000]),\n",
       " 298: tensor([0.0000, 0.0963, 0.1313, 0.1990, 0.1050, 0.1652, 0.0921, 0.1138, 0.1441,\n",
       "         0.1185, 0.0939, 0.0348, 0.0802, 0.1474, 0.0000, 0.0932, 0.0000, 0.1296,\n",
       "         0.1717, 0.2067, 0.0684, 0.0300, 0.0253, 0.1555, 0.1087, 0.1018, 0.3370,\n",
       "         0.0956]),\n",
       " 3011: tensor([0.1454, 0.1897, 0.1112, 0.0740, 0.0108, 0.3261, 0.0672, 0.0504, 0.1684,\n",
       "         0.1942, 0.1190, 0.1149, 0.1198, 0.1239, 0.0833, 0.0590, 0.1226, 0.1273,\n",
       "         0.1277, 0.1282, 0.0834, 0.0433, 0.1547, 0.1070, 0.1529, 0.0000, 0.0299,\n",
       "         0.1683]),\n",
       " 2044: tensor([0.0000, 0.1340, 0.0564, 0.0932, 0.1608, 0.1005, 0.2157, 0.0790, 0.0209,\n",
       "         0.2319, 0.0000, 0.2230, 0.0342, 0.3434, 0.0000, 0.2092, 0.0000, 0.2578,\n",
       "         0.2804, 0.0868, 0.0000, 0.0000, 0.4286, 0.0933, 0.0427, 0.0053, 0.4587,\n",
       "         0.0695]),\n",
       " 2782: tensor([0.0000, 0.0000, 0.2457, 0.1139, 0.1028, 0.0608, 0.0000, 0.0000, 0.1662,\n",
       "         0.2012, 0.0713, 0.0000, 0.0000, 0.1029, 0.0000, 0.2503, 0.4475, 0.0000,\n",
       "         0.0970, 0.0000, 0.0765, 0.0000, 0.0000, 0.0000, 0.0868, 0.0000, 0.1186,\n",
       "         0.0060]),\n",
       " 2875: tensor([0.1584, 0.1578, 0.1683, 0.1176, 0.1592, 0.1730, 0.1665, 0.1351, 0.1184,\n",
       "         0.0953, 0.0474, 0.0408, 0.1462, 0.1751, 0.1448, 0.0943, 0.0905, 0.0812,\n",
       "         0.1585, 0.0782, 0.1214, 0.1297, 0.0638, 0.2029, 0.0000, 0.1632, 0.1723,\n",
       "         0.1232]),\n",
       " 1173: tensor([0.0657, 0.1943, 0.1200, 0.0443, 0.0000, 0.3569, 0.0473, 0.0000, 0.2600,\n",
       "         0.1186, 0.0375, 0.0189, 0.2596, 0.1163, 0.1898, 0.0485, 0.1972, 0.0536,\n",
       "         0.1029, 0.0777, 0.0663, 0.0110, 0.0951, 0.2139, 0.1260, 0.0000, 0.0178,\n",
       "         0.2820]),\n",
       " 2206: tensor([0.0680, 0.2168, 0.3046, 0.0348, 0.2133, 0.0000, 0.2018, 0.3333, 0.2336,\n",
       "         0.1013, 0.0297, 0.0000, 0.4057, 0.2790, 0.3224, 0.0000, 0.0000, 0.1354,\n",
       "         0.0727, 0.1019, 0.0256, 0.1871, 0.0000, 0.0546, 0.4336, 0.1070, 0.0000,\n",
       "         0.1884]),\n",
       " 3052: tensor([0.2249, 0.1847, 0.0000, 0.2017, 0.1597, 0.5701, 0.1262, 0.1153, 0.0000,\n",
       "         0.0000, 0.0000, 0.1801, 0.2186, 0.1455, 0.0000, 0.0941, 0.0944, 0.2176,\n",
       "         0.3216, 0.0518, 0.0556, 0.2697, 0.4676, 0.0000, 0.0000, 0.0000, 0.1156,\n",
       "         0.1279]),\n",
       " 3295: tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.7613, 0.1644, 0.0071, 0.0000, 0.1779,\n",
       "         0.2096, 0.2123, 0.0984, 0.1062, 0.0951, 0.3544, 0.2340, 0.3550, 0.3992,\n",
       "         0.0000, 0.1060, 0.1908, 0.0000, 0.0767, 0.1062, 0.4228, 0.2431, 0.1157,\n",
       "         0.2143]),\n",
       " 2862: tensor([0.0000, 0.0000, 0.1314, 0.1960, 0.1715, 0.7137, 0.1682, 0.2223, 0.0000,\n",
       "         0.0000, 0.1872, 0.0913, 0.0997, 0.1813, 0.1735, 0.0000, 0.0000, 0.2253,\n",
       "         0.2963, 0.1982, 0.0000, 0.0433, 0.3219, 0.0000, 0.1528, 0.0739, 0.0000,\n",
       "         0.0000]),\n",
       " 3023: tensor([0.0875, 0.0988, 0.0000, 0.1511, 0.2200, 0.0486, 0.1473, 0.1129, 0.2772,\n",
       "         0.1906, 0.1170, 0.1612, 0.2672, 0.1007, 0.1671, 0.1602, 0.1562, 0.1398,\n",
       "         0.1680, 0.0599, 0.1738, 0.1315, 0.0298, 0.0000, 0.1504, 0.0903, 0.0401,\n",
       "         0.1221]),\n",
       " 3486: tensor([0.0904, 0.3432, 0.0000, 0.1537, 0.0000, 0.2822, 0.0272, 0.3391, 0.0802,\n",
       "         0.1048, 0.0000, 0.0000, 0.1969, 0.1153, 0.1228, 0.1005, 0.1480, 0.3403,\n",
       "         0.3793, 0.0000, 0.1554, 0.0000, 0.0730, 0.1296, 0.1730, 0.0050, 0.0010,\n",
       "         0.2442]),\n",
       " 1193: tensor([0.1730, 0.2600, 0.1272, 0.0000, 0.0000, 0.0581, 0.0000, 0.0846, 0.1416,\n",
       "         0.0104, 0.2102, 0.1382, 0.1112, 0.0664, 0.2703, 0.1055, 0.0991, 0.0000,\n",
       "         0.0000, 0.2946, 0.0000, 0.0158, 0.3507, 0.1559, 0.0000, 0.0900, 0.0415,\n",
       "         0.0000]),\n",
       " 2457: tensor([0.0000, 0.1197, 0.1908, 0.0020, 0.2539, 0.1072, 0.1295, 0.3048, 0.0415,\n",
       "         0.0955, 0.0872, 0.0000, 0.2774, 0.1377, 0.0000, 0.0433, 0.0000, 0.1203,\n",
       "         0.0443, 0.0447, 0.0000, 0.2006, 0.0000, 0.0731, 0.0857, 0.0439, 0.2737,\n",
       "         0.0000]),\n",
       " 3899: tensor([0.0822, 0.1115, 0.0827, 0.0837, 0.1085, 0.2547, 0.0842, 0.0902, 0.1245,\n",
       "         0.0000, 0.1617, 0.1845, 0.2052, 0.1166, 0.1337, 0.0000, 0.2009, 0.0000,\n",
       "         0.1734, 0.1184, 0.0973, 0.0000, 0.1952, 0.0193, 0.0000, 0.1184, 0.0000,\n",
       "         0.1554]),\n",
       " 2300: tensor([0.1414, 0.1171, 0.4418, 0.0000, 0.2991, 0.0271, 0.0430, 0.3299, 0.0000,\n",
       "         0.0000, 0.0055, 0.1835, 0.5072, 0.1949, 0.0000, 0.3078, 0.0000, 0.0000,\n",
       "         0.1043, 0.1436, 0.3176, 0.0131, 0.1784, 0.0764, 0.1488, 0.2329, 0.0989,\n",
       "         0.1227]),\n",
       " 968: tensor([0.0547, 0.1711, 0.1249, 0.0476, 0.2028, 0.2183, 0.1048, 0.1765, 0.0928,\n",
       "         0.1128, 0.1279, 0.2653, 0.0000, 0.0000, 0.0000, 0.0825, 0.1374, 0.0104,\n",
       "         0.2432, 0.0639, 0.0670, 0.0152, 0.1011, 0.2053, 0.0977, 0.2247, 0.0251,\n",
       "         0.0970]),\n",
       " 2387: tensor([0.2506, 0.1750, 0.1988, 0.1941, 0.0289, 0.1825, 0.0918, 0.1081, 0.0000,\n",
       "         0.3038, 0.1723, 0.2432, 0.1181, 0.2385, 0.2125, 0.1296, 0.2304, 0.1151,\n",
       "         0.0351, 0.0848, 0.0283, 0.1001, 0.1065, 0.2107, 0.0000, 0.1647, 0.0462,\n",
       "         0.3231]),\n",
       " 711: tensor([0.2403, 0.0000, 0.0915, 0.0803, 0.3869, 0.0000, 0.1222, 0.2318, 0.4290,\n",
       "         0.0000, 0.1071, 0.0000, 0.1119, 0.2910, 0.0829, 0.3363, 0.2154, 0.2009,\n",
       "         0.0847, 0.2800, 0.1577, 0.0078, 0.0000, 0.0000, 0.2998, 0.3340, 0.1559,\n",
       "         0.0326]),\n",
       " 2723: tensor([0.1220, 0.1312, 0.0731, 0.1403, 0.0000, 0.1592, 0.1088, 0.1017, 0.1950,\n",
       "         0.1315, 0.2077, 0.0000, 0.0000, 0.1750, 0.1479, 0.1196, 0.1507, 0.1784,\n",
       "         0.0000, 0.1490, 0.1566, 0.1141, 0.0000, 0.0000, 0.0753, 0.1312, 0.1745,\n",
       "         0.1852]),\n",
       " 4426: tensor([0.0000, 0.2093, 0.2171, 0.0000, 0.2770, 0.0000, 0.1737, 0.2313, 0.1917,\n",
       "         0.0557, 0.0926, 0.0000, 0.0451, 0.2222, 0.1286, 0.0000, 0.0721, 0.1864,\n",
       "         0.2150, 0.1857, 0.0000, 0.0694, 0.1602, 0.1456, 0.0562, 0.2351, 0.0810,\n",
       "         0.0973]),\n",
       " 3930: tensor([0.0758, 0.0944, 0.0000, 0.0751, 0.2165, 0.0959, 0.1219, 0.0993, 0.2016,\n",
       "         0.2043, 0.1026, 0.1240, 0.2552, 0.1294, 0.1498, 0.1411, 0.1387, 0.1212,\n",
       "         0.0883, 0.1332, 0.1967, 0.1181, 0.0025, 0.0000, 0.1349, 0.1388, 0.0375,\n",
       "         0.1470]),\n",
       " 1760: tensor([0.0153, 0.0856, 0.2625, 0.2465, 0.1270, 0.3073, 0.0000, 0.0363, 0.2336,\n",
       "         0.0046, 0.2815, 0.1785, 0.2561, 0.1430, 0.1787, 0.1782, 0.1909, 0.0456,\n",
       "         0.1602, 0.0365, 0.0491, 0.0012, 0.0885, 0.2291, 0.0939, 0.0000, 0.1504,\n",
       "         0.2155]),\n",
       " 3648: tensor([0.0000, 0.0000, 0.2547, 0.1617, 0.2525, 0.4697, 0.0574, 0.2477, 0.0891,\n",
       "         0.0988, 0.1543, 0.0009, 0.0000, 0.2245, 0.1731, 0.0878, 0.0000, 0.1335,\n",
       "         0.1027, 0.2149, 0.0000, 0.0000, 0.1736, 0.0000, 0.1198, 0.1815, 0.0850,\n",
       "         0.0000]),\n",
       " 2287: tensor([0.0000, 0.2923, 0.0000, 0.2448, 0.0000, 0.3918, 0.0582, 0.0000, 0.0000,\n",
       "         0.0000, 0.6708, 0.2258, 0.0000, 0.2188, 0.1685, 0.2053, 0.3411, 0.2346,\n",
       "         0.3830, 0.5461, 0.0221, 0.0000, 0.2363, 0.4832, 0.1984, 0.0000, 0.1008,\n",
       "         0.0944]),\n",
       " 3399: tensor([0.2474, 0.0000, 0.0000, 0.3048, 0.3148, 0.3786, 0.0000, 0.2098, 0.1617,\n",
       "         0.0398, 0.3462, 0.0000, 0.1518, 0.1447, 0.1092, 0.4779, 0.1103, 0.1902,\n",
       "         0.2513, 0.0525, 0.1805, 0.2528, 0.4503, 0.1832, 0.0934, 0.0663, 0.0000,\n",
       "         0.2539]),\n",
       " 3797: tensor([0.0000, 0.0000, 0.5603, 0.0628, 0.6500, 0.3519, 0.2563, 0.2444, 0.0332,\n",
       "         0.3789, 0.0991, 0.5973, 0.3497, 0.5857, 0.0000, 0.2015, 0.0000, 0.4876,\n",
       "         0.1766, 0.3395, 0.0000, 0.4804, 0.2135, 0.0000, 0.0490, 0.1707, 0.0000,\n",
       "         0.0000]),\n",
       " 1338: tensor([0.0000, 0.4328, 0.2535, 0.0000, 0.0000, 0.0505, 0.1875, 0.2478, 0.0000,\n",
       "         0.0000, 0.1003, 0.3558, 0.1854, 0.1711, 0.0000, 0.3328, 0.1294, 0.0000,\n",
       "         0.2181, 0.0000, 0.2633, 0.4742, 0.0753, 0.3942, 0.0000, 0.1545, 0.3453,\n",
       "         0.3587]),\n",
       " 1633: tensor([0.0874, 0.0746, 0.0000, 0.0930, 0.1384, 0.2536, 0.1479, 0.1215, 0.1554,\n",
       "         0.0781, 0.0905, 0.1941, 0.3726, 0.1229, 0.2315, 0.0836, 0.2616, 0.0453,\n",
       "         0.0000, 0.2111, 0.2447, 0.1160, 0.0000, 0.0438, 0.1919, 0.3657, 0.1880,\n",
       "         0.0158]),\n",
       " 290: tensor([0.2090, 0.0000, 0.0138, 0.2350, 0.0000, 0.0000, 0.0000, 0.0000, 0.1309,\n",
       "         0.0686, 0.0356, 0.0828, 0.0957, 0.1375, 0.1450, 0.0139, 0.0000, 0.0812,\n",
       "         0.1572, 0.0639, 0.0937, 0.0000, 0.1460, 0.1017, 0.1859, 0.1158, 0.2410,\n",
       "         0.0475]),\n",
       " 2777: tensor([0.1595, 0.0000, 0.0919, 0.0357, 0.1465, 0.1901, 0.1108, 0.0000, 0.1752,\n",
       "         0.0224, 0.2979, 0.1573, 0.1350, 0.1916, 0.0000, 0.1135, 0.0000, 0.1878,\n",
       "         0.1598, 0.2408, 0.0463, 0.2600, 0.1181, 0.0722, 0.0480, 0.1473, 0.1858,\n",
       "         0.0000]),\n",
       " 2758: tensor([0.2060, 0.1182, 0.0000, 0.1841, 0.2046, 0.0912, 0.1198, 0.1875, 0.2432,\n",
       "         0.1600, 0.0394, 0.1182, 0.2525, 0.0714, 0.1166, 0.0000, 0.1595, 0.1212,\n",
       "         0.2476, 0.1403, 0.1292, 0.0507, 0.2068, 0.0000, 0.2214, 0.2637, 0.1103,\n",
       "         0.1604]),\n",
       " 4208: tensor([0.0000, 0.0975, 0.2432, 0.0030, 0.0000, 0.0966, 0.0633, 0.0000, 0.2113,\n",
       "         0.4457, 0.5942, 0.0736, 0.0000, 0.0824, 0.1996, 0.2781, 0.0000, 0.1522,\n",
       "         0.0833, 0.0000, 0.1881, 0.3549, 0.0048, 0.0568, 0.0288, 0.2329, 0.0000,\n",
       "         0.0000]),\n",
       " 3323: tensor([0.3135, 0.3504, 0.0000, 0.1147, 0.0000, 0.2128, 0.0328, 0.2484, 0.1060,\n",
       "         0.0000, 0.0000, 0.1052, 0.1322, 0.2699, 0.2303, 0.2718, 0.1292, 0.4386,\n",
       "         0.0757, 0.0000, 0.3097, 0.0000, 0.0000, 0.0000, 0.2548, 0.1672, 0.0000,\n",
       "         0.1360]),\n",
       " 1880: tensor([0.1633, 0.1129, 0.0000, 0.1992, 0.1341, 0.1334, 0.1966, 0.2208, 0.0733,\n",
       "         0.0629, 0.0424, 0.1340, 0.0900, 0.1364, 0.0433, 0.1365, 0.1359, 0.1317,\n",
       "         0.1098, 0.1398, 0.1224, 0.1198, 0.1358, 0.1339, 0.1173, 0.1404, 0.0000,\n",
       "         0.1520]),\n",
       " 1099: tensor([0.1447, 0.1396, 0.1394, 0.1278, 0.1604, 0.1575, 0.1712, 0.1380, 0.1226,\n",
       "         0.1320, 0.0862, 0.0888, 0.1629, 0.1739, 0.1177, 0.0872, 0.1385, 0.1044,\n",
       "         0.1800, 0.1497, 0.1411, 0.1300, 0.1034, 0.2055, 0.0000, 0.1413, 0.1453,\n",
       "         0.1461]),\n",
       " 994: tensor([0.1308, 0.0431, 0.1764, 0.1419, 0.2232, 0.1580, 0.1106, 0.1155, 0.0000,\n",
       "         0.1759, 0.0717, 0.2973, 0.2231, 0.0000, 0.0000, 0.1860, 0.1639, 0.1035,\n",
       "         0.2349, 0.2220, 0.0636, 0.0031, 0.2032, 0.1030, 0.1021, 0.1260, 0.1070,\n",
       "         0.1004]),\n",
       " 3239: tensor([0.1916, 0.1151, 0.0588, 0.2136, 0.1744, 0.1298, 0.1503, 0.1558, 0.0668,\n",
       "         0.0579, 0.0735, 0.1620, 0.0617, 0.1022, 0.1122, 0.0920, 0.0919, 0.1266,\n",
       "         0.1249, 0.1645, 0.1551, 0.0659, 0.1323, 0.0906, 0.0780, 0.1393, 0.0000,\n",
       "         0.1395]),\n",
       " 3223: tensor([0.2392, 0.1593, 0.0608, 0.1073, 0.0000, 0.0963, 0.2454, 0.3041, 0.1353,\n",
       "         0.0965, 0.1104, 0.1602, 0.0693, 0.3457, 0.1062, 0.1996, 0.0589, 0.0713,\n",
       "         0.1299, 0.1003, 0.0356, 0.0672, 0.0000, 0.1503, 0.1516, 0.1509, 0.0469,\n",
       "         0.1613]),\n",
       " 82: tensor([0.1910, 0.1187, 0.0895, 0.2249, 0.3915, 0.3643, 0.0000, 0.1469, 0.1429,\n",
       "         0.2334, 0.0602, 0.4253, 0.1389, 0.0000, 0.0000, 0.2010, 0.1452, 0.0362,\n",
       "         0.0778, 0.3426, 0.0000, 0.0062, 0.2464, 0.1369, 0.0000, 0.1933, 0.0899,\n",
       "         0.0896]),\n",
       " 15: tensor([0.0000, 0.2958, 0.2329, 0.0969, 0.0684, 0.0624, 0.1068, 0.0000, 0.0000,\n",
       "         0.0609, 0.2263, 0.2242, 0.0000, 0.0592, 0.3629, 0.2104, 0.0972, 0.0000,\n",
       "         0.2391, 0.1029, 0.2732, 0.0808, 0.0000, 0.1315, 0.0000, 0.0558, 0.1801,\n",
       "         0.1065]),\n",
       " 999: tensor([0.0000, 0.3834, 0.0000, 0.0555, 0.0000, 0.1637, 0.0000, 0.0177, 0.1370,\n",
       "         0.3322, 0.2221, 0.1029, 0.0428, 0.1493, 0.2310, 0.2990, 0.2110, 0.2887,\n",
       "         0.2288, 0.1725, 0.2911, 0.0056, 0.2904, 0.2363, 0.0763, 0.0000, 0.1490,\n",
       "         0.1870]),\n",
       " 2474: tensor([0.1613, 0.0792, 0.1557, 0.1685, 0.1622, 0.1076, 0.1086, 0.0000, 0.2335,\n",
       "         0.0552, 0.1783, 0.1112, 0.0000, 0.2668, 0.0686, 0.2479, 0.0000, 0.1709,\n",
       "         0.1691, 0.2442, 0.0483, 0.0971, 0.1435, 0.0187, 0.1007, 0.2244, 0.1980,\n",
       "         0.0000]),\n",
       " 1421: tensor([0.0000, 0.0000, 0.0515, 0.1264, 0.1435, 0.1624, 0.1282, 0.2132, 0.2462,\n",
       "         0.1126, 0.1547, 0.1461, 0.1622, 0.0890, 0.0392, 0.3738, 0.0000, 0.0610,\n",
       "         0.0779, 0.0854, 0.0000, 0.3464, 0.0557, 0.0000, 0.1864, 0.0326, 0.0000,\n",
       "         0.0856]),\n",
       " 2569: tensor([0.2485, 0.0176, 0.0000, 0.5631, 0.0000, 0.0519, 0.0201, 0.1809, 0.0715,\n",
       "         0.1475, 0.0283, 0.0276, 0.1888, 0.0000, 0.0000, 0.0000, 0.0046, 0.2967,\n",
       "         0.0905, 0.0587, 0.2830, 0.3288, 0.0000, 0.0491, 0.2628, 0.6350, 0.2370,\n",
       "         0.2485]),\n",
       " 3962: tensor([0.0000, 0.2285, 0.2504, 0.0548, 0.0026, 0.1999, 0.1999, 0.1577, 0.2837,\n",
       "         0.0000, 0.2800, 0.0000, 0.4129, 0.1139, 0.0000, 0.1252, 0.0000, 0.1875,\n",
       "         0.0947, 0.1287, 0.0000, 0.0153, 0.0399, 0.1595, 0.1240, 0.0000, 0.1122,\n",
       "         0.0775]),\n",
       " 3511: tensor([0.0627, 0.1162, 0.2254, 0.0516, 0.1651, 0.1494, 0.1701, 0.2007, 0.1207,\n",
       "         0.1479, 0.1132, 0.2168, 0.1885, 0.2086, 0.1582, 0.1548, 0.1375, 0.0694,\n",
       "         0.1026, 0.1581, 0.2006, 0.1666, 0.1465, 0.2478, 0.0000, 0.2830, 0.1633,\n",
       "         0.1570]),\n",
       " 898: tensor([0.1438, 0.1748, 0.2572, 0.1822, 0.0000, 0.1671, 0.2065, 0.1452, 0.1764,\n",
       "         0.1578, 0.1688, 0.1526, 0.1331, 0.0000, 0.1620, 0.1881, 0.0865, 0.2066,\n",
       "         0.0000, 0.1379, 0.1711, 0.0000, 0.0461, 0.1546, 0.1861, 0.1621, 0.1388,\n",
       "         0.1080]),\n",
       " 1850: tensor([0.1862, 0.1060, 0.1235, 0.1427, 0.0000, 0.0670, 0.1591, 0.2074, 0.2058,\n",
       "         0.0837, 0.1305, 0.0793, 0.0572, 0.1097, 0.1611, 0.0268, 0.2140, 0.1525,\n",
       "         0.1034, 0.1040, 0.1724, 0.1349, 0.0000, 0.1064, 0.1965, 0.1495, 0.0868,\n",
       "         0.0645]),\n",
       " 3844: tensor([0.0684, 0.0000, 0.0927, 0.0825, 0.0000, 0.1498, 0.1165, 0.1301, 0.2194,\n",
       "         0.0197, 0.2266, 0.0505, 0.0330, 0.0114, 0.0602, 0.0000, 0.1554, 0.1445,\n",
       "         0.0000, 0.1729, 0.2902, 0.0459, 0.0000, 0.1011, 0.1679, 0.0212, 0.1589,\n",
       "         0.1910]),\n",
       " 1142: tensor([0.0771, 0.1717, 0.2220, 0.1694, 0.0000, 0.1752, 0.2140, 0.1772, 0.2409,\n",
       "         0.0396, 0.1399, 0.1462, 0.0000, 0.0000, 0.0955, 0.3036, 0.0257, 0.2568,\n",
       "         0.0000, 0.1113, 0.3013, 0.3487, 0.2165, 0.1690, 0.1901, 0.0338, 0.0800,\n",
       "         0.0742]),\n",
       " 2435: tensor([0.1585, 0.1147, 0.0338, 0.1042, 0.0000, 0.3313, 0.0850, 0.1400, 0.0000,\n",
       "         0.2775, 0.1604, 0.1393, 0.2118, 0.1650, 0.1043, 0.0000, 0.2682, 0.2680,\n",
       "         0.0000, 0.0000, 0.1753, 0.2011, 0.0000, 0.1816, 0.2596, 0.2458, 0.2636,\n",
       "         0.0000]),\n",
       " 3167: tensor([0.2187, 0.1654, 0.2229, 0.0120, 0.1891, 0.3283, 0.1441, 0.3049, 0.1862,\n",
       "         0.1501, 0.0660, 0.2029, 0.1232, 0.2542, 0.1543, 0.1472, 0.0734, 0.0616,\n",
       "         0.3355, 0.0509, 0.2026, 0.1204, 0.1004, 0.1859, 0.0000, 0.2445, 0.1278,\n",
       "         0.1264]),\n",
       " 1861: tensor([0.0937, 0.1603, 0.1553, 0.2789, 0.2873, 0.2855, 0.0000, 0.0512, 0.1988,\n",
       "         0.0000, 0.2093, 0.1878, 0.0912, 0.2566, 0.1722, 0.0000, 0.1799, 0.0000,\n",
       "         0.2692, 0.0300, 0.0760, 0.0000, 0.2504, 0.0454, 0.0000, 0.0659, 0.0000,\n",
       "         0.2697]),\n",
       " 2808: tensor([0.0522, 0.1393, 0.1694, 0.1802, 0.0052, 0.0969, 0.1802, 0.1231, 0.1660,\n",
       "         0.1457, 0.1455, 0.1663, 0.0839, 0.0000, 0.1302, 0.1790, 0.0903, 0.1642,\n",
       "         0.0000, 0.1082, 0.1789, 0.2201, 0.1104, 0.2041, 0.1610, 0.1084, 0.1319,\n",
       "         0.1462]),\n",
       " 557: tensor([0.2467, 0.0094, 0.2280, 0.2661, 0.0000, 0.0231, 0.0000, 0.1371, 0.0000,\n",
       "         0.2067, 0.0144, 0.2497, 0.5050, 0.0000, 0.0000, 0.0528, 0.0000, 0.3935,\n",
       "         0.0000, 0.0841, 0.2450, 0.0000, 0.2202, 0.0582, 0.1112, 0.0000, 0.1016,\n",
       "         0.1973]),\n",
       " 3760: tensor([0.2099, 0.1003, 0.0000, 0.4071, 0.1987, 0.1350, 0.1507, 0.1895, 0.0911,\n",
       "         0.1828, 0.1236, 0.0931, 0.1956, 0.1056, 0.0509, 0.1094, 0.0593, 0.1125,\n",
       "         0.3459, 0.1303, 0.1663, 0.1849, 0.1197, 0.0247, 0.0763, 0.4867, 0.0662,\n",
       "         0.2208]),\n",
       " 3088: tensor([0.0468, 0.2772, 0.3200, 0.1292, 0.0000, 0.0000, 0.1488, 0.1605, 0.1693,\n",
       "         0.2281, 0.1019, 0.0000, 0.0000, 0.0000, 0.1479, 0.2790, 0.0000, 0.0796,\n",
       "         0.0000, 0.1323, 0.4184, 0.0000, 0.0000, 0.0000, 0.0735, 0.1713, 0.0747,\n",
       "         0.2304]),\n",
       " 2735: tensor([0.2645, 0.1388, 0.0000, 0.0000, 0.0000, 0.0000, 0.4512, 0.0193, 0.1347,\n",
       "         0.1099, 0.0000, 0.0000, 0.1049, 0.3809, 0.0000, 0.0043, 0.0437, 0.1343,\n",
       "         0.1323, 0.0000, 0.0542, 0.0196, 0.0000, 0.1100, 0.1837, 0.0000, 0.2447,\n",
       "         0.2116]),\n",
       " 469: tensor([0.0903, 0.2463, 0.1621, 0.0000, 0.2447, 0.2590, 0.0000, 0.3533, 0.0000,\n",
       "         0.1974, 0.2244, 0.0091, 0.2579, 0.0000, 0.0000, 0.0678, 0.1046, 0.1158,\n",
       "         0.0000, 0.2139, 0.2181, 0.1096, 0.0000, 0.0000, 0.1544, 0.2714, 0.1776,\n",
       "         0.0000]),\n",
       " 1318: tensor([0.0000, 0.0677, 0.2430, 0.0000, 0.2009, 0.0000, 0.0446, 0.1438, 0.1620,\n",
       "         0.1278, 0.3557, 0.3593, 0.2077, 0.6356, 0.0000, 0.0000, 0.0000, 0.1041,\n",
       "         0.0760, 0.2096, 0.0000, 0.1068, 0.0000, 0.0000, 0.0737, 0.2118, 0.2947,\n",
       "         0.0203]),\n",
       " 1105: tensor([0.1774, 0.4570, 0.0000, 0.3125, 0.0000, 0.1911, 0.2113, 0.0000, 0.1493,\n",
       "         0.1597, 0.4750, 0.0923, 0.0413, 0.1856, 0.0683, 0.1149, 0.2531, 0.2267,\n",
       "         0.1635, 0.1748, 0.2342, 0.1922, 0.1203, 0.2112, 0.0499, 0.0000, 0.0000,\n",
       "         0.2973]),\n",
       " 3040: tensor([0.0000, 0.1132, 0.0778, 0.0677, 0.1856, 0.2733, 0.1394, 0.0000, 0.0000,\n",
       "         0.1251, 0.1955, 0.0000, 0.2796, 0.0644, 0.0000, 0.1326, 0.0000, 0.0058,\n",
       "         0.2499, 0.1668, 0.0000, 0.1968, 0.0000, 0.1753, 0.2971, 0.2222, 0.2693,\n",
       "         0.0909]),\n",
       " 3306: tensor([0.1177, 0.0000, 0.0000, 0.3677, 0.1108, 0.3504, 0.0268, 0.3469, 0.2982,\n",
       "         0.0000, 0.3639, 0.0000, 0.2825, 0.1914, 0.0934, 0.2420, 0.0757, 0.1045,\n",
       "         0.1774, 0.0000, 0.1332, 0.1509, 0.2287, 0.2663, 0.2298, 0.1988, 0.0000,\n",
       "         0.0922]),\n",
       " 277: tensor([0.1497, 0.1555, 0.0835, 0.1136, 0.0000, 0.1934, 0.1414, 0.1300, 0.2449,\n",
       "         0.1313, 0.2000, 0.0000, 0.0000, 0.1807, 0.1667, 0.1547, 0.2267, 0.2116,\n",
       "         0.0000, 0.1250, 0.1731, 0.1307, 0.0000, 0.0000, 0.1673, 0.2554, 0.2208,\n",
       "         0.2277]),\n",
       " 3325: tensor([0.0112, 0.1736, 0.0620, 0.0471, 0.1300, 0.1658, 0.2524, 0.0725, 0.2312,\n",
       "         0.0477, 0.1644, 0.2582, 0.1523, 0.0000, 0.2129, 0.2399, 0.1847, 0.2732,\n",
       "         0.0000, 0.0685, 0.3275, 0.2610, 0.1420, 0.1706, 0.0000, 0.3360, 0.0720,\n",
       "         0.1653]),\n",
       " 2588: tensor([0.1126, 0.0000, 0.0543, 0.0000, 0.1718, 0.1540, 0.0999, 0.0000, 0.1747,\n",
       "         0.1842, 0.3503, 0.1237, 0.0000, 0.1956, 0.0298, 0.0000, 0.0000, 0.1814,\n",
       "         0.1038, 0.2011, 0.2503, 0.2646, 0.1183, 0.0177, 0.1089, 0.2225, 0.0000,\n",
       "         0.0000]),\n",
       " 2356: tensor([0.1272, 0.2161, 0.0000, 0.2542, 0.0000, 0.3172, 0.1445, 0.1192, 0.3606,\n",
       "         0.2162, 0.0840, 0.0000, 0.0000, 0.2319, 0.1402, 0.1422, 0.5076, 0.2667,\n",
       "         0.0000, 0.2126, 0.2066, 0.0000, 0.0000, 0.0000, 0.4226, 0.3901, 0.2158,\n",
       "         0.3193]),\n",
       " 1446: tensor([0.1135, 0.1857, 0.0929, 0.1483, 0.0623, 0.1506, 0.1761, 0.1961, 0.1343,\n",
       "         0.1807, 0.1113, 0.0510, 0.1038, 0.0000, 0.0000, 0.0662, 0.1555, 0.0897,\n",
       "         0.0315, 0.0481, 0.1023, 0.1113, 0.1273, 0.0000, 0.2172, 0.1130, 0.0892,\n",
       "         0.1425]),\n",
       " 1274: tensor([0.0537, 0.0000, 0.1367, 0.0000, 0.1350, 0.0000, 0.0000, 0.3839, 0.2377,\n",
       "         0.0000, 0.0021, 0.0000, 0.3128, 0.0961, 0.0693, 0.3947, 0.0788, 0.2770,\n",
       "         0.0867, 0.0000, 0.0870, 0.4062, 0.0000, 0.0000, 0.0000, 0.3364, 0.0466,\n",
       "         0.1844]),\n",
       " 1104: tensor([0.2431, 0.2548, 0.0000, 0.1055, 0.1618, 0.1988, 0.1601, 0.1327, 0.2578,\n",
       "         0.1766, 0.1071, 0.2728, 0.1634, 0.1117, 0.2581, 0.0127, 0.3104, 0.1801,\n",
       "         0.0876, 0.2204, 0.2269, 0.0274, 0.3392, 0.0000, 0.3004, 0.2088, 0.1645,\n",
       "         0.2051]),\n",
       " 1790: tensor([0.1789, 0.1937, 0.1223, 0.1256, 0.0506, 0.2968, 0.0587, 0.0356, 0.1604,\n",
       "         0.1766, 0.1074, 0.1297, 0.1426, 0.1002, 0.0798, 0.0895, 0.1414, 0.1080,\n",
       "         0.1398, 0.1492, 0.0799, 0.0290, 0.1388, 0.1322, 0.1472, 0.0000, 0.0202,\n",
       "         0.2041]),\n",
       " 1948: tensor([0.4178, 0.4038, 0.1363, 0.0000, 0.0000, 0.2971, 0.0000, 0.4534, 0.1298,\n",
       "         0.0000, 0.0000, 0.2565, 0.0000, 0.0179, 0.3362, 0.4164, 0.1183, 0.0000,\n",
       "         0.0000, 0.3510, 0.0000, 0.0988, 0.5031, 0.4913, 0.0000, 0.3376, 0.1435,\n",
       "         0.0000]),\n",
       " 2545: tensor([0.0521, 0.0517, 0.2119, 0.2383, 0.0000, 0.0960, 0.0000, 0.2288, 0.2072,\n",
       "         0.0199, 0.1809, 0.0317, 0.1125, 0.2326, 0.1483, 0.0000, 0.2352, 0.2473,\n",
       "         0.0256, 0.0774, 0.2757, 0.0775, 0.0000, 0.1276, 0.1204, 0.1091, 0.1023,\n",
       "         0.0957]),\n",
       " 4293: tensor([0.0000, 0.0301, 0.0449, 0.2353, 0.1755, 0.2503, 0.0388, 0.1120, 0.0985,\n",
       "         0.0856, 0.1525, 0.0000, 0.0847, 0.1322, 0.1369, 0.1807, 0.0000, 0.2009,\n",
       "         0.1820, 0.2326, 0.0000, 0.0919, 0.0000, 0.1013, 0.0896, 0.0265, 0.3377,\n",
       "         0.2797]),\n",
       " 1365: tensor([0.2173, 0.0351, 0.0000, 0.0000, 0.0000, 0.1719, 0.1549, 0.2056, 0.1649,\n",
       "         0.1060, 0.0403, 0.1367, 0.1902, 0.0974, 0.1610, 0.0424, 0.1509, 0.1366,\n",
       "         0.1389, 0.1341, 0.1335, 0.2288, 0.0000, 0.2600, 0.1133, 0.1695, 0.1468,\n",
       "         0.1871]),\n",
       " 1376: tensor([0.1551, 0.0000, 0.0955, 0.2098, 0.0000, 0.0832, 0.2219, 0.0712, 0.1812,\n",
       "         0.0304, 0.1391, 0.0000, 0.0757, 0.1375, 0.0000, 0.1031, 0.2315, 0.0000,\n",
       "         0.2425, 0.1572, 0.0463, 0.0000, 0.2138, 0.1358, 0.0000, 0.0000, 0.2084,\n",
       "         0.1011]),\n",
       " 2772: tensor([0.0000, 0.0000, 0.1691, 0.1726, 0.1000, 0.1915, 0.0823, 0.1311, 0.1698,\n",
       "         0.2328, 0.1220, 0.1303, 0.0976, 0.0589, 0.0838, 0.2887, 0.0000, 0.2777,\n",
       "         0.1268, 0.0851, 0.0000, 0.0824, 0.1759, 0.0000, 0.1122, 0.1481, 0.1462,\n",
       "         0.0442]),\n",
       " 1216: tensor([0.1437, 0.0000, 0.0000, 0.0000, 0.4081, 0.2126, 0.1045, 0.0000, 0.1859,\n",
       "         0.3464, 0.1444, 0.2207, 0.1980, 0.0910, 0.3173, 0.1071, 0.2724, 0.2092,\n",
       "         0.0589, 0.0000, 0.0720, 0.0000, 0.0000, 0.0538, 0.2140, 0.1636, 0.0146,\n",
       "         0.0506]),\n",
       " 2793: tensor([0.3601, 0.1039, 0.1548, 0.1417, 0.1399, 0.0000, 0.1266, 0.1521, 0.3365,\n",
       "         0.0712, 0.0000, 0.1430, 0.1222, 0.1222, 0.0989, 0.2163, 0.1728, 0.2228,\n",
       "         0.1192, 0.1014, 0.2400, 0.2863, 0.1780, 0.0414, 0.2504, 0.0000, 0.1179,\n",
       "         0.0573]),\n",
       " 1044: tensor([0.1036, 0.1919, 0.2453, 0.2361, 0.2004, 0.0573, 0.0000, 0.2073, 0.0000,\n",
       "         0.3130, 0.0771, 0.1082, 0.5412, 0.0000, 0.0000, 0.1103, 0.0720, 0.2806,\n",
       "         0.0000, 0.2416, 0.2805, 0.0000, 0.1694, 0.0000, 0.0338, 0.1101, 0.2182,\n",
       "         0.2493]),\n",
       " 1152: tensor([0.3345, 0.2810, 0.0000, 0.2992, 0.0000, 0.0122, 0.3918, 0.2464, 0.2893,\n",
       "         0.1580, 0.1823, 0.0000, 0.0000, 0.0074, 0.1390, 0.2086, 0.0486, 0.0677,\n",
       "         0.0000, 0.0000, 0.0794, 0.2625, 0.0000, 0.0000, 0.1949, 0.4955, 0.2104,\n",
       "         0.2576]),\n",
       " 4057: tensor([0.0000, 0.0000, 0.0000, 0.1905, 0.1851, 0.2340, 0.0166, 0.2469, 0.1139,\n",
       "         0.2299, 0.1391, 0.1675, 0.1102, 0.1125, 0.1868, 0.3127, 0.0000, 0.1721,\n",
       "         0.0572, 0.0064, 0.0000, 0.1369, 0.1924, 0.0000, 0.1367, 0.2679, 0.1824,\n",
       "         0.0000]),\n",
       " 3415: tensor([0.0000, 0.0000, 0.1968, 0.1037, 0.1541, 0.0965, 0.1567, 0.1685, 0.1806,\n",
       "         0.0746, 0.1094, 0.1113, 0.1661, 0.1201, 0.0997, 0.2460, 0.0000, 0.1441,\n",
       "         0.0819, 0.0801, 0.0000, 0.1739, 0.2034, 0.0000, 0.1118, 0.1157, 0.1640,\n",
       "         0.1610]),\n",
       " 3179: tensor([0.2176, 0.0000, 0.0140, 0.1335, 0.0000, 0.0000, 0.0000, 0.0000, 0.2210,\n",
       "         0.1714, 0.0487, 0.2684, 0.2209, 0.1177, 0.2347, 0.0833, 0.0665, 0.0000,\n",
       "         0.0000, 0.0000, 0.1117, 0.0000, 0.1116, 0.1149, 0.0643, 0.0539, 0.1759,\n",
       "         0.0618]),\n",
       " 4377: tensor([0.1059, 0.0000, 0.1588, 0.0493, 0.1489, 0.2014, 0.1166, 0.0000, 0.1986,\n",
       "         0.0936, 0.3207, 0.1691, 0.1099, 0.1805, 0.0649, 0.1117, 0.0000, 0.1666,\n",
       "         0.1819, 0.2194, 0.1147, 0.2604, 0.1530, 0.1301, 0.0639, 0.1699, 0.1415,\n",
       "         0.0000]),\n",
       " 1204: tensor([0.1656, 0.1518, 0.2479, 0.0941, 0.1322, 0.0742, 0.1585, 0.0517, 0.1103,\n",
       "         0.1630, 0.1350, 0.1521, 0.0000, 0.0000, 0.0910, 0.1946, 0.0642, 0.1100,\n",
       "         0.0000, 0.1072, 0.2513, 0.3029, 0.2119, 0.1136, 0.1119, 0.1418, 0.1835,\n",
       "         0.1138]),\n",
       " 3120: tensor([0.0000, 0.0000, 0.0431, 0.0095, 0.1162, 0.0000, 0.0413, 0.1805, 0.1376,\n",
       "         0.0000, 0.0582, 0.0000, 0.1572, 0.0418, 0.0858, 0.1800, 0.2240, 0.3129,\n",
       "         0.1087, 0.1840, 0.1422, 0.2637, 0.0000, 0.0333, 0.3495, 0.1935, 0.2393,\n",
       "         0.4398]),\n",
       " 3790: tensor([0.0057, 0.1680, 0.0000, 0.0026, 0.0118, 0.2820, 0.0000, 0.0022, 0.0000,\n",
       "         0.0000, 0.0094, 0.1358, 0.3271, 0.0578, 0.0000, 0.0738, 0.1260, 0.0000,\n",
       "         0.1752, 0.0000, 0.0953, 0.0000, 0.0000, 0.3161, 0.0671, 0.0000, 0.0000,\n",
       "         0.2804]),\n",
       " 1035: tensor([0.0900, 0.2789, 0.1507, 0.1366, 0.1046, 0.2093, 0.1703, 0.2526, 0.2560,\n",
       "         0.2386, 0.1961, 0.0944, 0.1257, 0.0000, 0.0000, 0.1552, 0.1599, 0.0062,\n",
       "         0.1411, 0.0000, 0.1561, 0.0444, 0.1497, 0.1451, 0.1586, 0.2980, 0.1555,\n",
       "         0.2013]),\n",
       " 1291: tensor([0.0000, 0.1324, 0.0506, 0.0000, 0.3067, 0.1313, 0.2842, 0.0355, 0.1471,\n",
       "         0.3057, 0.2373, 0.1817, 0.3643, 0.2085, 0.0317, 0.2112, 0.0142, 0.1716,\n",
       "         0.0000, 0.1825, 0.0948, 0.2227, 0.1800, 0.0375, 0.0000, 0.1949, 0.2015,\n",
       "         0.0889]),\n",
       " 4397: tensor([0.2195, 0.0289, 0.0000, 0.4484, 0.0582, 0.1621, 0.0656, 0.1184, 0.0000,\n",
       "         0.1829, 0.1207, 0.0860, 0.2510, 0.0000, 0.0971, 0.0000, 0.1731, 0.1553,\n",
       "         0.0735, 0.2961, 0.2490, 0.2081, 0.3269, 0.0000, 0.2939, 0.6846, 0.2158,\n",
       "         0.0444]),\n",
       " 1699: tensor([0.2776, 0.0000, 0.0625, 0.1864, 0.0000, 0.0000, 0.0424, 0.0898, 0.0800,\n",
       "         0.0260, 0.1002, 0.1361, 0.0687, 0.2509, 0.2322, 0.1601, 0.0453, 0.2151,\n",
       "         0.2275, 0.1852, 0.0247, 0.0000, 0.1714, 0.0610, 0.2517, 0.1508, 0.1774,\n",
       "         0.1747]),\n",
       " 2711: tensor([0.1800, 0.1016, 0.5345, 0.0000, 0.0905, 0.0943, 0.2500, 0.1109, 0.0890,\n",
       "         0.0818, 0.0000, 0.0378, 0.1474, 0.4950, 0.1395, 0.1112, 0.0830, 0.0000,\n",
       "         0.0818, 0.0000, 0.0473, 0.1569, 0.0000, 0.1744, 0.0000, 0.1641, 0.0620,\n",
       "         0.2168]),\n",
       " 4399: tensor([0.1589, 0.2371, 0.0000, 0.1687, 0.0000, 0.0863, 0.0786, 0.1713, 0.1095,\n",
       "         0.2875, 0.1848, 0.0773, 0.2087, 0.1049, 0.1453, 0.0971, 0.1191, 0.1702,\n",
       "         0.0975, 0.2313, 0.1928, 0.1046, 0.1899, 0.0746, 0.1341, 0.0000, 0.0866,\n",
       "         0.1745]),\n",
       " 990: tensor([0.2256, 0.0549, 0.2137, 0.2279, 0.0000, 0.0000, 0.0603, 0.1466, 0.0331,\n",
       "         0.1619, 0.2418, 0.0000, 0.0000, 0.0188, 0.1404, 0.0022, 0.0000, 0.0968,\n",
       "         0.0000, 0.3506, 0.4352, 0.1219, 0.0000, 0.0177, 0.1311, 0.0000, 0.1502,\n",
       "         0.1954]),\n",
       " 1494: tensor([0.0821, 0.1924, 0.0000, 0.2477, 0.0000, 0.1107, 0.3721, 0.0559, 0.1264,\n",
       "         0.0000, 0.2517, 0.1841, 0.4380, 0.0000, 0.0432, 0.0000, 0.3832, 0.0000,\n",
       "         0.0000, 0.0964, 0.0529, 0.0000, 0.0000, 0.4731, 0.1884, 0.2416, 0.3652,\n",
       "         0.4495]),\n",
       " 3169: tensor([0.1524, 0.1216, 0.0304, 0.0671, 0.0000, 0.1618, 0.1156, 0.1798, 0.1519,\n",
       "         0.1652, 0.1300, 0.1132, 0.1653, 0.0265, 0.2128, 0.0196, 0.1922, 0.1211,\n",
       "         0.1231, 0.1388, 0.1825, 0.1737, 0.0000, 0.1409, 0.0805, 0.2117, 0.1345,\n",
       "         0.0977]),\n",
       " 4407: tensor([0.1658, 0.2334, 0.2867, 0.0000, 0.0000, 0.0860, 0.1315, 0.2299, 0.0000,\n",
       "         0.0000, 0.2101, 0.0000, 0.3644, 0.1943, 0.0000, 0.1655, 0.2341, 0.0000,\n",
       "         0.2221, 0.1086, 0.1296, 0.1880, 0.1582, 0.3419, 0.0404, 0.0908, 0.2045,\n",
       "         0.1818]),\n",
       " 1189: tensor([0.4017, 0.3238, 0.1924, 0.0679, 0.0000, 0.0878, 0.3469, 0.4420, 0.1084,\n",
       "         0.2343, 0.0095, 0.2099, 0.1267, 0.5959, 0.1846, 0.4435, 0.1719, 0.0217,\n",
       "         0.1728, 0.0240, 0.0705, 0.1255, 0.0000, 0.0000, 0.2196, 0.3357, 0.0000,\n",
       "         0.0935]),\n",
       " 3635: tensor([0.0000, 0.2281, 0.3367, 0.2423, 0.1311, 0.3180, 0.1133, 0.0737, 0.1902,\n",
       "         0.0000, 0.1080, 0.0000, 0.0006, 0.1807, 0.2681, 0.1848, 0.1586, 0.0027,\n",
       "         0.0176, 0.0747, 0.1497, 0.1017, 0.1402, 0.2240, 0.0000, 0.2186, 0.1657,\n",
       "         0.0532]),\n",
       " 3165: tensor([0.1582, 0.1813, 0.0988, 0.2033, 0.0000, 0.2409, 0.2487, 0.1216, 0.2425,\n",
       "         0.1881, 0.2487, 0.0000, 0.0000, 0.2193, 0.1836, 0.1733, 0.2189, 0.2045,\n",
       "         0.0000, 0.1096, 0.2019, 0.2026, 0.0000, 0.0000, 0.2249, 0.3590, 0.2970,\n",
       "         0.2634]),\n",
       " 2325: tensor([0.1963, 0.0581, 0.0423, 0.0000, 0.0000, 0.1477, 0.1194, 0.2324, 0.0000,\n",
       "         0.0000, 0.1417, 0.2916, 0.2679, 0.0845, 0.0000, 0.0000, 0.0838, 0.0000,\n",
       "         0.1913, 0.1503, 0.0999, 0.2162, 0.2670, 0.1043, 0.0000, 0.1289, 0.1308,\n",
       "         0.0800]),\n",
       " 3160: tensor([0.2624, 0.0000, 0.0000, 0.2073, 0.1065, 0.1371, 0.2648, 0.2948, 0.2993,\n",
       "         0.0000, 0.1384, 0.0000, 0.2614, 0.2410, 0.0819, 0.3333, 0.1407, 0.2974,\n",
       "         0.0580, 0.2022, 0.0368, 0.1032, 0.1963, 0.2775, 0.1184, 0.0971, 0.0000,\n",
       "         0.2153]),\n",
       " 4487: tensor([0.0501, 0.1820, 0.1010, 0.0861, 0.1207, 0.0387, 0.2662, 0.1413, 0.0816,\n",
       "         0.1369, 0.1802, 0.0625, 0.0000, 0.0000, 0.0000, 0.0000, 0.1503, 0.1671,\n",
       "         0.2263, 0.0000, 0.0000, 0.0572, 0.1699, 0.1916, 0.1091, 0.1763, 0.0684,\n",
       "         0.0493]),\n",
       " 1916: tensor([0.0000, 0.0224, 0.4198, 0.0000, 0.1097, 0.2609, 0.2583, 0.0000, 0.3082,\n",
       "         0.3500, 0.3367, 0.2663, 0.0882, 0.1112, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.5023, 0.0058, 0.0760, 0.0000, 0.5607, 0.2993, 0.0000, 0.4390, 0.0000,\n",
       "         0.1828]),\n",
       " 3300: tensor([0.2450, 0.1484, 0.1720, 0.1221, 0.1293, 0.2038, 0.1999, 0.1937, 0.0274,\n",
       "         0.1580, 0.0145, 0.0520, 0.1700, 0.2420, 0.2064, 0.1694, 0.0666, 0.1510,\n",
       "         0.0120, 0.0241, 0.0882, 0.2715, 0.0592, 0.1928, 0.0000, 0.2073, 0.1674,\n",
       "         0.0858]),\n",
       " 2201: tensor([0.1223, 0.1472, 0.0000, 0.2249, 0.1849, 0.1282, 0.0957, 0.2291, 0.0599,\n",
       "         0.0000, 0.1365, 0.0395, 0.1383, 0.1309, 0.0635, 0.0175, 0.1528, 0.1128,\n",
       "         0.0000, 0.0748, 0.1554, 0.1111, 0.1248, 0.0914, 0.0665, 0.1259, 0.2084,\n",
       "         0.0670]),\n",
       " 647: tensor([0.0672, 0.1615, 0.0394, 0.0284, 0.1811, 0.2078, 0.2548, 0.1041, 0.2235,\n",
       "         0.0824, 0.1341, 0.0499, 0.0104, 0.0000, 0.0000, 0.1045, 0.1351, 0.0967,\n",
       "         0.1531, 0.1067, 0.0715, 0.1121, 0.0158, 0.1980, 0.1149, 0.1553, 0.0585,\n",
       "         0.0490]),\n",
       " 4375: tensor([0.1800, 0.1390, 0.2043, 0.0747, 0.1603, 0.0389, 0.1162, 0.0498, 0.1075,\n",
       "         0.1442, 0.1098, 0.1099, 0.0000, 0.0000, 0.0644, 0.1505, 0.0804, 0.1162,\n",
       "         0.0000, 0.0689, 0.1677, 0.2294, 0.1893, 0.0995, 0.1179, 0.1283, 0.1097,\n",
       "         0.0801]),\n",
       " 1884: tensor([0.3196, 0.0000, 0.6151, 0.0674, 0.0000, 0.0000, 0.0538, 0.1536, 0.0000,\n",
       "         0.0000, 0.3030, 0.0303, 0.0000, 0.4817, 0.3588, 0.2996, 0.2388, 0.5042,\n",
       "         0.3529, 0.6805, 0.0000, 0.0000, 0.0000, 0.3477, 0.0000, 0.0512, 0.1828,\n",
       "         0.0000]),\n",
       " 2073: tensor([0.1683, 0.0000, 0.1139, 0.2295, 0.0000, 0.0000, 0.1883, 0.0000, 0.0980,\n",
       "         0.2979, 0.1464, 0.1782, 0.1186, 0.1443, 0.1720, 0.1400, 0.0143, 0.1223,\n",
       "         0.0000, 0.1781, 0.1329, 0.0000, 0.1948, 0.1675, 0.1478, 0.1076, 0.1772,\n",
       "         0.1752]),\n",
       " 2960: tensor([0.1501, 0.2099, 0.0107, 0.0356, 0.0000, 0.3270, 0.0939, 0.2799, 0.1730,\n",
       "         0.1093, 0.1683, 0.0000, 0.0000, 0.2681, 0.1439, 0.1839, 0.3221, 0.2550,\n",
       "         0.0000, 0.1046, 0.1924, 0.0289, 0.0000, 0.0000, 0.3877, 0.4015, 0.1311,\n",
       "         0.1550]),\n",
       " 3063: tensor([0.2524, 0.1175, 0.0000, 0.2085, 0.1086, 0.0490, 0.1189, 0.1685, 0.2094,\n",
       "         0.1288, 0.0000, 0.0260, 0.3026, 0.0439, 0.0950, 0.1630, 0.2500, 0.0351,\n",
       "         0.4111, 0.2142, 0.1137, 0.0349, 0.2185, 0.0000, 0.1872, 0.2017, 0.0558,\n",
       "         0.1358]),\n",
       " 2318: tensor([0.0000, 0.1588, 0.0508, 0.1161, 0.1588, 0.1791, 0.2179, 0.1287, 0.1229,\n",
       "         0.0021, 0.0942, 0.0000, 0.1083, 0.0304, 0.0000, 0.2076, 0.0000, 0.1980,\n",
       "         0.0922, 0.0101, 0.0000, 0.1771, 0.0000, 0.0672, 0.1142, 0.1236, 0.2896,\n",
       "         0.0541]),\n",
       " 432: tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2086, 0.5694, 0.4860, 0.0000,\n",
       "         0.0000, 0.0287, 0.0000, 0.7935, 0.0000, 0.4186, 0.0000, 0.1984, 0.1649,\n",
       "         0.0000, 0.0000, 0.0781, 0.0000, 0.0000, 0.6397, 0.0000, 0.0409, 0.0000,\n",
       "         0.1088]),\n",
       " 2775: tensor([0.0000, 0.3494, 0.0000, 0.0000, 0.4375, 0.0871, 0.4015, 0.0000, 0.1826,\n",
       "         0.2209, 0.3537, 0.4374, 0.0000, 0.4298, 0.1429, 0.2647, 0.6134, 0.2445,\n",
       "         0.0000, 0.0265, 0.0000, 0.1140, 0.3919, 0.0000, 0.5041, 0.0297, 0.0000,\n",
       "         0.0881]),\n",
       " 3925: tensor([0.1732, 0.0000, 0.1026, 0.0601, 0.1910, 0.0000, 0.0910, 0.2257, 0.1048,\n",
       "         0.0000, 0.0846, 0.0000, 0.1852, 0.3181, 0.1042, 0.1974, 0.1741, 0.1507,\n",
       "         0.0113, 0.3025, 0.1000, 0.3071, 0.0000, 0.0000, 0.0739, 0.2229, 0.2441,\n",
       "         0.1864]),\n",
       " 900: tensor([0.0770, 0.1759, 0.0918, 0.0666, 0.1207, 0.1316, 0.0442, 0.2624, 0.0000,\n",
       "         0.1744, 0.0335, 0.0000, 0.1803, 0.0000, 0.0000, 0.0491, 0.1168, 0.1101,\n",
       "         0.0000, 0.0000, 0.2908, 0.1212, 0.0000, 0.0000, 0.1909, 0.0761, 0.0165,\n",
       "         0.0710]),\n",
       " 3572: tensor([0.2673, 0.0548, 0.1770, 0.0000, 0.0250, 0.1305, 0.1795, 0.1387, 0.0000,\n",
       "         0.0000, 0.1514, 0.1174, 0.4212, 0.1454, 0.0000, 0.1139, 0.1175, 0.0000,\n",
       "         0.1310, 0.2774, 0.1016, 0.2635, 0.2990, 0.1866, 0.0000, 0.1761, 0.1540,\n",
       "         0.0465]),\n",
       " 2736: tensor([0.1907, 0.1089, 0.0501, 0.1946, 0.1825, 0.1211, 0.1331, 0.1536, 0.0623,\n",
       "         0.0629, 0.0796, 0.1604, 0.0538, 0.1057, 0.1086, 0.0968, 0.0691, 0.1247,\n",
       "         0.1227, 0.1770, 0.1609, 0.0686, 0.1291, 0.0899, 0.0636, 0.1251, 0.0000,\n",
       "         0.1561]),\n",
       " 4081: tensor([0.1630, 0.0924, 0.0000, 0.1555, 0.2436, 0.1637, 0.2476, 0.1138, 0.1932,\n",
       "         0.2989, 0.0000, 0.1533, 0.2031, 0.0705, 0.1632, 0.0051, 0.0903, 0.0984,\n",
       "         0.3324, 0.1665, 0.1033, 0.0243, 0.3058, 0.0000, 0.2562, 0.1553, 0.1409,\n",
       "         0.1074]),\n",
       " 1578: tensor([0.1134, 0.0944, 0.0000, 0.0000, 0.0000, 0.2239, 0.1192, 0.1863, 0.1028,\n",
       "         0.0000, 0.1667, 0.1121, 0.1146, 0.2295, 0.2320, 0.1353, 0.2085, 0.2029,\n",
       "         0.0352, 0.2200, 0.2211, 0.1691, 0.0000, 0.2731, 0.2157, 0.0589, 0.1376,\n",
       "         0.1642]),\n",
       " 3211: tensor([0.1438, 0.0000, 0.1341, 0.1396, 0.0000, 0.0000, 0.0884, 0.0639, 0.1914,\n",
       "         0.1492, 0.1177, 0.3229, 0.2936, 0.1400, 0.1016, 0.1119, 0.0946, 0.1437,\n",
       "         0.0361, 0.0985, 0.0241, 0.0000, 0.1219, 0.0540, 0.1750, 0.0411, 0.1838,\n",
       "         0.0000]),\n",
       " 2037: tensor([0.4100, 0.4160, 0.0000, 0.3727, 0.0000, 0.3118, 0.0000, 0.0281, 0.2447,\n",
       "         0.3904, 0.0000, 0.0000, 0.0000, 0.3055, 0.3104, 0.3644, 0.1752, 0.4664,\n",
       "         0.4424, 0.0000, 0.1019, 0.0000, 0.0579, 0.2261, 0.4990, 0.0192, 0.0804,\n",
       "         0.1446]),\n",
       " 2956: tensor([0.1864, 0.1530, 0.0000, 0.2145, 0.3447, 0.1703, 0.2347, 0.2030, 0.1753,\n",
       "         0.2237, 0.1074, 0.1973, 0.1087, 0.1667, 0.1601, 0.1830, 0.0539, 0.0845,\n",
       "         0.1031, 0.1306, 0.2155, 0.0550, 0.0060, 0.0000, 0.0767, 0.3084, 0.0647,\n",
       "         0.1601]),\n",
       " 1466: tensor([0.1447, 0.0622, 0.3109, 0.0719, 0.0000, 0.2284, 0.3319, 0.0761, 0.2124,\n",
       "         0.1447, 0.2212, 0.0068, 0.0000, 0.0908, 0.2341, 0.2116, 0.0000, 0.1494,\n",
       "         0.0000, 0.1745, 0.0000, 0.3182, 0.0000, 0.0378, 0.0000, 0.1631, 0.1817,\n",
       "         0.1213]),\n",
       " 4227: tensor([0.1465, 0.0923, 0.1019, 0.0820, 0.1139, 0.1390, 0.0742, 0.1314, 0.1651,\n",
       "         0.1484, 0.2300, 0.0770, 0.0000, 0.0000, 0.0000, 0.1224, 0.1808, 0.1506,\n",
       "         0.1363, 0.2044, 0.0237, 0.0828, 0.1114, 0.0775, 0.1423, 0.2148, 0.1514,\n",
       "         0.1111]),\n",
       " 1787: tensor([0.3462, 0.0489, 0.0000, 0.1305, 0.0000, 0.4250, 0.2003, 0.4952, 0.0013,\n",
       "         0.0000, 0.4310, 0.4877, 0.5496, 0.0000, 0.4219, 0.0000, 0.0360, 0.4707,\n",
       "         0.0000, 0.1996, 0.4131, 0.0000, 0.0000, 0.4453, 0.0000, 0.2760, 0.0775,\n",
       "         0.0235]),\n",
       " 1708: tensor([0.0000, 0.4005, 0.0000, 0.4381, 0.0000, 0.0093, 0.4431, 0.7374, 0.0000,\n",
       "         0.0000, 0.3501, 0.3596, 0.0000, 0.2239, 0.3760, 0.4456, 0.1709, 0.1410,\n",
       "         0.3109, 0.3654, 0.1023, 0.0000, 0.3689, 0.5137, 0.1993, 0.0000, 0.0810,\n",
       "         0.2937]),\n",
       " 796: tensor([0.0813, 0.0778, 0.0000, 0.0461, 0.0000, 0.0686, 0.0000, 0.0476, 0.0000,\n",
       "         0.1594, 0.4091, 0.3741, 0.2125, 0.1045, 0.3141, 0.2306, 0.2358, 0.3559,\n",
       "         0.0000, 0.2739, 0.0138, 0.4160, 0.0000, 0.5052, 0.0000, 0.5205, 0.3395,\n",
       "         0.0266]),\n",
       " 2254: tensor([0.1172, 0.0281, 0.1054, 0.0000, 0.1107, 0.1768, 0.0772, 0.0000, 0.0942,\n",
       "         0.1121, 0.2519, 0.1648, 0.0000, 0.1802, 0.0779, 0.1489, 0.0000, 0.1546,\n",
       "         0.1101, 0.1761, 0.1200, 0.2654, 0.1135, 0.0000, 0.0678, 0.1837, 0.0000,\n",
       "         0.0000]),\n",
       " 4071: tensor([0.0000, 0.1933, 0.1853, 0.0000, 0.0737, 0.2321, 0.2255, 0.2116, 0.2093,\n",
       "         0.0149, 0.1356, 0.0770, 0.0136, 0.1216, 0.0538, 0.1231, 0.0000, 0.0611,\n",
       "         0.2259, 0.2124, 0.1071, 0.1110, 0.3031, 0.3189, 0.0542, 0.1409, 0.0685,\n",
       "         0.1700]),\n",
       " 4273: tensor([0.0000, 0.0000, 0.4706, 0.0000, 0.2710, 0.3680, 0.3188, 0.1608, 0.0722,\n",
       "         0.1803, 0.4829, 0.0113, 0.1312, 0.6490, 0.1902, 0.3583, 0.1440, 0.2761,\n",
       "         0.2024, 0.2701, 0.2074, 0.5583, 0.0658, 0.0000, 0.2752, 0.0000, 0.1412,\n",
       "         0.1058]),\n",
       " 523: tensor([0.0000, 0.0000, 0.0102, 0.0558, 0.5492, 0.1077, 0.1576, 0.1277, 0.0864,\n",
       "         0.0000, 0.0218, 0.1130, 0.0789, 0.1369, 0.1034, 0.2134, 0.0000, 0.0000,\n",
       "         0.1088, 0.0930, 0.0000, 0.4153, 0.0189, 0.0000, 0.5594, 0.1490, 0.0000,\n",
       "         0.0000]),\n",
       " 2257: tensor([0.1754, 0.1681, 0.0981, 0.2163, 0.1952, 0.0621, 0.1890, 0.1183, 0.0969,\n",
       "         0.0038, 0.0930, 0.1501, 0.1239, 0.0000, 0.1511, 0.0678, 0.2696, 0.1264,\n",
       "         0.0000, 0.0933, 0.1391, 0.1368, 0.2521, 0.2138, 0.0577, 0.0166, 0.0465,\n",
       "         0.1488]),\n",
       " 837: tensor([0.1975, 0.1686, 0.0815, 0.1387, 0.0000, 0.1856, 0.0000, 0.3582, 0.0000,\n",
       "         0.1993, 0.1316, 0.1373, 0.4229, 0.0000, 0.0000, 0.2022, 0.1679, 0.1386,\n",
       "         0.0000, 0.1387, 0.2694, 0.1023, 0.0000, 0.0000, 0.2223, 0.0508, 0.1419,\n",
       "         0.1740]),\n",
       " 2825: tensor([0.1573, 0.2849, 0.0000, 0.1166, 0.1164, 0.4604, 0.1794, 0.3552, 0.0000,\n",
       "         0.0000, 0.2142, 0.2396, 0.2490, 0.0390, 0.0000, 0.1842, 0.0335, 0.3065,\n",
       "         0.2325, 0.1020, 0.0000, 0.2458, 0.2176, 0.0202, 0.0000, 0.0097, 0.1601,\n",
       "         0.1179]),\n",
       " 4122: tensor([0.1595, 0.1720, 0.1750, 0.1273, 0.1655, 0.1918, 0.1569, 0.1381, 0.1212,\n",
       "         0.0888, 0.0629, 0.0468, 0.1369, 0.1628, 0.1535, 0.0906, 0.0949, 0.0800,\n",
       "         0.1408, 0.0814, 0.1190, 0.1235, 0.0786, 0.2159, 0.0000, 0.1547, 0.1665,\n",
       "         0.1153]),\n",
       " 2963: tensor([0.0167, 0.0000, 0.0000, 0.0000, 0.0985, 0.0000, 0.0520, 0.0000, 0.0000,\n",
       "         0.2094, 0.2392, 0.4029, 0.2021, 0.1176, 0.4196, 0.0240, 0.1478, 0.3699,\n",
       "         0.4857, 0.2866, 0.3246, 0.0000, 0.1801, 0.0000, 0.3262, 0.2655, 0.0820,\n",
       "         0.3686]),\n",
       " 804: tensor([0.2200, 0.0337, 0.1159, 0.2500, 0.0000, 0.0680, 0.1594, 0.0873, 0.0210,\n",
       "         0.0648, 0.0133, 0.3698, 0.2022, 0.0000, 0.0000, 0.1834, 0.0039, 0.1832,\n",
       "         0.1723, 0.0071, 0.1771, 0.0000, 0.1943, 0.3756, 0.1756, 0.0123, 0.0369,\n",
       "         0.1405]),\n",
       " 2558: tensor([0.0000, 0.3681, 0.1812, 0.0117, 0.1948, 0.2889, 0.1298, 0.1692, 0.0348,\n",
       "         0.3503, 0.0000, 0.0404, 0.0575, 0.1071, 0.0000, 0.1324, 0.0000, 0.4403,\n",
       "         0.2204, 0.3715, 0.0469, 0.2485, 0.0000, 0.1300, 0.0733, 0.0432, 0.2819,\n",
       "         0.4661]),\n",
       " 2362: tensor([0.0000, 0.3570, 0.0000, 0.3544, 0.0000, 0.1928, 0.2177, 0.1828, 0.0856,\n",
       "         0.0257, 0.0220, 0.0000, 0.2233, 0.0948, 0.1023, 0.2424, 0.1688, 0.1621,\n",
       "         0.1936, 0.2432, 0.2436, 0.2749, 0.1515, 0.1982, 0.1518, 0.0000, 0.3685,\n",
       "         0.4032]),\n",
       " 4297: tensor([0.0000, 0.4327, 0.1986, 0.0000, 0.1498, 0.1818, 0.2806, 0.1775, 0.0000,\n",
       "         0.1069, 0.2799, 0.1313, 0.2301, 0.2864, 0.0000, 0.2893, 0.0560, 0.1637,\n",
       "         0.2261, 0.2375, 0.0000, 0.2510, 0.4131, 0.3563, 0.0000, 0.3531, 0.0788,\n",
       "         0.2591]),\n",
       " 147: tensor([0.0000, 0.3809, 0.0000, 0.1964, 0.0000, 0.0000, 0.2727, 0.4023, 0.0000,\n",
       "         0.0313, 0.3373, 0.1004, 0.1797, 0.1716, 0.2476, 0.3093, 0.1743, 0.2336,\n",
       "         0.1139, 0.0691, 0.1188, 0.2944, 0.2523, 0.2297, 0.1155, 0.0000, 0.3085,\n",
       "         0.0672]),\n",
       " 2579: tensor([0.1961, 0.1465, 0.0000, 0.3006, 0.0000, 0.1669, 0.1249, 0.1744, 0.0652,\n",
       "         0.0296, 0.2041, 0.2082, 0.1081, 0.0722, 0.1328, 0.3579, 0.0976, 0.1194,\n",
       "         0.2580, 0.0539, 0.1119, 0.1846, 0.1999, 0.0000, 0.2252, 0.2549, 0.0637,\n",
       "         0.1897]),\n",
       " 4188: tensor([0.1719, 0.1488, 0.0000, 0.0947, 0.2485, 0.1165, 0.1064, 0.1604, 0.1172,\n",
       "         0.0692, 0.1200, 0.1614, 0.2305, 0.1175, 0.1060, 0.0659, 0.1804, 0.1080,\n",
       "         0.0114, 0.1461, 0.1568, 0.1094, 0.0000, 0.0237, 0.1422, 0.1826, 0.1186,\n",
       "         0.1471]),\n",
       " 4176: tensor([0.1330, 0.1110, 0.0592, 0.1326, 0.1519, 0.0598, 0.1702, 0.2211, 0.1286,\n",
       "         0.0877, 0.0802, 0.1230, 0.0687, 0.1547, 0.0466, 0.1745, 0.0607, 0.1431,\n",
       "         0.1637, 0.1899, 0.0994, 0.0687, 0.1117, 0.1289, 0.1103, 0.1070, 0.0000,\n",
       "         0.1794]),\n",
       " 3662: tensor([0.1393, 0.0000, 0.0000, 0.2312, 0.0000, 0.0897, 0.0000, 0.2664, 0.1952,\n",
       "         0.1586, 0.1123, 0.0000, 0.0860, 0.0364, 0.0000, 0.0000, 0.0986, 0.0000,\n",
       "         0.3117, 0.1364, 0.1445, 0.0000, 0.0000, 0.1094, 0.0000, 0.0000, 0.1969,\n",
       "         0.0124]),\n",
       " 3166: tensor([0.2471, 0.3038, 0.0133, 0.1642, 0.0000, 0.0507, 0.1388, 0.0846, 0.2012,\n",
       "         0.1205, 0.0998, 0.0000, 0.1762, 0.0482, 0.1232, 0.2110, 0.1978, 0.0807,\n",
       "         0.2293, 0.2606, 0.2057, 0.1840, 0.1335, 0.1559, 0.1307, 0.0000, 0.2155,\n",
       "         0.2531]),\n",
       " 4144: tensor([0.2774, 0.0000, 0.0272, 0.0741, 0.0000, 0.0000, 0.2545, 0.0159, 0.1360,\n",
       "         0.3059, 0.0506, 0.2829, 0.0109, 0.1191, 0.0478, 0.0533, 0.2320, 0.2412,\n",
       "         0.0572, 0.1045, 0.1310, 0.0000, 0.0714, 0.3068, 0.0706, 0.0824, 0.2446,\n",
       "         0.1256]),\n",
       " 1406: tensor([0.0000, 0.0535, 0.1306, 0.0702, 0.0000, 0.0760, 0.0000, 0.2682, 0.2619,\n",
       "         0.0766, 0.2921, 0.1111, 0.0410, 0.1931, 0.3333, 0.0054, 0.2138, 0.1033,\n",
       "         0.1890, 0.1656, 0.2328, 0.1230, 0.0000, 0.1201, 0.2049, 0.0621, 0.0000,\n",
       "         0.0000]),\n",
       " 3677: tensor([0.0000, 0.1719, 0.1266, 0.0000, 0.3312, 0.3095, 0.1391, 0.1384, 0.2197,\n",
       "         0.1395, 0.0220, 0.1845, 0.2419, 0.1973, 0.1646, 0.1006, 0.0243, 0.1301,\n",
       "         0.1905, 0.2470, 0.0842, 0.1647, 0.1113, 0.0782, 0.0000, 0.1387, 0.1554,\n",
       "         0.1458]),\n",
       " 1045: tensor([0.0816, 0.1611, 0.2037, 0.0809, 0.1094, 0.0989, 0.1008, 0.1669, 0.0845,\n",
       "         0.1659, 0.1804, 0.0914, 0.1501, 0.0000, 0.0000, 0.0812, 0.1402, 0.1210,\n",
       "         0.1113, 0.0753, 0.1251, 0.0000, 0.1942, 0.0268, 0.1330, 0.1596, 0.1206,\n",
       "         0.1156]),\n",
       " 2738: tensor([0.1299, 0.0976, 0.1002, 0.1357, 0.0000, 0.1651, 0.1373, 0.1049, 0.0950,\n",
       "         0.1396, 0.1608, 0.0000, 0.0000, 0.1391, 0.0738, 0.1004, 0.1936, 0.0921,\n",
       "         0.0000, 0.1515, 0.0762, 0.1041, 0.0000, 0.0283, 0.2379, 0.0729, 0.1324,\n",
       "         0.0868]),\n",
       " 464: tensor([0.1671, 0.2513, 0.2257, 0.1781, 0.2462, 0.0746, 0.0000, 0.1811, 0.0000,\n",
       "         0.2404, 0.1803, 0.0231, 0.3292, 0.0000, 0.0000, 0.1882, 0.1454, 0.1876,\n",
       "         0.0000, 0.0406, 0.1527, 0.1395, 0.0360, 0.0000, 0.1521, 0.1090, 0.1881,\n",
       "         0.0814]),\n",
       " 2624: tensor([0.0926, 0.1603, 0.0732, 0.0362, 0.0322, 0.0000, 0.1089, 0.1576, 0.0631,\n",
       "         0.3146, 0.1013, 0.0000, 0.0734, 0.0000, 0.1897, 0.1939, 0.0119, 0.1630,\n",
       "         0.0000, 0.2099, 0.2566, 0.1192, 0.1062, 0.2805, 0.2268, 0.2933, 0.0000,\n",
       "         0.1416]),\n",
       " 790: tensor([0.0945, 0.1790, 0.1329, 0.0738, 0.2094, 0.2047, 0.0664, 0.1489, 0.1968,\n",
       "         0.2874, 0.2633, 0.0550, 0.0023, 0.0000, 0.0000, 0.2057, 0.1669, 0.1629,\n",
       "         0.0000, 0.1455, 0.1308, 0.0000, 0.1502, 0.0000, 0.1863, 0.1710, 0.1982,\n",
       "         0.1996]),\n",
       " 2918: tensor([0.1740, 0.1899, 0.0000, 0.0536, 0.0000, 0.1684, 0.2525, 0.0757, 0.1097,\n",
       "         0.0000, 0.0809, 0.3151, 0.0964, 0.0000, 0.0624, 0.0000, 0.0955, 0.3966,\n",
       "         0.0000, 0.2411, 0.2816, 0.1005, 0.0000, 0.1146, 0.2302, 0.3761, 0.2288,\n",
       "         0.1684]),\n",
       " 2174: tensor([0.1678, 0.1106, 0.0000, 0.1566, 0.1501, 0.1711, 0.3303, 0.1332, 0.0000,\n",
       "         0.2231, 0.1451, 0.0357, 0.0573, 0.1309, 0.1380, 0.2326, 0.0560, 0.0000,\n",
       "         0.1826, 0.1793, 0.2622, 0.0906, 0.1929, 0.0610, 0.0000, 0.3198, 0.0786,\n",
       "         0.1111]),\n",
       " 2455: tensor([0.0000, 0.1186, 0.1182, 0.0000, 0.2054, 0.0000, 0.1663, 0.2065, 0.0000,\n",
       "         0.0000, 0.1976, 0.2240, 0.0447, 0.2481, 0.3068, 0.0569, 0.0560, 0.1971,\n",
       "         0.0358, 0.1600, 0.1813, 0.0588, 0.0829, 0.1585, 0.0960, 0.1247, 0.0071,\n",
       "         0.1590]),\n",
       " 1323: tensor([0.0000, 0.2012, 0.2275, 0.0000, 0.1853, 0.0000, 0.0613, 0.1763, 0.1636,\n",
       "         0.1182, 0.3077, 0.1151, 0.0743, 0.3431, 0.0000, 0.0000, 0.2314, 0.2398,\n",
       "         0.2777, 0.1678, 0.0000, 0.0843, 0.2304, 0.1614, 0.0616, 0.2937, 0.1002,\n",
       "         0.2651]),\n",
       " 2785: tensor([0.2167, 0.1451, 0.1672, 0.0000, 0.0000, 0.0413, 0.1341, 0.4253, 0.0000,\n",
       "         0.0000, 0.0687, 0.2780, 0.3102, 0.2799, 0.0000, 0.1991, 0.1047, 0.0000,\n",
       "         0.1556, 0.2379, 0.1319, 0.3369, 0.3639, 0.1483, 0.0000, 0.2221, 0.1884,\n",
       "         0.0926]),\n",
       " 2850: tensor([0.2029, 0.0944, 0.0000, 0.3402, 0.2534, 0.4489, 0.0455, 0.1095, 0.1313,\n",
       "         0.2981, 0.0000, 0.1216, 0.0965, 0.0964, 0.1628, 0.2067, 0.2742, 0.1766,\n",
       "         0.0864, 0.1805, 0.2290, 0.1410, 0.1756, 0.3160, 0.2713, 0.1713, 0.0000,\n",
       "         0.1298]),\n",
       " 1536: tensor([0.1585, 0.0000, 0.1509, 0.0807, 0.1829, 0.2264, 0.1122, 0.0000, 0.2433,\n",
       "         0.1340, 0.3452, 0.1565, 0.1479, 0.1745, 0.0443, 0.1725, 0.0000, 0.1427,\n",
       "         0.1789, 0.2189, 0.1682, 0.2755, 0.1868, 0.1363, 0.0827, 0.1716, 0.1694,\n",
       "         0.0000]),\n",
       " 899: tensor([0.0000, 0.3187, 0.1973, 0.0578, 0.1378, 0.1967, 0.0000, 0.5260, 0.0000,\n",
       "         0.3883, 0.2424, 0.1883, 0.1345, 0.0000, 0.0000, 0.0000, 0.1972, 0.1142,\n",
       "         0.0000, 0.0774, 0.2928, 0.1683, 0.0858, 0.0000, 0.1642, 0.2163, 0.1601,\n",
       "         0.1080]),\n",
       " 3142: tensor([0.0541, 0.1352, 0.1859, 0.1484, 0.0401, 0.1255, 0.1796, 0.1141, 0.1557,\n",
       "         0.1530, 0.1246, 0.1552, 0.0858, 0.0000, 0.1080, 0.1546, 0.0764, 0.1773,\n",
       "         0.0000, 0.0911, 0.1992, 0.1831, 0.1198, 0.1564, 0.1659, 0.1066, 0.1278,\n",
       "         0.1052]),\n",
       " 2597: tensor([0.0000, 0.0000, 0.2736, 0.3357, 0.1125, 0.1498, 0.0000, 0.0000, 0.2636,\n",
       "         0.2110, 0.1790, 0.0096, 0.0000, 0.2284, 0.0377, 0.3440, 0.4528, 0.1324,\n",
       "         0.3421, 0.0564, 0.0340, 0.1523, 0.0000, 0.0000, 0.0229, 0.0000, 0.1403,\n",
       "         0.0478]),\n",
       " 1554: tensor([0.0440, 0.0374, 0.0988, 0.2302, 0.0000, 0.1457, 0.0000, 0.1625, 0.1371,\n",
       "         0.1097, 0.2169, 0.0000, 0.0000, 0.2231, 0.0272, 0.0004, 0.0460, 0.1020,\n",
       "         0.0000, 0.2667, 0.3201, 0.0000, 0.0000, 0.1175, 0.1234, 0.0764, 0.1175,\n",
       "         0.1692]),\n",
       " 2548: tensor([0.1111, 0.1227, 0.1956, 0.0933, 0.1451, 0.1521, 0.1893, 0.1461, 0.1113,\n",
       "         0.1529, 0.0589, 0.0425, 0.0973, 0.1885, 0.1685, 0.1170, 0.1165, 0.1217,\n",
       "         0.0498, 0.0266, 0.0814, 0.2007, 0.1052, 0.2114, 0.0000, 0.1640, 0.1521,\n",
       "         0.1446]),\n",
       " 1073: tensor([0.0000, 0.0000, 0.1616, 0.1200, 0.2319, 0.1194, 0.1491, 0.2147, 0.1869,\n",
       "         0.0751, 0.1160, 0.1834, 0.2095, 0.1953, 0.1482, 0.3337, 0.0000, 0.1815,\n",
       "         0.0942, 0.1034, 0.0000, 0.2529, 0.2113, 0.0000, 0.1701, 0.1674, 0.1998,\n",
       "         0.0883]),\n",
       " 892: tensor([0.1554, 0.2461, 0.2987, 0.1417, 0.5186, 0.4568, 0.0006, 0.3776, 0.0000,\n",
       "         0.1645, 0.1411, 0.3363, 0.0000, 0.0000, 0.0000, 0.0841, 0.2958, 0.4847,\n",
       "         0.0000, 0.0000, 0.1133, 0.3986, 0.2532, 0.0000, 0.3314, 0.3305, 0.1495,\n",
       "         0.0193]),\n",
       " 3850: tensor([0.3182, 0.0635, 0.0074, 0.0190, 0.0000, 0.0356, 0.1273, 0.0948, 0.1541,\n",
       "         0.1798, 0.1085, 0.0000, 0.0000, 0.0000, 0.0000, 0.2382, 0.0993, 0.0205,\n",
       "         0.0000, 0.0940, 0.0497, 0.1487, 0.0000, 0.0579, 0.1201, 0.1584, 0.0042,\n",
       "         0.1455]),\n",
       " 4063: tensor([0.0000, 0.0000, 0.0867, 0.2431, 0.2102, 0.2086, 0.0000, 0.0000, 0.0724,\n",
       "         0.4447, 0.0538, 0.2754, 0.0000, 0.2365, 0.1594, 0.0139, 0.5038, 0.0000,\n",
       "         0.2190, 0.0000, 0.1241, 0.0000, 0.0000, 0.0000, 0.1202, 0.0000, 0.1087,\n",
       "         0.0794]),\n",
       " 2857: tensor([0.0000, 0.0479, 0.0000, 0.1669, 0.2513, 0.1621, 0.1723, 0.1508, 0.0399,\n",
       "         0.0350, 0.1220, 0.0656, 0.1124, 0.1650, 0.0079, 0.0746, 0.0376, 0.1155,\n",
       "         0.0858, 0.0932, 0.1426, 0.1226, 0.0729, 0.0542, 0.1065, 0.1181, 0.0742,\n",
       "         0.0726]),\n",
       " 1030: tensor([0.0990, 0.1626, 0.1228, 0.1100, 0.1003, 0.1316, 0.1376, 0.1601, 0.2273,\n",
       "         0.1360, 0.1499, 0.2011, 0.1733, 0.0000, 0.0000, 0.1193, 0.1374, 0.0334,\n",
       "         0.1701, 0.0250, 0.0234, 0.0219, 0.2036, 0.1019, 0.0943, 0.1936, 0.1187,\n",
       "         0.1527]),\n",
       " 1127: tensor([0.0000, 0.2185, 0.3063, 0.0000, 0.3481, 0.0000, 0.1996, 0.2332, 0.1957,\n",
       "         0.0444, 0.0940, 0.0893, 0.2401, 0.4065, 0.0986, 0.0000, 0.0000, 0.3048,\n",
       "         0.2388, 0.2952, 0.0000, 0.1153, 0.0311, 0.0894, 0.1074, 0.3666, 0.1710,\n",
       "         0.1464]),\n",
       " 1431: tensor([0.1568, 0.2942, 0.0120, 0.0510, 0.3033, 0.1112, 0.1269, 0.0000, 0.0000,\n",
       "         0.0000, 0.0691, 0.2948, 0.1317, 0.0000, 0.3544, 0.4484, 0.1437, 0.1440,\n",
       "         0.0000, 0.0000, 0.1423, 0.4396, 0.3593, 0.0000, 0.0000, 0.4578, 0.4910,\n",
       "         0.2798]),\n",
       " 1885: tensor([0.2091, 0.1083, 0.0470, 0.0498, 0.0000, 0.0472, 0.0000, 0.1856, 0.1973,\n",
       "         0.4414, 0.1201, 0.1048, 0.1871, 0.1259, 0.1728, 0.0322, 0.0814, 0.2783,\n",
       "         0.0420, 0.1332, 0.1990, 0.0105, 0.2792, 0.0794, 0.2862, 0.0000, 0.0000,\n",
       "         0.2018]),\n",
       " 4061: tensor([0.1212, 0.0000, 0.0968, 0.4950, 0.2189, 0.0000, 0.2759, 1.0818, 0.0458,\n",
       "         0.0000, 0.0000, 0.0000, 0.4265, 0.1192, 0.2096, 0.0225, 0.5782, 0.3989,\n",
       "         0.2464, 0.0000, 0.0000, 0.4359, 0.0000, 0.0000, 0.0000, 0.1072, 0.2944,\n",
       "         0.3380]),\n",
       " 1221: tensor([0.0000, 0.0363, 0.0000, 0.3331, 0.1292, 0.0000, 0.3119, 0.2813, 0.0945,\n",
       "         0.3318, 0.2143, 0.0031, 0.3959, 0.0170, 0.0535, 0.0113, 0.2033, 0.1232,\n",
       "         0.0000, 0.0208, 0.1484, 0.3091, 0.0632, 0.0000, 0.2608, 0.1202, 0.0000,\n",
       "         0.0578]),\n",
       " 2094: tensor([0.0819, 0.3310, 0.0000, 0.4118, 0.0000, 0.0000, 0.2690, 0.1972, 0.0000,\n",
       "         0.0000, 0.0055, 0.0000, 0.2962, 0.0577, 0.0440, 0.1942, 0.0522, 0.0662,\n",
       "         0.0612, 0.3931, 0.3380, 0.4210, 0.0715, 0.0046, 0.0680, 0.0000, 0.3862,\n",
       "         0.0764]),\n",
       " 4362: tensor([0.0000, 0.0517, 0.1821, 0.1328, 0.2394, 0.1275, 0.0784, 0.0656, 0.0047,\n",
       "         0.0000, 0.2002, 0.0000, 0.3602, 0.1357, 0.0000, 0.0028, 0.0000, 0.1930,\n",
       "         0.2104, 0.2474, 0.0000, 0.1176, 0.0000, 0.0798, 0.1964, 0.0868, 0.2600,\n",
       "         0.0130]),\n",
       " 4364: tensor([0.3991, 0.0373, 0.2559, 0.0779, 0.0000, 0.3251, 0.1682, 0.2818, 0.3080,\n",
       "         0.3908, 0.1659, 0.1120, 0.0000, 0.3343, 0.4546, 0.0484, 0.0000, 0.0000,\n",
       "         0.2196, 0.1347, 0.3241, 0.0722, 0.0742, 0.1327, 0.0835, 0.3235, 0.0178,\n",
       "         0.2924]),\n",
       " 1265: tensor([0.0634, 0.0946, 0.1118, 0.0825, 0.1053, 0.2492, 0.1423, 0.1138, 0.0953,\n",
       "         0.0320, 0.2349, 0.1385, 0.1621, 0.1753, 0.1473, 0.0000, 0.1836, 0.0000,\n",
       "         0.1959, 0.2100, 0.0423, 0.0000, 0.2536, 0.1233, 0.0000, 0.2164, 0.0000,\n",
       "         0.2295]),\n",
       " 2326: tensor([0.0820, 0.2486, 0.0844, 0.1680, 0.1925, 0.2117, 0.2586, 0.1561, 0.1218,\n",
       "         0.1371, 0.1532, 0.1350, 0.0877, 0.1470, 0.3726, 0.0570, 0.2204, 0.1660,\n",
       "         0.0000, 0.2090, 0.1474, 0.1359, 0.0000, 0.0651, 0.0000, 0.3467, 0.1774,\n",
       "         0.0957]),\n",
       " 1521: tensor([0.0000, 0.4255, 0.0020, 0.3141, 0.0000, 0.4784, 0.5017, 0.2738, 0.3287,\n",
       "         0.0688, 0.1549, 0.0000, 0.0000, 0.7630, 0.3806, 0.0816, 0.1559, 0.1847,\n",
       "         0.0000, 0.0334, 0.3430, 0.0218, 0.0000, 0.0000, 0.2765, 0.9355, 0.2076,\n",
       "         0.1089]),\n",
       " 1430: tensor([0.1471, 0.0980, 0.1600, 0.1497, 0.0000, 0.0731, 0.1636, 0.2003, 0.1420,\n",
       "         0.0930, 0.0918, 0.1050, 0.1007, 0.1172, 0.1043, 0.0630, 0.1490, 0.1670,\n",
       "         0.0278, 0.0444, 0.1041, 0.1363, 0.0000, 0.1123, 0.1449, 0.1710, 0.1293,\n",
       "         0.1060]),\n",
       " 2853: tensor([0.1615, 0.1911, 0.1106, 0.1328, 0.0449, 0.3168, 0.0879, 0.0187, 0.1787,\n",
       "         0.1534, 0.1022, 0.1231, 0.1527, 0.1099, 0.0947, 0.0802, 0.1466, 0.1019,\n",
       "         0.1337, 0.1322, 0.0707, 0.0291, 0.1312, 0.1328, 0.1317, 0.0000, 0.0174,\n",
       "         0.2169]),\n",
       " 2164: tensor([0.2260, 0.0000, 0.0000, 0.1952, 0.0000, 0.0000, 0.1784, 0.0000, 0.1039,\n",
       "         0.2046, 0.0748, 0.1486, 0.1078, 0.1547, 0.0595, 0.0000, 0.1397, 0.1644,\n",
       "         0.0690, 0.0000, 0.2565, 0.0000, 0.0175, 0.3773, 0.0310, 0.0847, 0.1126,\n",
       "         0.2279]),\n",
       " 3759: tensor([0.0000, 0.1843, 0.1193, 0.0000, 0.1803, 0.1872, 0.1270, 0.1321, 0.0916,\n",
       "         0.0990, 0.0412, 0.0899, 0.1483, 0.1534, 0.0743, 0.2123, 0.0482, 0.0855,\n",
       "         0.1320, 0.1703, 0.0947, 0.1369, 0.1613, 0.1249, 0.0000, 0.1534, 0.0794,\n",
       "         0.1080]),\n",
       " 497: tensor([0.1641, 0.1041, 0.1173, 0.1662, 0.0000, 0.2196, 0.0720, 0.1187, 0.1385,\n",
       "         0.0858, 0.2661, 0.0000, 0.0000, 0.1406, 0.1096, 0.1672, 0.0898, 0.1159,\n",
       "         0.0000, 0.1950, 0.1242, 0.1330, 0.0000, 0.0000, 0.1498, 0.0247, 0.1840,\n",
       "         0.1221]),\n",
       " 4086: tensor([0.2595, 0.1105, 0.2904, 0.0000, 0.0000, 0.0058, 0.1161, 0.2666, 0.0000,\n",
       "         0.0000, 0.0816, 0.0000, 0.4457, 0.2412, 0.0000, 0.1330, 0.1006, 0.0000,\n",
       "         0.0947, 0.1620, 0.1114, 0.3111, 0.1837, 0.1971, 0.0831, 0.0000, 0.0701,\n",
       "         0.1271]),\n",
       " 3684: tensor([0.1059, 0.0000, 0.2334, 0.0000, 0.0322, 0.1628, 0.1905, 0.0894, 0.0000,\n",
       "         0.0000, 0.1134, 0.2100, 0.3032, 0.2289, 0.0000, 0.0808, 0.0125, 0.0000,\n",
       "         0.1475, 0.0706, 0.1406, 0.2955, 0.0642, 0.1306, 0.0000, 0.0834, 0.0000,\n",
       "         0.0421]),\n",
       " 1506: tensor([0.2288, 0.0703, 0.1879, 0.1568, 0.0000, 0.0842, 0.0249, 0.2209, 0.1011,\n",
       "         0.0992, 0.2740, 0.0000, 0.0000, 0.0196, 0.0913, 0.0949, 0.1703, 0.1483,\n",
       "         0.0000, 0.2025, 0.4043, 0.0000, 0.0000, 0.0000, 0.1156, 0.0083, 0.1553,\n",
       "         0.1895]),\n",
       " 409: tensor([0.1678, 0.0000, 0.0000, 0.0000, 0.2872, 0.0000, 0.0762, 0.2643, 0.1137,\n",
       "         0.0000, 0.2343, 0.0000, 0.2055, 0.3371, 0.2873, 0.0867, 0.1147, 0.2758,\n",
       "         0.0674, 0.0000, 0.0000, 0.1852, 0.0000, 0.0000, 0.0000, 0.0295, 0.1713,\n",
       "         0.2378]),\n",
       " 3091: tensor([0.0000, 0.0000, 0.2586, 0.1711, 0.0411, 0.3507, 0.0221, 0.0000, 0.0000,\n",
       "         0.1310, 0.0000, 0.2588, 0.3466, 0.4445, 0.0000, 0.3510, 0.2096, 0.3544,\n",
       "         0.1769, 0.1368, 0.0000, 0.0000, 0.2019, 0.0000, 0.0797, 0.0000, 0.2798,\n",
       "         0.0271]),\n",
       " 2586: tensor([0.1162, 0.2195, 0.1232, 0.1165, 0.0604, 0.1906, 0.2169, 0.2096, 0.0706,\n",
       "         0.1725, 0.1418, 0.0457, 0.0478, 0.0000, 0.0000, 0.0434, 0.0975, 0.1559,\n",
       "         0.0000, 0.0194, 0.1709, 0.1031, 0.1272, 0.0000, 0.1890, 0.1299, 0.0757,\n",
       "         0.0846]),\n",
       " 2913: tensor([0.1819, 0.1699, 0.1068, 0.1482, 0.0000, 0.2294, 0.1433, 0.1319, 0.3269,\n",
       "         0.0815, 0.1615, 0.0000, 0.0000, 0.1348, 0.1095, 0.2183, 0.2724, 0.1442,\n",
       "         0.0000, 0.1772, 0.1393, 0.1084, 0.0000, 0.0000, 0.2582, 0.2578, 0.1995,\n",
       "         0.2566]),\n",
       " 2389: tensor([0.1577, 0.1814, 0.0000, 0.1056, 0.1764, 0.1003, 0.0718, 0.1449, 0.1397,\n",
       "         0.0902, 0.0989, 0.1422, 0.2428, 0.1597, 0.1025, 0.0441, 0.1568, 0.0946,\n",
       "         0.0274, 0.1464, 0.1990, 0.0881, 0.0000, 0.0000, 0.1461, 0.1468, 0.1563,\n",
       "         0.2128]),\n",
       " 24: tensor([0.2360, 0.0000, 0.1256, 0.1714, 0.0000, 0.0000, 0.0457, 0.0000, 0.1585,\n",
       "         0.2230, 0.1150, 0.1572, 0.0722, 0.1393, 0.1995, 0.2621, 0.0380, 0.1019,\n",
       "         0.0956, 0.1303, 0.1447, 0.0000, 0.1547, 0.1128, 0.1546, 0.0981, 0.1354,\n",
       "         0.1858]),\n",
       " 252: tensor([0.0000, 0.1206, 0.0884, 0.0000, 0.1660, 0.0433, 0.1555, 0.0708, 0.1910,\n",
       "         0.1302, 0.1210, 0.0979, 0.1872, 0.1382, 0.0957, 0.1756, 0.0811, 0.1461,\n",
       "         0.1743, 0.1058, 0.1311, 0.1680, 0.1302, 0.1286, 0.0000, 0.0516, 0.1394,\n",
       "         0.0715]),\n",
       " 1023: tensor([0.1363, 0.2476, 0.1480, 0.1716, 0.0015, 0.0400, 0.1696, 0.0999, 0.1904,\n",
       "         0.2181, 0.1952, 0.0000, 0.1175, 0.0000, 0.0000, 0.0787, 0.2111, 0.2169,\n",
       "         0.0921, 0.1689, 0.1956, 0.0916, 0.0486, 0.0176, 0.2558, 0.0567, 0.1966,\n",
       "         0.2337]),\n",
       " 2854: tensor([0.1093, 0.0251, 0.0000, 0.0000, 0.0000, 0.1864, 0.0480, 0.1883, 0.4780,\n",
       "         0.4496, 0.0130, 0.0369, 0.1000, 0.1871, 0.0000, 0.0527, 0.0472, 0.0515,\n",
       "         0.1551, 0.0000, 0.0602, 0.2677, 0.0000, 0.0929, 0.0000, 0.2802, 0.0842,\n",
       "         0.2853]),\n",
       " 3414: tensor([0.1431, 0.1653, 0.0000, 0.0000, 0.0000, 0.0914, 0.2557, 0.1982, 0.2955,\n",
       "         0.1517, 0.0481, 0.1694, 0.1659, 0.2655, 0.1268, 0.1048, 0.2229, 0.0346,\n",
       "         0.1525, 0.0806, 0.1963, 0.1849, 0.0000, 0.0000, 0.2051, 0.3048, 0.1629,\n",
       "         0.0919]),\n",
       " 1251: tensor([0.6397, 0.0000, 0.0000, 0.5733, 0.0000, 0.4601, 0.7379, 0.1199, 0.0000,\n",
       "         0.0000, 0.4173, 0.0000, 0.6540, 0.0000, 0.0000, 0.3963, 0.8344, 0.0000,\n",
       "         0.0098, 0.1489, 0.0000, 0.0000, 0.5801, 0.7052, 0.0000, 0.0000, 0.4988,\n",
       "         1.1177]),\n",
       " 3838: tensor([0.5964, 0.1202, 0.1315, 0.0000, 0.0558, 0.0000, 0.4591, 0.1551, 0.2460,\n",
       "         0.4050, 0.0000, 0.3809, 0.1472, 0.4146, 0.1065, 0.0000, 0.6323, 0.0000,\n",
       "         0.0000, 0.0000, 0.2739, 0.1895, 0.3831, 0.0000, 0.8074, 0.0000, 0.1617,\n",
       "         0.4034]),\n",
       " 2915: tensor([0.0929, 0.0986, 0.0000, 0.0846, 0.1171, 0.1447, 0.0000, 0.0560, 0.1988,\n",
       "         0.0912, 0.1375, 0.3017, 0.2453, 0.0712, 0.1949, 0.1151, 0.1536, 0.1353,\n",
       "         0.0103, 0.0906, 0.2560, 0.1474, 0.0754, 0.0000, 0.1004, 0.2795, 0.0031,\n",
       "         0.0000]),\n",
       " 501: tensor([3.3965e-01, 2.0160e-01, 1.5407e-01, 2.2185e-01, 4.4356e-04, 5.4041e-03,\n",
       "         1.0246e-01, 0.0000e+00, 5.2906e-01, 0.0000e+00, 2.4419e-01, 6.1840e-02,\n",
       "         2.1735e-01, 7.6949e-02, 2.3806e-01, 2.4461e-01, 2.1583e-01, 1.8583e-01,\n",
       "         0.0000e+00, 5.3014e-01, 1.9557e-01, 0.0000e+00, 1.9973e-01, 0.0000e+00,\n",
       "         0.0000e+00, 1.5389e-01, 2.3346e-01, 2.5817e-01]),\n",
       " 641: tensor([0.0000, 0.3004, 0.0000, 0.1424, 0.0000, 0.2118, 0.0640, 0.1071, 0.0086,\n",
       "         0.1277, 0.3231, 0.1381, 0.0000, 0.2605, 0.1136, 0.2374, 0.2149, 0.3009,\n",
       "         0.2221, 0.4227, 0.1992, 0.0000, 0.2648, 0.4309, 0.1605, 0.0000, 0.0786,\n",
       "         0.2268]),\n",
       " 502: tensor([0.6713, 0.3215, 0.4871, 0.0000, 0.0000, 0.8522, 0.0000, 0.0000, 0.3556,\n",
       "         0.7871, 1.0886, 0.5476, 0.8797, 0.4481, 0.0000, 0.6821, 0.5082, 0.0000,\n",
       "         0.0000, 0.5228, 0.0000, 0.7243, 0.2273, 1.4397, 0.0000, 0.0048, 0.5839,\n",
       "         0.0000]),\n",
       " 631: tensor([0.0835, 0.3007, 0.0807, 0.1814, 0.3411, 0.2903, 0.1495, 0.1806, 0.1329,\n",
       "         0.2049, 0.2232, 0.0498, 0.2154, 0.0000, 0.0000, 0.1953, 0.1996, 0.1308,\n",
       "         0.0000, 0.0334, 0.1313, 0.1327, 0.1299, 0.0000, 0.2437, 0.1571, 0.1116,\n",
       "         0.1122]),\n",
       " 605: tensor([0.1186, 0.1016, 0.2272, 0.1866, 0.1772, 0.0532, 0.2066, 0.1520, 0.1223,\n",
       "         0.1834, 0.0864, 0.2369, 0.0000, 0.0000, 0.1536, 0.1679, 0.1511, 0.1887,\n",
       "         0.0000, 0.0571, 0.2864, 0.1321, 0.2855, 0.1750, 0.1374, 0.1352, 0.0928,\n",
       "         0.0994]),\n",
       " 675: tensor([0.3499, 0.0600, 0.0108, 0.1719, 0.0000, 0.1741, 0.1853, 0.0446, 0.1664,\n",
       "         0.1078, 0.2001, 0.0000, 0.0000, 0.1394, 0.0851, 0.2103, 0.1065, 0.1367,\n",
       "         0.0000, 0.0901, 0.1245, 0.1965, 0.0000, 0.0958, 0.1886, 0.1000, 0.1797,\n",
       "         0.2268]),\n",
       " 12: tensor([0.2504, 0.0486, 0.0000, 0.0000, 0.0000, 0.0302, 0.2209, 0.0090, 0.1455,\n",
       "         0.0000, 0.2498, 0.0256, 0.0528, 0.0479, 0.0968, 0.2812, 0.1429, 0.2286,\n",
       "         0.1360, 0.3387, 0.2098, 0.2831, 0.0000, 0.2318, 0.0773, 0.1181, 0.2191,\n",
       "         0.0519]),\n",
       " 786: tensor([0.1346, 0.0724, 0.2544, 0.2749, 0.0000, 0.1457, 0.1264, 0.2010, 0.0602,\n",
       "         0.1150, 0.0548, 0.0981, 0.1401, 0.0755, 0.1451, 0.0596, 0.1670, 0.1088,\n",
       "         0.0895, 0.1341, 0.1642, 0.1672, 0.0000, 0.1052, 0.1705, 0.1078, 0.2281,\n",
       "         0.0975]),\n",
       " 636: tensor([0.1669, 0.0000, 0.1145, 0.0000, 0.1461, 0.3374, 0.0367, 0.0000, 0.3657,\n",
       "         0.1383, 0.2117, 0.2053, 0.0176, 0.1999, 0.0808, 0.0000, 0.0000, 0.0568,\n",
       "         0.1237, 0.2505, 0.3764, 0.4460, 0.1877, 0.0000, 0.0268, 0.2426, 0.0000,\n",
       "         0.0000]),\n",
       " 4085: tensor([0.2128, 0.1259, 0.0759, 0.1113, 0.0000, 0.2219, 0.0230, 0.0478, 0.1604,\n",
       "         0.0516, 0.2336, 0.0000, 0.0000, 0.1326, 0.0834, 0.1473, 0.0887, 0.1495,\n",
       "         0.0000, 0.1762, 0.0557, 0.0719, 0.0000, 0.0000, 0.0964, 0.0425, 0.1506,\n",
       "         0.1434]),\n",
       " 2912: tensor([0.0000, 0.0000, 0.0636, 0.3529, 0.2416, 0.2698, 0.0178, 0.2861, 0.4051,\n",
       "         0.1782, 0.1111, 0.1189, 0.2409, 0.0000, 0.3134, 0.4471, 0.0000, 0.0023,\n",
       "         0.0796, 0.0515, 0.0000, 0.0958, 0.3507, 0.0000, 0.2065, 0.2382, 0.0000,\n",
       "         0.0000]),\n",
       " 4121: tensor([0.4631, 0.0000, 0.2848, 0.3348, 0.0000, 0.0000, 0.2897, 0.0000, 0.0000,\n",
       "         0.0000, 0.2824, 0.3470, 0.0546, 0.5319, 0.0874, 0.2578, 0.2084, 0.3615,\n",
       "         0.4332, 0.0212, 0.0000, 0.0000, 0.0963, 0.1415, 0.0000, 0.0000, 0.0000,\n",
       "         0.2611]),\n",
       " 1354: tensor([0.1204, 0.1209, 0.0000, 0.1162, 0.3206, 0.1713, 0.2381, 0.0928, 0.1658,\n",
       "         0.2650, 0.0889, 0.1337, 0.2306, 0.0820, 0.1450, 0.0000, 0.0393, 0.1037,\n",
       "         0.2513, 0.1286, 0.1273, 0.0431, 0.1072, 0.0000, 0.0865, 0.1163, 0.0731,\n",
       "         0.1239]),\n",
       " 2645: tensor([0.0691, 0.0226, 0.2515, 0.0966, 0.1459, 0.1694, 0.0000, 0.0000, 0.1441,\n",
       "         0.0000, 0.1588, 0.2180, 0.5717, 0.5825, 0.2453, 0.0000, 0.1390, 0.0000,\n",
       "         0.4367, 0.0000, 0.1926, 0.1907, 0.1544, 0.2748, 0.0000, 0.0820, 0.0000,\n",
       "         0.5313]),\n",
       " 2225: tensor([0.0000, 0.0000, 0.1032, 0.4266, 0.4229, 0.0000, 0.0772, 0.7998, 0.0000,\n",
       "         0.0000, 0.2926, 0.0000, 0.1341, 0.0589, 0.1063, 0.0000, 0.3661, 0.3457,\n",
       "         0.2972, 0.0000, 0.0000, 0.5894, 0.0000, 0.0000, 0.0000, 0.0197, 0.2836,\n",
       "         0.1750]),\n",
       " 3676: tensor([0.2774, 0.1452, 0.0000, 0.0605, 0.2316, 0.1457, 0.2847, 0.6890, 0.0000,\n",
       "         0.0000, 0.3002, 0.2903, 0.1048, 0.2313, 0.0000, 0.3628, 0.1583, 0.3799,\n",
       "         0.2174, 0.4574, 0.0000, 0.0327, 0.0000, 0.1807, 0.0000, 0.1292, 0.0996,\n",
       "         0.0000]),\n",
       " 85: tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.5145, 0.3274, 0.0000, 0.0000, 0.2280,\n",
       "         0.0248, 0.4277, 0.3084, 0.4288, 0.0835, 0.4832, 0.3708, 0.3864, 0.3589,\n",
       "         0.3513, 0.5939, 0.5194, 0.0000, 0.0635, 0.3187, 0.2439, 0.2564, 0.3704,\n",
       "         0.5237]),\n",
       " 2789: tensor([0.0000, 0.6425, 0.0000, 0.0123, 0.0000, 0.1185, 0.5008, 0.0313, 0.1388,\n",
       "         0.0000, 0.3941, 0.2731, 0.0236, 0.0780, 0.2289, 0.1201, 0.0681, 0.0327,\n",
       "         0.2926, 0.0543, 0.0000, 0.3711, 0.0000, 0.0019, 0.1696, 0.0000, 0.2562,\n",
       "         0.1140]),\n",
       " 3874: tensor([0.1671, 0.0560, 0.0083, 0.1617, 0.2070, 0.2113, 0.1997, 0.1538, 0.1670,\n",
       "         0.1149, 0.1113, 0.1005, 0.1126, 0.1250, 0.1446, 0.1926, 0.0844, 0.1439,\n",
       "         0.1549, 0.1657, 0.0797, 0.1280, 0.1022, 0.0829, 0.0858, 0.0671, 0.0000,\n",
       "         0.0999]),\n",
       " 1566: tensor([0.2252, 0.1809, 0.0000, 0.1253, 0.0000, 0.1435, 0.3181, 0.2358, 0.1412,\n",
       "         0.0000, 0.1354, 0.2256, 0.1157, 0.0000, 0.2626, 0.0000, 0.1195, 0.4107,\n",
       "         0.0000, 0.2497, 0.4738, 0.1301, 0.0000, 0.2388, 0.1610, 0.3409, 0.1427,\n",
       "         0.1127]),\n",
       " 3970: tensor([0.4032, 0.0000, 0.0758, 0.2726, 0.0000, 0.0000, 0.0866, 0.0000, 0.0750,\n",
       "         0.0352, 0.0758, 0.0613, 0.0011, 0.2725, 0.1344, 0.0000, 0.0614, 0.1057,\n",
       "         0.2500, 0.1890, 0.1206, 0.0000, 0.1148, 0.2505, 0.0729, 0.1200, 0.0357,\n",
       "         0.0869]),\n",
       " 3170: tensor([0.0208, 0.0998, 0.2586, 0.1175, 0.0366, 0.1162, 0.2234, 0.0108, 0.0000,\n",
       "         0.0818, 0.0660, 0.1751, 0.1849, 0.0852, 0.2147, 0.1499, 0.2150, 0.2219,\n",
       "         0.0000, 0.1609, 0.2063, 0.2552, 0.0000, 0.1160, 0.0000, 0.3645, 0.2814,\n",
       "         0.3129]),\n",
       " 2232: tensor([0.1352, 0.0000, 0.0000, 0.3466, 0.1331, 0.1722, 0.1610, 0.1358, 0.2111,\n",
       "         0.1616, 0.1635, 0.0000, 0.2013, 0.0572, 0.1198, 0.0671, 0.0081, 0.1689,\n",
       "         0.0852, 0.2250, 0.1967, 0.3060, 0.0000, 0.0000, 0.2788, 0.5740, 0.0115,\n",
       "         0.0956]),\n",
       " 3432: tensor([0.0000, 0.0000, 0.1625, 0.1338, 0.1682, 0.0867, 0.1331, 0.1814, 0.1785,\n",
       "         0.1119, 0.0945, 0.1711, 0.1668, 0.0860, 0.0939, 0.2671, 0.0000, 0.1675,\n",
       "         0.0767, 0.1009, 0.0000, 0.1672, 0.2075, 0.0000, 0.1328, 0.1390, 0.1411,\n",
       "         0.1366]),\n",
       " 3721: tensor([0.2354, 0.0305, 0.0000, 0.0177, 0.0419, 0.4167, 0.1173, 0.2953, 0.0000,\n",
       "         0.0791, 0.1548, 0.4437, 0.2004, 0.2746, 0.0000, 0.1049, 0.0260, 0.2401,\n",
       "         0.4249, 0.2414, 0.0000, 0.1300, 0.0225, 0.1555, 0.0000, 0.0000, 0.0165,\n",
       "         0.0248]),\n",
       " 2905: tensor([0.1577, 0.1773, 0.0000, 0.0485, 0.0991, 0.3389, 0.0039, 0.1937, 0.0000,\n",
       "         0.0190, 0.1872, 0.3819, 0.2811, 0.1579, 0.0350, 0.1810, 0.0768, 0.2231,\n",
       "         0.3946, 0.1726, 0.2690, 0.1123, 0.0343, 0.2925, 0.1629, 0.0174, 0.0257,\n",
       "         0.1688]),\n",
       " 1010: tensor([0.0000, 0.1990, 0.1076, 0.0000, 0.2905, 0.0829, 0.0875, 0.1171, 0.0645,\n",
       "         0.0357, 0.0131, 0.0740, 0.1158, 0.1682, 0.1403, 0.0935, 0.0144, 0.1455,\n",
       "         0.1160, 0.1993, 0.0715, 0.1005, 0.0934, 0.1235, 0.0000, 0.1113, 0.0677,\n",
       "         0.1307]),\n",
       " 172: tensor([0.0598, 0.0401, 0.0000, 0.0999, 0.1246, 0.2279, 0.1177, 0.1927, 0.3183,\n",
       "         0.3179, 0.0237, 0.3266, 0.1534, 0.0235, 0.0724, 0.0020, 0.1033, 0.2432,\n",
       "         0.0509, 0.1478, 0.2692, 0.2052, 0.3351, 0.0000, 0.4229, 0.1575, 0.1820,\n",
       "         0.1946]),\n",
       " 2877: tensor([0.3253, 0.0000, 0.0000, 0.3383, 0.0000, 0.0000, 0.0120, 0.0000, 0.1509,\n",
       "         0.0000, 0.0746, 0.1930, 0.1614, 0.2008, 0.1319, 0.2117, 0.0853, 0.1655,\n",
       "         0.0115, 0.1440, 0.0000, 0.0000, 0.2390, 0.0811, 0.1451, 0.1196, 0.0227,\n",
       "         0.1395]),\n",
       " 1650: tensor([0.0000, 0.1586, 0.0563, 0.1058, 0.1330, 0.5323, 0.1647, 0.0028, 0.3037,\n",
       "         0.3112, 0.2680, 0.0000, 0.0992, 0.2800, 0.0000, 0.1851, 0.0000, 0.2152,\n",
       "         0.1529, 0.0000, 0.0000, 0.1660, 0.0000, 0.0369, 0.0564, 0.0000, 0.3451,\n",
       "         0.0754]),\n",
       " 2885: tensor([0.0000, 0.3150, 0.2775, 0.1611, 0.4291, 0.1499, 0.1810, 0.2746, 0.1212,\n",
       "         0.0539, 0.1874, 0.0000, 0.1981, 0.1199, 0.0000, 0.1830, 0.0000, 0.2624,\n",
       "         0.0000, 0.0827, 0.0000, 0.2493, 0.0616, 0.0409, 0.2314, 0.0000, 0.0024,\n",
       "         0.0380]),\n",
       " 1881: tensor([0.0200, 0.0914, 0.2041, 0.0000, 0.1610, 0.2657, 0.0792, 0.0000, 0.2954,\n",
       "         0.2194, 0.3816, 0.0000, 0.0799, 0.2804, 0.1302, 0.3902, 0.0000, 0.1448,\n",
       "         0.2621, 0.0485, 0.1277, 0.2736, 0.1618, 0.0359, 0.1458, 0.2010, 0.1301,\n",
       "         0.0000]),\n",
       " 1661: tensor([0.0711, 0.2161, 0.0846, 0.1727, 0.2291, 0.4282, 0.0000, 0.1291, 0.0314,\n",
       "         0.0000, 0.0959, 0.1706, 0.2246, 0.1354, 0.0250, 0.0000, 0.3371, 0.0000,\n",
       "         0.2596, 0.0000, 0.0607, 0.0000, 0.2377, 0.0451, 0.0000, 0.2631, 0.0000,\n",
       "         0.2229]),\n",
       " 620: tensor([0.0274, 0.1877, 0.2445, 0.0278, 0.0766, 0.0954, 0.1583, 0.2451, 0.0000,\n",
       "         0.1359, 0.1914, 0.0000, 0.0713, 0.0000, 0.0000, 0.0000, 0.0692, 0.2416,\n",
       "         0.0000, 0.0000, 0.1729, 0.0548, 0.1004, 0.0000, 0.2091, 0.1818, 0.1135,\n",
       "         0.1424]),\n",
       " 2734: tensor([0.1533, 0.0495, 0.2037, 0.1753, 0.2638, 0.0747, 0.4122, 0.0515, 0.2565,\n",
       "         0.0541, 0.1707, 0.1457, 0.0524, 0.0260, 0.1301, 0.2143, 0.1176, 0.2769,\n",
       "         0.0000, 0.1379, 0.1506, 0.3325, 0.0000, 0.1392, 0.0000, 0.1755, 0.2579,\n",
       "         0.2604]),\n",
       " 1441: tensor([0.1140, 0.0781, 0.1184, 0.0929, 0.0000, 0.1054, 0.1372, 0.0645, 0.1863,\n",
       "         0.0841, 0.1455, 0.0309, 0.0383, 0.1952, 0.1415, 0.2159, 0.1901, 0.1984,\n",
       "         0.0054, 0.0561, 0.2180, 0.0398, 0.0000, 0.1123, 0.2235, 0.1156, 0.1450,\n",
       "         0.1010]),\n",
       " 3204: tensor([0.0000, 0.1948, 0.0569, 0.1737, 0.2407, 0.2830, 0.1314, 0.2077, 0.3797,\n",
       "         0.1467, 0.0872, 0.0000, 0.1625, 0.4746, 0.0000, 0.1230, 0.0000, 0.1500,\n",
       "         0.0000, 0.2209, 0.0000, 0.0000, 0.0000, 0.1542, 0.1510, 0.0911, 0.0064,\n",
       "         0.0845]),\n",
       " 2923: tensor([0.1529, 0.0320, 0.1070, 0.1588, 0.0972, 0.0892, 0.1482, 0.1434, 0.1831,\n",
       "         0.0957, 0.0505, 0.0729, 0.0896, 0.1420, 0.2015, 0.1073, 0.0000, 0.1037,\n",
       "         0.1544, 0.1658, 0.1343, 0.0381, 0.0271, 0.1559, 0.1455, 0.1058, 0.1574,\n",
       "         0.1434]),\n",
       " 2178: tensor([0.0000, 0.1820, 0.0323, 0.0676, 0.0000, 0.3792, 0.0000, 0.1480, 0.0000,\n",
       "         0.2993, 0.2171, 0.3000, 0.1560, 0.0344, 0.1581, 0.3424, 0.2059, 0.4026,\n",
       "         0.0000, 0.2140, 0.2643, 0.2893, 0.0000, 0.3666, 0.1564, 0.3168, 0.2652,\n",
       "         0.0000]),\n",
       " 1179: tensor([0.0000, 0.0000, 0.0000, 0.1584, 0.1340, 0.1893, 0.1831, 0.2772, 0.1637,\n",
       "         0.3044, 0.1931, 0.2154, 0.1228, 0.4486, 0.2044, 0.5510, 0.0000, 0.2268,\n",
       "         0.0000, 0.1110, 0.0000, 0.2781, 0.2925, 0.0000, 0.2011, 0.2235, 0.0000,\n",
       "         0.2585]),\n",
       " 1369: tensor([0.3326, 0.2751, 0.0000, 0.1765, 0.0231, 0.2641, 0.0000, 0.2302, 0.0000,\n",
       "         0.0968, 0.1921, 0.3041, 0.2350, 0.2073, 0.0000, 0.2383, 0.0791, 0.1545,\n",
       "         0.2751, 0.2173, 0.0104, 0.0000, 0.0921, 0.3306, 0.0165, 0.0906, 0.2115,\n",
       "         0.2375]),\n",
       " 566: tensor([0.0857, 0.1071, 0.1130, 0.0953, 0.1346, 0.1531, 0.0000, 0.1275, 0.1159,\n",
       "         0.0834, 0.0711, 0.2599, 0.0570, 0.0000, 0.0000, 0.1161, 0.1049, 0.0593,\n",
       "         0.1668, 0.1605, 0.0927, 0.0287, 0.1052, 0.1192, 0.0991, 0.1249, 0.0386,\n",
       "         0.0808]),\n",
       " 4143: tensor([0.1697, 0.1387, 0.1975, 0.0671, 0.1565, 0.0440, 0.1340, 0.0544, 0.0998,\n",
       "         0.1542, 0.1058, 0.1074, 0.0000, 0.0000, 0.0669, 0.1476, 0.0777, 0.1188,\n",
       "         0.0000, 0.0673, 0.1885, 0.2331, 0.1848, 0.1106, 0.1231, 0.1327, 0.1094,\n",
       "         0.0880]),\n",
       " 3330: tensor([0.0655, 0.1885, 0.0565, 0.1239, 0.2297, 0.2279, 0.0584, 0.1470, 0.2399,\n",
       "         0.1029, 0.1222, 0.1917, 0.0000, 0.0000, 0.0000, 0.1105, 0.1167, 0.0081,\n",
       "         0.2477, 0.0348, 0.0969, 0.0615, 0.0523, 0.2965, 0.0941, 0.1846, 0.0474,\n",
       "         0.0776]),\n",
       " 536: tensor([0.0856, 0.1717, 0.0776, 0.0761, 0.1294, 0.2108, 0.1728, 0.2182, 0.0642,\n",
       "         0.1474, 0.1323, 0.0837, 0.1176, 0.0000, 0.0000, 0.1169, 0.1330, 0.0895,\n",
       "         0.0000, 0.0081, 0.1371, 0.0674, 0.1173, 0.0000, 0.2507, 0.1496, 0.1003,\n",
       "         0.1015]),\n",
       " 2730: tensor([0.2620, 0.1333, 0.2916, 0.0778, 0.2875, 0.2565, 0.1424, 0.1618, 0.2163,\n",
       "         0.0000, 0.1971, 0.1450, 0.0489, 0.2506, 0.1582, 0.0000, 0.0402, 0.0000,\n",
       "         0.2532, 0.0797, 0.0167, 0.0000, 0.2507, 0.1508, 0.0000, 0.1185, 0.0000,\n",
       "         0.2635]),\n",
       " 4011: tensor([0.1040, 0.1065, 0.0000, 0.1166, 0.1749, 0.0999, 0.0970, 0.1028, 0.2503,\n",
       "         0.1848, 0.0912, 0.1891, 0.2352, 0.0588, 0.1217, 0.0428, 0.0900, 0.1606,\n",
       "         0.1031, 0.1075, 0.1776, 0.1180, 0.0638, 0.0000, 0.1738, 0.1461, 0.0766,\n",
       "         0.1266]),\n",
       " 4330: tensor([0.0000, 0.1122, 0.2057, 0.1667, 0.0608, 0.4466, 0.1579, 0.1643, 0.2924,\n",
       "         0.2505, 0.0936, 0.0000, 0.1226, 0.2337, 0.0000, 0.0706, 0.0000, 0.0710,\n",
       "         0.1351, 0.0911, 0.0644, 0.1234, 0.0000, 0.0654, 0.2151, 0.2965, 0.1393,\n",
       "         0.2300]),\n",
       " 4380: tensor([0.2106, 0.0000, 0.0887, 0.1937, 0.0000, 0.0000, 0.0769, 0.0000, 0.0977,\n",
       "         0.1632, 0.1038, 0.1730, 0.1846, 0.1808, 0.1836, 0.1683, 0.0000, 0.1249,\n",
       "         0.0274, 0.0397, 0.1655, 0.0000, 0.0711, 0.0940, 0.1389, 0.0705, 0.1257,\n",
       "         0.1592]),\n",
       " 4363: tensor([0.0000, 0.1554, 0.1564, 0.0000, 0.1872, 0.1258, 0.1504, 0.0821, 0.0611,\n",
       "         0.1068, 0.0041, 0.0969, 0.1408, 0.1937, 0.0433, 0.2212, 0.0449, 0.1000,\n",
       "         0.1340, 0.1598, 0.1302, 0.1138, 0.1359, 0.0956, 0.0000, 0.1685, 0.0932,\n",
       "         0.0561]),\n",
       " 2781: tensor([0.0000, 0.0000, 0.0935, 0.1428, 0.1696, 0.0766, 0.1029, 0.1713, 0.1945,\n",
       "         0.1244, 0.0715, 0.1623, 0.1370, 0.0570, 0.1553, 0.2613, 0.0000, 0.0848,\n",
       "         0.0632, 0.0570, 0.0000, 0.1380, 0.1990, 0.0000, 0.1136, 0.1636, 0.1320,\n",
       "         0.0961]),\n",
       " 4018: tensor([0.0737, 0.1067, 0.0898, 0.1183, 0.0940, 0.2278, 0.0617, 0.1005, 0.1354,\n",
       "         0.0241, 0.1606, 0.1836, 0.2044, 0.0729, 0.1071, 0.0000, 0.1852, 0.0000,\n",
       "         0.1658, 0.1342, 0.1097, 0.0000, 0.2100, 0.0030, 0.0000, 0.1276, 0.0000,\n",
       "         0.1354]),\n",
       " 1008: tensor([0.2208, 0.1900, 0.1841, 0.2226, 0.0810, 0.0811, 0.1214, 0.1867, 0.1195,\n",
       "         0.0785, 0.1226, 0.0017, 0.2361, 0.0000, 0.0000, 0.1837, 0.2078, 0.1174,\n",
       "         0.0021, 0.0200, 0.1116, 0.2052, 0.1403, 0.0000, 0.3154, 0.0827, 0.1451,\n",
       "         0.1151]),\n",
       " 4269: tensor([0.1656, 0.1829, 0.0000, 0.0905, 0.2018, 0.1818, 0.0562, 0.0807, 0.2723,\n",
       "         0.2016, 0.1432, 0.1545, 0.1845, 0.0837, 0.1022, 0.0393, 0.2953, 0.1994,\n",
       "         0.0446, 0.1883, 0.1520, 0.1763, 0.1948, 0.0000, 0.2557, 0.0680, 0.1007,\n",
       "         0.0847]),\n",
       " 4283: tensor([0.3020, 0.1830, 0.0000, 0.2114, 0.3236, 0.1862, 0.2847, 0.1398, 0.3748,\n",
       "         0.2268, 0.1555, 0.0738, 0.2659, 0.2065, 0.2291, 0.2804, 0.5031, 0.1603,\n",
       "         0.2339, 0.2396, 0.0686, 0.0267, 0.2089, 0.0000, 0.4378, 0.1160, 0.1653,\n",
       "         0.0000]),\n",
       " 2449: tensor([0.2944, 0.1422, 0.1998, 0.0000, 0.0065, 0.1319, 0.1544, 0.0000, 0.0000,\n",
       "         0.0000, 0.0465, 0.1528, 0.1033, 0.2996, 0.0000, 0.2048, 0.2941, 0.0000,\n",
       "         0.0049, 0.0649, 0.0380, 0.3477, 0.3067, 0.0000, 0.1236, 0.1916, 0.2218,\n",
       "         0.0888]),\n",
       " 2371: tensor([0.0594, 0.1527, 0.1671, 0.0794, 0.0419, 0.2173, 0.1588, 0.2045, 0.0618,\n",
       "         0.0697, 0.1180, 0.1722, 0.0888, 0.0000, 0.1547, 0.2170, 0.0558, 0.1876,\n",
       "         0.0000, 0.1111, 0.2306, 0.2945, 0.2192, 0.1441, 0.1599, 0.0879, 0.0311,\n",
       "         0.0000]),\n",
       " 1986: tensor([0.0825, 0.1465, 0.1689, 0.1860, 0.0000, 0.1221, 0.1959, 0.1185, 0.1547,\n",
       "         0.1295, 0.1739, 0.1441, 0.0910, 0.0000, 0.1258, 0.1699, 0.0956, 0.1463,\n",
       "         0.0000, 0.1193, 0.1504, 0.0076, 0.0588, 0.2016, 0.1495, 0.1490, 0.1990,\n",
       "         0.0799]),\n",
       " 3199: tensor([0.0397, 0.0000, 0.0385, 0.1143, 0.0000, 0.0484, 0.0116, 0.0080, 0.2258,\n",
       "         0.2862, 0.1636, 0.0000, 0.1249, 0.2301, 0.0000, 0.3749, 0.5362, 0.0000,\n",
       "         0.4152, 0.3028, 0.2518, 0.0000, 0.0571, 0.3529, 0.0000, 0.0000, 0.2432,\n",
       "         0.0000]),\n",
       " 4098: tensor([0.1521, 0.0000, 0.0268, 0.2506, 0.1303, 0.0000, 0.0000, 0.5676, 0.1004,\n",
       "         0.0000, 0.3376, 0.0000, 0.3802, 0.1744, 0.2034, 0.0438, 0.1769, 0.3384,\n",
       "         0.2113, 0.0000, 0.0571, 0.5828, 0.0000, 0.0000, 0.0000, 0.1121, 0.2189,\n",
       "         0.3771]),\n",
       " 1576: tensor([0.0000, 0.2587, 0.2556, 0.0000, 0.4014, 0.0000, 0.3071, 0.1904, 0.0792,\n",
       "         0.0213, 0.0564, 0.0000, 0.0897, 0.2814, 0.1559, 0.0000, 0.0354, 0.3555,\n",
       "         0.1600, 0.2461, 0.0533, 0.0524, 0.0000, 0.1999, 0.0891, 0.2745, 0.0785,\n",
       "         0.1984]),\n",
       " 450: tensor([0.0000, 0.1448, 0.2966, 0.0000, 0.3692, 0.0000, 0.0899, 0.2001, 0.3149,\n",
       "         0.1759, 0.2139, 0.0000, 0.3459, 0.4411, 0.1619, 0.0000, 0.0481, 0.2703,\n",
       "         0.2310, 0.2110, 0.0000, 0.1749, 0.1150, 0.0000, 0.1564, 0.1584, 0.2956,\n",
       "         0.0000]),\n",
       " 551: tensor([0.0000, 0.0000, 0.0000, 0.2741, 0.3051, 0.3155, 0.1571, 0.4008, 0.2128,\n",
       "         0.0667, 0.0174, 0.0631, 0.0147, 0.2290, 0.1104, 0.1778, 0.0000, 0.0000,\n",
       "         0.1434, 0.1557, 0.0000, 0.0945, 0.2390, 0.0000, 0.2477, 0.2722, 0.0000,\n",
       "         0.0000]),\n",
       " 154: tensor([0.2008, 0.0510, 0.0000, 0.0000, 0.0657, 0.2318, 0.1387, 0.0000, 0.1993,\n",
       "         0.2818, 0.2756, 0.1118, 0.0000, 0.1108, 0.2083, 0.0317, 0.0000, 0.2061,\n",
       "         0.2013, 0.2748, 0.2131, 0.4354, 0.1131, 0.0000, 0.0959, 0.3768, 0.0000,\n",
       "         0.0000]),\n",
       " 880: tensor([0.0000, 0.1508, 0.1226, 0.0000, 0.1320, 0.1417, 0.1544, 0.1225, 0.1112,\n",
       "         0.0720, 0.1374, 0.1041, 0.1194, 0.1504, 0.0511, 0.1852, 0.0284, 0.0874,\n",
       "         0.1502, 0.1290, 0.0978, 0.1555, 0.2018, 0.1865, 0.0000, 0.0650, 0.1064,\n",
       "         0.0801]),\n",
       " 393: tensor([0.1499, 0.0000, 0.2054, 0.3430, 0.0909, 0.0000, 0.1909, 0.4627, 0.1153,\n",
       "         0.0000, 0.2784, 0.0000, 0.3248, 0.0396, 0.1138, 0.1113, 0.1880, 0.0983,\n",
       "         0.0218, 0.0034, 0.2194, 0.5625, 0.0000, 0.0000, 0.0281, 0.2692, 0.0775,\n",
       "         0.2640]),\n",
       " 869: tensor([0.0395, 0.1328, 0.1655, 0.1359, 0.0349, 0.1303, 0.1946, 0.1145, 0.1370,\n",
       "         0.1624, 0.1161, 0.1475, 0.0891, 0.0000, 0.1096, 0.1370, 0.0704, 0.1716,\n",
       "         0.0000, 0.0949, 0.2149, 0.1792, 0.1184, 0.1774, 0.1698, 0.1088, 0.1280,\n",
       "         0.1191]),\n",
       " 90: tensor([0.0689, 0.0721, 0.1882, 0.0000, 0.0000, 0.1061, 0.1963, 0.1016, 0.0000,\n",
       "         0.0000, 0.2508, 0.1924, 0.2022, 0.1986, 0.0000, 0.3357, 0.2488, 0.0000,\n",
       "         0.1276, 0.1024, 0.1510, 0.1743, 0.2578, 0.0623, 0.0000, 0.2629, 0.1371,\n",
       "         0.0825]),\n",
       " 220: tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.6909, 0.1681, 0.0022, 0.0000, 0.2744,\n",
       "         0.3309, 0.3443, 0.0432, 0.2081, 0.0828, 0.5277, 0.3104, 0.3834, 0.6069,\n",
       "         0.0000, 0.1075, 0.3910, 0.0000, 0.0567, 0.1945, 0.5332, 0.3691, 0.0000,\n",
       "         0.2159]),\n",
       " 1028: tensor([0.1478, 0.0000, 0.0000, 0.1332, 0.0000, 0.1482, 0.1946, 0.3332, 0.0933,\n",
       "         0.0391, 0.4143, 0.0000, 0.2405, 0.0000, 0.0000, 0.1276, 0.0592, 0.0000,\n",
       "         0.0207, 0.1337, 0.0000, 0.0000, 0.2962, 0.1626, 0.0000, 0.0000, 0.2365,\n",
       "         0.2361]),\n",
       " 214: tensor([0.3382, 0.0092, 0.1539, 0.1296, 0.4250, 0.0000, 0.1563, 0.2931, 0.1081,\n",
       "         0.0000, 0.0000, 0.2139, 0.2386, 0.0732, 0.1358, 0.1868, 0.1103, 0.1219,\n",
       "         0.1872, 0.2656, 0.1631, 0.2440, 0.1507, 0.0096, 0.1764, 0.0000, 0.0339,\n",
       "         0.3017]),\n",
       " 896: tensor([0.0854, 0.0433, 0.2443, 0.1273, 0.2759, 0.1008, 0.2500, 0.1310, 0.0047,\n",
       "         0.2365, 0.0851, 0.1384, 0.3088, 0.0000, 0.0000, 0.1449, 0.2416, 0.1223,\n",
       "         0.2294, 0.1944, 0.0339, 0.0261, 0.2835, 0.0586, 0.1012, 0.1589, 0.1325,\n",
       "         0.1063]),\n",
       " 3041: tensor([0.2453, 0.0856, 0.1918, 0.1538, 0.1739, 0.0000, 0.1266, 0.2207, 0.2049,\n",
       "         0.0000, 0.1903, 0.1314, 0.1913, 0.1622, 0.2585, 0.0191, 0.0000, 0.0796,\n",
       "         0.1334, 0.1721, 0.2260, 0.0406, 0.0000, 0.1082, 0.2027, 0.0909, 0.0736,\n",
       "         0.1370]),\n",
       " 3449: tensor([0.1740, 0.0503, 0.0000, 0.0000, 0.0000, 0.2601, 0.0561, 0.2333, 0.0000,\n",
       "         0.1225, 0.2614, 0.2340, 0.2280, 0.1801, 0.1517, 0.1492, 0.3016, 0.2383,\n",
       "         0.0000, 0.0748, 0.2200, 0.2920, 0.0000, 0.2778, 0.2930, 0.3311, 0.2052,\n",
       "         0.0000]),\n",
       " 1723: tensor([0.0889, 0.1202, 0.0894, 0.0923, 0.1066, 0.2546, 0.0994, 0.0832, 0.1267,\n",
       "         0.0000, 0.1679, 0.1778, 0.1996, 0.1023, 0.1316, 0.0000, 0.2064, 0.0000,\n",
       "         0.1725, 0.1182, 0.0951, 0.0000, 0.1999, 0.0189, 0.0000, 0.1269, 0.0000,\n",
       "         0.1597]),\n",
       " 3077: tensor([0.0000, 0.2974, 0.1602, 0.0000, 0.2530, 0.0714, 0.0382, 0.3076, 0.2834,\n",
       "         0.0007, 0.0713, 0.0860, 0.0328, 0.1658, 0.2586, 0.0000, 0.0854, 0.0390,\n",
       "         0.2305, 0.3061, 0.0000, 0.1454, 0.2176, 0.1718, 0.0000, 0.0784, 0.0811,\n",
       "         0.0641]),\n",
       " 1319: tensor([0.0739, 0.1700, 0.0000, 0.0839, 0.0541, 0.3769, 0.1554, 0.1752, 0.0000,\n",
       "         0.0000, 0.1881, 0.1991, 0.1362, 0.0933, 0.0000, 0.1556, 0.1250, 0.1367,\n",
       "         0.1398, 0.2107, 0.0100, 0.1144, 0.1655, 0.1315, 0.0586, 0.1063, 0.1213,\n",
       "         0.2251]),\n",
       " 3107: tensor([0.0028, 0.2073, 0.2153, 0.2079, 0.3502, 0.4559, 0.0722, 0.0764, 0.0713,\n",
       "         0.0000, 0.1461, 0.3504, 0.1043, 0.1491, 0.1595, 0.0000, 0.2713, 0.0000,\n",
       "         0.2993, 0.1030, 0.1692, 0.0000, 0.3042, 0.0435, 0.0000, 0.1647, 0.0000,\n",
       "         0.2384]),\n",
       " 1836: tensor([0.0000, 0.0000, 0.1754, 0.0923, 0.4320, 0.0546, 0.0735, 0.2178, 0.2051,\n",
       "         0.1849, 0.0441, 0.2021, 0.1883, 0.1440, 0.0832, 0.2937, 0.0000, 0.1944,\n",
       "         0.1072, 0.1801, 0.0000, 0.3657, 0.1214, 0.0000, 0.2350, 0.2052, 0.0000,\n",
       "         0.0000]),\n",
       " 4331: tensor([0.1724, 0.2749, 0.3002, 0.0000, 0.2954, 0.3741, 0.0988, 0.2329, 0.4385,\n",
       "         0.3231, 0.1961, 0.5533, 0.2703, 0.2526, 0.0769, 0.1909, 0.1517, 0.2895,\n",
       "         0.0293, 0.0000, 0.2628, 0.1106, 0.2262, 0.0641, 0.0000, 0.2005, 0.0168,\n",
       "         0.3756]),\n",
       " 3398: tensor([0.2888, 0.1569, 0.0000, 0.2225, 0.0000, 0.1810, 0.2957, 0.2499, 0.1019,\n",
       "         0.0000, 0.1547, 0.3144, 0.3462, 0.0000, 0.2819, 0.1024, 0.1748, 0.2298,\n",
       "         0.0000, 0.1757, 0.0629, 0.0000, 0.0000, 0.2824, 0.0301, 0.0757, 0.1681,\n",
       "         0.1304]),\n",
       " 4107: tensor([0.1835, 0.2547, 0.0807, 0.0000, 0.1656, 0.1203, 0.1336, 0.0000, 0.2798,\n",
       "         0.0995, 0.2338, 0.0000, 0.0000, 0.1979, 0.0815, 0.2211, 0.0000, 0.1192,\n",
       "         0.0810, 0.2361, 0.0000, 0.1493, 0.1875, 0.0000, 0.0593, 0.4178, 0.0000,\n",
       "         0.0000]),\n",
       " 3998: tensor([0.0000, 0.0000, 0.0000, 0.3787, 0.3805, 0.1457, 0.2573, 0.0000, 0.0000,\n",
       "         0.1498, 0.3027, 0.1038, 0.0000, 0.0000, 0.4254, 0.2419, 0.3053, 0.0000,\n",
       "         0.2573, 0.5170, 0.2304, 0.2604, 0.0000, 0.2469, 0.0000, 0.2504, 0.0198,\n",
       "         0.2190]),\n",
       " 4324: tensor([0.2110, 0.2075, 0.0165, 0.2069, 0.3073, 0.2367, 0.3975, 0.1221, 0.1169,\n",
       "         0.0299, 0.0453, 0.2506, 0.2219, 0.1848, 0.2613, 0.0780, 0.3746, 0.3517,\n",
       "         0.0000, 0.2918, 0.1569, 0.2333, 0.1135, 0.0264, 0.0000, 0.1491, 0.1118,\n",
       "         0.2080]),\n",
       " 81: tensor([0.2099, 0.1917, 0.1547, 0.1345, 0.0278, 0.2185, 0.0641, 0.0585, 0.1633,\n",
       "         0.2178, 0.1017, 0.1587, 0.1661, 0.0964, 0.0965, 0.0861, 0.1267, 0.1163,\n",
       "         0.1372, 0.1584, 0.1064, 0.0752, 0.1823, 0.1162, 0.1632, 0.0000, 0.0389,\n",
       "         0.2143]),\n",
       " 3060: tensor([0.1158, 0.1894, 0.0567, 0.1961, 0.0000, 0.0000, 0.2469, 0.1397, 0.1609,\n",
       "         0.1547, 0.0668, 0.1668, 0.2535, 0.0000, 0.2446, 0.0093, 0.0962, 0.2322,\n",
       "         0.0000, 0.1061, 0.2538, 0.0000, 0.0000, 0.2683, 0.0716, 0.2859, 0.1471,\n",
       "         0.1804]),\n",
       " 1779: tensor([0.1426, 0.1698, 0.2272, 0.0958, 0.0988, 0.1042, 0.1681, 0.0401, 0.1146,\n",
       "         0.1499, 0.1208, 0.1213, 0.0253, 0.0000, 0.0654, 0.1912, 0.0892, 0.1282,\n",
       "         0.0000, 0.0895, 0.2723, 0.2617, 0.1694, 0.1187, 0.1559, 0.1574, 0.1630,\n",
       "         0.1022]),\n",
       " 4177: tensor([0.2631, 0.1688, 0.0000, 0.1093, 0.1401, 0.2063, 0.0397, 0.1126, 0.3221,\n",
       "         0.1243, 0.0237, 0.2346, 0.2472, 0.0914, 0.2393, 0.0000, 0.2813, 0.1037,\n",
       "         0.0196, 0.1912, 0.1243, 0.0839, 0.0705, 0.0000, 0.2964, 0.2691, 0.2228,\n",
       "         0.0597]),\n",
       " 2343: tensor([0.0000, 0.0828, 0.1436, 0.1205, 0.0000, 0.0952, 0.0779, 0.1367, 0.2777,\n",
       "         0.0678, 0.1492, 0.0000, 0.0000, 0.0201, 0.1459, 0.1602, 0.3019, 0.1857,\n",
       "         0.0000, 0.2680, 0.3175, 0.0000, 0.0000, 0.0000, 0.0744, 0.1317, 0.1084,\n",
       "         0.1713]),\n",
       " 1052: tensor([0.1914, 0.0000, 0.0000, 0.1872, 0.1677, 0.1601, 0.0000, 0.2361, 0.0393,\n",
       "         0.0036, 0.2746, 0.0000, 0.0289, 0.1951, 0.0000, 0.1122, 0.0849, 0.0699,\n",
       "         0.2388, 0.0371, 0.2256, 0.1355, 0.3288, 0.2837, 0.2309, 0.1786, 0.0000,\n",
       "         0.1264]),\n",
       " 3422: tensor([0.0810, 0.1375, 0.0000, 0.0835, 0.1690, 0.7181, 0.0888, 0.2071, 0.0000,\n",
       "         0.0000, 0.2631, 0.3091, 0.2177, 0.1093, 0.0000, 0.2108, 0.0899, 0.0567,\n",
       "         0.3331, 0.0576, 0.0000, 0.0653, 0.1325, 0.0529, 0.0000, 0.0722, 0.1266,\n",
       "         0.1753]),\n",
       " 4489: tensor([0.1603, 0.0757, 0.0184, 0.2068, 0.0000, 0.2589, 0.1296, 0.2393, 0.2737,\n",
       "         0.1582, 0.2022, 0.0000, 0.0000, 0.3055, 0.1538, 0.2824, 0.0225, 0.0916,\n",
       "         0.0000, 0.0497, 0.4796, 0.0234, 0.0000, 0.0000, 0.0834, 0.6501, 0.1773,\n",
       "         0.2931]),\n",
       " 3603: tensor([0.3638, 0.1631, 0.2384, 0.1496, 0.1925, 0.0000, 0.1862, 0.1532, 0.2198,\n",
       "         0.1258, 0.0000, 0.2767, 0.2284, 0.1191, 0.0918, 0.1476, 0.2490, 0.0833,\n",
       "         0.2278, 0.1767, 0.1413, 0.1851, 0.3635, 0.0000, 0.3073, 0.0000, 0.0926,\n",
       "         0.2762]),\n",
       " 1054: tensor([0.0000, 0.2775, 0.0000, 0.0000, 0.4336, 0.1849, 0.2325, 0.1275, 0.2831,\n",
       "         0.1431, 0.0414, 0.0247, 0.1406, 0.1301, 0.1783, 0.1162, 0.0817, 0.3420,\n",
       "         0.3022, 0.1397, 0.0155, 0.2332, 0.0000, 0.2654, 0.0067, 0.0767, 0.0500,\n",
       "         0.2059]),\n",
       " 945: tensor([0.1513, 0.2174, 0.0401, 0.1243, 0.0550, 0.0796, 0.1546, 0.2063, 0.0267,\n",
       "         0.1713, 0.0787, 0.1253, 0.2562, 0.0000, 0.0000, 0.0567, 0.1661, 0.0271,\n",
       "         0.0556, 0.1525, 0.1744, 0.1028, 0.0843, 0.0000, 0.2282, 0.1204, 0.0975,\n",
       "         0.1591]),\n",
       " 2413: tensor([0.0491, 0.1489, 0.1579, 0.1928, 0.0000, 0.0697, 0.1502, 0.1142, 0.0997,\n",
       "         0.1603, 0.1274, 0.1686, 0.0453, 0.0000, 0.1377, 0.1534, 0.0669, 0.1494,\n",
       "         0.0000, 0.1130, 0.2385, 0.0808, 0.0706, 0.2023, 0.1508, 0.1572, 0.1672,\n",
       "         0.1176]),\n",
       " 2872: tensor([0.1781, 0.3927, 0.1780, 0.3137, 0.0000, 0.1670, 0.0000, 0.3170, 0.0000,\n",
       "         0.1118, 0.3531, 0.3433, 0.2935, 0.1238, 0.0710, 0.1127, 0.1996, 0.2718,\n",
       "         0.1381, 0.3105, 0.1112, 0.0156, 0.2513, 0.1399, 0.0000, 0.0000, 0.0000,\n",
       "         0.1598]),\n",
       " 2470: tensor([0.3272, 0.2036, 0.1377, 0.0729, 0.1762, 0.5553, 0.0538, 0.0000, 0.2109,\n",
       "         0.1551, 0.1950, 0.3364, 0.3879, 0.1627, 0.2113, 0.1326, 0.2126, 0.2433,\n",
       "         0.0000, 0.1931, 0.3017, 0.1414, 0.1953, 0.0000, 0.0000, 0.4808, 0.2163,\n",
       "         0.0000]),\n",
       " 976: tensor([0.1362, 0.0954, 0.1280, 0.1279, 0.2085, 0.0000, 0.0243, 0.1034, 0.0651,\n",
       "         0.0240, 0.1967, 0.1902, 0.2375, 0.0000, 0.0000, 0.1357, 0.1845, 0.0599,\n",
       "         0.2021, 0.2168, 0.0872, 0.0694, 0.2173, 0.0071, 0.1794, 0.1498, 0.1641,\n",
       "         0.1264]),\n",
       " 1701: tensor([0.1948, 0.1601, 0.0909, 0.2611, 0.0000, 0.0464, 0.2346, 0.1635, 0.1391,\n",
       "         0.0524, 0.0700, 0.1891, 0.1512, 0.0000, 0.2029, 0.0923, 0.2195, 0.1204,\n",
       "         0.0000, 0.2120, 0.1136, 0.0000, 0.0000, 0.2203, 0.2743, 0.1799, 0.1230,\n",
       "         0.1781]),\n",
       " 1579: tensor([0.0159, 0.0431, 0.0000, 0.0165, 0.0000, 0.0460, 0.1050, 0.2341, 0.1442,\n",
       "         0.1885, 0.1834, 0.1529, 0.1375, 0.0613, 0.1375, 0.0417, 0.2036, 0.0702,\n",
       "         0.0294, 0.1446, 0.1462, 0.1467, 0.0000, 0.1143, 0.0611, 0.2978, 0.1348,\n",
       "         0.0947]),\n",
       " 3162: tensor([0.1547, 0.0000, 0.0000, 0.1453, 0.1430, 0.1475, 0.1018, 0.1799, 0.2092,\n",
       "         0.0000, 0.1624, 0.0000, 0.1680, 0.1705, 0.0000, 0.1774, 0.1119, 0.1519,\n",
       "         0.1746, 0.0497, 0.0139, 0.1486, 0.2278, 0.0893, 0.0446, 0.1019, 0.0000,\n",
       "         0.0715]),\n",
       " 4151: tensor([0.1584, 0.1644, 0.1535, 0.0963, 0.1145, 0.1226, 0.1141, 0.1142, 0.0937,\n",
       "         0.1585, 0.1461, 0.1563, 0.0832, 0.1344, 0.1870, 0.1335, 0.0690, 0.1536,\n",
       "         0.0721, 0.0000, 0.1117, 0.3259, 0.1217, 0.2186, 0.0000, 0.1784, 0.1424,\n",
       "         0.1148]),\n",
       " 4150: tensor([0.0581, 0.0000, 0.0226, 0.2339, 0.2006, 0.0000, 0.0651, 0.3072, 0.1400,\n",
       "         0.0000, 0.1307, 0.0000, 0.1255, 0.1966, 0.1782, 0.0825, 0.2555, 0.1711,\n",
       "         0.0396, 0.0328, 0.0853, 0.2053, 0.0000, 0.0000, 0.0406, 0.1997, 0.2321,\n",
       "         0.1282]),\n",
       " 2354: tensor([0.1122, 0.1733, 0.0000, 0.0131, 0.0326, 0.2765, 0.1996, 0.2401, 0.0000,\n",
       "         0.0000, 0.1686, 0.3237, 0.0530, 0.0587, 0.0000, 0.1135, 0.1273, 0.1868,\n",
       "         0.1342, 0.1745, 0.1075, 0.0137, 0.2020, 0.1210, 0.1635, 0.0522, 0.0294,\n",
       "         0.0673]),\n",
       " 3331: tensor([0.0000, 0.0000, 0.2205, 0.0370, 0.2492, 0.1547, 0.1224, 0.1886, 0.1166,\n",
       "         0.0789, 0.1782, 0.2515, 0.1955, 0.2664, 0.1400, 0.2600, 0.0000, 0.2454,\n",
       "         0.1373, 0.1996, 0.0000, 0.2604, 0.1873, 0.0000, 0.2081, 0.0927, 0.0968,\n",
       "         0.0792]),\n",
       " 1034: tensor([0.0297, 0.2848, 0.0191, 0.2392, 0.3174, 0.4076, 0.1158, 0.2092, 0.0402,\n",
       "         0.2817, 0.0872, 0.1798, 0.3225, 0.0000, 0.0000, 0.2806, 0.2300, 0.0081,\n",
       "         0.0000, 0.0306, 0.0000, 0.0490, 0.2786, 0.0000, 0.1055, 0.2010, 0.0453,\n",
       "         0.0517]),\n",
       " 2414: tensor([0.1543, 0.0000, 0.2759, 0.0000, 0.0817, 0.0251, 0.2656, 0.0000, 0.2355,\n",
       "         0.2863, 0.1087, 0.4999, 0.2184, 0.1814, 0.2230, 0.4262, 0.0000, 0.1217,\n",
       "         0.0548, 0.1565, 0.3563, 0.0000, 0.2356, 0.0000, 0.1870, 0.2338, 0.0000,\n",
       "         0.0000]),\n",
       " 669: tensor([0.2213, 0.3960, 0.1961, 0.2631, 0.0000, 0.0000, 0.2472, 0.2345, 0.1598,\n",
       "         0.1466, 0.0608, 0.1739, 0.3640, 0.0682, 0.2096, 0.1817, 0.1083, 0.1780,\n",
       "         0.1546, 0.2651, 0.1950, 0.3504, 0.2361, 0.0730, 0.1783, 0.0000, 0.2733,\n",
       "         0.0442]),\n",
       " 3388: tensor([0.0862, 0.1079, 0.1619, 0.1152, 0.1842, 0.0842, 0.0455, 0.1389, 0.0316,\n",
       "         0.2037, 0.3159, 0.0685, 0.2198, 0.2260, 0.1887, 0.1437, 0.0000, 0.1079,\n",
       "         0.2453, 0.1924, 0.0000, 0.0377, 0.0000, 0.0574, 0.0637, 0.0077, 0.5683,\n",
       "         0.0808]),\n",
       " 3472: tensor([0.1831, 0.1528, 0.2836, 0.2232, 0.0000, 0.1411, 0.3243, 0.2564, 0.1867,\n",
       "         0.0019, 0.3062, 0.3107, 0.1492, 0.3336, 0.0000, 0.2122, 0.0528, 0.0921,\n",
       "         0.1875, 0.0326, 0.1189, 0.0256, 0.1983, 0.0041, 0.0505, 0.1056, 0.0000,\n",
       "         0.0000]),\n",
       " 4037: tensor([0.0000, 0.1745, 0.2790, 0.1303, 0.1563, 0.2981, 0.1398, 0.0633, 0.0922,\n",
       "         0.1885, 0.4647, 0.0000, 0.3008, 0.0525, 0.0000, 0.1117, 0.0000, 0.0341,\n",
       "         0.2615, 0.2317, 0.0000, 0.1553, 0.0000, 0.1792, 0.2407, 0.3110, 0.0392,\n",
       "         0.1176]),\n",
       " 4203: tensor([0.1211, 0.1558, 0.1666, 0.0572, 0.1031, 0.0761, 0.2167, 0.0952, 0.0648,\n",
       "         0.2135, 0.0873, 0.0927, 0.0109, 0.0000, 0.1178, 0.1830, 0.0841, 0.1178,\n",
       "         0.0000, 0.0727, 0.3262, 0.2464, 0.1943, 0.1791, 0.1496, 0.1706, 0.1275,\n",
       "         0.1406]),\n",
       " 4194: tensor([0.0678, 0.0000, 0.1298, 0.1375, 0.0000, 0.1358, 0.1102, 0.2121, 0.1892,\n",
       "         0.0920, 0.2188, 0.0000, 0.0876, 0.1508, 0.0000, 0.1214, 0.0000, 0.0000,\n",
       "         0.2265, 0.4192, 0.0673, 0.0000, 0.0629, 0.3702, 0.0000, 0.0000, 0.1487,\n",
       "         0.0604]),\n",
       " 2262: tensor([0.1319, 0.0000, 0.0000, 0.1282, 0.0000, 0.1705, 0.0711, 0.3518, 0.0000,\n",
       "         0.1069, 0.1508, 0.0000, 0.2304, 0.0000, 0.0000, 0.1294, 0.3529, 0.0000,\n",
       "         0.1810, 0.1416, 0.1673, 0.0000, 0.1523, 0.0231, 0.0000, 0.0000, 0.2390,\n",
       "         0.1100]),\n",
       " 2024: tensor([0.2835, 0.0000, 0.0000, 0.1882, 0.0000, 0.0000, 0.3537, 0.0000, 0.3115,\n",
       "         0.0000, 0.1381, 0.3380, 0.0340, 0.1477, 0.0000, 0.0000, 0.2873, 0.2551,\n",
       "         0.0000, 0.2660, 0.0000, 0.0000, 0.0000, 0.6362, 0.0000, 0.0000, 0.2209,\n",
       "         0.0000]),\n",
       " 2675: tensor([0.2624, 0.1938, 0.0759, 0.0553, 0.0023, 0.1808, 0.1401, 0.1387, 0.4091,\n",
       "         0.2037, 0.1719, 0.1171, 0.2200, 0.0000, 0.1521, 0.0000, 0.0345, 0.0000,\n",
       "         0.1301, 0.1250, 0.2009, 0.0000, 0.2953, 0.0711, 0.0428, 0.2272, 0.0000,\n",
       "         0.0425]),\n",
       " 2792: tensor([0.0756, 0.1355, 0.1836, 0.1436, 0.0897, 0.0991, 0.3567, 0.4682, 0.0000,\n",
       "         0.0251, 0.1443, 0.1259, 0.1278, 0.1464, 0.0769, 0.0464, 0.2420, 0.0000,\n",
       "         0.3283, 0.3226, 0.0000, 0.0000, 0.2249, 0.2851, 0.0871, 0.3165, 0.0000,\n",
       "         0.2114]),\n",
       " 2282: tensor([0.2222, 0.0994, 0.0383, 0.0353, 0.1760, 0.0000, 0.2180, 0.1289, 0.0680,\n",
       "         0.0000, 0.1445, 0.2417, 0.2099, 0.1007, 0.1801, 0.0464, 0.0169, 0.0000,\n",
       "         0.1299, 0.1180, 0.0731, 0.0000, 0.2795, 0.0735, 0.0000, 0.2135, 0.0000,\n",
       "         0.1928]),\n",
       " 2880: tensor([0.0336, 0.0000, 0.1821, 0.0190, 0.2103, 0.0000, 0.2266, 0.3330, 0.1679,\n",
       "         0.0000, 0.0000, 0.0000, 0.3392, 0.2206, 0.3176, 0.2218, 0.1200, 0.1173,\n",
       "         0.0006, 0.1745, 0.1770, 0.0000, 0.0000, 0.1871, 0.1572, 0.2600, 0.0000,\n",
       "         0.0000]),\n",
       " 372: tensor([0.1220, 0.2940, 0.1463, 0.1474, 0.3457, 0.3121, 0.0000, 0.2693, 0.0000,\n",
       "         0.3270, 0.1957, 0.1490, 0.2637, 0.0000, 0.0000, 0.0667, 0.1912, 0.1483,\n",
       "         0.0000, 0.0000, 0.0244, 0.0608, 0.2272, 0.0000, 0.0000, 0.2196, 0.2297,\n",
       "         0.1103]),\n",
       " 3489: tensor([0.1864, 0.2156, 0.1102, 0.2311, 0.0000, 0.0000, 0.1355, 0.1844, 0.2076,\n",
       "         0.1438, 0.0789, 0.1552, 0.1741, 0.0000, 0.2307, 0.1386, 0.1975, 0.1295,\n",
       "         0.0000, 0.1312, 0.0351, 0.0000, 0.0000, 0.2668, 0.1126, 0.2326, 0.1001,\n",
       "         0.1923]),\n",
       " 1737: tensor([0.0000, 0.2550, 0.2033, 0.0000, 0.1620, 0.0630, 0.2908, 0.1607, 0.0000,\n",
       "         0.0921, 0.0923, 0.0974, 0.1123, 0.2715, 0.0000, 0.1318, 0.1593, 0.0777,\n",
       "         0.1352, 0.2178, 0.1710, 0.1322, 0.0864, 0.2843, 0.0000, 0.3355, 0.0587,\n",
       "         0.1625]),\n",
       " 2693: tensor([0.0617, 0.0000, 0.3047, 0.2057, 0.0000, 0.2117, 0.1053, 0.3115, 0.2418,\n",
       "         0.0000, 0.0959, 0.0856, 0.2343, 0.0356, 0.1476, 0.0305, 0.1151, 0.0071,\n",
       "         0.0000, 0.0000, 0.0000, 0.2636, 0.0760, 0.2781, 0.1169, 0.0000, 0.3643,\n",
       "         0.0690]),\n",
       " 4447: tensor([0.3133, 0.0000, 0.0716, 0.1744, 0.0000, 0.0000, 0.0711, 0.0000, 0.2224,\n",
       "         0.1016, 0.0010, 0.1477, 0.0361, 0.1572, 0.1265, 0.1985, 0.0402, 0.3503,\n",
       "         0.1393, 0.2154, 0.3189, 0.0000, 0.1101, 0.0996, 0.0866, 0.1884, 0.0535,\n",
       "         0.0239]),\n",
       " 4313: tensor([0.0000, 0.0000, 0.0271, 0.0473, 0.0348, 0.8603, 0.0150, 0.0397, 0.0368,\n",
       "         0.0943, 0.0939, 0.0147, 0.0046, 0.1766, 0.3025, 0.1513, 0.0000, 0.0792,\n",
       "         0.1430, 0.0103, 0.0000, 0.1916, 0.0000, 0.0000, 0.2943, 0.3308, 0.0000,\n",
       "         0.0000]),\n",
       " 3510: tensor([0.0000, 0.1443, 0.1567, 0.0000, 0.3174, 0.0021, 0.0826, 0.1366, 0.2215,\n",
       "         0.0590, 0.1714, 0.0181, 0.1870, 0.1806, 0.1018, 0.0000, 0.0550, 0.2302,\n",
       "         0.2367, 0.1639, 0.0000, 0.0740, 0.1843, 0.1118, 0.0512, 0.1737, 0.1041,\n",
       "         0.1298]),\n",
       " 2281: tensor([9.4905e-02, 0.0000e+00, 2.6098e-01, 3.6521e-01, 4.6709e-01, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 3.5833e-01, 0.0000e+00, 4.1757e-01, 0.0000e+00,\n",
       "         0.0000e+00, 3.7123e-01, 7.0707e-03, 1.3308e-01, 8.8764e-03, 6.3219e-02,\n",
       "         0.0000e+00, 1.8988e-01, 5.4807e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         2.6616e-01, 3.3172e-01, 5.6369e-02, 4.0294e-04]),\n",
       " 3468: tensor([0.0000, 0.0000, 0.4567, 0.0000, 0.0671, 0.0256, 0.2091, 0.0628, 0.0000,\n",
       "         0.0000, 0.0000, 0.6122, 0.0034, 0.3252, 0.0000, 0.1388, 0.0000, 0.0000,\n",
       "         0.0413, 0.6411, 0.0000, 0.0000, 0.5297, 0.0000, 0.0000, 0.3946, 0.0271,\n",
       "         0.0424]),\n",
       " 3265: tensor([0.3147, 0.0000, 0.1458, 0.2573, 0.0000, 0.0000, 0.1175, 0.0000, 0.1067,\n",
       "         0.0000, 0.1132, 0.1693, 0.1413, 0.0839, 0.1445, 0.5015, 0.0353, 0.1898,\n",
       "         0.0000, 0.0000, 0.1566, 0.0000, 0.2018, 0.0000, 0.1425, 0.2012, 0.1732,\n",
       "         0.3416]),\n",
       " 2865: tensor([0.2089, 0.0000, 0.0000, 0.2271, 0.0000, 0.0334, 0.0000, 0.0230, 0.0000,\n",
       "         0.3948, 0.1050, 0.0000, 0.0000, 0.0000, 0.0000, 0.4463, 0.5955, 0.0000,\n",
       "         0.1476, 0.0000, 0.0431, 0.0000, 0.0000, 0.0963, 0.0000, 0.0000, 0.0112,\n",
       "         0.3069]),\n",
       " 2176: tensor([0.0000, 0.0000, 0.0000, 0.2674, 0.1575, 0.0627, 0.0094, 0.1438, 0.3193,\n",
       "         0.1778, 0.2004, 0.3545, 0.1355, 0.1467, 0.3446, 0.0521, 0.0000, 0.0551,\n",
       "         0.1706, 0.1208, 0.0000, 0.0451, 0.2692, 0.0000, 0.0729, 0.2533, 0.0231,\n",
       "         0.1730]),\n",
       " 2468: tensor([0.3297, 0.2421, 0.0872, 0.0743, 0.0000, 0.1113, 0.2228, 0.3830, 0.0470,\n",
       "         0.1375, 0.0810, 0.1889, 0.0665, 0.4760, 0.2014, 0.3223, 0.0699, 0.0655,\n",
       "         0.2055, 0.1399, 0.0121, 0.0802, 0.0000, 0.1774, 0.1973, 0.2020, 0.0000,\n",
       "         0.1593]),\n",
       " 3834: tensor([0.0940, 0.5578, 0.0000, 0.4228, 0.0385, 0.3170, 0.0000, 0.2381, 0.1063,\n",
       "         0.4584, 0.0000, 0.0000, 0.0000, 0.0000, 0.3474, 0.2175, 0.4084, 0.1710,\n",
       "         0.1027, 0.0000, 0.1665, 0.3257, 0.0000, 0.1731, 0.3535, 0.3213, 0.0000,\n",
       "         0.0000]),\n",
       " 3764: tensor([0.0000, 0.0000, 0.0000, 0.3842, 0.1181, 0.3204, 0.1443, 0.3729, 0.1275,\n",
       "         0.1270, 0.1259, 0.0061, 0.0101, 0.1411, 0.0463, 0.0177, 0.0000, 0.1103,\n",
       "         0.1258, 0.0227, 0.0000, 0.1246, 0.2348, 0.0000, 0.2512, 0.2198, 0.0850,\n",
       "         0.0000]),\n",
       " 2204: tensor([0.1126, 0.0908, 0.1569, 0.1972, 0.2250, 0.2005, 0.0881, 0.0671, 0.0828,\n",
       "         0.0415, 0.0749, 0.0645, 0.0083, 0.0419, 0.2909, 0.2023, 0.0000, 0.1759,\n",
       "         0.2242, 0.1584, 0.1183, 0.0560, 0.0000, 0.1100, 0.0994, 0.0905, 0.2844,\n",
       "         0.1864]),\n",
       " 4240: tensor([0.3500, 0.0720, 0.2107, 0.0181, 0.0000, 0.4162, 0.2916, 0.2298, 0.2778,\n",
       "         0.2593, 0.0090, 0.1122, 0.1873, 0.1502, 0.1324, 0.0000, 0.0885, 0.1887,\n",
       "         0.0774, 0.0156, 0.0665, 0.2682, 0.1828, 0.0480, 0.1331, 0.0000, 0.0038,\n",
       "         0.0164]),\n",
       " 3802: tensor([0.0540, 0.1622, 0.1821, 0.1246, 0.1485, 0.0000, 0.1782, 0.2456, 0.2184,\n",
       "         0.2472, 0.0841, 0.0252, 0.0000, 0.3006, 0.2686, 0.1287, 0.0000, 0.1605,\n",
       "         0.2087, 0.2875, 0.0341, 0.0107, 0.1710, 0.2233, 0.0852, 0.2157, 0.0496,\n",
       "         0.1275]),\n",
       " 451: tensor([0.0855, 0.1287, 0.1330, 0.1049, 0.0622, 0.0651, 0.1627, 0.1537, 0.1413,\n",
       "         0.1439, 0.1519, 0.0755, 0.0962, 0.0000, 0.0000, 0.0625, 0.1745, 0.0898,\n",
       "         0.1605, 0.0510, 0.0538, 0.0349, 0.1674, 0.0765, 0.1719, 0.1203, 0.1129,\n",
       "         0.1165]),\n",
       " 4290: tensor([0.1741, 0.1658, 0.1311, 0.1395, 0.0087, 0.1221, 0.0755, 0.0163, 0.1727,\n",
       "         0.2183, 0.1280, 0.1506, 0.1152, 0.1285, 0.0943, 0.1023, 0.1326, 0.1295,\n",
       "         0.1404, 0.1790, 0.0992, 0.0842, 0.1729, 0.1366, 0.1745, 0.0000, 0.0374,\n",
       "         0.1873]),\n",
       " 207: tensor([0.0477, 0.1552, 0.0986, 0.1153, 0.0000, 0.0000, 0.0495, 0.2003, 0.1181,\n",
       "         0.1540, 0.1520, 0.1415, 0.0836, 0.0155, 0.1858, 0.0588, 0.1470, 0.2005,\n",
       "         0.0834, 0.1516, 0.1010, 0.1364, 0.0000, 0.1701, 0.0453, 0.2300, 0.0973,\n",
       "         0.0034]),\n",
       " 494: tensor([0.0915, 0.0365, 0.0000, 0.1224, 0.2252, 0.1141, 0.1242, 0.1505, 0.1447,\n",
       "         0.1054, 0.1242, 0.1207, 0.2182, 0.1029, 0.0604, 0.1276, 0.1068, 0.1362,\n",
       "         0.0782, 0.0965, 0.1540, 0.0788, 0.0405, 0.0733, 0.1305, 0.1829, 0.0910,\n",
       "         0.0645]),\n",
       " 2422: tensor([0.1438, 0.1156, 0.1338, 0.1613, 0.0000, 0.1216, 0.1479, 0.1684, 0.0485,\n",
       "         0.1756, 0.0950, 0.0941, 0.0978, 0.1322, 0.1863, 0.1269, 0.1323, 0.1750,\n",
       "         0.0497, 0.0834, 0.1348, 0.0898, 0.0000, 0.1557, 0.1267, 0.1108, 0.0945,\n",
       "         0.0776]),\n",
       " 2641: tensor([0.1578, 0.0000, 0.3675, 0.1611, 0.0000, 0.0000, 0.1070, 0.0000, 0.0000,\n",
       "         0.0568, 0.1591, 0.1177, 0.0142, 0.2615, 0.2802, 0.2452, 0.2768, 0.1642,\n",
       "         0.1066, 0.2966, 0.0187, 0.0000, 0.0323, 0.0710, 0.1354, 0.0119, 0.0580,\n",
       "         0.0311]),\n",
       " 4137: tensor([0.0115, 0.1741, 0.1619, 0.2124, 0.0000, 0.1868, 0.2921, 0.1478, 0.1292,\n",
       "         0.0000, 0.3216, 0.2587, 0.0347, 0.2378, 0.1022, 0.1378, 0.0000, 0.1061,\n",
       "         0.0937, 0.0736, 0.1868, 0.3127, 0.2070, 0.0022, 0.0000, 0.1763, 0.0000,\n",
       "         0.0558]),\n",
       " 3343: tensor([0.0000, 0.3099, 0.0000, 0.0583, 0.0000, 0.0116, 0.0410, 0.0571, 0.1334,\n",
       "         0.3042, 0.4110, 0.1178, 0.0600, 0.1669, 0.2443, 0.1831, 0.1219, 0.2195,\n",
       "         0.1408, 0.2433, 0.2170, 0.0764, 0.2116, 0.2081, 0.0628, 0.0000, 0.0437,\n",
       "         0.1092]),\n",
       " 3341: tensor([0.0000, 0.3542, 0.2337, 0.2897, 0.1298, 0.2130, 0.2608, 0.2238, 0.5011,\n",
       "         0.0717, 0.1101, 0.0000, 0.4638, 0.0779, 0.0000, 0.1029, 0.0000, 0.1511,\n",
       "         0.0000, 0.2702, 0.0000, 0.1591, 0.0000, 0.2994, 0.3278, 0.0000, 0.1204,\n",
       "         0.1688]),\n",
       " 2590: tensor([0.1485, 0.1380, 0.2938, 0.0000, 0.2564, 0.1892, 0.0519, 0.0433, 0.0000,\n",
       "         0.0000, 0.0327, 0.0723, 0.2255, 0.3542, 0.0000, 0.2100, 0.2179, 0.0000,\n",
       "         0.0000, 0.1248, 0.2134, 0.2749, 0.2068, 0.0902, 0.1623, 0.0662, 0.1040,\n",
       "         0.1876]),\n",
       " 1746: tensor([0.0598, 0.4254, 0.0000, 0.5460, 0.0000, 0.2445, 0.5004, 0.0792, 0.5136,\n",
       "         0.0926, 0.1735, 0.0000, 0.0000, 0.4505, 0.2739, 0.0000, 0.4469, 0.3040,\n",
       "         0.0000, 0.0309, 0.2760, 0.0000, 0.0000, 0.0000, 0.4786, 0.7224, 0.3691,\n",
       "         0.3247]),\n",
       " 1617: tensor([0.1385, 0.1483, 0.1053, 0.1165, 0.0000, 0.1728, 0.0876, 0.0647, 0.1632,\n",
       "         0.1014, 0.2367, 0.0000, 0.0000, 0.1251, 0.0767, 0.1470, 0.1152, 0.1455,\n",
       "         0.0000, 0.1666, 0.1195, 0.1683, 0.0000, 0.0684, 0.1205, 0.0450, 0.2120,\n",
       "         0.1551]),\n",
       " 562: tensor([0.2107, 0.0748, 0.2065, 0.1574, 0.0175, 0.0498, 0.0512, 0.1470, 0.0583,\n",
       "         0.0000, 0.1225, 0.1832, 0.2099, 0.0000, 0.0000, 0.1977, 0.1994, 0.0910,\n",
       "         0.1758, 0.0953, 0.0878, 0.1148, 0.1531, 0.0633, 0.2799, 0.1007, 0.1350,\n",
       "         0.0750]),\n",
       " 259: tensor([0.0000, 0.0000, 0.2239, 0.2478, 0.2032, 0.4908, 0.2083, 0.2187, 0.2556,\n",
       "         0.0685, 0.3353, 0.0000, 0.1074, 0.0064, 0.2931, 0.0836, 0.0000, 0.1489,\n",
       "         0.1734, 0.0695, 0.0000, 0.0393, 0.0974, 0.0000, 0.2455, 0.0977, 0.2417,\n",
       "         0.0000]),\n",
       " 4219: tensor([0.2810, 0.0637, 0.0000, 0.0000, 0.1959, 0.1432, 0.0493, 0.0000, 0.2963,\n",
       "         0.2257, 0.5128, 0.1513, 0.0000, 0.1836, 0.0000, 0.0320, 0.0000, 0.1119,\n",
       "         0.1220, 0.2024, 0.0187, 0.1673, 0.1405, 0.0000, 0.0859, 0.3493, 0.0000,\n",
       "         0.0000]),\n",
       " 656: tensor([0.0000, 0.5078, 0.0000, 0.3607, 0.0000, 0.0000, 0.2897, 0.0272, 0.0858,\n",
       "         0.0248, 0.2428, 0.1283, 0.0000, 0.0967, 0.1823, 0.2021, 0.1498, 0.2165,\n",
       "         0.1837, 0.2753, 0.2592, 0.1660, 0.2210, 0.2173, 0.0550, 0.0000, 0.2286,\n",
       "         0.3165]),\n",
       " 2013: tensor([0.0000, 0.1665, 0.1025, 0.2481, 0.3404, 0.0722, 0.2603, 0.0000, 0.0000,\n",
       "         0.2115, 0.1995, 0.1234, 0.0000, 0.3178, 0.2346, 0.1961, 0.2198, 0.0000,\n",
       "         0.1836, 0.4749, 0.1881, 0.1477, 0.0000, 0.1839, 0.0000, 0.3295, 0.1068,\n",
       "         0.0011]),\n",
       " 1827: tensor([0.0996, 0.1073, 0.0000, 0.1589, 0.2279, 0.0486, 0.1355, 0.1154, 0.2764,\n",
       "         0.1796, 0.1089, 0.1566, 0.2798, 0.1006, 0.1587, 0.1658, 0.1603, 0.1297,\n",
       "         0.1790, 0.0739, 0.1738, 0.1382, 0.0064, 0.0000, 0.1299, 0.0993, 0.0339,\n",
       "         0.1331]),\n",
       " 1989: tensor([0.0000, 0.1570, 0.1152, 0.1702, 0.1488, 0.1350, 0.0918, 0.1714, 0.1679,\n",
       "         0.1027, 0.0344, 0.0000, 0.2104, 0.1520, 0.0000, 0.1164, 0.0000, 0.1840,\n",
       "         0.1517, 0.1868, 0.0000, 0.1011, 0.0000, 0.0644, 0.1816, 0.1392, 0.2485,\n",
       "         0.1179]),\n",
       " 2234: tensor([0.1875, 0.1524, 0.1750, 0.1252, 0.1711, 0.1936, 0.1723, 0.1309, 0.1218,\n",
       "         0.0775, 0.0946, 0.0566, 0.1250, 0.1814, 0.1773, 0.1037, 0.0856, 0.0913,\n",
       "         0.1244, 0.0442, 0.0966, 0.1472, 0.0549, 0.1982, 0.0000, 0.1459, 0.1681,\n",
       "         0.0989]),\n",
       " 1757: tensor([0.0000, 0.1965, 0.1217, 0.0000, 0.1844, 0.2197, 0.1267, 0.1275, 0.0768,\n",
       "         0.1000, 0.0407, 0.1297, 0.0964, 0.1665, 0.0872, 0.2296, 0.0471, 0.1175,\n",
       "         0.1416, 0.1967, 0.1012, 0.1283, 0.1649, 0.1453, 0.0000, 0.1424, 0.0663,\n",
       "         0.1268]),\n",
       " 3702: tensor([0.1303, 0.0766, 0.1221, 0.0714, 0.0917, 0.2710, 0.1289, 0.0663, 0.1029,\n",
       "         0.0000, 0.1427, 0.2154, 0.1766, 0.1333, 0.1472, 0.0000, 0.2238, 0.0000,\n",
       "         0.1413, 0.1323, 0.1283, 0.0000, 0.1826, 0.0544, 0.0000, 0.1296, 0.0000,\n",
       "         0.1365]),\n",
       " 2951: tensor([0.0000, 0.0000, 0.2523, 0.1106, 0.1608, 0.2511, 0.1313, 0.1152, 0.1834,\n",
       "         0.1403, 0.1436, 0.1950, 0.1103, 0.0675, 0.0615, 0.1812, 0.0000, 0.1101,\n",
       "         0.0446, 0.0896, 0.0000, 0.1241, 0.1218, 0.0000, 0.0818, 0.1167, 0.0740,\n",
       "         0.1434]),\n",
       " 4138: tensor([0.1050, 0.3052, 0.0000, 0.0000, 0.0000, 0.1526, 0.2164, 0.1702, 0.0000,\n",
       "         0.0000, 0.1178, 0.2675, 0.1856, 0.3222, 0.1750, 0.2632, 0.1557, 0.1212,\n",
       "         0.0738, 0.1044, 0.0459, 0.1717, 0.0000, 0.1351, 0.2565, 0.3465, 0.0622,\n",
       "         0.1593]),\n",
       " 3094: tensor([0.1941, 0.2027, 0.1009, 0.1089, 0.0000, 0.0653, 0.0821, 0.0102, 0.1947,\n",
       "         0.2610, 0.1651, 0.1182, 0.1559, 0.1284, 0.1117, 0.1188, 0.1343, 0.1498,\n",
       "         0.1251, 0.1759, 0.1459, 0.0825, 0.1828, 0.0971, 0.1476, 0.0000, 0.0292,\n",
       "         0.1781]),\n",
       " 3653: tensor([0.0000, 0.0914, 0.0893, 0.0988, 0.1146, 0.4796, 0.1200, 0.0392, 0.1907,\n",
       "         0.3169, 0.3024, 0.0000, 0.2313, 0.2464, 0.0000, 0.1338, 0.0000, 0.1469,\n",
       "         0.2270, 0.1033, 0.0000, 0.0973, 0.0000, 0.0452, 0.0905, 0.0000, 0.3426,\n",
       "         0.1821]),\n",
       " 2696: tensor([0.2491, 0.0000, 0.2801, 0.2572, 0.0000, 0.0000, 0.2320, 0.0000, 0.0000,\n",
       "         0.1734, 0.2382, 0.0169, 0.0000, 0.1895, 0.1301, 0.2548, 0.1586, 0.0944,\n",
       "         0.2737, 0.1884, 0.0937, 0.0000, 0.0595, 0.2663, 0.0109, 0.1086, 0.1879,\n",
       "         0.1922]),\n",
       " 4062: tensor([0.0112, 0.0593, 0.3928, 0.0145, 0.1434, 0.1066, 0.0818, 0.0000, 0.0000,\n",
       "         0.1898, 0.1547, 0.3666, 0.2626, 0.1731, 0.0951, 0.2648, 0.0734, 0.2416,\n",
       "         0.0000, 0.0475, 0.1107, 0.2213, 0.1663, 0.0726, 0.0000, 0.4833, 0.3321,\n",
       "         0.0000]),\n",
       " 3990: tensor([0.0000, 0.0906, 0.0000, 0.3118, 0.0000, 0.2066, 0.3941, 0.0835, 0.0000,\n",
       "         0.0000, 0.2298, 0.2664, 0.0000, 0.0814, 0.3332, 0.0000, 0.2262, 0.0268,\n",
       "         0.2175, 0.3380, 0.0219, 0.0000, 0.1002, 0.2470, 0.1543, 0.0000, 0.0754,\n",
       "         0.3578]),\n",
       " 3093: tensor([0.1644, 0.1020, 0.0472, 0.1556, 0.5167, 0.0000, 0.1527, 0.1794, 0.1122,\n",
       "         0.2336, 0.0000, 0.2996, 0.2914, 0.1909, 0.3290, 0.2235, 0.1371, 0.1885,\n",
       "         0.2056, 0.2412, 0.0615, 0.0950, 0.1914, 0.1261, 0.4465, 0.0000, 0.2578,\n",
       "         0.1772]),\n",
       " 4005: tensor([0.0000, 0.1701, 0.0940, 0.0353, 0.1422, 0.0971, 0.1207, 0.0000, 0.0000,\n",
       "         0.1140, 0.0883, 0.1861, 0.0000, 0.0165, 0.3695, 0.2014, 0.0000, 0.0000,\n",
       "         0.3478, 0.4347, 0.3518, 0.0156, 0.0000, 0.1032, 0.0000, 0.2011, 0.1071,\n",
       "         0.0891]),\n",
       " 1383: tensor([0.0518, 0.1528, 0.1733, 0.2032, 0.0000, 0.0606, 0.2383, 0.1228, 0.0995,\n",
       "         0.1903, 0.1767, 0.2206, 0.1035, 0.0000, 0.2127, 0.1639, 0.0340, 0.2253,\n",
       "         0.0000, 0.1567, 0.2134, 0.1122, 0.0707, 0.2395, 0.1021, 0.1670, 0.1836,\n",
       "         0.1041]),\n",
       " 3059: tensor([0.0020, 0.0000, 0.0000, 0.3280, 0.2523, 0.1361, 0.0000, 0.4718, 0.2550,\n",
       "         0.0000, 0.3086, 0.0000, 0.0935, 0.1095, 0.0000, 0.3245, 0.0000, 0.1937,\n",
       "         0.3161, 0.1218, 0.0278, 0.0862, 0.2876, 0.3794, 0.1976, 0.1357, 0.0000,\n",
       "         0.2013]),\n",
       " 3196: tensor([0.1884, 0.5731, 0.0000, 0.0681, 0.0000, 0.2246, 0.2091, 0.6553, 0.0000,\n",
       "         0.0000, 0.0000, 0.3550, 0.3548, 0.1840, 0.0000, 0.0923, 0.1119, 0.7980,\n",
       "         0.1065, 0.2674, 0.0000, 0.4844, 0.1007, 0.0000, 0.0000, 0.1364, 0.2452,\n",
       "         0.1550]),\n",
       " 3297: tensor([0.1244, 0.1655, 0.1560, 0.1380, 0.0000, 0.1963, 0.0490, 0.1543, 0.1747,\n",
       "         0.1400, 0.2170, 0.0000, 0.0000, 0.1873, 0.1068, 0.1704, 0.1383, 0.1446,\n",
       "         0.0000, 0.1742, 0.1603, 0.1141, 0.0000, 0.0000, 0.0895, 0.1743, 0.1911,\n",
       "         0.1761]),\n",
       " 1978: tensor([0.0000, 0.1519, 0.2916, 0.0000, 0.0844, 0.0000, 0.3168, 0.2865, 0.2925,\n",
       "         0.0906, 0.0339, 0.0000, 0.0540, 0.3238, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.2476, 0.2200, 0.0000, 0.0472, 0.3219, 0.1565, 0.1111, 0.3333, 0.1810,\n",
       "         0.0000]),\n",
       " 2213: tensor([0.0000, 0.0966, 0.2043, 0.0000, 0.2184, 0.0414, 0.1038, 0.0972, 0.0000,\n",
       "         0.0149, 0.2251, 0.0558, 0.2398, 0.2041, 0.1463, 0.0822, 0.1462, 0.1722,\n",
       "         0.0000, 0.1278, 0.2703, 0.0942, 0.2172, 0.2087, 0.0816, 0.0655, 0.0451,\n",
       "         0.1726]),\n",
       " 48: tensor([0.1672, 0.3994, 0.1054, 0.1556, 0.1556, 0.2312, 0.2215, 0.1920, 0.2525,\n",
       "         0.4322, 0.1185, 0.0978, 0.1668, 0.0000, 0.0000, 0.0000, 0.0906, 0.0000,\n",
       "         0.2431, 0.0486, 0.0281, 0.0000, 0.2047, 0.0068, 0.1165, 0.2667, 0.0000,\n",
       "         0.1518]),\n",
       " 3741: tensor([0.0000, 0.0887, 0.0000, 0.0000, 0.0000, 0.2300, 0.4006, 0.0868, 0.0000,\n",
       "         0.1385, 0.0035, 0.1195, 0.2540, 0.0000, 0.2435, 0.0000, 0.0000, 0.1456,\n",
       "         0.0000, 0.0000, 0.2785, 0.0000, 0.0000, 0.3765, 0.1719, 0.4158, 0.0963,\n",
       "         0.1467]),\n",
       " 212: tensor([0.0492, 0.0335, 0.1105, 0.0000, 0.0000, 0.0000, 0.0729, 0.0180, 0.0000,\n",
       "         0.0000, 0.0478, 0.0319, 0.3469, 0.0480, 0.0000, 0.1336, 0.1735, 0.0000,\n",
       "         0.0000, 0.0595, 0.1333, 0.0270, 0.2641, 0.0000, 0.2511, 0.0286, 0.1496,\n",
       "         0.2880]),\n",
       " 4472: tensor([0.3884, 0.0000, 0.1538, 0.2486, 0.1111, 0.4089, 0.4307, 0.0000, 0.0000,\n",
       "         0.3735, 0.0877, 0.1803, 0.1425, 0.3572, 0.1787, 0.2250, 0.1926, 0.2670,\n",
       "         0.0341, 0.1291, 0.0310, 0.3263, 0.2004, 0.0665, 0.0000, 0.5493, 0.2822,\n",
       "         0.1181]),\n",
       " 3672: tensor([0.2790, 0.0000, 0.0975, 0.3824, 0.0000, 0.0000, 0.0302, 0.0000, 0.0295,\n",
       "         0.1352, 0.1525, 0.0628, 0.0368, 0.1390, 0.0960, 0.1811, 0.0000, 0.0734,\n",
       "         0.2100, 0.2053, 0.0671, 0.0000, 0.0431, 0.2685, 0.0050, 0.0184, 0.2264,\n",
       "         0.0961]),\n",
       " 2091: tensor([0.0000, 0.1418, 0.0178, 0.0474, 0.0000, 0.1057, 0.2603, 0.2291, 0.1499,\n",
       "         0.2709, 0.3143, 0.0574, 0.1806, 0.1662, 0.1914, 0.0105, 0.1332, 0.1423,\n",
       "         0.0196, 0.2106, 0.1179, 0.0950, 0.1761, 0.2931, 0.2549, 0.0000, 0.1176,\n",
       "         0.3472]),\n",
       " 3876: tensor([0.2679, 0.1031, 0.2169, 0.2071, 0.1194, 0.0512, 0.1023, 0.0727, 0.0375,\n",
       "         0.2211, 0.1329, 0.2524, 0.1358, 0.0504, 0.1639, 0.1544, 0.1429, 0.0929,\n",
       "         0.0018, 0.0209, 0.0518, 0.1623, 0.0727, 0.0674, 0.0000, 0.1371, 0.2338,\n",
       "         0.2269]),\n",
       " 3222: tensor([0.0000, 0.0528, 0.1160, 0.0000, 0.1079, 0.0000, 0.0442, 0.0429, 0.0358,\n",
       "         0.0000, 0.2655, 0.0156, 0.0870, 0.1869, 0.0034, 0.0043, 0.0210, 0.1755,\n",
       "         0.0644, 0.1097, 0.2382, 0.0594, 0.0876, 0.1646, 0.0000, 0.0363, 0.0451,\n",
       "         0.1898]),\n",
       " 3337: tensor([0.0000, 0.0000, 0.3195, 0.0000, 0.1345, 0.2798, 0.0168, 0.0659, 0.1109,\n",
       "         0.1074, 0.0169, 0.1174, 0.0581, 0.2774, 0.0627, 0.1422, 0.0000, 0.2555,\n",
       "         0.1299, 0.1608, 0.0000, 0.0527, 0.1915, 0.0000, 0.0980, 0.0485, 0.1254,\n",
       "         0.1900]),\n",
       " 489: tensor([0.0000, 0.2648, 0.0547, 0.3797, 0.3791, 0.2106, 0.1177, 0.0000, 0.0000,\n",
       "         0.1427, 0.1537, 0.0341, 0.0000, 0.0000, 0.4130, 0.1927, 0.0000, 0.0000,\n",
       "         0.5595, 0.8288, 0.4564, 0.0000, 0.0000, 0.4274, 0.0000, 0.5194, 0.4712,\n",
       "         0.2763]),\n",
       " 4134: tensor([0.2071, 0.0000, 0.0000, 0.0000, 0.6942, 0.1139, 0.0512, 0.0000, 0.2837,\n",
       "         0.2654, 0.1286, 0.2591, 0.0627, 0.0496, 0.3127, 0.2083, 0.4808, 0.5324,\n",
       "         0.0000, 0.0500, 0.1350, 0.0000, 0.1421, 0.0000, 0.2818, 0.4031, 0.2213,\n",
       "         0.1651]),\n",
       " 2562: tensor([0.0662, 0.2783, 0.0000, 0.0691, 0.0438, 0.1827, 0.1094, 0.1613, 0.0000,\n",
       "         0.1499, 0.0581, 0.3052, 0.0928, 0.0000, 0.0000, 0.0714, 0.2196, 0.2647,\n",
       "         0.0371, 0.0853, 0.0643, 0.2684, 0.2757, 0.0040, 0.0328, 0.2349, 0.1059,\n",
       "         0.0987]),\n",
       " 397: tensor([0.1378, 0.0896, 0.0436, 0.1860, 0.4484, 0.0683, 0.0462, 0.0712, 0.0000,\n",
       "         0.3284, 0.1221, 0.1018, 0.2699, 0.0000, 0.0000, 0.2955, 0.1512, 0.0056,\n",
       "         0.0000, 0.2137, 0.0451, 0.0000, 0.2043, 0.0000, 0.0671, 0.2569, 0.2057,\n",
       "         0.1897]),\n",
       " 1970: tensor([0.0000, 0.1683, 0.1071, 0.1594, 0.1707, 0.1934, 0.1313, 0.1273, 0.2171,\n",
       "         0.1123, 0.1989, 0.0480, 0.3198, 0.0601, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.1748, 0.0000, 0.2021, 0.1551, 0.2754, 0.2126, 0.0000, 0.4754,\n",
       "         0.0873]),\n",
       " 1200: tensor([0.1492, 0.1316, 0.0000, 0.0000, 0.0000, 0.1245, 0.1763, 0.0891, 0.0678,\n",
       "         0.0000, 0.1090, 0.0804, 0.1138, 0.2943, 0.0666, 0.1951, 0.1251, 0.1514,\n",
       "         0.0830, 0.1503, 0.1476, 0.1947, 0.0000, 0.1338, 0.1630, 0.1223, 0.0667,\n",
       "         0.1262]),\n",
       " 2866: tensor([0.0417, 0.1666, 0.2790, 0.0734, 0.0711, 0.0645, 0.0638, 0.0000, 0.0748,\n",
       "         0.0613, 0.0931, 0.3246, 0.3208, 0.0762, 0.1230, 0.2531, 0.0829, 0.0688,\n",
       "         0.0000, 0.0000, 0.0912, 0.2149, 0.0942, 0.0187, 0.0000, 0.3755, 0.2699,\n",
       "         0.1218]),\n",
       " 4179: tensor([0.0751, 0.0000, 0.1757, 0.1333, 0.2423, 0.0000, 0.0870, 0.2075, 0.2194,\n",
       "         0.0000, 0.0939, 0.0000, 0.2113, 0.3036, 0.1685, 0.1908, 0.1558, 0.1155,\n",
       "         0.0603, 0.0444, 0.1973, 0.0000, 0.0000, 0.1308, 0.2406, 0.2081, 0.0000,\n",
       "         0.1137]),\n",
       " 3849: tensor([0.2228, 0.1373, 0.2307, 0.1613, 0.0000, 0.0585, 0.3342, 0.2571, 0.1939,\n",
       "         0.0228, 0.0785, 0.1792, 0.1272, 0.0905, 0.0811, 0.0464, 0.1525, 0.1563,\n",
       "         0.0000, 0.0000, 0.2002, 0.1082, 0.0000, 0.1084, 0.2017, 0.2284, 0.2354,\n",
       "         0.1484]),\n",
       " 3462: tensor([0.1296, 0.0000, 0.0221, 0.0989, 0.1394, 0.0000, 0.1516, 0.2886, 0.1565,\n",
       "         0.0000, 0.1901, 0.0000, 0.2206, 0.2104, 0.1151, 0.2123, 0.1911, 0.1275,\n",
       "         0.0521, 0.1485, 0.1706, 0.3153, 0.0000, 0.0000, 0.0699, 0.1598, 0.1954,\n",
       "         0.2227]),\n",
       " 1214: tensor([0.0301, 0.0807, 0.0638, 0.1538, 0.2180, 0.1008, 0.1060, 0.1560, 0.3016,\n",
       "         0.2034, 0.1685, 0.2265, 0.0813, 0.0814, 0.1092, 0.0791, 0.0934, 0.1284,\n",
       "         0.0000, 0.1571, 0.1341, 0.1483, 0.0401, 0.1061, 0.0000, 0.3627, 0.3247,\n",
       "         0.0364]),\n",
       " 3825: tensor([0.4308, 0.3607, 0.0000, 0.0000, 0.0000, 0.1900, 0.3334, 0.3663, 0.0742,\n",
       "         0.0000, 0.1429, 0.2183, 0.1084, 0.6272, 0.2563, 0.5013, 0.1475, 0.0906,\n",
       "         0.2659, 0.2634, 0.1057, 0.1452, 0.0000, 0.2985, 0.2753, 0.1218, 0.0000,\n",
       "         0.2589]),\n",
       " 1098: tensor([0.4502, 0.2658, 0.0721, 0.0266, 0.0000, 0.1695, 0.2121, 0.5427, 0.0020,\n",
       "         0.2984, 0.0313, 0.2607, 0.1232, 0.4814, 0.2670, 0.3997, 0.1363, 0.0923,\n",
       "         0.2711, 0.2396, 0.0821, 0.1777, 0.0000, 0.1582, 0.2471, 0.2696, 0.0000,\n",
       "         0.2230]),\n",
       " 4288: tensor([0.0000, 0.0000, 0.0000, 0.2471, 0.1910, 0.1549, 0.0511, 0.2426, 0.1045,\n",
       "         0.0658, 0.1948, 0.0978, 0.0000, 0.0000, 0.4043, 0.1424, 0.0000, 0.1213,\n",
       "         0.0148, 0.0000, 0.0000, 0.1037, 0.3139, 0.0000, 0.2045, 0.2682, 0.0275,\n",
       "         0.0000]),\n",
       " 1742: tensor([0.1473, 0.3527, 0.0000, 0.0512, 0.0980, 0.3295, 0.3413, 0.0965, 0.0000,\n",
       "         0.0640, 0.0000, 0.1892, 0.0546, 0.0715, 0.0000, 0.0727, 0.1665, 0.3706,\n",
       "         0.0874, 0.0728, 0.2033, 0.3869, 0.3005, 0.0000, 0.1810, 0.2616, 0.2640,\n",
       "         0.2674]),\n",
       " 2498: tensor([0.1142, 0.0757, 0.0000, 0.3323, 0.2321, 0.5085, 0.0000, 0.1223, 0.0000,\n",
       "         0.2343, 0.2674, 0.0917, 0.2769, 0.0279, 0.0000, 0.2947, 0.1785, 0.0000,\n",
       "         0.5845, 0.1411, 0.0000, 0.2719, 0.3053, 0.0000, 0.0000, 0.1263, 0.2676,\n",
       "         0.2012]),\n",
       " 2938: tensor([0.2913, 0.0000, 0.1323, 0.2186, 0.0000, 0.0000, 0.2901, 0.0000, 0.3321,\n",
       "         0.1045, 0.0892, 0.1942, 0.1557, 0.2052, 0.1832, 0.2876, 0.1331, 0.2053,\n",
       "         0.0628, 0.0558, 0.1184, 0.0000, 0.1499, 0.1813, 0.0610, 0.0808, 0.1740,\n",
       "         0.1984]),\n",
       " 1426: tensor([0.2147, 0.0000, 0.0000, 0.1540, 0.2413, 0.2748, 0.1261, 0.1248, 0.2364,\n",
       "         0.0000, 0.1468, 0.0000, 0.1391, 0.2410, 0.0544, 0.2473, 0.2046, 0.1762,\n",
       "         0.0722, 0.1703, 0.0881, 0.2457, 0.0945, 0.2744, 0.1048, 0.0748, 0.0000,\n",
       "         0.1709]),\n",
       " 4394: tensor([0.2750, 0.2279, 0.0853, 0.1199, 0.0383, 0.0365, 0.2293, 0.1917, 0.1219,\n",
       "         0.1199, 0.0559, 0.2595, 0.0098, 0.2306, 0.0484, 0.0422, 0.0000, 0.2138,\n",
       "         0.2658, 0.1626, 0.0000, 0.0600, 0.1144, 0.1424, 0.0593, 0.2100, 0.0000,\n",
       "         0.1733]),\n",
       " 1936: tensor([0.1386, 0.0000, 0.0000, 0.1669, 0.0000, 0.2108, 0.0071, 0.2995, 0.1243,\n",
       "         0.2976, 0.1882, 0.1178, 0.2980, 0.0000, 0.1725, 0.1035, 0.1900, 0.1559,\n",
       "         0.0619, 0.2659, 0.3059, 0.2538, 0.2741, 0.1687, 0.3792, 0.3963, 0.0732,\n",
       "         0.0000]),\n",
       " 3856: tensor([0.0000, 0.1774, 0.0633, 0.3109, 0.3600, 0.1126, 0.1914, 0.0000, 0.0000,\n",
       "         0.1445, 0.1992, 0.0000, 0.0000, 0.0000, 0.2938, 0.1633, 0.1025, 0.0000,\n",
       "         0.3864, 0.6035, 0.2810, 0.0000, 0.0000, 0.3261, 0.0000, 0.3788, 0.2821,\n",
       "         0.2277]),\n",
       " 53: tensor([0.0000, 0.2726, 0.3690, 0.0000, 0.2657, 0.0000, 0.2598, 0.1297, 0.1450,\n",
       "         0.1127, 0.0388, 0.0000, 0.1518, 0.3799, 0.2401, 0.0000, 0.0433, 0.4382,\n",
       "         0.2645, 0.2509, 0.0000, 0.0868, 0.1603, 0.1210, 0.1118, 0.3616, 0.2302,\n",
       "         0.0492]),\n",
       " 2402: tensor([0.0212, 0.1167, 0.3197, 0.3282, 0.0846, 0.3382, 0.1289, 0.1325, 0.2709,\n",
       "         0.0000, 0.0982, 0.0000, 0.0107, 0.1315, 0.2850, 0.1673, 0.0194, 0.0101,\n",
       "         0.2161, 0.3724, 0.1403, 0.0912, 0.0000, 0.2606, 0.0000, 0.3706, 0.2899,\n",
       "         0.0000]),\n",
       " 520: tensor([0.0000, 0.0000, 0.0527, 0.1851, 0.1028, 0.2297, 0.1366, 0.1559, 0.2524,\n",
       "         0.2170, 0.1473, 0.4002, 0.1085, 0.2027, 0.0877, 0.2373, 0.0000, 0.3206,\n",
       "         0.1505, 0.1820, 0.0000, 0.0432, 0.0755, 0.0000, 0.0540, 0.0399, 0.0000,\n",
       "         0.1734]),\n",
       " 4358: tensor([0.3169, 0.0000, 0.0039, 0.2162, 0.0000, 0.0000, 0.0286, 0.0000, 0.2351,\n",
       "         0.0000, 0.0000, 0.1059, 0.0768, 0.2096, 0.0800, 0.1460, 0.0000, 0.2090,\n",
       "         0.1319, 0.0070, 0.2119, 0.0000, 0.0793, 0.1607, 0.0537, 0.0000, 0.0514,\n",
       "         0.0819]),\n",
       " 4039: tensor([0.0000, 0.1101, 0.1795, 0.0932, 0.0000, 0.0428, 0.0292, 0.0713, 0.0695,\n",
       "         0.3605, 0.0420, 0.0516, 0.1205, 0.1885, 0.1602, 0.1491, 0.1354, 0.1664,\n",
       "         0.1459, 0.0858, 0.1359, 0.0962, 0.0000, 0.0775, 0.1042, 0.1531, 0.0000,\n",
       "         0.0431]),\n",
       " 1138: tensor([0.2071, 0.1097, 0.2179, 0.1641, 0.0000, 0.2196, 0.2825, 0.0910, 0.2827,\n",
       "         0.1826, 0.2294, 0.0000, 0.0000, 0.0678, 0.1661, 0.2011, 0.1462, 0.2938,\n",
       "         0.0000, 0.2964, 0.1607, 0.2351, 0.0000, 0.0042, 0.1180, 0.1164, 0.2971,\n",
       "         0.1852]),\n",
       " 3680: tensor([0.1525, 0.1608, 0.1533, 0.2553, 0.0000, 0.2516, 0.3761, 0.1242, 0.0598,\n",
       "         0.0455, 0.2153, 0.1026, 0.1171, 0.0599, 0.1699, 0.2065, 0.1406, 0.2208,\n",
       "         0.0177, 0.2198, 0.1960, 0.1100, 0.0000, 0.2634, 0.0342, 0.0500, 0.2740,\n",
       "         0.1907]),\n",
       " 3906: tensor([0.0019, 0.1563, 0.0000, 0.0476, 0.1633, 0.1513, 0.1207, 0.0176, 0.0976,\n",
       "         0.1267, 0.2125, 0.1127, 0.2827, 0.0694, 0.1040, 0.0000, 0.1403, 0.2176,\n",
       "         0.1869, 0.1534, 0.2780, 0.2111, 0.0000, 0.0000, 0.2646, 0.1948, 0.0000,\n",
       "         0.1251]),\n",
       " 2699: tensor([0.0000, 0.2657, 0.2726, 0.0000, 0.1034, 0.1280, 0.2337, 0.1992, 0.1288,\n",
       "         0.1248, 0.2229, 0.0297, 0.1010, 0.2886, 0.1022, 0.2455, 0.0368, 0.0546,\n",
       "         0.0580, 0.2008, 0.2397, 0.1311, 0.3078, 0.2594, 0.0460, 0.2317, 0.2208,\n",
       "         0.0796]),\n",
       " 4388: tensor([0.2109, 0.1632, 0.1636, 0.1282, 0.1109, 0.1779, 0.1520, 0.1822, 0.0722,\n",
       "         0.1013, 0.0525, 0.0658, 0.1338, 0.1837, 0.2163, 0.1330, 0.0855, 0.1184,\n",
       "         0.0075, 0.0226, 0.1096, 0.2548, 0.0529, 0.1694, 0.0000, 0.1969, 0.1543,\n",
       "         0.1027]),\n",
       " 1904: tensor([0.1710, 0.0000, 0.0875, 0.0925, 0.0393, 0.1596, 0.1384, 0.0000, 0.3040,\n",
       "         0.1555, 0.3650, 0.1483, 0.1131, 0.2866, 0.0294, 0.0827, 0.0000, 0.2143,\n",
       "         0.2155, 0.2481, 0.2240, 0.3082, 0.1720, 0.2775, 0.1380, 0.0925, 0.1044,\n",
       "         0.0000]),\n",
       " 2690: tensor([0.1400, 0.0000, 0.0653, 0.2252, 0.1749, 0.0000, 0.0000, 0.5848, 0.0556,\n",
       "         0.0000, 0.2697, 0.0000, 0.3609, 0.2198, 0.1754, 0.0000, 0.1711, 0.2970,\n",
       "         0.2262, 0.0000, 0.0238, 0.5682, 0.0000, 0.0000, 0.0000, 0.1537, 0.1895,\n",
       "         0.2686]),\n",
       " 3089: tensor([0.2149, 0.2268, 0.0874, 0.0000, 0.0946, 0.2734, 0.0154, 0.0000, 0.2327,\n",
       "         0.1799, 0.1262, 0.1839, 0.0512, 0.1521, 0.0810, 0.0191, 0.0000, 0.1130,\n",
       "         0.1950, 0.2264, 0.3769, 0.4246, 0.0983, 0.0000, 0.1215, 0.2407, 0.0000,\n",
       "         0.0000]),\n",
       " 1612: tensor([0.1932, 0.0000, 0.0903, 0.2015, 0.0000, 0.0000, 0.0635, 0.0000, 0.1131,\n",
       "         0.1675, 0.1053, 0.1677, 0.1623, 0.1623, 0.1144, 0.1369, 0.0000, 0.2078,\n",
       "         0.0941, 0.0782, 0.2228, 0.0000, 0.0518, 0.1555, 0.0818, 0.0953, 0.1334,\n",
       "         0.0948]),\n",
       " 4436: tensor([0.0944, 0.1470, 0.0000, 0.0234, 0.1047, 0.0548, 0.1259, 0.1276, 0.3034,\n",
       "         0.1272, 0.0138, 0.0886, 0.3165, 0.2012, 0.1104, 0.2863, 0.1104, 0.0405,\n",
       "         0.1345, 0.0580, 0.0911, 0.0013, 0.0958, 0.0000, 0.2774, 0.0177, 0.1575,\n",
       "         0.2107]),\n",
       " 1965: tensor([0.1832, 0.0000, 0.1278, 0.0203, 0.0722, 0.2565, 0.0766, 0.0000, 0.2164,\n",
       "         0.1543, 0.2873, 0.1502, 0.0951, 0.2260, 0.0000, 0.0810, 0.0000, 0.2293,\n",
       "         0.1625, 0.2644, 0.0382, 0.2275, 0.1814, 0.1071, 0.1277, 0.1958, 0.0606,\n",
       "         0.0000]),\n",
       " 2642: tensor([0.1289, 0.1858, 0.0000, 0.0000, 0.0000, 0.2021, 0.3750, 0.1724, 0.0000,\n",
       "         0.0456, 0.0747, 0.3341, 0.0000, 0.0000, 0.2723, 0.0000, 0.0000, 0.4485,\n",
       "         0.0000, 0.3169, 0.6779, 0.2834, 0.0000, 0.2771, 0.3514, 0.5113, 0.0431,\n",
       "         0.1386]),\n",
       " 903: tensor([0.0251, 0.1519, 0.1054, 0.1537, 0.0000, 0.0762, 0.1565, 0.1712, 0.1063,\n",
       "         0.2568, 0.1344, 0.1242, 0.1219, 0.0000, 0.1909, 0.1808, 0.0237, 0.1356,\n",
       "         0.0000, 0.0967, 0.2447, 0.1720, 0.1148, 0.2633, 0.1551, 0.1850, 0.1492,\n",
       "         0.1491]),\n",
       " 4348: tensor([0.0000, 0.1167, 0.2093, 0.0000, 0.1662, 0.1394, 0.1199, 0.1015, 0.0000,\n",
       "         0.0000, 0.2174, 0.1757, 0.3170, 0.0515, 0.0000, 0.0544, 0.1296, 0.0000,\n",
       "         0.1946, 0.1730, 0.1157, 0.0996, 0.2110, 0.0596, 0.0000, 0.1761, 0.1576,\n",
       "         0.0736]),\n",
       " 52: tensor([0.1712, 0.1642, 0.1317, 0.1412, 0.0063, 0.1205, 0.0739, 0.0192, 0.1729,\n",
       "         0.2183, 0.1243, 0.1472, 0.1171, 0.1277, 0.0920, 0.1027, 0.1319, 0.1288,\n",
       "         0.1406, 0.1795, 0.0999, 0.0854, 0.1723, 0.1337, 0.1756, 0.0000, 0.0388,\n",
       "         0.1851]),\n",
       " 3542: tensor([0.1302, 0.0910, 0.1539, 0.1590, 0.0000, 0.1036, 0.1208, 0.1864, 0.0745,\n",
       "         0.0911, 0.1027, 0.1018, 0.0952, 0.1578, 0.1337, 0.0588, 0.1248, 0.1498,\n",
       "         0.0575, 0.0818, 0.1136, 0.1237, 0.0000, 0.1556, 0.1475, 0.1572, 0.0540,\n",
       "         0.0882]),\n",
       " 4367: tensor([0.1512, 0.0302, 0.1078, 0.1635, 0.0977, 0.0860, 0.1472, 0.1436, 0.1837,\n",
       "         0.0851, 0.0500, 0.0656, 0.0937, 0.1386, 0.1999, 0.1061, 0.0000, 0.1025,\n",
       "         0.1540, 0.1646, 0.1302, 0.0372, 0.0254, 0.1546, 0.1477, 0.1055, 0.1548,\n",
       "         0.1400]),\n",
       " 3071: tensor([0.1281, 0.0981, 0.1018, 0.1377, 0.0000, 0.1488, 0.1484, 0.0957, 0.1027,\n",
       "         0.1418, 0.1547, 0.0000, 0.0000, 0.1405, 0.0859, 0.0980, 0.1748, 0.1006,\n",
       "         0.0000, 0.1501, 0.0736, 0.1184, 0.0000, 0.0303, 0.2197, 0.0623, 0.1388,\n",
       "         0.0947]),\n",
       " 2324: tensor([0.1624, 0.1948, 0.1279, 0.1275, 0.0462, 0.2840, 0.0654, 0.0407, 0.1656,\n",
       "         0.1692, 0.1062, 0.1319, 0.1481, 0.1025, 0.0867, 0.0911, 0.1336, 0.1077,\n",
       "         0.1449, 0.1454, 0.0865, 0.0449, 0.1417, 0.1340, 0.1562, 0.0000, 0.0335,\n",
       "         0.2090]),\n",
       " 534: tensor([0.2370, 0.2042, 0.0575, 0.1810, 0.1546, 0.2278, 0.1286, 0.1483, 0.2633,\n",
       "         0.1739, 0.2335, 0.1611, 0.0000, 0.0000, 0.0000, 0.1694, 0.1908, 0.1013,\n",
       "         0.0579, 0.1482, 0.0000, 0.0966, 0.1913, 0.1398, 0.1204, 0.1341, 0.1939,\n",
       "         0.0997]),\n",
       " 1844: tensor([0.2079, 0.1282, 0.1650, 0.0169, 0.1492, 0.0701, 0.1314, 0.0537, 0.0567,\n",
       "         0.1520, 0.0860, 0.1869, 0.0000, 0.0000, 0.0589, 0.1202, 0.0116, 0.0925,\n",
       "         0.0000, 0.0546, 0.2057, 0.2551, 0.1976, 0.1455, 0.1249, 0.1918, 0.0852,\n",
       "         0.0627]),\n",
       " 1404: tensor([0.2795, 0.0000, 0.0667, 0.2730, 0.0000, 0.0000, 0.0179, 0.0000, 0.1816,\n",
       "         0.0999, 0.1414, 0.1641, 0.1692, 0.1037, 0.1206, 0.2450, 0.0888, 0.2545,\n",
       "         0.0232, 0.1161, 0.1113, 0.0000, 0.1192, 0.0607, 0.0804, 0.1392, 0.0397,\n",
       "         0.1341]),\n",
       " 2879: tensor([0.0000, 0.2108, 0.1770, 0.0287, 0.1176, 0.0447, 0.0680, 0.1994, 0.0706,\n",
       "         0.3965, 0.1224, 0.0303, 0.0000, 0.3404, 0.0000, 0.0629, 0.0000, 0.1949,\n",
       "         0.1061, 0.2510, 0.0000, 0.0000, 0.2942, 0.1881, 0.0977, 0.0393, 0.2327,\n",
       "         0.1016]),\n",
       " 1774: tensor([0.0272, 0.1756, 0.3030, 0.2666, 0.2078, 0.1057, 0.2159, 0.0000, 0.1608,\n",
       "         0.1328, 0.0123, 0.0000, 0.0671, 0.1030, 0.2049, 0.2163, 0.0413, 0.0354,\n",
       "         0.0055, 0.0000, 0.0000, 0.3075, 0.1726, 0.2049, 0.0000, 0.1976, 0.3110,\n",
       "         0.0000]),\n",
       " 2346: tensor([0.0000, 0.6686, 0.0000, 0.3159, 0.0000, 0.5810, 0.4055, 0.1745, 0.1762,\n",
       "         0.0917, 0.4938, 0.3569, 0.0000, 0.4427, 0.0000, 0.0000, 0.3320, 0.3624,\n",
       "         0.3408, 0.3869, 0.3479, 0.0000, 0.3272, 0.6427, 0.2728, 0.0000, 0.0000,\n",
       "         0.5309]),\n",
       " 3057: tensor([0.1096, 0.1596, 0.0000, 0.0934, 0.1579, 0.7509, 0.0913, 0.0914, 0.0000,\n",
       "         0.0000, 0.3039, 0.3410, 0.1628, 0.0868, 0.0000, 0.2149, 0.0073, 0.0958,\n",
       "         0.2468, 0.1140, 0.0000, 0.0000, 0.2731, 0.0229, 0.0000, 0.0000, 0.1248,\n",
       "         0.2903]),\n",
       " 261: tensor([0.2160, 0.0000, 0.1157, 0.2024, 0.0000, 0.0000, 0.0950, 0.0000, 0.0930,\n",
       "         0.1789, 0.0985, 0.1470, 0.1673, 0.1784, 0.1714, 0.2215, 0.0096, 0.1538,\n",
       "         0.0579, 0.0780, 0.1698, 0.0000, 0.0758, 0.1020, 0.1519, 0.0859, 0.1106,\n",
       "         0.1860]),\n",
       " 3391: tensor([0.1137, 0.1289, 0.2001, 0.1029, 0.1436, 0.1615, 0.1824, 0.1455, 0.1185,\n",
       "         0.1589, 0.0724, 0.0467, 0.0889, 0.1896, 0.1734, 0.1137, 0.1094, 0.1252,\n",
       "         0.0664, 0.0300, 0.0886, 0.1935, 0.1040, 0.2036, 0.0000, 0.1671, 0.1467,\n",
       "         0.1377]),\n",
       " 3527: tensor([0.0000, 0.0000, 0.1261, 0.1306, 0.1600, 0.1104, 0.1060, 0.1627, 0.1903,\n",
       "         0.1253, 0.0775, 0.1633, 0.1364, 0.0891, 0.1165, 0.2719, 0.0000, 0.1167,\n",
       "         0.0813, 0.0858, 0.0000, 0.1331, 0.1736, 0.0000, 0.1271, 0.1243, 0.1498,\n",
       "         0.1079]),\n",
       " 1325: tensor([0.1796, 0.1175, 0.2940, 0.0083, 0.1809, 0.2043, 0.2198, 0.0497, 0.2892,\n",
       "         0.2624, 0.1309, 0.3864, 0.2594, 0.2741, 0.1031, 0.2029, 0.1858, 0.2199,\n",
       "         0.0000, 0.0860, 0.1765, 0.2320, 0.1377, 0.0848, 0.0000, 0.2595, 0.1167,\n",
       "         0.4027]),\n",
       " 885: tensor([0.0700, 0.1263, 0.2154, 0.0000, 0.1443, 0.1227, 0.1515, 0.1644, 0.0000,\n",
       "         0.0000, 0.1838, 0.1773, 0.2930, 0.0966, 0.0000, 0.0843, 0.1213, 0.0000,\n",
       "         0.1477, 0.1113, 0.1179, 0.1809, 0.1675, 0.1219, 0.0000, 0.1357, 0.1352,\n",
       "         0.0779]),\n",
       " 692: tensor([0.0875, 0.1790, 0.1385, 0.1405, 0.0000, 0.2032, 0.1084, 0.0686, 0.0803,\n",
       "         0.1811, 0.2190, 0.0000, 0.0000, 0.1494, 0.0770, 0.1127, 0.1857, 0.1124,\n",
       "         0.0000, 0.1038, 0.1426, 0.0690, 0.0000, 0.0000, 0.2788, 0.0144, 0.1631,\n",
       "         0.1472]),\n",
       " 156: tensor([0.0024, 0.0919, 0.0000, 0.2527, 0.0151, 0.1250, 0.2333, 0.1145, 0.0347,\n",
       "         0.0991, 0.1663, 0.1791, 0.3185, 0.0000, 0.2084, 0.0000, 0.1560, 0.0480,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0364, 0.3136, 0.1097, 0.0061, 0.0000,\n",
       "         0.2141]),\n",
       " 229: tensor([0.0000, 0.0000, 0.1222, 0.0000, 0.0000, 0.0085, 0.1602, 0.0000, 0.1351,\n",
       "         0.1583, 0.2107, 0.0000, 0.0000, 0.0256, 0.2034, 0.1796, 0.0018, 0.0029,\n",
       "         0.0000, 0.0000, 0.1959, 0.1836, 0.0000, 0.1659, 0.0000, 0.3001, 0.0133,\n",
       "         0.2633]),\n",
       " 2895: tensor([0.0165, 0.1829, 0.0000, 0.0625, 0.0000, 0.1593, 0.1878, 0.0968, 0.0720,\n",
       "         0.2604, 0.0492, 0.2614, 0.3508, 0.0000, 0.1582, 0.0000, 0.0000, 0.2665,\n",
       "         0.0000, 0.0255, 0.5191, 0.0000, 0.0000, 0.4110, 0.1199, 0.3442, 0.0884,\n",
       "         0.2066]),\n",
       " 3909: tensor([0.0000, 0.0997, 0.4164, 0.0476, 0.0893, 0.2898, 0.2719, 0.0712, 0.1445,\n",
       "         0.1609, 0.1907, 0.0511, 0.0915, 0.2179, 0.1295, 0.1689, 0.0876, 0.1630,\n",
       "         0.1048, 0.1848, 0.2478, 0.2168, 0.0209, 0.2907, 0.0000, 0.2472, 0.1704,\n",
       "         0.0490]),\n",
       " 3641: tensor([0.1098, 0.1143, 0.0000, 0.1662, 0.2663, 0.0741, 0.2287, 0.0000, 0.0087,\n",
       "         0.1774, 0.2676, 0.0000, 0.1053, 0.2011, 0.0025, 0.2130, 0.1417, 0.2096,\n",
       "         0.1776, 0.2521, 0.1130, 0.2589, 0.1206, 0.0000, 0.2720, 0.0788, 0.1325,\n",
       "         0.0950]),\n",
       " 984: tensor([0.1231, 0.1591, 0.1300, 0.1282, 0.0423, 0.0817, 0.1863, 0.1811, 0.1082,\n",
       "         0.1795, 0.1089, 0.0540, 0.1032, 0.0000, 0.0000, 0.0517, 0.1519, 0.1150,\n",
       "         0.0356, 0.0354, 0.0942, 0.0978, 0.1423, 0.0000, 0.1779, 0.1055, 0.1086,\n",
       "         0.1292]),\n",
       " 2431: tensor([0.1380, 0.1282, 0.1021, 0.1419, 0.0000, 0.1390, 0.1237, 0.1601, 0.0446,\n",
       "         0.1645, 0.1020, 0.0906, 0.1065, 0.1823, 0.1612, 0.0989, 0.1224, 0.1944,\n",
       "         0.0250, 0.0827, 0.1309, 0.0964, 0.0000, 0.1574, 0.1191, 0.1126, 0.1034,\n",
       "         0.0655]),\n",
       " 1012: tensor([0.1597, 0.1486, 0.2257, 0.0960, 0.1177, 0.0543, 0.1453, 0.0596, 0.1087,\n",
       "         0.1316, 0.1081, 0.1148, 0.0084, 0.0000, 0.0868, 0.1816, 0.1063, 0.1083,\n",
       "         0.0000, 0.0859, 0.2315, 0.2364, 0.1931, 0.1076, 0.1313, 0.1334, 0.1367,\n",
       "         0.1039]),\n",
       " 1555: tensor([0.1718, 0.0972, 0.0973, 0.1279, 0.0000, 0.1341, 0.1899, 0.0775, 0.0809,\n",
       "         0.1459, 0.1506, 0.0000, 0.0000, 0.1269, 0.0850, 0.0968, 0.1955, 0.1177,\n",
       "         0.0000, 0.1515, 0.0444, 0.1345, 0.0000, 0.0000, 0.2441, 0.0815, 0.1387,\n",
       "         0.1090]),\n",
       " 3235: tensor([0.0000, 0.2656, 0.0000, 0.1785, 0.0000, 0.2895, 0.0000, 0.1115, 0.0000,\n",
       "         0.2074, 0.3147, 0.0252, 0.2110, 0.1853, 0.1458, 0.1089, 0.2033, 0.2681,\n",
       "         0.0634, 0.2189, 0.1959, 0.0915, 0.2510, 0.2667, 0.1384, 0.0000, 0.0551,\n",
       "         0.2639]),\n",
       " 1539: tensor([0.0000, 0.0000, 0.1556, 0.0356, 0.1492, 0.1276, 0.1637, 0.0000, 0.0631,\n",
       "         0.0501, 0.2820, 0.0000, 0.4297, 0.1697, 0.1555, 0.1443, 0.0000, 0.0820,\n",
       "         0.3051, 0.2333, 0.2465, 0.3111, 0.3054, 0.0441, 0.0691, 0.2212, 0.1574,\n",
       "         0.0355]),\n",
       " 2601: tensor([0.0000, 0.1713, 0.1409, 0.3075, 0.0937, 0.2472, 0.1100, 0.1195, 0.0811,\n",
       "         0.0364, 0.0000, 0.0000, 0.0897, 0.0684, 0.0000, 0.2137, 0.0000, 0.0991,\n",
       "         0.1991, 0.1353, 0.0000, 0.0148, 0.0550, 0.2008, 0.0885, 0.2087, 0.3601,\n",
       "         0.0925]),\n",
       " 1326: tensor([0.0853, 0.0057, 0.0000, 0.1557, 0.1519, 0.3184, 0.1894, 0.2671, 0.0000,\n",
       "         0.0000, 0.1678, 0.1830, 0.1601, 0.2100, 0.0000, 0.1378, 0.2022, 0.1577,\n",
       "         0.2986, 0.2642, 0.1503, 0.1405, 0.2295, 0.1606, 0.0000, 0.0000, 0.1878,\n",
       "         0.1055]),\n",
       " 4312: tensor([0.0000, 0.1379, 0.0885, 0.2452, 0.2227, 0.3663, 0.0334, 0.0000, 0.0482,\n",
       "         0.1785, 0.2467, 0.1701, 0.0000, 0.0939, 0.0000, 0.1628, 0.0000, 0.2009,\n",
       "         0.2504, 0.4402, 0.0000, 0.1540, 0.0565, 0.1006, 0.0000, 0.0000, 0.6169,\n",
       "         0.3370]),\n",
       " 37: tensor([0.1352, 0.2154, 0.2005, 0.1473, 0.0000, 0.0000, 0.1168, 0.1264, 0.1778,\n",
       "         0.1976, 0.1836, 0.0000, 0.1444, 0.0000, 0.0000, 0.0787, 0.2369, 0.1853,\n",
       "         0.1521, 0.2056, 0.1681, 0.0810, 0.0882, 0.0329, 0.2255, 0.0680, 0.2156,\n",
       "         0.1865]),\n",
       " 650: tensor([1.4682e-01, 1.7553e-01, 1.3269e-01, 1.6036e-01, 3.2969e-01, 3.8679e-01,\n",
       "         5.2048e-05, 2.2740e-01, 7.0054e-02, 1.7147e-01, 7.8606e-02, 4.7756e-01,\n",
       "         2.5879e-01, 0.0000e+00, 0.0000e+00, 2.5464e-01, 9.7071e-02, 2.3318e-02,\n",
       "         2.4601e-01, 1.7361e-01, 7.5315e-02, 0.0000e+00, 2.6800e-01, 1.0697e-01,\n",
       "         9.0410e-02, 3.0962e-01, 8.0046e-02, 9.5051e-02]),\n",
       " 4495: tensor([0.1134, 0.0766, 0.2524, 0.0000, 0.0651, 0.1027, 0.1655, 0.1059, 0.0000,\n",
       "         0.0000, 0.1895, 0.1468, 0.3485, 0.1135, 0.0000, 0.1009, 0.1499, 0.0000,\n",
       "         0.1504, 0.1340, 0.1019, 0.2522, 0.1449, 0.1593, 0.0000, 0.1535, 0.1478,\n",
       "         0.0756]),\n",
       " 1331: tensor([0.1523, 0.0699, 0.1345, 0.0927, 0.1275, 0.1099, 0.0775, 0.1251, 0.0630,\n",
       "         0.1647, 0.0061, 0.0798, 0.1680, 0.1266, 0.0880, 0.0932, 0.0000, 0.1105,\n",
       "         0.1253, 0.0925, 0.1306, 0.0036, 0.1472, 0.1161, 0.1616, 0.0000, 0.2527,\n",
       "         0.0567]),\n",
       " 1778: tensor([0.2637, 0.0563, 0.0000, 0.2232, 0.1142, 0.1573, 0.0000, 0.0875, 0.3995,\n",
       "         0.1952, 0.0314, 0.0521, 0.0708, 0.1088, 0.0064, 0.1076, 0.0349, 0.3499,\n",
       "         0.1112, 0.2620, 0.2607, 0.3220, 0.2231, 0.0000, 0.3851, 0.5233, 0.1580,\n",
       "         0.2100]),\n",
       " 701: tensor([0.0000, 0.2123, 0.0000, 0.0639, 0.0000, 0.0000, 0.1509, 0.1588, 0.0000,\n",
       "         0.1252, 0.1086, 0.0633, 0.0422, 0.1177, 0.0000, 0.1481, 0.3502, 0.0495,\n",
       "         0.1219, 0.0000, 0.0737, 0.0255, 0.1544, 0.0000, 0.1202, 0.2316, 0.0000,\n",
       "         0.0000]),\n",
       " 3354: tensor([0.0000, 0.1339, 0.1631, 0.0939, 0.2200, 0.0470, 0.1736, 0.1690, 0.0000,\n",
       "         0.1975, 0.0306, 0.0000, 0.2215, 0.2599, 0.0000, 0.1192, 0.0000, 0.1710,\n",
       "         0.1231, 0.1605, 0.0000, 0.0427, 0.1994, 0.0595, 0.1768, 0.1420, 0.2888,\n",
       "         0.1210]),\n",
       " 1677: tensor([0.0000, 0.1584, 0.1665, 0.0000, 0.0331, 0.2121, 0.1995, 0.1221, 0.0715,\n",
       "         0.0000, 0.3421, 0.1101, 0.1750, 0.0000, 0.2069, 0.0000, 0.0249, 0.1183,\n",
       "         0.0640, 0.1067, 0.0313, 0.0179, 0.3466, 0.2953, 0.1295, 0.0792, 0.0428,\n",
       "         0.2871]),\n",
       " 908: tensor([0.4434, 0.0000, 0.1920, 0.1985, 0.0000, 0.0000, 0.0000, 0.0000, 0.2810,\n",
       "         0.1881, 0.0981, 0.1174, 0.0921, 0.3086, 0.2145, 0.3141, 0.0676, 0.2141,\n",
       "         0.1523, 0.0702, 0.1649, 0.0000, 0.0964, 0.0413, 0.1193, 0.0537, 0.0642,\n",
       "         0.3151]),\n",
       " 1662: tensor([0.1296, 0.1628, 0.1812, 0.1171, 0.0000, 0.1637, 0.2382, 0.1296, 0.0991,\n",
       "         0.1377, 0.1183, 0.1710, 0.1123, 0.0000, 0.1468, 0.1558, 0.0853, 0.2138,\n",
       "         0.0000, 0.2008, 0.2261, 0.0000, 0.0454, 0.1588, 0.2130, 0.1765, 0.1431,\n",
       "         0.1166]),\n",
       " 1853: tensor([0.0000, 0.2258, 0.3381, 0.0000, 0.2673, 0.0000, 0.1600, 0.2535, 0.1519,\n",
       "         0.0240, 0.1322, 0.0841, 0.1704, 0.4223, 0.1214, 0.0000, 0.0000, 0.2988,\n",
       "         0.2351, 0.2653, 0.0000, 0.1144, 0.1102, 0.1016, 0.0773, 0.3574, 0.1697,\n",
       "         0.1327]),\n",
       " 3997: tensor([0.0746, 0.3099, 0.0000, 0.0214, 0.0000, 0.2987, 0.1800, 0.0371, 0.1291,\n",
       "         0.1746, 0.3217, 0.0877, 0.0584, 0.1499, 0.1007, 0.1166, 0.1153, 0.1204,\n",
       "         0.2359, 0.2417, 0.2310, 0.1463, 0.0917, 0.1608, 0.1030, 0.0000, 0.0334,\n",
       "         0.1947]),\n",
       " 1511: tensor([0.1485, 0.1332, 0.1460, 0.1261, 0.0000, 0.1207, 0.1579, 0.1680, 0.0966,\n",
       "         0.1353, 0.0968, 0.0857, 0.1163, 0.1788, 0.1523, 0.0786, 0.1204, 0.1644,\n",
       "         0.0716, 0.0929, 0.1359, 0.1291, 0.0000, 0.1307, 0.1096, 0.1341, 0.0989,\n",
       "         0.0734]),\n",
       " 2842: tensor([0.2706, 0.3246, 0.0000, 0.0847, 0.0000, 0.0986, 0.0000, 0.2385, 0.1675,\n",
       "         0.1172, 0.0000, 0.0000, 0.0905, 0.0138, 0.2406, 0.2494, 0.1491, 0.1423,\n",
       "         0.3159, 0.0000, 0.1052, 0.0000, 0.0000, 0.1793, 0.0304, 0.0233, 0.0000,\n",
       "         0.2787]),\n",
       " 2518: tensor([0.0329, 0.3017, 0.0000, 0.0000, 0.0000, 0.3084, 0.0000, 0.1575, 0.0560,\n",
       "         0.0000, 0.2051, 0.3318, 0.1952, 0.1015, 0.2775, 0.2620, 0.1750, 0.0000,\n",
       "         0.0000, 0.3529, 0.0000, 0.0000, 0.1634, 0.1611, 0.0000, 0.0366, 0.1857,\n",
       "         0.0000]),\n",
       " 1867: tensor([0.0000, 0.1194, 0.2254, 0.1149, 0.2181, 0.3952, 0.1005, 0.1449, 0.2152,\n",
       "         0.0951, 0.4391, 0.0000, 0.2931, 0.1638, 0.0000, 0.1455, 0.0000, 0.2008,\n",
       "         0.1746, 0.0810, 0.0000, 0.0854, 0.0000, 0.0691, 0.1386, 0.0038, 0.0776,\n",
       "         0.0416]),\n",
       " 4025: tensor([0.0944, 0.2251, 0.0000, 0.3567, 0.3225, 0.0000, 0.0000, 0.2347, 0.0000,\n",
       "         0.2126, 0.0000, 0.1928, 0.1180, 0.2923, 0.3609, 0.0641, 0.0000, 0.0218,\n",
       "         0.0000, 0.3085, 0.0000, 0.1265, 0.6206, 0.3187, 0.3345, 0.0000, 0.3501,\n",
       "         0.0423]),\n",
       " 2806: tensor([0.1540, 0.1217, 0.0000, 0.3806, 0.3019, 0.5106, 0.0566, 0.0905, 0.1324,\n",
       "         0.2816, 0.0000, 0.0000, 0.1501, 0.0782, 0.2002, 0.2175, 0.4682, 0.1855,\n",
       "         0.0489, 0.1814, 0.2568, 0.1109, 0.1796, 0.3222, 0.2473, 0.1405, 0.0000,\n",
       "         0.1265]),\n",
       " 2823: tensor([0.0000, 0.1657, 0.1077, 0.0000, 0.1420, 0.1667, 0.1403, 0.1118, 0.1402,\n",
       "         0.0935, 0.1169, 0.1313, 0.1244, 0.1315, 0.0486, 0.1645, 0.0411, 0.1215,\n",
       "         0.1870, 0.1397, 0.1177, 0.1731, 0.1851, 0.1815, 0.0000, 0.0614, 0.1064,\n",
       "         0.0928]),\n",
       " 2168: tensor([0.0345, 0.1585, 0.1404, 0.2502, 0.0000, 0.2285, 0.2926, 0.0709, 0.1123,\n",
       "         0.1125, 0.2076, 0.0853, 0.1077, 0.0000, 0.1042, 0.1359, 0.1767, 0.0910,\n",
       "         0.0000, 0.1968, 0.0658, 0.0000, 0.0000, 0.3129, 0.2415, 0.0691, 0.2867,\n",
       "         0.1293]),\n",
       " 1177: tensor([0.0000, 0.2055, 0.1252, 0.0000, 0.1773, 0.2188, 0.1209, 0.1207, 0.0611,\n",
       "         0.0878, 0.0460, 0.1257, 0.1063, 0.1685, 0.0850, 0.2149, 0.0577, 0.1046,\n",
       "         0.1392, 0.1947, 0.0904, 0.1252, 0.1814, 0.1426, 0.0000, 0.1397, 0.0647,\n",
       "         0.1244]),\n",
       " 1700: tensor([0.0000, 0.1219, 0.1509, 0.0000, 0.1382, 0.0923, 0.1329, 0.1304, 0.0351,\n",
       "         0.0364, 0.2620, 0.0863, 0.1516, 0.1548, 0.0892, 0.1654, 0.1070, 0.1172,\n",
       "         0.0424, 0.1202, 0.1813, 0.1397, 0.2572, 0.2617, 0.0527, 0.0040, 0.0844,\n",
       "         0.1308]),\n",
       " 2549: tensor([0.1408, 0.5080, 0.1344, 0.3261, 0.0000, 0.1856, 0.2105, 0.0000, 0.2581,\n",
       "         0.2835, 0.2356, 0.0000, 0.0000, 0.1590, 0.2325, 0.0992, 0.0000, 0.0450,\n",
       "         0.0000, 0.0000, 0.1308, 0.0000, 0.0000, 0.0000, 0.1979, 0.3072, 0.1685,\n",
       "         0.2224]),\n",
       " 1467: tensor([0.2214, 0.1947, 0.0000, 0.0000, 0.0000, 0.1274, 0.2139, 0.1507, 0.0531,\n",
       "         0.0000, 0.1308, 0.1108, 0.1110, 0.2626, 0.2255, 0.1377, 0.2384, 0.1559,\n",
       "         0.0945, 0.1291, 0.2088, 0.1672, 0.0000, 0.2440, 0.2017, 0.1381, 0.0277,\n",
       "         0.1217]),\n",
       " 2886: tensor([0.1058, 0.0000, 0.0000, 0.4685, 0.2030, 0.7086, 0.0000, 0.0349, 0.1677,\n",
       "         0.2543, 0.0682, 0.0000, 0.1668, 0.0000, 0.1642, 0.0930, 0.4768, 0.0507,\n",
       "         0.0313, 0.0332, 0.4099, 0.2466, 0.3228, 0.3476, 0.3423, 0.2191, 0.0000,\n",
       "         0.0000]),\n",
       " 2434: tensor([0.2309, 0.1239, 0.0516, 0.0000, 0.0645, 0.1848, 0.1024, 0.0000, 0.1480,\n",
       "         0.2252, 0.2822, 0.2166, 0.0000, 0.1535, 0.0965, 0.0258, 0.0000, 0.1562,\n",
       "         0.1210, 0.2559, 0.1085, 0.2369, 0.1059, 0.0000, 0.0558, 0.2953, 0.0000,\n",
       "         0.0000]),\n",
       " 2105: tensor([0.1284, 0.1226, 0.1293, 0.1110, 0.1808, 0.1383, 0.1849, 0.1481, 0.1315,\n",
       "         0.1284, 0.1039, 0.0840, 0.1809, 0.1714, 0.1442, 0.0833, 0.1135, 0.1110,\n",
       "         0.1847, 0.1590, 0.1433, 0.1462, 0.0692, 0.2081, 0.0000, 0.1239, 0.1723,\n",
       "         0.1575]),\n",
       " 2653: tensor([0.2178, 0.1475, 0.2122, 0.2595, 0.0000, 0.1163, 0.1877, 0.0780, 0.2239,\n",
       "         0.0000, 0.0266, 0.3165, 0.0000, 0.0000, 0.0461, 0.2291, 0.1156, 0.1280,\n",
       "         0.0000, 0.1021, 0.1362, 0.0000, 0.0000, 0.0000, 0.2724, 0.1169, 0.2264,\n",
       "         0.1898]),\n",
       " 2240: tensor([0.1242, 0.0000, 0.0000, 0.1833, 0.0000, 0.0888, 0.1326, 0.2018, 0.2060,\n",
       "         0.0609, 0.2433, 0.0000, 0.1727, 0.1192, 0.0000, 0.0109, 0.2171, 0.0000,\n",
       "         0.2712, 0.1436, 0.0145, 0.0000, 0.1290, 0.0549, 0.0000, 0.0000, 0.2343,\n",
       "         0.0823]),\n",
       " 3075: tensor([0.0471, 0.0787, 0.0000, 0.2576, 0.0474, 0.0000, 0.2255, 0.1938, 0.0368,\n",
       "         0.0705, 0.1070, 0.2306, 0.2430, 0.1568, 0.0865, 0.3853, 0.0627, 0.1295,\n",
       "         0.3483, 0.0000, 0.2037, 0.2323, 0.0000, 0.0000, 0.2057, 0.2461, 0.0589,\n",
       "         0.2558]),\n",
       " 2676: tensor([0.0000, 0.1518, 0.1289, 0.2410, 0.3106, 0.0384, 0.1833, 0.0000, 0.0000,\n",
       "         0.1740, 0.2250, 0.0426, 0.0000, 0.1075, 0.3243, 0.1109, 0.1831, 0.0000,\n",
       "         0.3282, 0.4956, 0.2875, 0.0334, 0.0000, 0.2471, 0.0000, 0.2469, 0.1812,\n",
       "         0.1146]),\n",
       " 1781: tensor([0.2182, 0.1381, 0.1785, 0.0000, 0.2549, 0.1084, 0.0000, 0.0655, 0.0000,\n",
       "         0.0000, 0.1405, 0.0665, 0.0851, 0.0664, 0.1814, 0.3444, 0.2819, 0.0000,\n",
       "         0.2080, 0.3109, 0.0476, 0.1537, 0.3362, 0.0747, 0.0000, 0.0000, 0.0000,\n",
       "         0.2076]),\n",
       " 1553: tensor([0.0000, 0.2136, 0.0000, 0.0000, 0.0000, 0.3001, 0.0000, 0.0549, 0.0000,\n",
       "         0.0000, 0.1581, 0.0450, 0.0502, 0.3606, 0.0815, 0.4003, 0.0000, 0.1452,\n",
       "         0.1481, 0.2458, 0.1046, 0.3255, 0.0000, 0.2538, 0.0984, 0.0743, 0.1675,\n",
       "         0.0891]),\n",
       " 604: tensor([0.3279, 0.0000, 0.4733, 0.0911, 0.0000, 0.0000, 0.0740, 0.0000, 0.1545,\n",
       "         0.2004, 0.1210, 0.0079, 0.0955, 0.2785, 0.2818, 0.4127, 0.2379, 0.3346,\n",
       "         0.0272, 0.1483, 0.1000, 0.0000, 0.0000, 0.0000, 0.2333, 0.0457, 0.0749,\n",
       "         0.2667]),\n",
       " 4170: tensor([0.3235, 0.0738, 0.1867, 0.2803, 0.2915, 0.0000, 0.3696, 0.0056, 0.3131,\n",
       "         0.0587, 0.2353, 0.2493, 0.0403, 0.0267, 0.1816, 0.2838, 0.0793, 0.3230,\n",
       "         0.0000, 0.1229, 0.0819, 0.2039, 0.0000, 0.0403, 0.0000, 0.1247, 0.3512,\n",
       "         0.1547]),\n",
       " 1825: tensor([0.2563, 0.1617, 0.0000, 0.2355, 0.2042, 0.2449, 0.1673, 0.2504, 0.3100,\n",
       "         0.1177, 0.1339, 0.1911, 0.3036, 0.0696, 0.2779, 0.0000, 0.1745, 0.2522,\n",
       "         0.2817, 0.1742, 0.1860, 0.0868, 0.1533, 0.0000, 0.1907, 0.3330, 0.1953,\n",
       "         0.1366]),\n",
       " 2205: tensor([0.3757, 0.1501, 0.3815, 0.3314, 0.2760, 0.4936, 0.0000, 0.1610, 0.3907,\n",
       "         0.0000, 0.2424, 0.2490, 0.0638, 0.2971, 0.1480, 0.0000, 0.0392, 0.0000,\n",
       "         0.2937, 0.1969, 0.0000, 0.0000, 0.4047, 0.0931, 0.0000, 0.1116, 0.0000,\n",
       "         0.2565]),\n",
       " 1812: tensor([0.0000, 0.1743, 0.1275, 0.0000, 0.2943, 0.0000, 0.1342, 0.1118, 0.1496,\n",
       "         0.0866, 0.0625, 0.0448, 0.0626, 0.2069, 0.1342, 0.0412, 0.0167, 0.1737,\n",
       "         0.1713, 0.1713, 0.1295, 0.1280, 0.1004, 0.1998, 0.0000, 0.1382, 0.1145,\n",
       "         0.1022]),\n",
       " 3911: tensor([0.0000, 0.0000, 0.2099, 0.1674, 0.1009, 0.0005, 0.0000, 0.0000, 0.0631,\n",
       "         0.1809, 0.2260, 0.2811, 0.0000, 0.1102, 0.0330, 0.1677, 0.3977, 0.2722,\n",
       "         0.0155, 0.0835, 0.2127, 0.0670, 0.0000, 0.0000, 0.2123, 0.0000, 0.0528,\n",
       "         0.2038]),\n",
       " 4072: tensor([0.0000, 0.0556, 0.2690, 0.0508, 0.1367, 0.0000, 0.2146, 0.0000, 0.0000,\n",
       "         0.1796, 0.0000, 0.1782, 0.3320, 0.4695, 0.0000, 0.1586, 0.2178, 0.0608,\n",
       "         0.0205, 0.2594, 0.0000, 0.0000, 0.1563, 0.0000, 0.0598, 0.0000, 0.0402,\n",
       "         0.2414]),\n",
       " 809: tensor([0.3679, 0.0000, 0.0350, 0.0000, 0.3171, 0.2236, 0.0000, 0.1256, 0.0000,\n",
       "         0.0000, 0.1144, 0.2256, 0.1846, 0.3023, 0.1318, 0.1938, 0.3870, 0.0000,\n",
       "         0.0799, 0.0499, 0.0000, 0.0402, 0.1166, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.3615]),\n",
       " 335: tensor([0.0401, 0.1352, 0.3311, 0.1655, 0.0000, 0.1117, 0.1387, 0.1689, 0.2212,\n",
       "         0.1485, 0.1036, 0.0940, 0.1718, 0.0000, 0.1846, 0.1937, 0.0505, 0.1928,\n",
       "         0.0000, 0.1029, 0.1506, 0.0000, 0.0783, 0.1198, 0.1403, 0.1636, 0.0430,\n",
       "         0.0953]),\n",
       " 3493: tensor([0.1452, 0.1414, 0.1394, 0.1282, 0.1621, 0.1554, 0.1669, 0.1406, 0.1201,\n",
       "         0.1347, 0.0888, 0.0918, 0.1601, 0.1730, 0.1188, 0.0850, 0.1340, 0.1054,\n",
       "         0.1775, 0.1499, 0.1409, 0.1281, 0.1023, 0.2072, 0.0000, 0.1420, 0.1493,\n",
       "         0.1391]),\n",
       " 1711: tensor([0.0000, 0.1551, 0.0997, 0.1691, 0.2128, 0.1284, 0.1351, 0.0000, 0.0000,\n",
       "         0.2217, 0.1770, 0.0792, 0.0000, 0.1405, 0.2234, 0.0757, 0.1285, 0.0000,\n",
       "         0.2285, 0.3918, 0.1860, 0.0000, 0.0000, 0.1632, 0.0000, 0.1671, 0.1455,\n",
       "         0.1172]),\n",
       " 2031: tensor([0.0000, 0.1992, 0.1868, 0.0000, 0.2693, 0.0643, 0.1196, 0.1269, 0.1501,\n",
       "         0.0529, 0.0485, 0.0988, 0.0715, 0.2122, 0.1570, 0.0422, 0.0156, 0.1729,\n",
       "         0.0852, 0.2347, 0.1015, 0.0661, 0.1130, 0.0973, 0.0000, 0.1895, 0.1123,\n",
       "         0.1781]),\n",
       " 1632: tensor([0.0852, 0.0255, 0.3431, 0.1927, 0.0000, 0.0000, 0.3091, 0.2363, 0.0281,\n",
       "         0.1840, 0.1651, 0.0000, 0.0000, 0.0903, 0.1403, 0.1532, 0.0000, 0.0912,\n",
       "         0.0000, 0.2445, 0.4060, 0.2563, 0.0000, 0.0000, 0.0808, 0.1060, 0.1370,\n",
       "         0.2011]),\n",
       " 2834: tensor([0.1198, 0.2451, 0.3343, 0.0000, 0.3927, 0.1523, 0.0615, 0.2678, 0.0000,\n",
       "         0.0000, 0.1508, 0.1262, 0.0161, 0.2708, 0.2927, 0.3247, 0.3221, 0.0000,\n",
       "         0.3663, 0.3127, 0.0344, 0.1845, 0.4166, 0.2043, 0.0000, 0.0000, 0.0000,\n",
       "         0.0769]),\n",
       " 3375: tensor([0.0475, 0.2160, 0.1770, 0.0978, 0.0722, 0.1844, 0.0758, 0.0349, 0.1154,\n",
       "         0.1328, 0.0910, 0.2483, 0.1694, 0.0907, 0.1663, 0.1859, 0.1857, 0.1028,\n",
       "         0.2211, 0.0000, 0.0879, 0.1008, 0.0867, 0.0350, 0.0000, 0.2916, 0.0821,\n",
       "         0.2617]),\n",
       " 2720: tensor([0.0000e+00, 1.3679e-01, 8.9048e-02, 0.0000e+00, 3.0538e-01, 6.6050e-02,\n",
       "         1.5714e-01, 5.3958e-02, 2.4665e-02, 2.0351e-01, 1.9877e-01, 1.9031e-01,\n",
       "         2.4707e-01, 2.8881e-01, 0.0000e+00, 2.8750e-01, 1.0560e-01, 8.7704e-02,\n",
       "         0.0000e+00, 1.8530e-01, 0.0000e+00, 3.4611e-01, 2.6025e-02, 0.0000e+00,\n",
       "         9.8962e-02, 3.3993e-04, 2.1574e-01, 6.7706e-03]),\n",
       " 3713: tensor([0.0677, 0.0969, 0.0000, 0.0000, 0.0000, 0.1211, 0.1563, 0.1088, 0.0717,\n",
       "         0.1021, 0.0599, 0.1206, 0.1556, 0.2005, 0.0907, 0.1944, 0.0323, 0.1333,\n",
       "         0.1301, 0.1196, 0.0883, 0.1636, 0.0000, 0.2261, 0.0969, 0.1771, 0.2081,\n",
       "         0.1586]),\n",
       " 4298: tensor([0.2050, 0.0000, 0.0000, 0.0000, 0.3808, 0.1394, 0.1139, 0.0000, 0.2263,\n",
       "         0.1536, 0.1211, 0.0000, 0.0382, 0.1556, 0.4555, 0.2281, 0.3090, 0.3822,\n",
       "         0.1627, 0.0464, 0.1801, 0.0000, 0.2525, 0.0839, 0.2038, 0.2224, 0.2720,\n",
       "         0.3185]),\n",
       " 2126: tensor([0.1125, 0.0000, 0.0000, 0.1215, 0.0000, 0.2199, 0.3533, 0.5437, 0.0167,\n",
       "         0.0149, 0.2016, 0.0000, 0.2664, 0.0000, 0.0000, 0.0000, 0.1868, 0.0000,\n",
       "         0.1668, 0.1214, 0.0543, 0.0000, 0.2456, 0.0000, 0.0000, 0.0000, 0.3311,\n",
       "         0.2350]),\n",
       " 3173: tensor([0.0148, 0.0988, 0.0000, 0.0110, 0.2157, 0.0381, 0.4968, 0.0669, 0.0000,\n",
       "         0.3397, 0.0000, 0.0000, 0.0605, 0.3134, 0.0446, 0.1067, 0.0102, 0.0366,\n",
       "         0.5556, 0.1367, 0.2113, 0.0318, 0.1612, 0.0000, 0.0840, 0.2967, 0.0092,\n",
       "         0.2408]),\n",
       " 3576: tensor([0.1191, 0.1067, 0.2806, 0.2033, 0.0000, 0.2319, 0.0898, 0.0775, 0.2377,\n",
       "         0.0620, 0.1790, 0.1792, 0.1772, 0.0000, 0.1188, 0.1643, 0.1817, 0.1416,\n",
       "         0.0000, 0.0704, 0.0722, 0.0000, 0.0692, 0.1154, 0.1415, 0.0232, 0.1323,\n",
       "         0.1821]),\n",
       " 2480: tensor([0.0000, 0.0000, 0.2752, 0.0816, 0.3751, 0.4160, 0.2747, 0.2717, 0.0820,\n",
       "         0.2507, 0.2037, 0.0343, 0.1097, 0.3528, 0.0856, 0.3318, 0.0000, 0.2645,\n",
       "         0.0950, 0.2208, 0.0000, 0.2114, 0.1402, 0.0000, 0.1658, 0.1515, 0.0000,\n",
       "         0.0000]),\n",
       " 4268: tensor([0.3028, 0.0000, 0.0000, 0.3682, 0.2878, 0.0929, 0.2472, 0.1398, 0.1359,\n",
       "         0.0000, 0.4128, 0.0000, 0.3208, 0.1083, 0.0862, 0.0789, 0.1073, 0.3161,\n",
       "         0.1909, 0.2360, 0.0022, 0.1478, 0.2770, 0.0847, 0.0185, 0.1991, 0.0000,\n",
       "         0.2830]),\n",
       " 1645: tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.3070, 0.2382, 0.2516, 0.0000, 0.4783,\n",
       "         0.3747, 0.2469, 0.3372, 0.2031, 0.0000, 0.3351, 0.2165, 0.0111, 0.2386,\n",
       "         0.0000, 0.0000, 0.2143, 0.0000, 0.0376, 0.0000, 0.2496, 0.2768, 0.0389,\n",
       "         0.1367]),\n",
       " 2238: tensor([0.1951, 0.1791, 0.1961, 0.0889, 0.1496, 0.0581, 0.0749, 0.0000, 0.0889,\n",
       "         0.1175, 0.0782, 0.1694, 0.0000, 0.0000, 0.0344, 0.1488, 0.0280, 0.1497,\n",
       "         0.0000, 0.1458, 0.3327, 0.1733, 0.2308, 0.1008, 0.1636, 0.1170, 0.1318,\n",
       "         0.1537]),\n",
       " 4374: tensor([0.0000, 0.1500, 0.1389, 0.0000, 0.1943, 0.1611, 0.1190, 0.0944, 0.0838,\n",
       "         0.0811, 0.0212, 0.1171, 0.1493, 0.1854, 0.0453, 0.1586, 0.0173, 0.0746,\n",
       "         0.1729, 0.1685, 0.1314, 0.1289, 0.1590, 0.1060, 0.0000, 0.1613, 0.0746,\n",
       "         0.0759]),\n",
       " 1021: tensor([0.0695, 0.1722, 0.4821, 0.3312, 0.3010, 0.0280, 0.0000, 0.0000, 0.2726,\n",
       "         0.1054, 0.0317, 0.0000, 0.2493, 0.0842, 0.0861, 0.0000, 0.0000, 0.0000,\n",
       "         0.1734, 0.0000, 0.1710, 0.0989, 0.0694, 0.0502, 0.0000, 0.1872, 0.0000,\n",
       "         0.2558]),\n",
       " 1820: tensor([0.1721, 0.1362, 0.0000, 0.0662, 0.4341, 0.2107, 0.1431, 0.1208, 0.2740,\n",
       "         0.0939, 0.2017, 0.1389, 0.0848, 0.2270, 0.1427, 0.2076, 0.2061, 0.3309,\n",
       "         0.0152, 0.1851, 0.0738, 0.1352, 0.1475, 0.1609, 0.4051, 0.0000, 0.1803,\n",
       "         0.0045]),\n",
       " 4022: tensor([0.2328, 0.0000, 0.0000, 0.3040, 0.1967, 0.2020, 0.0000, 0.3384, 0.1807,\n",
       "         0.0995, 0.1294, 0.0000, 0.1760, 0.2089, 0.0000, 0.3054, 0.1497, 0.1676,\n",
       "         0.1794, 0.0063, 0.1057, 0.2238, 0.3181, 0.3742, 0.2408, 0.1572, 0.0000,\n",
       "         0.1046]),\n",
       " 3209: tensor([0.0157, 0.2147, 0.3622, 0.2289, 0.1788, 0.3691, 0.1222, 0.0000, 0.1591,\n",
       "         0.2624, 0.2475, 0.2923, 0.0000, 0.0387, 0.0117, 0.0000, 0.0743, 0.0000,\n",
       "         0.3235, 0.0317, 0.0503, 0.0000, 0.1901, 0.0074, 0.0000, 0.1197, 0.0000,\n",
       "         0.2281]),\n",
       " 3985: tensor([0.0091, 0.0000, 0.0826, 0.1350, 0.0000, 0.1644, 0.3363, 0.1112, 0.1409,\n",
       "         0.1079, 0.1039, 0.0000, 0.0000, 0.2801, 0.1283, 0.1491, 0.0000, 0.1143,\n",
       "         0.0000, 0.0049, 0.1826, 0.2271, 0.0000, 0.0000, 0.0000, 0.3635, 0.1391,\n",
       "         0.2230]),\n",
       " 3712: tensor([0.1999, 0.0458, 0.1343, 0.0215, 0.1361, 0.0647, 0.0000, 0.2691, 0.0000,\n",
       "         0.0000, 0.0366, 0.1691, 0.4324, 0.0000, 0.0000, 0.0510, 0.0734, 0.1295,\n",
       "         0.0000, 0.1518, 0.2822, 0.0875, 0.1271, 0.0000, 0.3114, 0.1391, 0.1179,\n",
       "         0.1163]),\n",
       " 2832: tensor([0.0000, 0.0000, 0.3108, 0.2247, 0.0759, 0.3654, 0.0045, 0.1376, 0.3893,\n",
       "         0.1295, 0.0194, 0.0175, 0.1213, 0.0682, 0.1679, 0.2573, 0.0380, 0.0730,\n",
       "         0.0766, 0.2042, 0.0000, 0.1084, 0.2759, 0.0000, 0.1257, 0.3311, 0.3190,\n",
       "         0.2090]),\n",
       " 2050: tensor([0.0000, 0.2584, 0.1853, 0.2267, 0.0183, 0.0790, 0.0931, 0.1967, 0.2254,\n",
       "         0.1013, 0.0026, 0.0000, 0.0873, 0.1462, 0.0452, 0.1262, 0.0000, 0.2408,\n",
       "         0.2647, 0.1862, 0.1002, 0.0504, 0.0134, 0.0827, 0.0628, 0.2098, 0.2713,\n",
       "         0.0596]),\n",
       " 3623: tensor([0.0995, 0.0847, 0.0569, 0.0662, 0.0000, 0.1366, 0.2301, 0.0826, 0.3316,\n",
       "         0.1288, 0.1090, 0.0000, 0.0000, 0.0806, 0.1737, 0.3047, 0.2285, 0.0873,\n",
       "         0.0000, 0.0251, 0.2160, 0.1121, 0.0000, 0.0000, 0.1346, 0.4112, 0.1015,\n",
       "         0.3060]),\n",
       " 2827: tensor([0.0407, 0.0189, 0.0000, 0.0000, 0.0000, 0.0393, 0.0398, 0.0666, 0.1381,\n",
       "         0.1945, 0.0689, 0.1383, 0.2166, 0.1715, 0.1188, 0.1996, 0.1096, 0.0495,\n",
       "         0.1778, 0.1319, 0.0912, 0.3145, 0.0000, 0.1028, 0.1278, 0.3409, 0.1155,\n",
       "         0.0398]),\n",
       " 4452: tensor([0.1471, 0.3312, 0.0000, 0.4829, 0.1087, 0.1517, 0.1805, 0.3694, 0.1729,\n",
       "         0.0617, 0.0762, 0.0315, 0.0558, 0.2166, 0.2460, 0.1058, 0.1226, 0.2630,\n",
       "         0.2093, 0.1711, 0.1517, 0.0799, 0.3643, 0.2560, 0.2624, 0.2229, 0.0000,\n",
       "         0.3111]),\n",
       " 3658: tensor([0.0832, 0.0982, 0.1163, 0.0870, 0.1333, 0.1334, 0.0000, 0.1240, 0.1104,\n",
       "         0.0778, 0.0694, 0.2406, 0.0587, 0.0000, 0.0000, 0.1038, 0.1118, 0.0711,\n",
       "         0.1803, 0.1654, 0.0852, 0.0338, 0.0940, 0.1204, 0.1034, 0.1127, 0.0377,\n",
       "         0.0789]),\n",
       " 2070: tensor([0.1396, 0.0000, 0.0000, 0.3156, 0.2443, 0.1877, 0.0000, 0.3439, 0.0573,\n",
       "         0.0000, 0.3304, 0.0000, 0.1618, 0.1890, 0.0000, 0.2628, 0.1729, 0.2552,\n",
       "         0.1093, 0.1095, 0.0942, 0.0688, 0.2983, 0.3019, 0.1296, 0.1027, 0.0000,\n",
       "         0.2345]),\n",
       " 2507: tensor([0.0000, 0.1240, 0.0000, 0.2145, 0.1006, 0.0000, 0.1874, 0.0000, 0.0000,\n",
       "         0.3203, 0.0000, 0.0000, 0.3579, 0.3540, 0.0000, 0.1089, 0.2914, 0.0241,\n",
       "         0.0492, 0.4073, 0.0000, 0.0000, 0.2649, 0.0000, 0.0637, 0.0000, 0.0987,\n",
       "         0.1855]),\n",
       " 2129: tensor([0.0000, 0.1076, 0.0656, 0.0000, 0.2724, 0.2254, 0.0669, 0.1865, 0.1681,\n",
       "         0.1190, 0.0000, 0.0576, 0.1727, 0.1172, 0.0000, 0.2031, 0.0452, 0.0000,\n",
       "         0.0000, 0.1803, 0.0120, 0.1206, 0.0235, 0.1100, 0.0000, 0.0371, 0.0609,\n",
       "         0.0790]),\n",
       " 42: tensor([0.0709, 0.1838, 0.1186, 0.2784, 0.0000, 0.0943, 0.1974, 0.1726, 0.2655,\n",
       "         0.1261, 0.1819, 0.0000, 0.0000, 0.0627, 0.1760, 0.2558, 0.1705, 0.1545,\n",
       "         0.0000, 0.2106, 0.3815, 0.0828, 0.0000, 0.0000, 0.1077, 0.2363, 0.2016,\n",
       "         0.0827]),\n",
       " 1769: tensor([0.0000, 0.2520, 0.2099, 0.0414, 0.0000, 0.3156, 0.0234, 0.2230, 0.1909,\n",
       "         0.0203, 0.2605, 0.0000, 0.0000, 0.2160, 0.0699, 0.3085, 0.1630, 0.1277,\n",
       "         0.0000, 0.2463, 0.1655, 0.2049, 0.0000, 0.0000, 0.0180, 0.2930, 0.2614,\n",
       "         0.0853]),\n",
       " 2860: tensor([0.3778, 0.2599, 0.3012, 0.3439, 0.0210, 0.0445, 0.2341, 0.1744, 0.0000,\n",
       "         0.2361, 0.3993, 0.2811, 0.0418, 0.1884, 0.1320, 0.1742, 0.1902, 0.1035,\n",
       "         0.0068, 0.1651, 0.0088, 0.3540, 0.2444, 0.1289, 0.1191, 0.0000, 0.1236,\n",
       "         0.2731]),\n",
       " 3110: tensor([0.2684, 0.0000, 0.3561, 0.1049, 0.0000, 0.0000, 0.0759, 0.0000, 0.1240,\n",
       "         0.2494, 0.0523, 0.1030, 0.1181, 0.2331, 0.3999, 0.1696, 0.2260, 0.1260,\n",
       "         0.0000, 0.1428, 0.0000, 0.0000, 0.0304, 0.1413, 0.1940, 0.0458, 0.1884,\n",
       "         0.1622]),\n",
       " 658: tensor([0.2958, 0.0497, 0.0000, 0.2882, 0.2751, 0.1959, 0.2975, 0.0705, 0.2140,\n",
       "         0.1800, 0.1398, 0.0000, 0.0000, 0.1628, 0.1520, 0.1440, 0.1673, 0.2494,\n",
       "         0.3786, 0.2076, 0.0477, 0.0352, 0.0336, 0.0461, 0.0000, 0.0393, 0.2527,\n",
       "         0.0843]),\n",
       " 3386: tensor([0.0000, 0.0000, 0.1260, 0.0238, 0.1459, 0.1853, 0.1717, 0.1420, 0.2208,\n",
       "         0.0162, 0.0000, 0.2572, 0.2214, 0.2157, 0.1512, 0.3730, 0.0604, 0.2779,\n",
       "         0.1186, 0.1625, 0.0000, 0.2380, 0.1523, 0.0000, 0.1637, 0.1036, 0.1519,\n",
       "         0.1791]),\n",
       " 1071: tensor([0.1194, 0.0879, 0.0593, 0.0652, 0.0000, 0.1849, 0.1860, 0.1510, 0.2064,\n",
       "         0.1011, 0.1085, 0.0831, 0.1690, 0.1549, 0.2015, 0.1663, 0.1592, 0.1171,\n",
       "         0.2517, 0.1952, 0.1605, 0.2011, 0.0000, 0.0659, 0.1261, 0.1056, 0.1115,\n",
       "         0.0694]),\n",
       " 906: tensor([0.0000, 0.1843, 0.2190, 0.0000, 0.2328, 0.0000, 0.3564, 0.1801, 0.0957,\n",
       "         0.1839, 0.3375, 0.0000, 0.1477, 0.2206, 0.0893, 0.0000, 0.1642, 0.3913,\n",
       "         0.1505, 0.1446, 0.0000, 0.0892, 0.2022, 0.2236, 0.0995, 0.2920, 0.1637,\n",
       "         0.2559]),\n",
       " 4088: tensor([0.1236, 0.1615, 0.1790, 0.1217, 0.0000, 0.1643, 0.2370, 0.1327, 0.1054,\n",
       "         0.1327, 0.1186, 0.1610, 0.1331, 0.0000, 0.1483, 0.1540, 0.0904, 0.2151,\n",
       "         0.0000, 0.1936, 0.1961, 0.0000, 0.0449, 0.1619, 0.2096, 0.1690, 0.1379,\n",
       "         0.1155]),\n",
       " 910: tensor([1.8545e-01, 1.9054e-01, 1.0630e-01, 1.2965e-01, 0.0000e+00, 2.3134e-04,\n",
       "         1.3277e-01, 4.3291e-02, 2.7199e-01, 2.0026e-01, 1.8793e-01, 1.4268e-01,\n",
       "         7.4611e-02, 1.7316e-01, 1.8377e-01, 1.4370e-01, 5.9576e-02, 1.5857e-01,\n",
       "         1.5619e-01, 1.5667e-01, 1.6067e-01, 9.4502e-02, 2.0947e-01, 9.6560e-02,\n",
       "         1.8012e-01, 0.0000e+00, 8.5210e-02, 2.0116e-01]),\n",
       " 3145: tensor([0.0000, 0.1300, 0.2786, 0.0000, 0.0489, 0.0866, 0.1738, 0.0251, 0.0000,\n",
       "         0.0000, 0.1693, 0.1920, 0.3800, 0.1220, 0.0000, 0.2535, 0.1066, 0.0000,\n",
       "         0.0990, 0.0539, 0.0462, 0.0745, 0.1876, 0.0989, 0.0000, 0.1556, 0.0970,\n",
       "         0.0383]),\n",
       " 4205: tensor([0.0000, 0.0991, 0.1299, 0.2000, 0.1045, 0.1631, 0.0941, 0.1136, 0.1545,\n",
       "         0.1247, 0.0911, 0.0346, 0.0729, 0.1488, 0.0000, 0.0966, 0.0000, 0.1339,\n",
       "         0.1734, 0.2032, 0.0549, 0.0324, 0.0290, 0.1522, 0.1095, 0.1064, 0.3384,\n",
       "         0.0927]),\n",
       " 2459: tensor([0.3781, 0.0000, 0.1924, 0.3242, 0.0000, 0.0000, 0.0577, 0.0000, 0.0477,\n",
       "         0.0000, 0.0220, 0.0777, 0.0117, 0.1465, 0.2362, 0.2535, 0.1130, 0.0781,\n",
       "         0.0538, 0.1218, 0.0876, 0.0000, 0.0016, 0.2813, 0.0925, 0.1036, 0.2773,\n",
       "         0.1796]),\n",
       " 717: tensor([0.1210, 0.0722, 0.0314, 0.1000, 0.0000, 0.0368, 0.0000, 0.2574, 0.0000,\n",
       "         0.1261, 0.0076, 0.4374, 0.2707, 0.0000, 0.0000, 0.0249, 0.2376, 0.0434,\n",
       "         0.1074, 0.3736, 0.3374, 0.0000, 0.0176, 0.0828, 0.1388, 0.0000, 0.0769,\n",
       "         0.1443]),\n",
       " 2751: tensor([0.0000, 0.0763, 0.1987, 0.1574, 0.0000, 0.3011, 0.0000, 0.1649, 0.0705,\n",
       "         0.2932, 0.3453, 0.0000, 0.0000, 0.1278, 0.1326, 0.2852, 0.0828, 0.0233,\n",
       "         0.0000, 0.1027, 0.0789, 0.0528, 0.0000, 0.3381, 0.1320, 0.3900, 0.0893,\n",
       "         0.1937]),\n",
       " 2552: tensor([0.1805, 0.0000, 0.0000, 0.1030, 0.0000, 0.0000, 0.0000, 0.0000, 0.3256,\n",
       "         0.2483, 0.0000, 0.1745, 0.1666, 0.0231, 0.0201, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.3552, 0.0000, 0.1144, 0.5432, 0.0000, 0.0000, 0.0859,\n",
       "         0.0073]),\n",
       " 1337: tensor([0.1455, 0.0000, 0.3810, 0.0000, 0.0000, 0.0000, 0.0000, 0.1521, 0.5126,\n",
       "         0.0000, 0.1029, 0.0000, 0.1254, 0.0000, 0.1200, 0.5593, 0.2019, 0.1806,\n",
       "         0.2063, 0.0000, 0.1114, 0.0930, 0.0000, 0.0000, 0.0755, 0.2204, 0.0000,\n",
       "         0.0000]),\n",
       " 628: tensor([0.1658, 0.1903, 0.1322, 0.1387, 0.0350, 0.0514, 0.1018, 0.1540, 0.2385,\n",
       "         0.1688, 0.1867, 0.0000, 0.1588, 0.0000, 0.0000, 0.1924, 0.2342, 0.0935,\n",
       "         0.1544, 0.0056, 0.0996, 0.1609, 0.0078, 0.1228, 0.2299, 0.0867, 0.1317,\n",
       "         0.0883]),\n",
       " 1935: tensor([0.0485, 0.1481, 0.1564, 0.1933, 0.0000, 0.0717, 0.1508, 0.1141, 0.1007,\n",
       "         0.1585, 0.1267, 0.1699, 0.0486, 0.0000, 0.1365, 0.1546, 0.0677, 0.1500,\n",
       "         0.0000, 0.1139, 0.2384, 0.0800, 0.0709, 0.2044, 0.1503, 0.1560, 0.1679,\n",
       "         0.1178]),\n",
       " 2501: tensor([0.0634, 0.0701, 0.0000, 0.1363, 0.2534, 0.1071, 0.1615, 0.1725, 0.1439,\n",
       "         0.1033, 0.1122, 0.1347, 0.2474, 0.1080, 0.0788, 0.0866, 0.1155, 0.1235,\n",
       "         0.0665, 0.1036, 0.1687, 0.1037, 0.0210, 0.1113, 0.1754, 0.1877, 0.0966,\n",
       "         0.0904]),\n",
       " 2077: tensor([0.0000, 0.0000, 0.2897, 0.0640, 0.1360, 0.2695, 0.1730, 0.1097, 0.2462,\n",
       "         0.2064, 0.2327, 0.2425, 0.2058, 0.2117, 0.1254, 0.3722, 0.0000, 0.0569,\n",
       "         0.1674, 0.1822, 0.0000, 0.1066, 0.1893, 0.0000, 0.1497, 0.0554, 0.1662,\n",
       "         0.1120]),\n",
       " 2489: tensor([0.0000, 0.1477, 0.1186, 0.0924, 0.1511, 0.1337, 0.0868, 0.1114, 0.1273,\n",
       "         0.1197, 0.1180, 0.0000, 0.1429, 0.0820, 0.0000, 0.1135, 0.0000, 0.1301,\n",
       "         0.1255, 0.1414, 0.0000, 0.1149, 0.0000, 0.1258, 0.1328, 0.1344, 0.2374,\n",
       "         0.0527]),\n",
       " 3678: tensor([0.2616, 0.1252, 0.3642, 0.1174, 0.1498, 0.1068, 0.0679, 0.1449, 0.2199,\n",
       "         0.0000, 0.3614, 0.1519, 0.1156, 0.1642, 0.2218, 0.0000, 0.2528, 0.0000,\n",
       "         0.2206, 0.1087, 0.0508, 0.0794, 0.1590, 0.3126, 0.0000, 0.0414, 0.0000,\n",
       "         0.3903]),\n",
       " 2647: tensor([0.1579, 0.7244, 0.0000, 0.1664, 0.0000, 0.2315, 0.0000, 0.2960, 0.0082,\n",
       "         0.0318, 0.0000, 0.1618, 0.0342, 0.2225, 0.2896, 0.0283, 0.4294, 0.1164,\n",
       "         0.5766, 0.0062, 0.0619, 0.0000, 0.3923, 0.3450, 0.2766, 0.1941, 0.1375,\n",
       "         0.3081]),\n",
       " 1082: tensor([0.2440, 0.0000, 0.1848, 0.1950, 0.0000, 0.0000, 0.1403, 0.0000, 0.1101,\n",
       "         0.1684, 0.1217, 0.1364, 0.2048, 0.2164, 0.1478, 0.1780, 0.0000, 0.1872,\n",
       "         0.1045, 0.1277, 0.1682, 0.0000, 0.1353, 0.1444, 0.1258, 0.1234, 0.1350,\n",
       "         0.1638]),\n",
       " 1802: tensor([0.0000, 0.3813, 0.2513, 0.0000, 0.2822, 0.0301, 0.2523, 0.1644, 0.0468,\n",
       "         0.1460, 0.2480, 0.0697, 0.2011, 0.3836, 0.0477, 0.0000, 0.0428, 0.4237,\n",
       "         0.1635, 0.1957, 0.0000, 0.1444, 0.1922, 0.2310, 0.0307, 0.3972, 0.0887,\n",
       "         0.1656]),\n",
       " 74: tensor([0.2537, 0.1415, 0.0000, 0.4381, 0.0690, 0.2699, 0.1791, 0.1090, 0.2343,\n",
       "         0.0137, 0.1109, 0.2575, 0.2780, 0.0000, 0.3750, 0.0585, 0.3306, 0.2200,\n",
       "         0.1077, 0.2158, 0.1518, 0.1993, 0.1883, 0.0000, 0.3730, 0.6461, 0.2950,\n",
       "         0.0778]),\n",
       " 3664: tensor([0.0867, 0.0000, 0.1323, 0.0000, 0.1515, 0.1425, 0.1369, 0.0000, 0.1313,\n",
       "         0.0859, 0.1890, 0.1880, 0.0060, 0.2637, 0.0617, 0.1055, 0.0000, 0.1526,\n",
       "         0.1251, 0.1822, 0.2114, 0.2639, 0.1028, 0.0164, 0.0875, 0.1597, 0.0000,\n",
       "         0.0000]),\n",
       " 3439: tensor([0.3962, 0.1204, 0.0000, 0.1311, 0.2540, 0.3458, 0.1842, 0.0000, 0.2330,\n",
       "         0.2006, 0.0052, 0.0558, 0.0373, 0.2087, 0.1908, 0.1704, 0.1990, 0.3705,\n",
       "         0.1484, 0.1302, 0.0201, 0.3817, 0.0827, 0.1562, 0.0829, 0.2052, 0.0000,\n",
       "         0.0973]),\n",
       " 2025: tensor([0.2872, 0.2170, 0.0000, 0.3762, 0.2780, 0.1125, 0.2753, 0.2307, 0.3667,\n",
       "         0.1439, 0.0740, 0.2474, 0.3010, 0.1135, 0.2854, 0.0324, 0.2777, 0.2331,\n",
       "         0.1822, 0.1331, 0.0942, 0.1011, 0.0738, 0.0000, 0.1933, 0.3616, 0.2922,\n",
       "         0.1771]),\n",
       " 2072: tensor([0.0000, 0.1663, 0.2071, 0.0573, 0.1831, 0.2497, 0.0302, 0.1911, 0.1510,\n",
       "         0.2060, 0.1946, 0.0000, 0.2014, 0.2192, 0.0000, 0.1326, 0.0000, 0.1424,\n",
       "         0.2722, 0.0791, 0.0000, 0.0895, 0.0000, 0.0108, 0.0127, 0.0000, 0.4088,\n",
       "         0.0624]),\n",
       " 1887: tensor([0.0275, 0.0000, 0.0000, 0.0000, 0.6216, 0.1891, 0.0713, 0.0000, 0.2339,\n",
       "         0.3097, 0.1568, 0.1708, 0.0985, 0.0710, 0.3417, 0.2220, 0.2680, 0.3637,\n",
       "         0.0000, 0.0029, 0.0526, 0.0000, 0.0950, 0.0992, 0.4071, 0.2502, 0.0616,\n",
       "         0.0640]),\n",
       " 4370: tensor([0.0000, 0.0000, 0.0230, 0.3571, 0.1200, 0.2330, 0.0000, 0.0000, 0.0633,\n",
       "         0.2383, 0.0304, 0.1262, 0.0000, 0.1794, 0.2279, 0.0179, 0.2698, 0.0000,\n",
       "         0.1771, 0.1677, 0.0983, 0.0000, 0.0000, 0.0000, 0.2943, 0.0000, 0.2281,\n",
       "         0.0567]),\n",
       " 4007: tensor([0.2486, 0.2156, 0.2202, 0.0810, 0.0000, 0.1627, 0.1404, 0.0009, 0.1138,\n",
       "         0.2019, 0.2036, 0.1471, 0.1369, 0.1595, 0.1563, 0.1890, 0.1537, 0.1900,\n",
       "         0.1267, 0.2071, 0.0792, 0.1375, 0.1633, 0.1880, 0.1319, 0.0000, 0.1135,\n",
       "         0.0000]),\n",
       " 2813: tensor([0.1312, 0.0193, 0.0922, 0.1517, 0.2026, 0.2511, 0.2199, 0.2080, 0.1642,\n",
       "         0.0698, 0.2800, 0.2154, 0.1071, 0.1622, 0.2039, 0.1656, 0.0000, 0.1220,\n",
       "         0.1661, 0.1605, 0.0888, 0.1897, 0.0536, 0.0951, 0.0680, 0.1451, 0.0000,\n",
       "         0.1116]),\n",
       " 191: tensor([0.0930, 0.2108, 0.2521, 0.1549, 0.1232, 0.1345, 0.0039, 0.1505, 0.1979,\n",
       "         0.3952, 0.2184, 0.0891, 0.0901, 0.0000, 0.0000, 0.1175, 0.2416, 0.2538,\n",
       "         0.0000, 0.2422, 0.0976, 0.0133, 0.1584, 0.0000, 0.0435, 0.1711, 0.1964,\n",
       "         0.2453]),\n",
       " 3820: tensor([0.2546, 0.0000, 0.2853, 0.1722, 0.0000, 0.0000, 0.4067, 0.0000, 0.1730,\n",
       "         0.0000, 0.1389, 0.1984, 0.1451, 0.1490, 0.1767, 0.6033, 0.1905, 0.1547,\n",
       "         0.1339, 0.0037, 0.3385, 0.0000, 0.2313, 0.3094, 0.0000, 0.2116, 0.2506,\n",
       "         0.2938]),\n",
       " 0: tensor([0.0887, 0.1300, 0.1514, 0.0979, 0.0617, 0.0739, 0.1533, 0.1700, 0.1778,\n",
       "         0.1543, 0.1420, 0.0621, 0.0819, 0.0000, 0.0000, 0.0573, 0.1619, 0.0847,\n",
       "         0.1490, 0.0866, 0.0656, 0.0630, 0.1527, 0.0864, 0.1768, 0.1548, 0.1249,\n",
       "         0.1308]),\n",
       " 4448: tensor([0.0000, 0.2477, 0.0747, 0.0000, 0.3289, 0.2096, 0.0647, 0.1864, 0.1099,\n",
       "         0.0443, 0.0387, 0.1544, 0.2105, 0.1769, 0.0936, 0.0876, 0.0000, 0.1157,\n",
       "         0.1416, 0.2052, 0.0980, 0.1209, 0.0928, 0.1272, 0.0199, 0.0872, 0.1066,\n",
       "         0.1062]),\n",
       " 2970: tensor([0.0000, 0.1383, 0.1512, 0.1069, 0.1545, 0.0847, 0.1023, 0.1506, 0.0730,\n",
       "         0.0935, 0.1113, 0.0000, 0.1682, 0.0538, 0.0000, 0.1075, 0.0000, 0.1418,\n",
       "         0.1225, 0.1606, 0.0000, 0.1009, 0.0000, 0.1127, 0.1816, 0.1321, 0.1440,\n",
       "         0.0461]),\n",
       " 4401: tensor([0.1900, 0.1362, 0.2348, 0.1725, 0.0890, 0.0045, 0.0874, 0.1581, 0.1647,\n",
       "         0.0592, 0.1540, 0.0133, 0.2108, 0.0000, 0.0000, 0.1723, 0.2112, 0.1069,\n",
       "         0.1199, 0.0694, 0.0752, 0.1542, 0.1619, 0.0366, 0.2703, 0.1211, 0.1784,\n",
       "         0.1056]),\n",
       " 3628: tensor([0.1073, 0.2422, 0.2156, 0.4019, 0.2623, 0.1553, 0.0000, 0.2444, 0.0786,\n",
       "         0.1230, 0.0377, 0.0603, 0.2602, 0.1838, 0.0347, 0.0000, 0.1984, 0.0000,\n",
       "         0.2285, 0.0241, 0.1662, 0.0000, 0.1344, 0.0542, 0.0000, 0.3858, 0.0000,\n",
       "         0.1716]),\n",
       " 2360: tensor([0.2949, 0.2003, 0.1284, 0.2306, 0.1590, 0.0904, 0.1576, 0.2036, 0.0939,\n",
       "         0.1374, 0.1108, 0.2385, 0.1379, 0.1607, 0.0950, 0.0620, 0.1016, 0.2100,\n",
       "         0.0881, 0.1935, 0.1096, 0.0255, 0.0985, 0.1160, 0.0363, 0.2071, 0.0000,\n",
       "         0.1115]),\n",
       " 3975: tensor([0.0000, 0.0000, 0.4500, 0.1546, 0.0204, 0.1297, 0.0000, 0.0000, 0.3115,\n",
       "         0.0282, 0.0955, 0.0778, 0.0000, 0.2876, 0.2553, 0.1780, 0.1978, 0.2081,\n",
       "         0.1707, 0.1251, 0.0337, 0.2811, 0.0000, 0.0000, 0.0732, 0.0000, 0.0458,\n",
       "         0.2288]),\n",
       " 3601: tensor([0.1338, 0.1590, 0.0814, 0.1340, 0.0000, 0.2283, 0.1292, 0.0812, 0.2564,\n",
       "         0.1453, 0.1990, 0.0000, 0.0000, 0.1568, 0.1314, 0.1900, 0.2282, 0.1566,\n",
       "         0.0000, 0.1460, 0.1202, 0.1361, 0.0000, 0.0000, 0.2111, 0.2837, 0.2194,\n",
       "         0.2087]),\n",
       " 362: tensor([0.2173, 0.2445, 0.0648, 0.2051, 0.0000, 0.0697, 0.2340, 0.2428, 0.1841,\n",
       "         0.0735, 0.0724, 0.0045, 0.0425, 0.0000, 0.0000, 0.1244, 0.1402, 0.1247,\n",
       "         0.0126, 0.0075, 0.2287, 0.1879, 0.0000, 0.0832, 0.3069, 0.0901, 0.0808,\n",
       "         0.0351]),\n",
       " 1419: tensor([0.3044, 0.1705, 0.1179, 0.0000, 0.0000, 0.0958, 0.0000, 0.1881, 0.2323,\n",
       "         0.1271, 0.0460, 0.2274, 0.0994, 0.2129, 0.1371, 0.1919, 0.0799, 0.0000,\n",
       "         0.0000, 0.3671, 0.0000, 0.0000, 0.1838, 0.3069, 0.0000, 0.0365, 0.0437,\n",
       "         0.0000]),\n",
       " 4336: tensor([0.1440, 0.1508, 0.0000, 0.1882, 0.2043, 0.1909, 0.1950, 0.1767, 0.1104,\n",
       "         0.0264, 0.1285, 0.0347, 0.1386, 0.1183, 0.1271, 0.1831, 0.2303, 0.1466,\n",
       "         0.1107, 0.1761, 0.1465, 0.1057, 0.1620, 0.0861, 0.0563, 0.0783, 0.0000,\n",
       "         0.1426]),\n",
       " 462: tensor([0.0919, 0.1074, 0.1397, 0.0376, 0.1584, 0.1087, 0.1927, 0.2227, 0.0000,\n",
       "         0.1524, 0.0900, 0.0332, 0.2152, 0.0000, 0.0000, 0.0736, 0.1371, 0.1039,\n",
       "         0.0000, 0.0028, 0.1154, 0.0742, 0.0983, 0.0000, 0.2806, 0.1946, 0.0926,\n",
       "         0.1064]),\n",
       " 2856: tensor([0.0703, 0.0107, 0.1773, 0.0446, 0.0755, 0.2829, 0.3328, 0.1373, 0.0342,\n",
       "         0.1978, 0.0000, 0.0491, 0.1769, 0.2116, 0.1442, 0.1341, 0.0957, 0.1975,\n",
       "         0.0579, 0.0641, 0.1043, 0.3367, 0.0000, 0.1748, 0.0000, 0.3777, 0.2213,\n",
       "         0.1327]),\n",
       " 2288: tensor([0.1044, 0.1939, 0.0514, 0.2000, 0.0000, 0.2206, 0.1498, 0.0978, 0.2504,\n",
       "         0.1230, 0.2539, 0.0000, 0.0000, 0.2040, 0.1789, 0.1219, 0.1958, 0.1583,\n",
       "         0.0000, 0.1198, 0.1400, 0.1055, 0.0000, 0.0000, 0.2515, 0.2526, 0.2625,\n",
       "         0.1831]),\n",
       " 1995: tensor([0.1634, 0.1369, 0.1847, 0.1390, 0.1148, 0.1729, 0.1629, 0.1319, 0.0786,\n",
       "         0.1704, 0.0644, 0.0715, 0.1143, 0.2011, 0.1965, 0.1210, 0.1253, 0.1241,\n",
       "         0.0300, 0.0328, 0.0615, 0.1969, 0.0339, 0.1555, 0.0000, 0.2045, 0.1800,\n",
       "         0.1639]),\n",
       " 2144: tensor([0.0000, 0.2615, 0.2646, 0.0000, 0.1860, 0.1845, 0.1805, 0.1539, 0.1739,\n",
       "         0.1426, 0.0000, 0.1759, 0.0664, 0.3145, 0.0830, 0.1192, 0.0264, 0.1377,\n",
       "         0.2184, 0.1523, 0.1735, 0.2357, 0.0111, 0.0108, 0.0000, 0.2631, 0.1639,\n",
       "         0.0000]),\n",
       " 1943: tensor([0.0000, 0.2887, 0.0000, 0.0952, 0.0000, 0.1391, 0.0965, 0.0238, 0.1095,\n",
       "         0.2559, 0.2352, 0.0639, 0.0570, 0.1857, 0.1185, 0.1219, 0.1685, 0.2143,\n",
       "         0.1338, 0.2122, 0.2088, 0.0721, 0.2073, 0.2282, 0.1070, 0.0000, 0.1295,\n",
       "         0.2500]),\n",
       " 1504: tensor([0.0000, 0.1026, 0.0000, 0.0443, 0.0000, 0.2533, 0.2075, 0.1578, 0.1700,\n",
       "         0.1427, 0.3621, 0.2486, 0.0045, 0.1325, 0.2593, 0.0901, 0.1704, 0.2703,\n",
       "         0.1843, 0.1320, 0.1670, 0.1020, 0.2474, 0.2113, 0.2306, 0.0000, 0.0716,\n",
       "         0.0455]),\n",
       " 232: tensor([0.1400, 0.1830, 0.1055, 0.0888, 0.0416, 0.2848, 0.1021, 0.1287, 0.1403,\n",
       "         0.1448, 0.0715, 0.1135, 0.1591, 0.1008, 0.0582, 0.0596, 0.1128, 0.0887,\n",
       "         0.0996, 0.1040, 0.0588, 0.1067, 0.1277, 0.0932, 0.1380, 0.0000, 0.0605,\n",
       "         0.1603]),\n",
       " 1704: tensor([0.0240, 0.2860, 0.1353, 0.2720, 0.0000, 0.2847, 0.1424, 0.1220, 0.0624,\n",
       "         0.0476, 0.0173, 0.0078, 0.2301, 0.1028, 0.0126, 0.1168, 0.1273, 0.0886,\n",
       "         0.1432, 0.1773, 0.0915, 0.1790, 0.1061, 0.0587, 0.1505, 0.0000, 0.1482,\n",
       "         0.2088]),\n",
       " 2572: tensor([0.1810, 0.1962, 0.0619, 0.2430, 0.0000, 0.2025, 0.2813, 0.2687, 0.0707,\n",
       "         0.1106, 0.1558, 0.1235, 0.1412, 0.1659, 0.0161, 0.0706, 0.2177, 0.0175,\n",
       "         0.0000, 0.1119, 0.2339, 0.2488, 0.2319, 0.1806, 0.1269, 0.1644, 0.0000,\n",
       "         0.0482]),\n",
       " 1631: tensor([0.1446, 0.1007, 0.1152, 0.1369, 0.0000, 0.1531, 0.1185, 0.1348, 0.0622,\n",
       "         0.1340, 0.1474, 0.0948, 0.1083, 0.1450, 0.1861, 0.1829, 0.1190, 0.2205,\n",
       "         0.0674, 0.1384, 0.1437, 0.1114, 0.0000, 0.1685, 0.1088, 0.1449, 0.0822,\n",
       "         0.0452]),\n",
       " 3920: tensor([0.0000, 0.0000, 0.1941, 0.1096, 0.0438, 0.2224, 0.1138, 0.1061, 0.1905,\n",
       "         0.0745, 0.0000, 0.1265, 0.1489, 0.1869, 0.1597, 0.2353, 0.0125, 0.1452,\n",
       "         0.0918, 0.1324, 0.0000, 0.1629, 0.2218, 0.0000, 0.0492, 0.2010, 0.1711,\n",
       "         0.1887]),\n",
       " 2400: tensor([0.0730, 0.1633, 0.2007, 0.2156, 0.0000, 0.1764, 0.1899, 0.2167, 0.3880,\n",
       "         0.0452, 0.2707, 0.1761, 0.1325, 0.0000, 0.0952, 0.2608, 0.2679, 0.1609,\n",
       "         0.0000, 0.0701, 0.1021, 0.0034, 0.1125, 0.0572, 0.2227, 0.2211, 0.1886,\n",
       "         0.1511]),\n",
       " 2715: tensor([0.1691, 0.1912, 0.1666, 0.1742, 0.0000, 0.0773, 0.0787, 0.1675, 0.2055,\n",
       "         0.2238, 0.2099, 0.0000, 0.0000, 0.1343, 0.1449, 0.1799, 0.0543, 0.1506,\n",
       "         0.0000, 0.1477, 0.3598, 0.1145, 0.0000, 0.0485, 0.0890, 0.1465, 0.1702,\n",
       "         0.2402]),\n",
       " 2059: tensor([0.0076, 0.2736, 0.0000, 0.5043, 0.3109, 0.4024, 0.1073, 0.3320, 0.2330,\n",
       "         0.0259, 0.0432, 0.1336, 0.1660, 0.0765, 0.0735, 0.0000, 0.1912, 0.0000,\n",
       "         0.1543, 0.0000, 0.2354, 0.0000, 0.3220, 0.0096, 0.0000, 0.3012, 0.0000,\n",
       "         0.1061]),\n",
       " 2369: tensor([0.1543, 0.3057, 0.2079, 0.2286, 0.1891, 0.2522, 0.1246, 0.1021, 0.2553,\n",
       "         0.1234, 0.1022, 0.0000, 0.0815, 0.1660, 0.2258, 0.1245, 0.0826, 0.0294,\n",
       "         0.2405, 0.0367, 0.1424, 0.0914, 0.1009, 0.2468, 0.0000, 0.0083, 0.1034,\n",
       "         0.0450]),\n",
       " 3509: tensor([0.0000, 0.0568, 0.1660, 0.2590, 0.1017, 0.3323, 0.1585, 0.0873, 0.2967,\n",
       "         0.1825, 0.1734, 0.0000, 0.0000, 0.2128, 0.0000, 0.2595, 0.0000, 0.0996,\n",
       "         0.3244, 0.0000, 0.1715, 0.0264, 0.0000, 0.0813, 0.0941, 0.2333, 0.0000,\n",
       "         0.1718]),\n",
       " 2279: tensor([0.2161, 0.1062, 0.2827, 0.1171, 0.2612, 0.0000, 0.1786, 0.0894, 0.1092,\n",
       "         0.0000, 0.0000, 0.0821, 0.0178, 0.1367, 0.0526, 0.2057, 0.0423, 0.1211,\n",
       "         0.1676, 0.0819, 0.0695, 0.4467, 0.0853, 0.0000, 0.2199, 0.0000, 0.0637,\n",
       "         0.0000]),\n",
       " 30: tensor([0.3006, 0.0000, 0.0000, 0.0000, 0.2369, 0.3266, 0.1642, 0.0000, 0.0903,\n",
       "         0.2734, 0.1044, 0.2524, 0.1185, 0.1607, 0.2300, 0.1428, 0.2740, 0.2471,\n",
       "         0.2965, 0.0412, 0.0000, 0.0000, 0.3195, 0.0000, 0.2482, 0.0589, 0.1297,\n",
       "         0.1389]),\n",
       " 4299: tensor([0.0000, 0.0000, 0.3033, 0.1401, 0.0708, 0.1198, 0.0000, 0.0000, 0.1086,\n",
       "         0.2468, 0.1812, 0.0893, 0.0000, 0.1611, 0.1590, 0.0748, 0.3769, 0.1429,\n",
       "         0.0762, 0.0384, 0.1866, 0.0663, 0.0000, 0.0000, 0.0693, 0.0000, 0.1427,\n",
       "         0.1949]),\n",
       " 1649: tensor([0.0000, 0.1237, 0.1157, 0.0278, 0.2372, 0.1165, 0.1578, 0.0745, 0.0000,\n",
       "         0.1707, 0.1459, 0.0000, 0.1630, 0.2040, 0.0000, 0.1661, 0.0000, 0.1960,\n",
       "         0.1829, 0.0767, 0.0000, 0.0805, 0.0000, 0.0344, 0.1137, 0.1030, 0.2330,\n",
       "         0.0912]),\n",
       " 3799: tensor([0.2030, 0.2627, 0.1132, 0.1612, 0.0000, 0.1179, 0.1033, 0.0391, 0.1719,\n",
       "         0.2495, 0.1024, 0.1132, 0.2379, 0.1166, 0.0828, 0.1368, 0.1476, 0.1487,\n",
       "         0.1271, 0.2049, 0.1642, 0.1343, 0.1538, 0.0881, 0.1356, 0.0000, 0.0622,\n",
       "         0.2059]),\n",
       " 4211: tensor([0.0807, 0.0871, 0.0000, 0.1178, 0.2054, 0.1036, 0.1601, 0.1160, 0.1060,\n",
       "         0.0724, 0.1126, 0.0987, 0.2230, 0.1590, 0.0818, 0.0533, 0.1239, 0.1346,\n",
       "         0.0220, 0.1472, 0.1794, 0.1157, 0.0000, 0.0000, 0.1655, 0.1107, 0.0666,\n",
       "         0.1209]),\n",
       " 4110: tensor([0.0363, 0.0888, 0.1298, 0.1564, 0.1265, 0.1135, 0.0981, 0.1396, 0.1300,\n",
       "         0.0767, 0.0633, 0.0413, 0.0950, 0.1461, 0.0462, 0.1012, 0.0000, 0.1362,\n",
       "         0.2045, 0.2108, 0.0761, 0.0037, 0.1032, 0.1259, 0.0813, 0.0746, 0.2994,\n",
       "         0.0563]),\n",
       " 4147: tensor([0.3494, 0.0000, 0.1605, 0.3549, 0.0000, 0.0000, 0.0758, 0.0000, 0.0355,\n",
       "         0.0866, 0.0901, 0.0502, 0.0112, 0.0958, 0.1859, 0.4893, 0.0000, 0.0194,\n",
       "         0.0000, 0.0000, 0.1330, 0.0000, 0.0771, 0.0321, 0.0580, 0.1198, 0.2918,\n",
       "         0.4775]),\n",
       " 411: tensor([0.1676, 0.0477, 0.0756, 0.1322, 0.0000, 0.1307, 0.1616, 0.1891, 0.1602,\n",
       "         0.1461, 0.1420, 0.1167, 0.1645, 0.0697, 0.1366, 0.1156, 0.1547, 0.1057,\n",
       "         0.1304, 0.1384, 0.1573, 0.1595, 0.0000, 0.1117, 0.1148, 0.1852, 0.1548,\n",
       "         0.0802]),\n",
       " 4477: tensor([0.1548, 0.0414, 0.1375, 0.1548, 0.0000, 0.1064, 0.0281, 0.0731, 0.1212,\n",
       "         0.0000, 0.1568, 0.0000, 0.0000, 0.0678, 0.0531, 0.0000, 0.0000, 0.0097,\n",
       "         0.0000, 0.2475, 0.2871, 0.0091, 0.0000, 0.0000, 0.1480, 0.0000, 0.0915,\n",
       "         0.0307]),\n",
       " 2890: tensor([0.0000, 0.3479, 0.0000, 0.3515, 0.0000, 0.2059, 0.1498, 0.0000, 0.2723,\n",
       "         0.0664, 0.2193, 0.0737, 0.0000, 0.2183, 0.0898, 0.1358, 0.1247, 0.2270,\n",
       "         0.1621, 0.1418, 0.2370, 0.1668, 0.1477, 0.1864, 0.1002, 0.0000, 0.1281,\n",
       "         0.2867]),\n",
       " 1613: tensor([0.1257, 0.1888, 0.1788, 0.0000, 0.1206, 0.2608, 0.1295, 0.1195, 0.0000,\n",
       "         0.0000, 0.2362, 0.1166, 0.2351, 0.1385, 0.0000, 0.1546, 0.1144, 0.0000,\n",
       "         0.0572, 0.0000, 0.2361, 0.3414, 0.1259, 0.1305, 0.0784, 0.0086, 0.1200,\n",
       "         0.0932]),\n",
       " 3492: tensor([0.0000, 0.0000, 0.0000, 0.3243, 0.1396, 0.0000, 0.2867, 0.3808, 0.0000,\n",
       "         0.2942, 0.2213, 0.0074, 0.4278, 0.0000, 0.0000, 0.0000, 0.2121, 0.0171,\n",
       "         0.1277, 0.0212, 0.1811, 0.1873, 0.0000, 0.0000, 0.3299, 0.1182, 0.0000,\n",
       "         0.0000]),\n",
       " 3220: tensor([0.0939, 0.0357, 0.1209, 0.1240, 0.0000, 0.0706, 0.1591, 0.0857, 0.2213,\n",
       "         0.0000, 0.1581, 0.0291, 0.0000, 0.1388, 0.0363, 0.0801, 0.1507, 0.1338,\n",
       "         0.0000, 0.0044, 0.2139, 0.0255, 0.0000, 0.1292, 0.2259, 0.0442, 0.2082,\n",
       "         0.1574]),\n",
       " 3666: tensor([0.0000, 0.0000, 0.0000, 0.0300, 0.4635, 0.1775, 0.0000, 0.1849, 0.1421,\n",
       "         0.0000, 0.2946, 0.0000, 0.0190, 0.1892, 0.0000, 0.1949, 0.0177, 0.1272,\n",
       "         0.0599, 0.0858, 0.3330, 0.3368, 0.1019, 0.3515, 0.0536, 0.0714, 0.0000,\n",
       "         0.2441]),\n",
       " 627: tensor([0.2336, 0.0000, 0.0824, 0.2973, 0.0000, 0.1379, 0.3648, 0.0000, 0.1441,\n",
       "         0.2038, 0.0534, 0.0037, 0.2381, 0.2515, 0.1260, 0.1982, 0.2471, 0.2369,\n",
       "         0.0000, 0.0897, 0.0365, 0.2903, 0.0000, 0.0867, 0.0000, 0.4521, 0.3493,\n",
       "         0.3348]),\n",
       " 2181: tensor([0.1819, 0.0629, 0.0000, 0.0000, 0.3190, 0.0794, 0.1310, 0.0000, 0.0000,\n",
       "         0.0000, 0.0644, 0.1658, 0.0297, 0.1458, 0.2024, 0.2981, 0.3721, 0.0000,\n",
       "         0.2774, 0.2121, 0.1900, 0.1809, 0.4645, 0.0393, 0.0000, 0.0000, 0.0000,\n",
       "         0.0646]),\n",
       " 1975: tensor([0.1419, 0.0214, 0.1198, 0.1645, 0.0972, 0.0697, 0.1608, 0.1487, 0.1395,\n",
       "         0.0359, 0.0176, 0.0237, 0.1113, 0.1337, 0.1983, 0.0949, 0.0000, 0.1000,\n",
       "         0.1684, 0.1533, 0.1577, 0.0306, 0.0569, 0.1374, 0.1469, 0.1288, 0.1114,\n",
       "         0.1037]),\n",
       " 2147: tensor([0.0858, 0.1596, 0.0429, 0.0759, 0.0000, 0.2111, 0.2599, 0.1333, 0.0175,\n",
       "         0.0749, 0.0814, 0.1868, 0.1000, 0.0000, 0.1953, 0.1082, 0.0515, 0.1515,\n",
       "         0.0000, 0.1121, 0.2202, 0.0000, 0.0120, 0.2609, 0.2371, 0.1472, 0.0391,\n",
       "         0.1009]),\n",
       " 829: tensor([0.1975, 0.1220, 0.1690, 0.1266, 0.1697, 0.1867, 0.0000, 0.2715, 0.0000,\n",
       "         0.1267, 0.0749, 0.1346, 0.4370, 0.0000, 0.0000, 0.0416, 0.1926, 0.3869,\n",
       "         0.0000, 0.0586, 0.1202, 0.1401, 0.1825, 0.0000, 0.1685, 0.1127, 0.1501,\n",
       "         0.0395]),\n",
       " 1777: tensor([0.1448, 0.1178, 0.0643, 0.1175, 0.1684, 0.0397, 0.1741, 0.0280, 0.0377,\n",
       "         0.0594, 0.0754, 0.1602, 0.0331, 0.0000, 0.0932, 0.0363, 0.0992, 0.0958,\n",
       "         0.0000, 0.0000, 0.0488, 0.1969, 0.1815, 0.2146, 0.0814, 0.0673, 0.0000,\n",
       "         0.0886]),\n",
       " 2490: tensor([0.1654, 0.3928, 0.1030, 0.2386, 0.4651, 0.6009, 0.1815, 0.3127, 0.0754,\n",
       "         0.3691, 0.2795, 0.0765, 0.2784, 0.0000, 0.0000, 0.2089, 0.3457, 0.1696,\n",
       "         0.0000, 0.2387, 0.1602, 0.1244, 0.2710, 0.0000, 0.2308, 0.2658, 0.1930,\n",
       "         0.0313]),\n",
       " 4064: tensor([0.0303, 0.0000, 0.2491, 0.0000, 0.0452, 0.2246, 0.1756, 0.0000, 0.1184,\n",
       "         0.0132, 0.2302, 0.1575, 0.1152, 0.1702, 0.0700, 0.2446, 0.0000, 0.1122,\n",
       "         0.1145, 0.1877, 0.3140, 0.1890, 0.2715, 0.0000, 0.0223, 0.1905, 0.2043,\n",
       "         0.0000]),\n",
       " 2479: tensor([0.1448, 0.2869, 0.1680, 0.1927, 0.2219, 0.2131, 0.3062, 0.1102, 0.1766,\n",
       "         0.0300, 0.0116, 0.3583, 0.3367, 0.0048, 0.1462, 0.0000, 0.1267, 0.0000,\n",
       "         0.1977, 0.0411, 0.2028, 0.0000, 0.3263, 0.0000, 0.0872, 0.1382, 0.0000,\n",
       "         0.0876]),\n",
       " 919: tensor([0.0900, 0.2461, 0.0710, 0.0441, 0.0719, 0.1833, 0.2290, 0.2660, 0.0825,\n",
       "         0.1737, 0.1756, 0.0321, 0.1455, 0.0000, 0.0000, 0.0665, 0.0976, 0.0155,\n",
       "         0.0000, 0.0878, 0.2894, 0.0459, 0.0993, 0.0000, 0.2520, 0.1880, 0.1552,\n",
       "         0.1313]),\n",
       " 2141: tensor([0.0737, 0.0000, 0.4333, 0.1896, 0.0000, 0.0000, 0.1372, 0.0000, 0.0210,\n",
       "         0.0000, 0.1559, 0.1240, 0.0837, 0.2231, 0.2401, 0.3525, 0.1557, 0.1283,\n",
       "         0.2399, 0.2908, 0.0480, 0.0000, 0.0000, 0.3386, 0.0000, 0.0362, 0.0364,\n",
       "         0.0000]),\n",
       " 1145: tensor([0.1193, 0.1193, 0.1538, 0.0689, 0.0000, 0.1590, 0.3043, 0.0462, 0.1057,\n",
       "         0.1557, 0.1262, 0.0000, 0.0000, 0.0047, 0.0629, 0.2359, 0.2575, 0.0533,\n",
       "         0.0000, 0.1381, 0.0000, 0.2084, 0.0000, 0.0000, 0.2329, 0.1949, 0.1465,\n",
       "         0.1383]),\n",
       " 1439: tensor([0.2225, 0.0408, 0.0780, 0.1870, 0.1778, 0.2096, 0.1091, 0.0434, 0.1135,\n",
       "         0.0000, 0.0447, 0.1666, 0.0937, 0.1256, 0.2680, 0.1351, 0.0000, 0.1309,\n",
       "         0.2064, 0.2541, 0.1077, 0.0843, 0.0000, 0.1749, 0.0972, 0.1088, 0.3064,\n",
       "         0.2375]),\n",
       " 2739: tensor([0.1541, 0.2054, 0.0000, 0.0000, 0.0000, 0.2245, 0.1860, 0.2631, 0.0000,\n",
       "         0.0879, 0.1247, 0.1589, 0.1710, 0.2473, 0.1424, 0.2197, 0.0000, 0.0520,\n",
       "         0.1899, 0.2003, 0.0000, 0.1536, 0.0000, 0.2859, 0.1835, 0.0785, 0.0212,\n",
       "         0.3035]),\n",
       " 1797: tensor([0.0000, 0.0000, 0.0000, 0.2809, 0.2358, 0.3735, 0.0000, 0.0000, 0.2004,\n",
       "         0.2726, 0.1518, 0.3272, 0.0000, 0.0085, 0.2807, 0.2695, 0.1314, 0.0000,\n",
       "         0.5725, 0.2520, 0.0472, 0.0000, 0.0000, 0.0000, 0.2250, 0.0000, 0.4498,\n",
       "         0.0379]),\n",
       " 3275: tensor([0.0000, 0.0000, 0.3511, 0.0008, 0.1130, 0.3192, 0.1595, 0.0360, 0.0792,\n",
       "         0.0993, 0.2598, 0.1684, 0.1275, 0.4199, 0.2285, 0.2440, 0.0000, 0.1402,\n",
       "         0.1990, 0.1627, 0.0475, 0.2926, 0.1372, 0.0000, 0.1524, 0.0248, 0.1706,\n",
       "         0.0000]),\n",
       " 404: tensor([0.0958, 0.1895, 0.1804, 0.0346, 0.1742, 0.1249, 0.0000, 0.2552, 0.0000,\n",
       "         0.2312, 0.1567, 0.0000, 0.2703, 0.0000, 0.0000, 0.0558, 0.1047, 0.1779,\n",
       "         0.0000, 0.0481, 0.1210, 0.0857, 0.0610, 0.0000, 0.1171, 0.1908, 0.1374,\n",
       "         0.0863]),\n",
       " 1176: tensor([0.1091, 0.1256, 0.0000, 0.1109, 0.2244, 0.0849, 0.0568, 0.0290, 0.0971,\n",
       "         0.2219, 0.0769, 0.0923, 0.2074, 0.1221, 0.0427, 0.0000, 0.0337, 0.0471,\n",
       "         0.0587, 0.1418, 0.2446, 0.1500, 0.0159, 0.0216, 0.0381, 0.2303, 0.0460,\n",
       "         0.3576]),\n",
       " 4056: tensor([0.2813, 0.1019, 0.0000, 0.3010, 0.1951, 0.1116, 0.0987, 0.1291, 0.1885,\n",
       "         0.1438, 0.0733, 0.1111, 0.1937, 0.0321, 0.1560, 0.0000, 0.1382, 0.1257,\n",
       "         0.1898, 0.2454, 0.1694, 0.1240, 0.1650, 0.0000, 0.1690, 0.5662, 0.1241,\n",
       "         0.1200]),\n",
       " 3714: tensor([0.2926, 0.1629, 0.0000, 0.0000, 0.0000, 0.0472, 0.0822, 0.2713, 0.0000,\n",
       "         0.1699, 0.1752, 0.2156, 0.1287, 0.2905, 0.2651, 0.2493, 0.3015, 0.2104,\n",
       "         0.0298, 0.0929, 0.1128, 0.4057, 0.0000, 0.2242, 0.1406, 0.2864, 0.0000,\n",
       "         0.0000]),\n",
       " 4282: tensor([0.0530, 0.1322, 0.0000, 0.1021, 0.0777, 0.5994, 0.1233, 0.1130, 0.0000,\n",
       "         0.0057, 0.2301, 0.2770, 0.1473, 0.0570, 0.0000, 0.1273, 0.1043, 0.0928,\n",
       "         0.3277, 0.0870, 0.0000, 0.1632, 0.3502, 0.0696, 0.0000, 0.0338, 0.0949,\n",
       "         0.1411]),\n",
       " 3498: tensor([0.0308, 0.2323, 0.0487, 0.3269, 0.0000, 0.1290, 0.1190, 0.2437, 0.2728,\n",
       "         0.2399, 0.0741, 0.0000, 0.0000, 0.1005, 0.2122, 0.1720, 0.2390, 0.1559,\n",
       "         0.0000, 0.0373, 0.3420, 0.0508, 0.0000, 0.0000, 0.1469, 0.3697, 0.1357,\n",
       "         0.3157]),\n",
       " 1691: tensor([0.0000, 0.0000, 0.2182, 0.1579, 0.1058, 0.1779, 0.0000, 0.0000, 0.1390,\n",
       "         0.2545, 0.1086, 0.1387, 0.0000, 0.1361, 0.1385, 0.1505, 0.4082, 0.0834,\n",
       "         0.1520, 0.0356, 0.1436, 0.0186, 0.0000, 0.0000, 0.0935, 0.0000, 0.1503,\n",
       "         0.1443]),\n",
       " 3768: tensor([0.0000, 0.0872, 0.1751, 0.1692, 0.1426, 0.0857, 0.1506, 0.0000, 0.0000,\n",
       "         0.1476, 0.0000, 0.2116, 0.3104, 0.4804, 0.0000, 0.1636, 0.1763, 0.1822,\n",
       "         0.1318, 0.2087, 0.0000, 0.0000, 0.1218, 0.0000, 0.1388, 0.0000, 0.0810,\n",
       "         0.1907]),\n",
       " 3129: tensor([0.1280, 0.1430, 0.0862, 0.1375, 0.0000, 0.1759, 0.1082, 0.1137, 0.2005,\n",
       "         0.1322, 0.2126, 0.0000, 0.0000, 0.1730, 0.1411, 0.1455, 0.1706, 0.1777,\n",
       "         0.0000, 0.1535, 0.1630, 0.1312, 0.0000, 0.0000, 0.0762, 0.1426, 0.1909,\n",
       "         0.1834]),\n",
       " 3349: tensor([0.1637, 0.1040, 0.1241, 0.1436, 0.0000, 0.1323, 0.1416, 0.1520, 0.0884,\n",
       "         0.1611, 0.1075, 0.1125, 0.1231, 0.1309, 0.2041, 0.1422, 0.1382, 0.1926,\n",
       "         0.0868, 0.1288, 0.1281, 0.1057, 0.0000, 0.1394, 0.1167, 0.1596, 0.0839,\n",
       "         0.0429]),\n",
       " 1896: tensor([0.2275, 0.1926, 0.0000, 0.0711, 0.0000, 0.0608, 0.3234, 0.3070, 0.2070,\n",
       "         0.2480, 0.0000, 0.1675, 0.2195, 0.3909, 0.1225, 0.1765, 0.1792, 0.0847,\n",
       "         0.1766, 0.0000, 0.1474, 0.2356, 0.0000, 0.0000, 0.2167, 0.4077, 0.2410,\n",
       "         0.1126]),\n",
       " 3347: tensor([0.0829, 0.1001, 0.0000, 0.2525, 0.3323, 0.2178, 0.2233, 0.1184, 0.1049,\n",
       "         0.0996, 0.0012, 0.0606, 0.1597, 0.1645, 0.0372, 0.0000, 0.0797, 0.0000,\n",
       "         0.1842, 0.1625, 0.0977, 0.0497, 0.2469, 0.0000, 0.0388, 0.2044, 0.0000,\n",
       "         0.2366]),\n",
       " 1360: tensor([0.1471, 0.2357, 0.0999, 0.0693, 0.0000, 0.3180, 0.1690, 0.0968, 0.2493,\n",
       "         0.1037, 0.2310, 0.0000, 0.0000, 0.1607, 0.0791, 0.2678, 0.2849, 0.1546,\n",
       "         0.0000, 0.2303, 0.1317, 0.1759, 0.0000, 0.0000, 0.1683, 0.3551, 0.2627,\n",
       "         0.2367]),\n",
       " 2030: tensor([0.0000, 0.1503, 0.2776, 0.0000, 0.0000, 0.0411, 0.2058, 0.0000, 0.0000,\n",
       "         0.0000, 0.2165, 0.2657, 0.1567, 0.1117, 0.0000, 0.2148, 0.1141, 0.0000,\n",
       "         0.2513, 0.2835, 0.0000, 0.0456, 0.4111, 0.1433, 0.0000, 0.1916, 0.2775,\n",
       "         0.1646]),\n",
       " 2855: tensor([0.4400, 0.4017, 0.3866, 0.0706, 0.0197, 0.0000, 0.1998, 0.3027, 0.4245,\n",
       "         0.0000, 0.0000, 0.2435, 0.1308, 0.2713, 0.2489, 0.1608, 0.2049, 0.1149,\n",
       "         0.1978, 0.1565, 0.1758, 0.0806, 0.1520, 0.1380, 0.1186, 0.0000, 0.1903,\n",
       "         0.2048]),\n",
       " 354: tensor([0.1110, 0.1700, 0.0890, 0.1090, 0.2521, 0.2366, 0.1311, 0.1541, 0.1449,\n",
       "         0.0838, 0.1311, 0.1166, 0.1222, 0.0000, 0.0000, 0.1916, 0.1293, 0.1111,\n",
       "         0.0000, 0.0675, 0.1653, 0.1594, 0.1347, 0.0000, 0.2604, 0.1948, 0.0715,\n",
       "         0.0875]),\n",
       " 3181: tensor([0.0000, 0.1496, 0.1230, 0.0000, 0.1942, 0.2202, 0.1138, 0.1032, 0.1668,\n",
       "         0.0885, 0.0451, 0.1927, 0.1248, 0.2021, 0.1258, 0.1000, 0.0380, 0.1240,\n",
       "         0.2370, 0.1727, 0.0990, 0.1533, 0.1855, 0.1124, 0.0000, 0.0900, 0.1211,\n",
       "         0.1018]),\n",
       " 2458: tensor([0.1620, 0.0022, 0.0285, 0.0030, 0.0000, 0.0306, 0.1890, 0.1217, 0.2748,\n",
       "         0.3546, 0.0000, 0.0158, 0.0504, 0.0528, 0.1534, 0.0099, 0.0135, 0.2087,\n",
       "         0.0352, 0.0691, 0.0713, 0.0445, 0.2095, 0.1219, 0.0685, 0.0000, 0.0000,\n",
       "         0.0304]),\n",
       " 1438: tensor([0.1422, 0.1899, 0.0554, 0.0517, 0.0000, 0.2206, 0.3152, 0.1221, 0.1244,\n",
       "         0.2555, 0.0831, 0.1096, 0.3274, 0.0000, 0.1970, 0.0000, 0.0000, 0.2440,\n",
       "         0.0000, 0.1093, 0.3071, 0.0000, 0.0000, 0.3309, 0.0046, 0.4092, 0.1366,\n",
       "         0.0551]),\n",
       " 2352: tensor([0.1386, 0.2173, 0.0102, 0.0900, 0.0585, 0.0000, 0.1054, 0.1873, 0.1601,\n",
       "         0.1469, 0.0452, 0.0000, 0.2751, 0.0000, 0.0633, 0.0454, 0.2526, 0.1411,\n",
       "         0.0000, 0.0000, 0.3218, 0.0000, 0.0000, 0.1294, 0.0000, 0.2602, 0.1909,\n",
       "         0.2331]),\n",
       " 256: tensor([0.1366, 0.1692, 0.0864, 0.1434, 0.0739, 0.1221, 0.1996, 0.1648, 0.1261,\n",
       "         0.1364, 0.1246, 0.0580, 0.1325, 0.0000, 0.0000, 0.0916, 0.1557, 0.0935,\n",
       "         0.0000, 0.0167, 0.1124, 0.1203, 0.1359, 0.0000, 0.2551, 0.1072, 0.0845,\n",
       "         0.1323]),\n",
       " 2598: tensor([0.0028, 0.1545, 0.1354, 0.0374, 0.0000, 0.1270, 0.1326, 0.1872, 0.1401,\n",
       "         0.0536, 0.0828, 0.1099, 0.1689, 0.3066, 0.1555, 0.2426, 0.1007, 0.1018,\n",
       "         0.2058, 0.2258, 0.1013, 0.1918, 0.0000, 0.0035, 0.1007, 0.1397, 0.0786,\n",
       "         0.0350]),\n",
       " 3729: tensor([0.0000, 0.2149, 0.1134, 0.0000, 0.2667, 0.1600, 0.1265, 0.0569, 0.2545,\n",
       "         0.0383, 0.2119, 0.1108, 0.3585, 0.2325, 0.0322, 0.2232, 0.0009, 0.1221,\n",
       "         0.2651, 0.0850, 0.1107, 0.2229, 0.0000, 0.0000, 0.0000, 0.1777, 0.1748,\n",
       "         0.1029]),\n",
       " 444: tensor([0.3493, 0.0312, 0.2057, 0.1654, 0.2399, 0.0000, 0.1694, 0.1107, 0.0902,\n",
       "         0.0925, 0.0000, 0.2009, 0.1611, 0.1450, 0.1412, 0.1408, 0.1086, 0.1425,\n",
       "         0.1639, 0.1718, 0.1084, 0.2950, 0.2860, 0.0692, 0.2747, 0.0000, 0.1456,\n",
       "         0.1425]),\n",
       " 4191: tensor([0.0000, 0.1543, 0.1691, 0.2634, 0.3055, 0.0476, 0.1344, 0.0000, 0.0000,\n",
       "         0.1658, 0.2371, 0.0604, 0.0000, 0.1855, 0.2305, 0.0675, 0.1304, 0.0000,\n",
       "         0.2547, 0.3726, 0.2157, 0.0655, 0.0000, 0.1857, 0.0000, 0.1935, 0.1618,\n",
       "         0.0767]),\n",
       " 3926: tensor([0.0000, 0.1203, 0.1051, 0.1136, 0.1551, 0.1908, 0.0535, 0.0586, 0.0865,\n",
       "         0.0512, 0.1701, 0.0000, 0.2532, 0.1135, 0.0000, 0.1474, 0.0000, 0.1347,\n",
       "         0.1806, 0.1428, 0.0000, 0.0711, 0.0000, 0.0821, 0.0962, 0.1042, 0.2557,\n",
       "         0.0651]),\n",
       " 1387: tensor([0.0000, 0.0000, 0.0726, 0.1458, 0.1160, 0.2424, 0.1061, 0.1847, 0.1092,\n",
       "         0.1664, 0.1508, 0.1608, 0.0724, 0.1478, 0.1649, 0.2845, 0.0000, 0.2585,\n",
       "         0.0950, 0.0738, 0.0000, 0.1191, 0.1411, 0.0000, 0.0634, 0.1210, 0.0547,\n",
       "         0.0000]),\n",
       " 1255: tensor([0.1313, 0.0439, 0.0641, 0.0000, 0.0971, 0.1784, 0.0647, 0.0000, 0.0862,\n",
       "         0.1246, 0.2930, 0.1141, 0.0000, 0.1799, 0.0566, 0.1132, 0.0000, 0.2105,\n",
       "         0.1254, 0.1721, 0.1351, 0.2379, 0.1143, 0.0000, 0.0872, 0.2050, 0.0000,\n",
       "         0.0000]),\n",
       " 3421: tensor([0.0373, 0.0000, 0.0663, 0.2362, 0.0000, 0.0892, 0.1542, 0.1118, 0.0989,\n",
       "         0.2042, 0.1253, 0.0000, 0.0867, 0.0000, 0.0000, 0.1170, 0.1418, 0.0000,\n",
       "         0.1825, 0.2949, 0.0000, 0.0000, 0.0962, 0.0894, 0.0000, 0.0000, 0.2020,\n",
       "         0.1117]),\n",
       " 2466: tensor([0.2011, 0.1188, 0.1634, 0.2655, 0.1830, 0.2209, 0.0227, 0.0000, 0.1864,\n",
       "         0.0314, 0.1906, 0.2290, 0.3453, 0.3308, 0.1337, 0.0000, 0.1041, 0.0000,\n",
       "         0.3964, 0.0000, 0.0230, 0.0628, 0.2728, 0.0877, 0.0000, 0.0000, 0.0000,\n",
       "         0.5428]),\n",
       " 1249: tensor([0.0799, 0.0000, 0.0000, 0.0000, 0.3744, 0.1568, 0.1556, 0.0000, 0.1300,\n",
       "         0.1611, 0.2376, 0.0641, 0.1277, 0.0901, 0.3998, 0.1694, 0.2397, 0.3560,\n",
       "         0.0517, 0.1052, 0.1742, 0.0000, 0.0940, 0.0000, 0.2572, 0.1851, 0.1800,\n",
       "         0.2582]),\n",
       " 1822: tensor([0.3631, 0.1146, 0.1927, 0.1155, 0.1713, 0.0000, 0.1282, 0.1321, 0.1927,\n",
       "         0.0717, 0.0000, 0.1653, 0.1218, 0.1241, 0.1834, 0.1805, 0.1710, 0.1808,\n",
       "         0.1714, 0.1413, 0.1378, 0.2640, 0.2145, 0.0000, 0.1971, 0.0000, 0.0538,\n",
       "         0.1159]),\n",
       " 2286: tensor([0.2191, 0.0757, 0.1774, 0.2326, 0.2450, 0.0000, 0.1669, 0.1932, 0.2852,\n",
       "         0.1954, 0.0000, 0.1702, 0.1049, 0.1378, 0.0000, 0.2314, 0.1944, 0.2354,\n",
       "         0.1068, 0.1689, 0.1163, 0.3655, 0.3305, 0.0446, 0.1521, 0.0000, 0.0821,\n",
       "         0.1998]),\n",
       " 1941: tensor([0.0000, 0.0000, 0.3538, 0.1454, 0.0822, 0.0000, 0.0000, 0.0000, 0.2428,\n",
       "         0.1669, 0.0000, 0.0218, 0.0000, 0.1558, 0.1798, 0.2501, 0.2817, 0.0654,\n",
       "         0.1761, 0.1189, 0.0317, 0.0665, 0.0000, 0.0000, 0.0663, 0.0000, 0.1216,\n",
       "         0.2320]),\n",
       " 1275: tensor([0.1449, 0.0000, 0.0000, 0.4865, 0.0000, 0.3128, 0.5270, 0.0152, 0.0000,\n",
       "         0.0000, 0.0846, 0.0000, 0.1444, 0.0830, 0.0000, 0.0331, 0.3275, 0.0000,\n",
       "         0.1539, 0.4142, 0.2189, 0.0000, 0.3876, 0.2336, 0.0000, 0.0000, 0.4993,\n",
       "         0.2630]),\n",
       " 4428: tensor([0.2262, 0.0000, 0.1286, 0.0950, 0.3962, 0.0000, 0.0000, 0.2417, 0.1233,\n",
       "         0.0000, 0.1720, 0.0000, 0.2259, 0.5568, 0.3458, 0.0997, 0.1946, 0.4197,\n",
       "         0.1688, 0.0407, 0.0161, 0.0000, 0.0000, 0.0476, 0.1966, 0.0864, 0.2292,\n",
       "         0.2625]),\n",
       " 3273: tensor([0.1631, 0.0000, 0.2433, 0.2511, 0.0000, 0.0000, 0.0615, 0.0000, 0.0000,\n",
       "         0.4123, 0.2559, 0.0000, 0.0000, 0.2167, 0.0163, 0.1909, 0.0000, 0.0041,\n",
       "         0.3287, 0.0369, 0.1613, 0.0000, 0.0000, 0.3051, 0.0000, 0.0711, 0.0918,\n",
       "         0.3102]),\n",
       " 4416: tensor([0.0742, 0.1087, 0.0754, 0.0000, 0.2464, 0.1271, 0.0588, 0.0000, 0.0000,\n",
       "         0.0307, 0.2190, 0.0000, 0.0844, 0.3487, 0.0339, 0.2838, 0.0000, 0.1647,\n",
       "         0.1082, 0.1792, 0.0980, 0.2034, 0.1910, 0.0318, 0.1251, 0.2769, 0.0000,\n",
       "         0.0000]),\n",
       " 1101: tensor([0.2241, 0.1810, 0.3751, 0.0418, 0.2152, 0.2983, 0.1087, 0.2789, 0.0966,\n",
       "         0.4987, 0.1340, 0.3655, 0.1206, 0.3711, 0.1618, 0.1474, 0.2162, 0.1752,\n",
       "         0.1514, 0.0784, 0.1237, 0.1706, 0.1047, 0.2552, 0.0000, 0.2317, 0.0687,\n",
       "         0.2521]),\n",
       " 297: tensor([0.2524, 0.3736, 0.0000, 0.2897, 0.3884, 0.4019, 0.3209, 0.2308, 0.2256,\n",
       "         0.0024, 0.0979, 0.4390, 0.2266, 0.0000, 0.0000, 0.2596, 0.1403, 0.0858,\n",
       "         0.1588, 0.0710, 0.2623, 0.1710, 0.0242, 0.0894, 0.3204, 0.2706, 0.1509,\n",
       "         0.1138]),\n",
       " 3992: tensor([0.1806, 0.0895, 0.1537, 0.0000, 0.1104, 0.1849, 0.1061, 0.0000, 0.2863,\n",
       "         0.3963, 0.4178, 0.1734, 0.0372, 0.1343, 0.1957, 0.0677, 0.0000, 0.1004,\n",
       "         0.2485, 0.1842, 0.2895, 0.3961, 0.0934, 0.0000, 0.0663, 0.3292, 0.0000,\n",
       "         0.0000]),\n",
       " 3450: tensor([0.1636, 0.2096, 0.0538, 0.1646, 0.0000, 0.0172, 0.0856, 0.1355, 0.1357,\n",
       "         0.2985, 0.1839, 0.1043, 0.1693, 0.1202, 0.1629, 0.1182, 0.1193, 0.1955,\n",
       "         0.0999, 0.2156, 0.1909, 0.0887, 0.2025, 0.0886, 0.1541, 0.0000, 0.0609,\n",
       "         0.1899]),\n",
       " 2769: tensor([0.0152, 0.1900, 0.2811, 0.1965, 0.2385, 0.0000, 0.1575, 0.2713, 0.0407,\n",
       "         0.2885, 0.0896, 0.1169, 0.3118, 0.2913, 0.0000, 0.0508, 0.0000, 0.1689,\n",
       "         0.2577, 0.0853, 0.0825, 0.1721, 0.1160, 0.1432, 0.1483, 0.0000, 0.4331,\n",
       "         0.0000]),\n",
       " 2787: tensor([0.2955, 0.1598, 0.1834, 0.2464, 0.1385, 0.3103, 0.0897, 0.0000, 0.2722,\n",
       "         0.1425, 0.1783, 0.2177, 0.2799, 0.1778, 0.2451, 0.0976, 0.1707, 0.0080,\n",
       "         0.0224, 0.2739, 0.1606, 0.0508, 0.1668, 0.0898, 0.0000, 0.2857, 0.3126,\n",
       "         0.2492]),\n",
       " 3184: tensor([0.0972, 0.1728, 0.0000, 0.0000, 0.0000, 0.0699, 0.2185, 0.2306, 0.2027,\n",
       "         0.0742, 0.0180, 0.1641, 0.1887, 0.2429, 0.1812, 0.1533, 0.1827, 0.1037,\n",
       "         0.0906, 0.0654, 0.1539, 0.1637, 0.0000, 0.0940, 0.1383, 0.2589, 0.1640,\n",
       "         0.1580]),\n",
       " 3617: tensor([0.1907, 0.1896, 0.0792, 0.0893, 0.0000, 0.1331, 0.2038, 0.2474, 0.1269,\n",
       "         0.2165, 0.1029, 0.1351, 0.1188, 0.4213, 0.1205, 0.2032, 0.0711, 0.1143,\n",
       "         0.1374, 0.1309, 0.0400, 0.1576, 0.0000, 0.0587, 0.1003, 0.2862, 0.0381,\n",
       "         0.0842]),\n",
       " 4106: tensor([0.2077, 0.1944, 0.0793, 0.0961, 0.0000, 0.1765, 0.2796, 0.0971, 0.0748,\n",
       "         0.0555, 0.1015, 0.2981, 0.0562, 0.0000, 0.2021, 0.1142, 0.0596, 0.1154,\n",
       "         0.0000, 0.2255, 0.1852, 0.0000, 0.0000, 0.2681, 0.2421, 0.2574, 0.1380,\n",
       "         0.1156]),\n",
       " 703: tensor([0.0000, 0.1850, 0.1718, 0.0621, 0.1543, 0.0636, 0.1347, 0.1522, 0.1859,\n",
       "         0.0194, 0.3263, 0.0000, 0.2994, 0.1661, 0.0000, 0.0700, 0.0000, 0.0509,\n",
       "         0.0682, 0.1939, 0.0000, 0.1201, 0.0000, 0.1933, 0.1144, 0.0910, 0.0563,\n",
       "         0.0559]),\n",
       " 987: tensor([0.0641, 0.0000, 0.0000, 0.1205, 0.3095, 0.2265, 0.1007, 0.1974, 0.2444,\n",
       "         0.0000, 0.2439, 0.0000, 0.1490, 0.1157, 0.1011, 0.3069, 0.0000, 0.1665,\n",
       "         0.1441, 0.0783, 0.0655, 0.1435, 0.1183, 0.1899, 0.0587, 0.0495, 0.0000,\n",
       "         0.1294]),\n",
       " 1951: tensor([0.0000, 0.0519, 0.3427, 0.2197, 0.3206, 0.0922, 0.0515, 0.0000, 0.0000,\n",
       "         0.2566, 0.3205, 0.1300, 0.0000, 0.1652, 0.1423, 0.2016, 0.0682, 0.0000,\n",
       "         0.2620, 0.3976, 0.4050, 0.0000, 0.0000, 0.0621, 0.0000, 0.2500, 0.0326,\n",
       "         0.1492]),\n",
       " 3779: tensor([0.1869, 0.1120, 0.0090, 0.1628, 0.1470, 0.1180, 0.1822, 0.2039, 0.0853,\n",
       "         0.0467, 0.0853, 0.1517, 0.0718, 0.1722, 0.0651, 0.1464, 0.0870, 0.1577,\n",
       "         0.1062, 0.1682, 0.1380, 0.1265, 0.1614, 0.1031, 0.1104, 0.1206, 0.0000,\n",
       "         0.1744]),\n",
       " 3227: tensor([0.1738, 0.0000, 0.0000, 0.0000, 0.4018, 0.0803, 0.0718, 0.0000, 0.1353,\n",
       "         0.1182, 0.1449, 0.0000, 0.0633, 0.1296, 0.4906, 0.1599, 0.2732, 0.4303,\n",
       "         0.0691, 0.0763, 0.2374, 0.0000, 0.2726, 0.0000, 0.2300, 0.2638, 0.2029,\n",
       "         0.2899]),\n",
       " 624: tensor([0.1210, 0.1864, 0.1261, 0.0638, 0.3562, 0.4910, 0.0000, 0.3491, 0.0000,\n",
       "         0.3457, 0.4172, 0.0467, 0.0000, 0.0000, 0.0000, 0.1118, 0.2215, 0.2461,\n",
       "         0.0000, 0.1154, 0.0315, 0.0316, 0.2775, 0.0000, 0.0707, 0.3522, 0.2249,\n",
       "         0.2326]),\n",
       " 226: tensor([0.1090, 0.1284, 0.0870, 0.0898, 0.1791, 0.1314, 0.0000, 0.1556, 0.0361,\n",
       "         0.1192, 0.1286, 0.3445, 0.1108, 0.0000, 0.0000, 0.1379, 0.1332, 0.0000,\n",
       "         0.2483, 0.2799, 0.0855, 0.0000, 0.1056, 0.0923, 0.1259, 0.2028, 0.0866,\n",
       "         0.1659]),\n",
       " 2937: tensor([0.1996, 0.1686, 0.1016, 0.1622, 0.0000, 0.1166, 0.2161, 0.1213, 0.1393,\n",
       "         0.0784, 0.0566, 0.1085, 0.1416, 0.0000, 0.1974, 0.0950, 0.1538, 0.1708,\n",
       "         0.0000, 0.1538, 0.2017, 0.0000, 0.0000, 0.1698, 0.2047, 0.2379, 0.1592,\n",
       "         0.1077]),\n",
       " 3003: tensor([0.0000, 0.0951, 0.1765, 0.3576, 0.0000, 0.2018, 0.1052, 0.2575, 0.0692,\n",
       "         0.0491, 0.2207, 0.0789, 0.2079, 0.1028, 0.3032, 0.2942, 0.1744, 0.2736,\n",
       "         0.0104, 0.1513, 0.1403, 0.0385, 0.2480, 0.2139, 0.1587, 0.0000, 0.1953,\n",
       "         0.3087]),\n",
       " 3319: tensor([0.1603, 0.1778, 0.0697, 0.1246, 0.0000, 0.2414, 0.1368, 0.0643, 0.2898,\n",
       "         0.1357, 0.1701, 0.0000, 0.0000, 0.1338, 0.1226, 0.2256, 0.2388, 0.1485,\n",
       "         0.0000, 0.1233, 0.0965, 0.1244, 0.0000, 0.0000, 0.1989, 0.2785, 0.2203,\n",
       "         0.2566]),\n",
       " 4251: tensor([0.0000, 0.1406, 0.0973, 0.0927, 0.3451, 0.1779, 0.3408, 0.0493, 0.1868,\n",
       "         0.0000, 0.1008, 0.1684, 0.0887, 0.0000, 0.1694, 0.1805, 0.2416, 0.2559,\n",
       "         0.0000, 0.1816, 0.1758, 0.3740, 0.0653, 0.1530, 0.0000, 0.2396, 0.1500,\n",
       "         0.2148]),\n",
       " 3835: tensor([0.0558, 0.3868, 0.1059, 0.3222, 0.2152, 0.3862, 0.0000, 0.0347, 0.2716,\n",
       "         0.0000, 0.1196, 0.2844, 0.1857, 0.0566, 0.0000, 0.0000, 0.1441, 0.0000,\n",
       "         0.1925, 0.0000, 0.1869, 0.0000, 0.3437, 0.0154, 0.0000, 0.1134, 0.0000,\n",
       "         0.1485]),\n",
       " 2786: tensor([0.2044, 0.0000, 0.0000, 0.0000, 0.3492, 0.2094, 0.0983, 0.0000, 0.2380,\n",
       "         0.1631, 0.1339, 0.0000, 0.1348, 0.0976, 0.4507, 0.1527, 0.2335, 0.2933,\n",
       "         0.1757, 0.0772, 0.2567, 0.0000, 0.2194, 0.0534, 0.1260, 0.2291, 0.2459,\n",
       "         0.3033]),\n",
       " 3709: tensor([0.1179, 0.2763, 0.0000, 0.1580, 0.0000, 0.0752, 0.0484, 0.1444, 0.0818,\n",
       "         0.2686, 0.2208, 0.0356, 0.2064, 0.0905, 0.1300, 0.1276, 0.1434, 0.1915,\n",
       "         0.0699, 0.2409, 0.1730, 0.0626, 0.1809, 0.1296, 0.0869, 0.0000, 0.0735,\n",
       "         0.1978]),\n",
       " 3692: tensor([0.1106, 0.0896, 0.0000, 0.1148, 0.2468, 0.1085, 0.1481, 0.1672, 0.1162,\n",
       "         0.0991, 0.1238, 0.1236, 0.2326, 0.1062, 0.0952, 0.0881, 0.1359, 0.1112,\n",
       "         0.0712, 0.1362, 0.1723, 0.1235, 0.0000, 0.0532, 0.1397, 0.1901, 0.0837,\n",
       "         0.1280]),\n",
       " 1: tensor([0.1827, 0.1291, 0.0613, 0.1611, 0.1375, 0.0672, 0.1765, 0.1967, 0.0850,\n",
       "         0.0642, 0.0826, 0.1597, 0.0621, 0.1449, 0.0590, 0.1268, 0.0945, 0.1528,\n",
       "         0.1304, 0.1896, 0.1252, 0.0793, 0.1288, 0.1108, 0.0984, 0.1239, 0.0000,\n",
       "         0.1849]),\n",
       " 1766: tensor([0.1204, 0.1089, 0.1105, 0.1252, 0.0689, 0.1299, 0.0652, 0.1502, 0.0561,\n",
       "         0.1237, 0.1071, 0.2333, 0.0846, 0.0000, 0.0000, 0.1062, 0.1268, 0.0805,\n",
       "         0.1966, 0.0924, 0.0752, 0.0169, 0.1375, 0.1240, 0.1480, 0.0962, 0.0911,\n",
       "         0.0908]),\n",
       " 2054: tensor([0.1227, 0.0957, 0.1001, 0.1301, 0.0000, 0.1471, 0.1322, 0.0807, 0.1004,\n",
       "         0.1288, 0.1500, 0.0000, 0.0000, 0.1210, 0.0802, 0.0874, 0.1797, 0.0833,\n",
       "         0.0000, 0.1371, 0.0706, 0.0989, 0.0000, 0.0219, 0.2250, 0.0552, 0.1291,\n",
       "         0.0899]),\n",
       " 4073: tensor([0.1873, 0.2012, 0.1209, 0.1375, 0.0658, 0.2875, 0.0695, 0.0333, 0.1637,\n",
       "         0.1675, 0.1000, 0.1292, 0.1422, 0.0953, 0.0687, 0.0855, 0.1388, 0.1022,\n",
       "         0.1359, 0.1551, 0.0863, 0.0595, 0.1323, 0.1267, 0.1417, 0.0000, 0.0483,\n",
       "         0.2044]),\n",
       " 2658: tensor([0.1231, 0.0588, 0.1272, 0.1694, 0.0000, 0.0957, 0.1788, 0.1764, 0.1323,\n",
       "         0.0428, 0.1228, 0.1082, 0.0896, 0.0920, 0.0768, 0.0172, 0.0991, 0.1309,\n",
       "         0.0203, 0.0458, 0.1227, 0.0791, 0.0000, 0.1543, 0.1307, 0.0987, 0.1632,\n",
       "         0.1164]),\n",
       " 327: tensor([0.0000, 0.1965, 0.1347, 0.0000, 0.2272, 0.1079, 0.1700, 0.0741, 0.0290,\n",
       "         0.1167, 0.0829, 0.0232, 0.1543, 0.1924, 0.0000, 0.2075, 0.0351, 0.2174,\n",
       "         0.1882, 0.1232, 0.0508, 0.1828, 0.1921, 0.1471, 0.0081, 0.1034, 0.0768,\n",
       "         0.0966]),\n",
       " 322: tensor([0.0000, 0.0000, 0.2314, 0.2063, 0.0987, 0.1020, 0.1242, 0.1321, 0.2856,\n",
       "         0.0280, 0.0659, 0.0342, 0.1677, 0.0777, 0.1016, 0.1989, 0.0000, 0.0712,\n",
       "         0.1290, 0.1034, 0.0000, 0.1298, 0.2515, 0.0000, 0.2169, 0.1476, 0.2165,\n",
       "         0.1816]),\n",
       " 1026: tensor([0.1645, 0.0523, 0.0786, 0.0774, 0.1137, 0.1667, 0.0944, 0.0000, 0.1892,\n",
       "         0.1481, 0.3046, 0.2118, 0.0266, 0.1554, 0.1015, 0.0000, 0.0000, 0.1356,\n",
       "         0.1308, 0.2945, 0.0370, 0.2039, 0.0835, 0.0576, 0.0655, 0.2295, 0.1635,\n",
       "         0.0000]),\n",
       " 1674: tensor([0.0718, 0.0908, 0.0000, 0.0802, 0.2161, 0.0969, 0.1261, 0.1018, 0.2000,\n",
       "         0.2033, 0.1024, 0.1218, 0.2560, 0.1284, 0.1493, 0.1381, 0.1363, 0.1227,\n",
       "         0.0884, 0.1330, 0.1970, 0.1190, 0.0044, 0.0000, 0.1371, 0.1406, 0.0378,\n",
       "         0.1458]),\n",
       " 2322: tensor([0.0000, 0.1443, 0.1274, 0.1713, 0.0932, 0.1407, 0.0987, 0.1119, 0.1203,\n",
       "         0.1345, 0.0655, 0.0182, 0.1285, 0.1208, 0.0000, 0.1018, 0.0000, 0.1274,\n",
       "         0.1377, 0.2137, 0.0000, 0.0444, 0.0063, 0.1244, 0.1171, 0.1467, 0.3052,\n",
       "         0.1155]),\n",
       " 3252: tensor([0.1274, 0.1419, 0.0000, 0.2272, 0.1205, 0.1688, 0.1992, 0.2114, 0.0697,\n",
       "         0.0579, 0.1121, 0.0960, 0.1004, 0.1497, 0.0470, 0.1361, 0.1772, 0.1166,\n",
       "         0.0805, 0.1357, 0.1615, 0.1469, 0.1449, 0.1034, 0.1019, 0.1171, 0.0000,\n",
       "         0.1173]),\n",
       " 1057: tensor([0.0000, 0.1531, 0.1228, 0.0000, 0.1339, 0.1467, 0.1582, 0.1234, 0.1130,\n",
       "         0.0706, 0.1366, 0.1017, 0.1217, 0.1499, 0.0496, 0.1841, 0.0264, 0.0881,\n",
       "         0.1503, 0.1311, 0.0956, 0.1570, 0.2017, 0.1879, 0.0000, 0.0642, 0.1066,\n",
       "         0.0810]),\n",
       " 1213: tensor([0.0000, 0.0000, 0.5459, 0.1370, 0.0689, 0.1344, 0.0000, 0.0000, 0.3510,\n",
       "         0.1986, 0.3406, 0.0000, 0.0000, 0.3904, 0.0000, 0.2703, 0.2990, 0.6115,\n",
       "         0.4455, 0.3576, 0.0659, 0.1735, 0.0000, 0.0000, 0.0000, 0.0000, 0.1745,\n",
       "         0.3151]),\n",
       " 2496: tensor([0.2262, 0.1479, 0.1501, 0.1506, 0.1770, 0.2078, 0.0776, 0.0097, 0.1219,\n",
       "         0.1083, 0.1275, 0.0439, 0.1778, 0.0000, 0.0000, 0.2173, 0.0624, 0.0828,\n",
       "         0.0000, 0.0129, 0.3191, 0.2657, 0.3010, 0.1533, 0.0075, 0.0245, 0.2431,\n",
       "         0.1256]),\n",
       " 1814: tensor([0.1492, 0.0000, 0.1994, 0.1226, 0.0000, 0.0000, 0.1913, 0.0000, 0.0611,\n",
       "         0.4324, 0.1277, 0.1957, 0.2392, 0.1081, 0.1629, 0.3236, 0.0964, 0.2108,\n",
       "         0.0000, 0.1070, 0.3046, 0.0000, 0.1563, 0.0667, 0.2496, 0.1666, 0.1226,\n",
       "         0.2826]),\n",
       " 499: tensor([0.2723, 0.2416, 0.0000, 0.1469, 0.3004, 0.1516, 0.3500, 0.1048, 0.1948,\n",
       "         0.0000, 0.0441, 0.1802, 0.4268, 0.0000, 0.0000, 0.3267, 0.0568, 0.2138,\n",
       "         0.0000, 0.0774, 0.2870, 0.2406, 0.0000, 0.0000, 0.4085, 0.1668, 0.1492,\n",
       "         0.0652]),\n",
       " 2475: tensor([0.0000, 0.4625, 0.0000, 0.2179, 0.0000, 0.0000, 0.2602, 0.4574, 0.0000,\n",
       "         0.0921, 0.2451, 0.0804, 0.1968, 0.1345, 0.1996, 0.3439, 0.0261, 0.1604,\n",
       "         0.2179, 0.1704, 0.2049, 0.2747, 0.2518, 0.1964, 0.1359, 0.0000, 0.3382,\n",
       "         0.0854]),\n",
       " 1548: tensor([0.0000, 0.0000, 0.1456, 0.1224, 0.1480, 0.3867, 0.1350, 0.1291, 0.0796,\n",
       "         0.0788, 0.0153, 0.0453, 0.0107, 0.1542, 0.0171, 0.1824, 0.0000, 0.0000,\n",
       "         0.1673, 0.1287, 0.0000, 0.2025, 0.0189, 0.0000, 0.2438, 0.1523, 0.0741,\n",
       "         0.0125]),\n",
       " 3394: tensor([0.2905, 0.0972, 0.0000, 0.3386, 0.0622, 0.0606, 0.1860, 0.2954, 0.0539,\n",
       "         0.1009, 0.1816, 0.1930, 0.1444, 0.0799, 0.0690, 0.2966, 0.0513, 0.2506,\n",
       "         0.2429, 0.0060, 0.1035, 0.1790, 0.1332, 0.0000, 0.2300, 0.3491, 0.0650,\n",
       "         0.2938]),\n",
       " 3213: tensor([0.2804, 0.0000, 0.2173, 0.4199, 0.0000, 0.0000, 0.0290, 0.0000, 0.0283,\n",
       "         0.0000, 0.2210, 0.0362, 0.1389, 0.1966, 0.1295, 0.2797, 0.0000, 0.1272,\n",
       "         0.2263, 0.0856, 0.1465, 0.0000, 0.0000, 0.1006, 0.0790, 0.0352, 0.1039,\n",
       "         0.2142]),\n",
       " 2513: tensor([0.2157, 0.0319, 0.1734, 0.2548, 0.0704, 0.3776, 0.1649, 0.1612, 0.0214,\n",
       "         0.1227, 0.0034, 0.3440, 0.2145, 0.0000, 0.0000, 0.2062, 0.0975, 0.3017,\n",
       "         0.0000, 0.2746, 0.2038, 0.1033, 0.2648, 0.0550, 0.1791, 0.0000, 0.0457,\n",
       "         0.1625]),\n",
       " 639: tensor([0.0837, 0.0000, 0.4327, 0.2046, 0.0000, 0.0000, 0.4086, 0.0000, 0.0000,\n",
       "         0.0863, 0.2930, 0.2904, 0.1062, 0.1001, 0.0629, 0.4093, 0.2154, 0.2422,\n",
       "         0.3580, 0.2257, 0.0057, 0.0000, 0.1547, 0.3072, 0.1084, 0.1304, 0.0969,\n",
       "         0.0145]),\n",
       " 1495: tensor([0.2625, 0.2289, 0.0246, 0.1420, 0.0964, 0.2025, 0.0825, 0.0000, 0.1446,\n",
       "         0.3332, 0.1946, 0.1259, 0.1539, 0.0000, 0.1521, 0.0468, 0.2950, 0.1596,\n",
       "         0.0568, 0.0083, 0.1654, 0.0286, 0.3702, 0.0769, 0.0000, 0.0000, 0.0591,\n",
       "         0.3685]),\n",
       " 237: tensor([0.1492, 0.1433, 0.0621, 0.0651, 0.1950, 0.2153, 0.1321, 0.1407, 0.1909,\n",
       "         0.1180, 0.1860, 0.1022, 0.0997, 0.0000, 0.0000, 0.1745, 0.0915, 0.1325,\n",
       "         0.0000, 0.0000, 0.0612, 0.1108, 0.1351, 0.0000, 0.2478, 0.1603, 0.1101,\n",
       "         0.1007]),\n",
       " 2635: tensor([0.2068, 0.2607, 0.0000, 0.2600, 0.0000, 0.0000, 0.0691, 0.1800, 0.1033,\n",
       "         0.2199, 0.1496, 0.0277, 0.2526, 0.0548, 0.0974, 0.1264, 0.1043, 0.1662,\n",
       "         0.0749, 0.2188, 0.2000, 0.1746, 0.2011, 0.1132, 0.0833, 0.0000, 0.1209,\n",
       "         0.2277]),\n",
       " 2142: tensor([0.2000, 0.0000, 0.0000, 0.2692, 0.0000, 0.0976, 0.1399, 0.1124, 0.2957,\n",
       "         0.0000, 0.2229, 0.0000, 0.1602, 0.1263, 0.0000, 0.0000, 0.1838, 0.0000,\n",
       "         0.4092, 0.1263, 0.0697, 0.0000, 0.1170, 0.1528, 0.0000, 0.0000, 0.2482,\n",
       "         0.0506]),\n",
       " 3523: tensor([0.0000, 0.1259, 0.0700, 0.0600, 0.0000, 0.2985, 0.0000, 0.1456, 0.0000,\n",
       "         0.2591, 0.1537, 0.2662, 0.1324, 0.0707, 0.1663, 0.3461, 0.1426, 0.3147,\n",
       "         0.0158, 0.2289, 0.1686, 0.2312, 0.0000, 0.2797, 0.1566, 0.3299, 0.1902,\n",
       "         0.0000]),\n",
       " 3174: tensor([0.0000, 0.1204, 0.0242, 0.2043, 0.2553, 0.2901, 0.0389, 0.0000, 0.1216,\n",
       "         0.0221, 0.3789, 0.0000, 0.1401, 0.0000, 0.0000, 0.0807, 0.0000, 0.1009,\n",
       "         0.1632, 0.2360, 0.0000, 0.2203, 0.0000, 0.1360, 0.0543, 0.1183, 0.3536,\n",
       "         0.1136]),\n",
       " 2948: tensor([0.3307, 0.0000, 0.1643, 0.2623, 0.1234, 0.0000, 0.0000, 0.6358, 0.3718,\n",
       "         0.0000, 0.1833, 0.0000, 0.2643, 0.3403, 0.3103, 0.4085, 0.1878, 0.3518,\n",
       "         0.1107, 0.3400, 0.0000, 0.3424, 0.0000, 0.0000, 0.1168, 0.3726, 0.2566,\n",
       "         0.1090]),\n",
       " 3176: tensor([0.1466, 0.1366, 0.0479, 0.0828, 0.0997, 0.2179, 0.2136, 0.0375, 0.0000,\n",
       "         0.0000, 0.1264, 0.1945, 0.2105, 0.0722, 0.1725, 0.0000, 0.2130, 0.0000,\n",
       "         0.1106, 0.1177, 0.1385, 0.0000, 0.1870, 0.0428, 0.0000, 0.2363, 0.0000,\n",
       "         0.1320]),\n",
       " 2910: tensor([0.0647, 0.0719, 0.0000, 0.1369, 0.2540, 0.1059, 0.1642, 0.1750, 0.1462,\n",
       "         0.1072, 0.1131, 0.1346, 0.2495, 0.1095, 0.0792, 0.0931, 0.1172, 0.1198,\n",
       "         0.0700, 0.1017, 0.1704, 0.1026, 0.0182, 0.1148, 0.1701, 0.1861, 0.0954,\n",
       "         0.0914]),\n",
       " 771: tensor([0.1787, 0.1949, 0.1226, 0.1270, 0.0511, 0.2975, 0.0598, 0.0366, 0.1590,\n",
       "         0.1759, 0.1064, 0.1293, 0.1427, 0.1002, 0.0787, 0.0896, 0.1415, 0.1078,\n",
       "         0.1401, 0.1513, 0.0809, 0.0322, 0.1389, 0.1322, 0.1485, 0.0000, 0.0240,\n",
       "         0.2054]),\n",
       " 369: tensor([0.0825, 0.0983, 0.1166, 0.0873, 0.1362, 0.1336, 0.0000, 0.1236, 0.1121,\n",
       "         0.0781, 0.0701, 0.2395, 0.0585, 0.0000, 0.0000, 0.1033, 0.1119, 0.0722,\n",
       "         0.1817, 0.1636, 0.0822, 0.0346, 0.0947, 0.1221, 0.1025, 0.1123, 0.0378,\n",
       "         0.0788]),\n",
       " 1165: tensor([0.2394, 0.0000, 0.1973, 0.2162, 0.0000, 0.0000, 0.0703, 0.0000, 0.1215,\n",
       "         0.1063, 0.1383, 0.1629, 0.1525, 0.1147, 0.1639, 0.3607, 0.1139, 0.2272,\n",
       "         0.0086, 0.1230, 0.1552, 0.0000, 0.0962, 0.0856, 0.1332, 0.1137, 0.0530,\n",
       "         0.1711]),\n",
       " 3284: tensor([0.0572, 0.0846, 0.0617, 0.0000, 0.4444, 0.1145, 0.0000, 0.2422, 0.0000,\n",
       "         0.0000, 0.0454, 0.0000, 0.0935, 0.2589, 0.0000, 0.1781, 0.2139, 0.0000,\n",
       "         0.2523, 0.3118, 0.0962, 0.0702, 0.2008, 0.1950, 0.0000, 0.0000, 0.0000,\n",
       "         0.2271]),\n",
       " 2478: tensor([0.1054, 0.0000, 0.1266, 0.0551, 0.1213, 0.1857, 0.1210, 0.0000, 0.1953,\n",
       "         0.1123, 0.3114, 0.1426, 0.1093, 0.1708, 0.0466, 0.0836, 0.0000, 0.1684,\n",
       "         0.1806, 0.2402, 0.1286, 0.2648, 0.1475, 0.1704, 0.0662, 0.1462, 0.1410,\n",
       "         0.0000]),\n",
       " 3822: tensor([0.2621, 0.2121, 0.0000, 0.3311, 0.0000, 0.3107, 0.4100, 0.0619, 0.0000,\n",
       "         0.0000, 0.3374, 0.0311, 0.3294, 0.0000, 0.0400, 0.0000, 0.3190, 0.2410,\n",
       "         0.0000, 0.4265, 0.1782, 0.3857, 0.0000, 0.5152, 0.2653, 0.0602, 0.4087,\n",
       "         0.3517]),\n",
       " 2471: tensor([0.2331, 0.4860, 0.0000, 0.4150, 0.1698, 0.5026, 0.1591, 0.6496, 0.0258,\n",
       "         0.2238, 0.1189, 0.0380, 0.1885, 0.0000, 0.0000, 0.0000, 0.3011, 0.0000,\n",
       "         0.0940, 0.1460, 0.0988, 0.0000, 0.2952, 0.0300, 0.0000, 0.5874, 0.0000,\n",
       "         0.2300]),\n",
       " 3289: tensor([0.0000, 0.0845, 0.0000, 0.0733, 0.0000, 0.2565, 0.3152, 0.2874, 0.2225,\n",
       "         0.1146, 0.0622, 0.0000, 0.0565, 0.1678, 0.2027, 0.0738, 0.2050, 0.1367,\n",
       "         0.0320, 0.0451, 0.1631, 0.2251, 0.1337, 0.1566, 0.0701, 0.0000, 0.2531,\n",
       "         0.0205]),\n",
       " 4387: tensor([0.3967, 0.1959, 0.0561, 0.0000, 0.0000, 0.0780, 0.1356, 0.0000, 0.0843,\n",
       "         0.2445, 0.0132, 0.3222, 0.0000, 0.1803, 0.0904, 0.2464, 0.0000, 0.2459,\n",
       "         0.0253, 0.2380, 0.2384, 0.0635, 0.2185, 0.0000, 0.1018, 0.3940, 0.0000,\n",
       "         0.0000]),\n",
       " 2804: tensor([0.0000, 0.0000, 0.1920, 0.1137, 0.0182, 0.5146, 0.0954, 0.0822, 0.1280,\n",
       "         0.1655, 0.2306, 0.1796, 0.0715, 0.3065, 0.2557, 0.2715, 0.0000, 0.1306,\n",
       "         0.1851, 0.1039, 0.0000, 0.0920, 0.1247, 0.0000, 0.1784, 0.0814, 0.0974,\n",
       "         0.0000]),\n",
       " 1468: tensor([0.0254, 0.0141, 0.0000, 0.1902, 0.1542, 0.4799, 0.0000, 0.1460, 0.0000,\n",
       "         0.1241, 0.2874, 0.0950, 0.2241, 0.0568, 0.0000, 0.2242, 0.1826, 0.0268,\n",
       "         0.4863, 0.1792, 0.0006, 0.1791, 0.0477, 0.0000, 0.0000, 0.1268, 0.2029,\n",
       "         0.2062]),\n",
       " 3685: tensor([0.2044, 0.0000, 0.1358, 0.1402, 0.0000, 0.0000, 0.0534, 0.0262, 0.1273,\n",
       "         0.1177, 0.0684, 0.1275, 0.1314, 0.1695, 0.1656, 0.1854, 0.0161, 0.1817,\n",
       "         0.1034, 0.0785, 0.0984, 0.0000, 0.1387, 0.0468, 0.1973, 0.0840, 0.1419,\n",
       "         0.1334]),\n",
       " 4047: tensor([0.0000, 0.2642, 0.1825, 0.0000, 0.1897, 0.0000, 0.2675, 0.1788, 0.2449,\n",
       "         0.0699, 0.0645, 0.0000, 0.0431, 0.3363, 0.0036, 0.1480, 0.0446, 0.1706,\n",
       "         0.2501, 0.2085, 0.0000, 0.0684, 0.0742, 0.2161, 0.0977, 0.3250, 0.1377,\n",
       "         0.1218]),\n",
       " 747: tensor([0.0760, 0.1710, 0.1677, 0.0580, 0.3321, 0.3049, 0.0000, 0.1534, 0.0000,\n",
       "         0.0699, 0.1309, 0.0131, 0.1342, 0.0000, 0.0000, 0.1058, 0.1181, 0.2205,\n",
       "         0.0000, 0.0000, 0.1274, 0.1549, 0.0401, 0.0000, 0.2242, 0.2581, 0.0705,\n",
       "         0.0023]),\n",
       " 2215: tensor([0.1301, 0.2085, 0.0000, 0.0000, 0.0000, 0.2356, 0.0867, 0.1732, 0.0000,\n",
       "         0.0000, 0.1494, 0.1216, 0.1103, 0.4059, 0.2144, 0.2692, 0.2505, 0.1359,\n",
       "         0.0000, 0.0000, 0.1209, 0.0827, 0.0000, 0.2882, 0.3750, 0.1658, 0.0788,\n",
       "         0.0713]),\n",
       " 3810: tensor([0.0000, 0.1147, 0.0320, 0.0000, 0.2973, 0.1605, 0.0199, 0.2352, 0.1758,\n",
       "         0.1939, 0.0622, 0.1183, 0.2144, 0.1250, 0.0000, 0.2345, 0.1517, 0.0000,\n",
       "         0.0000, 0.1659, 0.0606, 0.1497, 0.2039, 0.1768, 0.0000, 0.0687, 0.1530,\n",
       "         0.0214]),\n",
       " 3019: tensor([0.0930, 0.1193, 0.1310, 0.0928, 0.1777, 0.1158, 0.1836, 0.1623, 0.0987,\n",
       "         0.1303, 0.1019, 0.1011, 0.1801, 0.1543, 0.1334, 0.0947, 0.1021, 0.1281,\n",
       "         0.2043, 0.1617, 0.1572, 0.1701, 0.0545, 0.2180, 0.0000, 0.1582, 0.1737,\n",
       "         0.1460]),\n",
       " 1800: tensor([0.1201, 0.0876, 0.2267, 0.2121, 0.0000, 0.3033, 0.2786, 0.2914, 0.2482,\n",
       "         0.1873, 0.2293, 0.0000, 0.0000, 0.4043, 0.1311, 0.1078, 0.0857, 0.1345,\n",
       "         0.0000, 0.0932, 0.1875, 0.2082, 0.0000, 0.0000, 0.0952, 0.5487, 0.1876,\n",
       "         0.2092]),\n",
       " 3324: tensor([0.1644, 0.2418, 0.0000, 0.1874, 0.0000, 0.0789, 0.0773, 0.1560, 0.1066,\n",
       "         0.2828, 0.1937, 0.0698, 0.2049, 0.1041, 0.1431, 0.1018, 0.1190, 0.1640,\n",
       "         0.1007, 0.2529, 0.1999, 0.1079, 0.1857, 0.0821, 0.1216, 0.0000, 0.0971,\n",
       "         0.1748]),\n",
       " 510: tensor([0.1413, 0.0000, 0.4280, 0.0386, 0.0000, 0.0000, 0.1532, 0.0000, 0.0000,\n",
       "         0.0928, 0.1902, 0.1719, 0.2764, 0.1640, 0.0802, 0.3291, 0.1791, 0.2839,\n",
       "         0.2297, 0.1993, 0.1936, 0.0000, 0.1507, 0.1591, 0.2071, 0.2116, 0.1379,\n",
       "         0.0286]),\n",
       " 2469: tensor([0.0000, 0.3693, 0.3262, 0.0000, 0.2309, 0.1126, 0.1897, 0.4321, 0.0692,\n",
       "         0.2194, 0.2304, 0.0000, 0.4276, 0.1802, 0.0000, 0.2539, 0.0000, 0.1350,\n",
       "         0.0384, 0.0000, 0.0000, 0.1634, 0.0677, 0.0388, 0.0198, 0.0000, 0.4285,\n",
       "         0.1390]),\n",
       " 2921: tensor([0.0827, 0.1442, 0.1672, 0.1881, 0.0000, 0.1186, 0.1944, 0.1193, 0.1514,\n",
       "         0.1223, 0.1751, 0.1464, 0.0933, 0.0000, 0.1304, 0.1680, 0.0975, 0.1438,\n",
       "         0.0000, 0.1225, 0.1409, 0.0138, 0.0509, 0.2093, 0.1498, 0.1406, 0.1991,\n",
       "         0.0807]),\n",
       " 1258: tensor([0.0000, 0.1128, 0.0000, 0.0693, 0.0000, 0.2598, 0.0938, 0.0165, 0.0868,\n",
       "         0.0701, 0.1776, 0.0094, 0.0528, 0.2240, 0.1010, 0.2773, 0.0000, 0.2718,\n",
       "         0.1130, 0.1585, 0.1478, 0.1240, 0.0000, 0.2687, 0.0781, 0.1654, 0.3894,\n",
       "         0.1836]),\n",
       " 3058: tensor([0.0000, 0.0000, 0.1307, 0.1310, 0.0750, 0.2876, 0.0817, 0.1000, 0.2345,\n",
       "         0.1754, 0.0000, 0.2690, 0.1537, 0.2101, 0.2141, 0.3222, 0.0000, 0.1634,\n",
       "         0.0809, 0.1502, 0.0000, 0.1535, 0.2052, 0.0000, 0.0779, 0.2167, 0.1274,\n",
       "         0.1814]),\n",
       " ...}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X2_train data size:  4052\n",
      "X2_val data size:  225\n",
      "X2_test data size:  226\n"
     ]
    }
   ],
   "source": [
    "X2 = list(model2_dataset.values())\n",
    "X2 = [embedding.tolist() for embedding in X2]\n",
    "y2 = list(model2_dataset.keys())\n",
    "\n",
    "X2_train, X2_temp, y2_train, y2_temp = train_test_split(X2, y2, test_size=0.1, random_state=42)\n",
    "X2_val, X2_test, y2_val, y2_test = train_test_split(X2_temp, y2_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "print(\"X2_train data size: \", len(X2_train))\n",
    "print(\"X2_val data size: \", len(X2_val))\n",
    "print(\"X2_test data size: \", len(X2_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset2(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X_train = torch.tensor(X)\n",
    "        self.y_train = torch.tensor(y)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X_train)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X_train[idx], self.y_train[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model2(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size=28, num_classes=4503):\n",
    "        super(Model2, self).__init__()\n",
    "        self.linear1 = nn.Linear(input_size, num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(num_classes, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.relu(x)\n",
    "        out = self.linear2(x)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset2 = Dataset2(X2_train, y2_train)\n",
    "validation_dataset2 = Dataset2(X2_val, y2_val)\n",
    "test_dataset2 = Dataset2(X2_test, y2_test)\n",
    "\n",
    "batch_size=32\n",
    "train_dataloader2 = DataLoader(train_dataset2, batch_size, shuffle=True)\n",
    "validation_dataloader2 = DataLoader(validation_dataset2, batch_size=32)\n",
    "test_dataloader2 = DataLoader(test_dataset2, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(idx_to_word)\n",
    "model2 = Model2(num_classes=num_classes)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model2.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Train Loss: 0.27134026332527605, Val Loss: 0.30211034562852646\n",
      "Model saved as current validation loss is  0.30211034562852646\n",
      "Epoch 2/100, Train Loss: 0.2372627717250662, Val Loss: 0.3431283484564887\n",
      "Epoch 3/100, Train Loss: 0.13885037914315662, Val Loss: 0.4572447035047743\n",
      "Epoch 4/100, Train Loss: 0.061108798553536466, Val Loss: 0.5596921412150065\n",
      "Epoch 5/100, Train Loss: 0.034506489190862306, Val Loss: 0.613073844909668\n",
      "Epoch 6/100, Train Loss: 0.026751960628654033, Val Loss: 0.6347761705186632\n",
      "Early stopping at epoch 6 as there was no improvement in validation loss.\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "epochs = 100\n",
    "patience = 5\n",
    "best_val_loss = np.Inf\n",
    "current_patience = 0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model2.train()\n",
    "    # total_train_acc = 0.0\n",
    "    # total_train_count = 0.0\n",
    "    total_train_loss = 0.0\n",
    "\n",
    "    for inputs, labels in train_dataloader2:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model2(inputs)\n",
    "        train_loss = criterion(outputs, labels)\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # total_train_acc += (outputs.argmax(1) == labels).sum().item()\n",
    "        # total_train_count += labels.size(0)\n",
    "        total_train_loss += train_loss.item()\n",
    "        \n",
    "    model2.eval()\n",
    "    # total_val_acc = 0.0\n",
    "    # total_val_count = 0.0\n",
    "    total_val_loss = 0.0\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        for inputs, labels in validation_dataloader2:\n",
    "            outputs = model2(inputs)\n",
    "            val_loss = criterion(outputs, labels)\n",
    "            # total_val_acc += (outputs.argmax(1) == labels).sum().item()\n",
    "            # total_val_count += labels.size(0)\n",
    "            total_val_loss += val_loss.item()\n",
    "\n",
    "    # train_accuracy = total_train_acc / total_train_count\n",
    "    # val_accuracy = total_val_acc / total_val_count\n",
    "    avg_train_loss = total_train_loss / len(train_dataloader2.dataset)\n",
    "    avg_val_loss = total_val_loss / len(validation_dataloader2.dataset)\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{epochs}, Train Loss: {avg_train_loss}, Val Loss: {avg_val_loss}')\n",
    "\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        current_patience = 0\n",
    "        torch.save(model2.state_dict(), 'best_model2.pth')\n",
    "        print(\"Model saved as current validation loss is \", best_val_loss)\n",
    "\n",
    "    else:\n",
    "        current_patience += 1\n",
    "\n",
    "    if current_patience >= patience:\n",
    "        print(f'Early stopping at epoch {epoch+1} as there was no improvement in validation loss.')\n",
    "        break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 Test Loss: 0.004193168657996594, AUC Score: 0.86710635058186\n",
      "Model 2 Test Loss: 0.3007899216846027\n"
     ]
    }
   ],
   "source": [
    "#모델 1 테스트\n",
    "torch.manual_seed(42)\n",
    "\n",
    "model1.load_state_dict(torch.load('best_model.pth'))\n",
    "model1.eval()\n",
    "total_test_loss_model1 = 0.0\n",
    "fin_labels_model1 = []\n",
    "fin_outputs_model1 = []\n",
    "\n",
    "with torch.inference_mode():\n",
    "    for inputs, labels, _ in test_dataloader:\n",
    "        outputs, _ = model1(inputs)\n",
    "        test_loss = loss_fn(outputs, labels)\n",
    "        total_test_loss_model1 += test_loss.item()\n",
    "        fin_labels_model1.extend(labels)\n",
    "        fin_outputs_model1.extend(torch.sigmoid(outputs))\n",
    "\n",
    "avg_test_loss_model1 = total_test_loss_model1 / len(test_dataloader.dataset)\n",
    "auc_score_model1 = log_metrics(fin_outputs_model1, fin_labels_model1)[\"auc_micro\"]\n",
    "print(f\"Model 1 Test Loss: {avg_test_loss_model1}, AUC Score: {auc_score_model1}\")\n",
    "\n",
    "model2.load_state_dict(torch.load('best_model2.pth'))\n",
    "model2.eval()\n",
    "total_test_loss_model2 = 0.0\n",
    "fin_labels_model2 = []\n",
    "fin_outputs_model2 = []\n",
    "\n",
    "with torch.inference_mode():\n",
    "    for inputs, labels in test_dataloader2:\n",
    "        outputs = model2(inputs)\n",
    "        test_loss = criterion(outputs, labels)\n",
    "        total_test_loss_model2 += test_loss.item()\n",
    "\n",
    "avg_test_loss_model2 = total_test_loss_model2 / len(test_dataloader2.dataset)\n",
    "print(f\"Model 2 Test Loss: {avg_test_loss_model2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Emoji_to_Word_Translator(emoji_str):\n",
    "    emoji_name = emoji.demojize(emoji_str)[1:-1]\n",
    "    emoji_emotion = word_emotion(emoji_name)\n",
    "    input = torch.tensor([emoji_emotion + [0]*(1316-len(emoji_emotion))])\n",
    "    \n",
    "    model1.eval()\n",
    "    model2.eval()\n",
    "\n",
    "    with torch.inference_mode():\n",
    "\n",
    "        _, embedding = model1(input)\n",
    "        embedding = embedding[:, :28]\n",
    "\n",
    "        outputs = model2(embedding)\n",
    "        probabilities = torch.nn.functional.softmax(outputs, dim=1)\n",
    "\n",
    "    k = 1\n",
    "    _, top_indices = torch.topk(probabilities, k)\n",
    "    translated_words = \"\"\n",
    "    for idx in top_indices[0]:\n",
    "        translated_words += idx_to_word[idx.item()]\n",
    "        translated_words += \" \"\n",
    "\n",
    "    return translated_words\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Their '"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Emoji_to_Word_Translator('💕')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the dataset since go_emotions couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'simplified' at C:\\Users\\김성연\\.cache\\huggingface\\datasets\\go_emotions\\simplified\\0.0.0\\add492243ff905527e67aeb8b80c082af02207c3 (last modified on Thu Jan 11 19:31:53 2024).\n"
     ]
    }
   ],
   "source": [
    "# 평가 데이터셋\n",
    "eval_dataset = load_dataset('go_emotions', 'simplified')\n",
    "eval_dataset = eval_dataset['validation'].to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[NAME] is such a legendary daddy 😩</td>\n",
       "      <td>[27]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hahahah thank you so much, username does not c...</td>\n",
       "      <td>[1, 10, 15]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Any response helps and makes me feel like I’m ...</td>\n",
       "      <td>[15]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Man I love Canada🇨🇦</td>\n",
       "      <td>[18]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[NAME]. Get off of the computer my man. Get so...</td>\n",
       "      <td>[1, 5]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>Disgusting. Need to get the tooth hole fixed😂</td>\n",
       "      <td>[11]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>Damn. Is that what those shorts are supposed t...</td>\n",
       "      <td>[3, 7]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>Love my 90DF Family Reddit too! 💙</td>\n",
       "      <td>[18]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>Very very nice to see this irl. Nice post 👌🏼</td>\n",
       "      <td>[0, 4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>No. Or at least that’s what I suspect🤔</td>\n",
       "      <td>[22]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>114 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text       labels\n",
       "0                   [NAME] is such a legendary daddy 😩         [27]\n",
       "1    Hahahah thank you so much, username does not c...  [1, 10, 15]\n",
       "2    Any response helps and makes me feel like I’m ...         [15]\n",
       "3                                  Man I love Canada🇨🇦         [18]\n",
       "4    [NAME]. Get off of the computer my man. Get so...       [1, 5]\n",
       "..                                                 ...          ...\n",
       "109      Disgusting. Need to get the tooth hole fixed😂         [11]\n",
       "110  Damn. Is that what those shorts are supposed t...       [3, 7]\n",
       "111                  Love my 90DF Family Reddit too! 💙         [18]\n",
       "112       Very very nice to see this irl. Nice post 👌🏼       [0, 4]\n",
       "113             No. Or at least that’s what I suspect🤔         [22]\n",
       "\n",
       "[114 rows x 2 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['text', 'labels']\n",
    "new_eval_dataset = pd.DataFrame(columns=cols)\n",
    "k=0\n",
    "\n",
    "for i in range(len(eval_dataset)):\n",
    "    text = eval_dataset.iloc[i]['text']\n",
    "    if emoji.emoji_count(text) != 0:\n",
    "        new_eval_dataset.loc[k] = eval_dataset.iloc[i][['text', 'labels']]\n",
    "        k += 1\n",
    "        \n",
    "new_eval_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emoji_translator_to_text(text):\n",
    "    for char in text:\n",
    "        if emoji.emoji_count(char) == 1:\n",
    "            text = text.replace(char, Emoji_to_Word_Translator(char))\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emoji_delete(text):\n",
    "    for char in text:\n",
    "        if emoji.emoji_count(char) == 1:\n",
    "            text = text.replace(char, '')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emoji_extractor(text):\n",
    "    only_emoji = \"\"\n",
    "    for char in text:\n",
    "        if emoji.emoji_count(char) == 1:\n",
    "            only_emoji += char\n",
    "            only_emoji += \" \"\n",
    "    return only_emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'🤔 '"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emoji_extractor(new_eval_dataset['text'][113])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[62], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m new_eval_dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124memoji_delete_text\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m new_eval_dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(emoji_delete)\n\u001b[1;32m----> 2\u001b[0m new_eval_dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124memoji_translate_text\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mnew_eval_dataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43memoji_translator_to_text\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m new_eval_dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel_to_vector\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m new_eval_dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(label_to_vector)\n\u001b[0;32m      4\u001b[0m new_eval_dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124memoji_delete_text_emotion\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m new_eval_dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124memoji_delete_text\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(word_emotion)\n",
      "File \u001b[1;32mc:\\EED\\venv\\Lib\\site-packages\\pandas\\core\\series.py:4764\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[0;32m   4629\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[0;32m   4630\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4631\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4636\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4637\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m   4638\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4639\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4640\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4755\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4756\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m   4757\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   4758\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4759\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4760\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4761\u001b[0m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4762\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4763\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m-> 4764\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\EED\\venv\\Lib\\site-packages\\pandas\\core\\apply.py:1209\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1206\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[0;32m   1208\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[1;32m-> 1209\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\EED\\venv\\Lib\\site-packages\\pandas\\core\\apply.py:1289\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1283\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[0;32m   1284\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[0;32m   1285\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[0;32m   1286\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[0;32m   1287\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[0;32m   1288\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1289\u001b[0m mapped \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[0;32m   1291\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1293\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1294\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1295\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1296\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32mc:\\EED\\venv\\Lib\\site-packages\\pandas\\core\\base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[1;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[0;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[1;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\EED\\venv\\Lib\\site-packages\\pandas\\core\\algorithms.py:1814\u001b[0m, in \u001b[0;36mmap_array\u001b[1;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m   1812\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   1813\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1814\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1815\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1816\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[0;32m   1817\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[0;32m   1818\u001b[0m     )\n",
      "File \u001b[1;32mlib.pyx:2926\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "Cell \u001b[1;32mIn[58], line 4\u001b[0m, in \u001b[0;36memoji_translator_to_text\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m char \u001b[38;5;129;01min\u001b[39;00m text:\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m emoji\u001b[38;5;241m.\u001b[39memoji_count(char) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m----> 4\u001b[0m         text \u001b[38;5;241m=\u001b[39m text\u001b[38;5;241m.\u001b[39mreplace(char, \u001b[43mEmoji_to_Word_Translator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchar\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m text\n",
      "Cell \u001b[1;32mIn[54], line 3\u001b[0m, in \u001b[0;36mEmoji_to_Word_Translator\u001b[1;34m(emoji_str)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mEmoji_to_Word_Translator\u001b[39m(emoji_str):\n\u001b[0;32m      2\u001b[0m     emoji_name \u001b[38;5;241m=\u001b[39m emoji\u001b[38;5;241m.\u001b[39mdemojize(emoji_str)[\u001b[38;5;241m1\u001b[39m:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m----> 3\u001b[0m     emoji_emotion \u001b[38;5;241m=\u001b[39m \u001b[43mword_emotion\u001b[49m\u001b[43m(\u001b[49m\u001b[43memoji_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([emoji_emotion \u001b[38;5;241m+\u001b[39m [\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m*\u001b[39m(\u001b[38;5;241m1316\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mlen\u001b[39m(emoji_emotion))])\n\u001b[0;32m      6\u001b[0m     model1\u001b[38;5;241m.\u001b[39meval()\n",
      "Cell \u001b[1;32mIn[14], line 2\u001b[0m, in \u001b[0;36mword_emotion\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mword_emotion\u001b[39m(text):\n\u001b[1;32m----> 2\u001b[0m     emotions \u001b[38;5;241m=\u001b[39m \u001b[43mclassifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m     output \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m28\u001b[39m\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m emotion \u001b[38;5;129;01min\u001b[39;00m emotions[\u001b[38;5;241m0\u001b[39m]:\n",
      "File \u001b[1;32mc:\\EED\\venv\\Lib\\site-packages\\transformers\\pipelines\\text_classification.py:156\u001b[0m, in \u001b[0;36mTextClassificationPipeline.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    123\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;124;03m    Classify the text(s) given as inputs.\u001b[39;00m\n\u001b[0;32m    125\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;124;03m        If `top_k` is used, one such dictionary is returned per label.\u001b[39;00m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 156\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    157\u001b[0m     \u001b[38;5;66;03m# TODO try and retrieve it in a nicer way from _sanitize_parameters.\u001b[39;00m\n\u001b[0;32m    158\u001b[0m     _legacy \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_k\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m kwargs\n",
      "File \u001b[1;32mc:\\EED\\venv\\Lib\\site-packages\\transformers\\pipelines\\base.py:1140\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[1;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1132\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\n\u001b[0;32m   1133\u001b[0m         \u001b[38;5;28miter\u001b[39m(\n\u001b[0;32m   1134\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_iterator(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1137\u001b[0m         )\n\u001b[0;32m   1138\u001b[0m     )\n\u001b[0;32m   1139\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1140\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_single\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreprocess_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforward_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpostprocess_params\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\EED\\venv\\Lib\\site-packages\\transformers\\pipelines\\base.py:1147\u001b[0m, in \u001b[0;36mPipeline.run_single\u001b[1;34m(self, inputs, preprocess_params, forward_params, postprocess_params)\u001b[0m\n\u001b[0;32m   1145\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_single\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, preprocess_params, forward_params, postprocess_params):\n\u001b[0;32m   1146\u001b[0m     model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess(inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpreprocess_params)\n\u001b[1;32m-> 1147\u001b[0m     model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mforward_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1148\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpostprocess(model_outputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpostprocess_params)\n\u001b[0;32m   1149\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[1;32mc:\\EED\\venv\\Lib\\site-packages\\transformers\\pipelines\\base.py:1046\u001b[0m, in \u001b[0;36mPipeline.forward\u001b[1;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[0;32m   1044\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m inference_context():\n\u001b[0;32m   1045\u001b[0m         model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_inputs, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m-> 1046\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mforward_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1047\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_outputs, device\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m   1048\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\EED\\venv\\Lib\\site-packages\\transformers\\pipelines\\text_classification.py:187\u001b[0m, in \u001b[0;36mTextClassificationPipeline._forward\u001b[1;34m(self, model_inputs)\u001b[0m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_cache\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(model_forward)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m    186\u001b[0m     model_inputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_cache\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 187\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\EED\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\EED\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\EED\\venv\\Lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:1198\u001b[0m, in \u001b[0;36mRobertaForSequenceClassification.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[38;5;124;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[0;32m   1193\u001b[0m \u001b[38;5;124;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[0;32m   1194\u001b[0m \u001b[38;5;124;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[0;32m   1195\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m-> 1198\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroberta\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1199\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1200\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1203\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1204\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1205\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1206\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1207\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1208\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1209\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1210\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassifier(sequence_output)\n",
      "File \u001b[1;32mc:\\EED\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\EED\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\EED\\venv\\Lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:835\u001b[0m, in \u001b[0;36mRobertaModel.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    826\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[0;32m    828\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(\n\u001b[0;32m    829\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[0;32m    830\u001b[0m     position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    833\u001b[0m     past_key_values_length\u001b[38;5;241m=\u001b[39mpast_key_values_length,\n\u001b[0;32m    834\u001b[0m )\n\u001b[1;32m--> 835\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    836\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    837\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    838\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    839\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    840\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    841\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    842\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    843\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    844\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    845\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    846\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    847\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    848\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\EED\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\EED\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\EED\\venv\\Lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:524\u001b[0m, in \u001b[0;36mRobertaEncoder.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    513\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[0;32m    514\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[0;32m    515\u001b[0m         hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    521\u001b[0m         output_attentions,\n\u001b[0;32m    522\u001b[0m     )\n\u001b[0;32m    523\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 524\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    525\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    526\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    527\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    528\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    529\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    530\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    531\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    532\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    534\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    535\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[1;32mc:\\EED\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\EED\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\EED\\venv\\Lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:455\u001b[0m, in \u001b[0;36mRobertaLayer.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    452\u001b[0m     cross_attn_present_key_value \u001b[38;5;241m=\u001b[39m cross_attention_outputs[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    453\u001b[0m     present_key_value \u001b[38;5;241m=\u001b[39m present_key_value \u001b[38;5;241m+\u001b[39m cross_attn_present_key_value\n\u001b[1;32m--> 455\u001b[0m layer_output \u001b[38;5;241m=\u001b[39m \u001b[43mapply_chunking_to_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    456\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeed_forward_chunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchunk_size_feed_forward\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseq_len_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_output\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    458\u001b[0m outputs \u001b[38;5;241m=\u001b[39m (layer_output,) \u001b[38;5;241m+\u001b[39m outputs\n\u001b[0;32m    460\u001b[0m \u001b[38;5;66;03m# if decoder, return the attn key/values as the last output\u001b[39;00m\n",
      "File \u001b[1;32mc:\\EED\\venv\\Lib\\site-packages\\transformers\\pytorch_utils.py:242\u001b[0m, in \u001b[0;36mapply_chunking_to_forward\u001b[1;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[0;32m    239\u001b[0m     \u001b[38;5;66;03m# concatenate output at same dimension\u001b[39;00m\n\u001b[0;32m    240\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat(output_chunks, dim\u001b[38;5;241m=\u001b[39mchunk_dim)\n\u001b[1;32m--> 242\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minput_tensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\EED\\venv\\Lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:467\u001b[0m, in \u001b[0;36mRobertaLayer.feed_forward_chunk\u001b[1;34m(self, attention_output)\u001b[0m\n\u001b[0;32m    466\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfeed_forward_chunk\u001b[39m(\u001b[38;5;28mself\u001b[39m, attention_output):\n\u001b[1;32m--> 467\u001b[0m     intermediate_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mintermediate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattention_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    468\u001b[0m     layer_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(intermediate_output, attention_output)\n\u001b[0;32m    469\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m layer_output\n",
      "File \u001b[1;32mc:\\EED\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\EED\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\EED\\venv\\Lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:366\u001b[0m, in \u001b[0;36mRobertaIntermediate.forward\u001b[1;34m(self, hidden_states)\u001b[0m\n\u001b[0;32m    364\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m    365\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdense(hidden_states)\n\u001b[1;32m--> 366\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mintermediate_act_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    367\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m hidden_states\n",
      "File \u001b[1;32mc:\\EED\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\EED\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\EED\\venv\\Lib\\site-packages\\transformers\\activations.py:78\u001b[0m, in \u001b[0;36mGELUActivation.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m---> 78\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mact\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "new_eval_dataset['emoji_delete_text'] = new_eval_dataset['text'].apply(emoji_delete)\n",
    "new_eval_dataset['emoji_translate_text'] = new_eval_dataset['text'].apply(emoji_translator_to_text)\n",
    "new_eval_dataset['label_to_vector'] = new_eval_dataset['labels'].apply(label_to_vector)\n",
    "new_eval_dataset['emoji_delete_text_emotion'] = new_eval_dataset['emoji_delete_text'].apply(word_emotion)\n",
    "new_eval_dataset['emoji_translate_text_emotion'] = new_eval_dataset['emoji_translate_text'].apply(word_emotion)\n",
    "new_eval_dataset['only_emoji'] = new_eval_dataset['text'].apply(emoji_extractor)\n",
    "new_eval_dataset['only_emoji'] = new_eval_dataset['only_emoji'].apply(Emoji_to_Word_Translator)\n",
    "new_eval_dataset['only_emoji_emotion'] = new_eval_dataset['only_emoji'].apply(word_emotion)\n",
    "new_eval_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emoji translator 사용하지 않았을 때 Loss: 0.031954389065504074\n",
      "emoji translator 사용했을 때 Loss: 0.03158906474709511\n"
     ]
    }
   ],
   "source": [
    "# 바다에 색소 한 방울 떨어트리는 실험 ^^\n",
    "\n",
    "evaluation = torch.nn.MSELoss()\n",
    "\n",
    "# emoji translator 사용하지 않았을 때 Loss evaluation\n",
    "raw_loss = evaluation(torch.tensor(new_eval_dataset['emoji_delete_text_emotion'].to_list()), torch.tensor(new_eval_dataset['label_to_vector'].to_list()))\n",
    "#raw_loss_round = round(raw_loss.item(), 5)\n",
    "print(f\"emoji translator 사용하지 않았을 때 Loss: {raw_loss}\")\n",
    "# 0.0319\n",
    "\n",
    "# emoji translator 사용했을 때 Loss\n",
    "trans_loss = evaluation(torch.tensor(new_eval_dataset['emoji_translate_text_emotion'].to_list()), torch.tensor(new_eval_dataset['label_to_vector'].to_list()))\n",
    "#trans_loss_round = round(trans_loss.item(), 4)\n",
    "print(f\"emoji translator 사용했을 때 Loss: {trans_loss}\")\n",
    "# 0.0315"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# emoji weighted emotion 열 추가\n",
    "emoji_weight_1 = []\n",
    "emoji_weight_3 = []\n",
    "emoji_weight_4 = []\n",
    "emoji_weight_5 = []\n",
    "emoji_weight_6 = []\n",
    "emoji_weight_7 = []\n",
    "emoji_weight_8 = []\n",
    "emoji_weight_9 = []\n",
    "emoji_weight_10 = []\n",
    "emoji_weight_20 = []\n",
    "emoji_weight_30 = []\n",
    "emoji_weight_50 = []\n",
    "emoji_weight_70 = []\n",
    "\n",
    "for i in range(len(new_eval_dataset)):\n",
    "    text_emotion = torch.tensor(new_eval_dataset.iloc[i]['emoji_delete_text_emotion'])\n",
    "    emoji_emotion = torch.tensor(new_eval_dataset.iloc[i]['only_emoji_emotion'])\n",
    "    w_1_sum = emoji_emotion * 0.01 + text_emotion * 0.99\n",
    "    w_3_sum = emoji_emotion * 0.03 + text_emotion * 0.97\n",
    "    w_4_sum = emoji_emotion * 0.04 + text_emotion * 0.96\n",
    "    w_5_sum = emoji_emotion * 0.05 + text_emotion * 0.95\n",
    "    w_6_sum = emoji_emotion * 0.06 + text_emotion * 0.94\n",
    "    w_7_sum = emoji_emotion * 0.07 + text_emotion * 0.93\n",
    "    w_8_sum = emoji_emotion * 0.08 + text_emotion * 0.92\n",
    "    w_9_sum = emoji_emotion * 0.09 + text_emotion * 0.91\n",
    "    w_10_sum = emoji_emotion * 0.1 + text_emotion * 0.9\n",
    "    w_20_sum = emoji_emotion * 0.2 + text_emotion * 0.8\n",
    "    w_30_sum = emoji_emotion * 0.3 + text_emotion * 0.7\n",
    "    w_50_sum = emoji_emotion * 0.5 + text_emotion * 0.5\n",
    "    w_70_sum = emoji_emotion * 0.7 + text_emotion * 0.3\n",
    "    emoji_weight_1.append(w_1_sum.tolist())\n",
    "    emoji_weight_3.append(w_3_sum.tolist())\n",
    "    emoji_weight_4.append(w_4_sum.tolist())\n",
    "    emoji_weight_5.append(w_5_sum.tolist())\n",
    "    emoji_weight_6.append(w_6_sum.tolist())\n",
    "    emoji_weight_7.append(w_7_sum.tolist())\n",
    "    emoji_weight_8.append(w_8_sum.tolist())\n",
    "    emoji_weight_9.append(w_9_sum.tolist())\n",
    "    emoji_weight_10.append(w_10_sum.tolist())\n",
    "    emoji_weight_20.append(w_20_sum.tolist())\n",
    "    emoji_weight_30.append(w_30_sum.tolist())\n",
    "    emoji_weight_50.append(w_50_sum.tolist())\n",
    "    emoji_weight_70.append(w_70_sum.tolist())\n",
    "\n",
    "new_eval_dataset[\"emoji_weight_1\"] = emoji_weight_1\n",
    "new_eval_dataset[\"emoji_weight_3\"] = emoji_weight_3\n",
    "new_eval_dataset[\"emoji_weight_4\"] = emoji_weight_4\n",
    "new_eval_dataset[\"emoji_weight_5\"] = emoji_weight_5\n",
    "new_eval_dataset[\"emoji_weight_6\"] = emoji_weight_6\n",
    "new_eval_dataset[\"emoji_weight_7\"] = emoji_weight_7\n",
    "new_eval_dataset[\"emoji_weight_8\"] = emoji_weight_8\n",
    "new_eval_dataset[\"emoji_weight_9\"] = emoji_weight_9\n",
    "new_eval_dataset[\"emoji_weight_10\"] = emoji_weight_10\n",
    "new_eval_dataset[\"emoji_weight_20\"] = emoji_weight_20\n",
    "new_eval_dataset[\"emoji_weight_30\"] = emoji_weight_30\n",
    "new_eval_dataset[\"emoji_weight_50\"] = emoji_weight_50\n",
    "new_eval_dataset[\"emoji_weight_70\"] = emoji_weight_70\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "      <th>emoji_delete_text</th>\n",
       "      <th>emoji_translate_text</th>\n",
       "      <th>label_to_vector</th>\n",
       "      <th>emoji_delete_text_emotion</th>\n",
       "      <th>emoji_translate_text_emotion</th>\n",
       "      <th>only_emoji</th>\n",
       "      <th>only_emoji_emotion</th>\n",
       "      <th>emoji_weight_1</th>\n",
       "      <th>...</th>\n",
       "      <th>emoji_weight_5</th>\n",
       "      <th>emoji_weight_6</th>\n",
       "      <th>emoji_weight_7</th>\n",
       "      <th>emoji_weight_8</th>\n",
       "      <th>emoji_weight_9</th>\n",
       "      <th>emoji_weight_10</th>\n",
       "      <th>emoji_weight_20</th>\n",
       "      <th>emoji_weight_30</th>\n",
       "      <th>emoji_weight_50</th>\n",
       "      <th>emoji_weight_70</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[NAME] is such a legendary daddy 😩</td>\n",
       "      <td>[27]</td>\n",
       "      <td>[NAME] is such a legendary daddy</td>\n",
       "      <td>[NAME] is such a legendary daddy Their</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0.8371853232383728, 0.0010130126029253006, 0....</td>\n",
       "      <td>[0.7986921072006226, 0.0009594232542440295, 0....</td>\n",
       "      <td>Their</td>\n",
       "      <td>[0.0034218698274344206, 0.0018512787064537406,...</td>\n",
       "      <td>[0.8288477063179016, 0.0010213953210040927, 0....</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.7954971194267273, 0.0010549259604886174, 0....</td>\n",
       "      <td>[0.7871595621109009, 0.0010633085621520877, 0....</td>\n",
       "      <td>[0.7788218855857849, 0.001071691163815558, 0.0...</td>\n",
       "      <td>[0.7704842686653137, 0.00108007388189435, 0.00...</td>\n",
       "      <td>[0.7621466517448425, 0.0010884565999731421, 0....</td>\n",
       "      <td>[0.7538089752197266, 0.0010968392016366124, 0....</td>\n",
       "      <td>[0.6704326272010803, 0.0011806658003479242, 0....</td>\n",
       "      <td>[0.5870562791824341, 0.0012644925154745579, 0....</td>\n",
       "      <td>[0.4203035831451416, 0.0014321457128971815, 0....</td>\n",
       "      <td>[0.2535509169101715, 0.0015997989103198051, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hahahah thank you so much, username does not c...</td>\n",
       "      <td>[1, 10, 15]</td>\n",
       "      <td>Hahahah thank you so much, username does not c...</td>\n",
       "      <td>Hahahah thank you so much, username does not c...</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0.007812465541064739, 0.5283613801002502, 0.0...</td>\n",
       "      <td>[0.00707726925611496, 0.5504684448242188, 0.00...</td>\n",
       "      <td>Their</td>\n",
       "      <td>[0.0034218698274344206, 0.0018512787064537406,...</td>\n",
       "      <td>[0.007768559735268354, 0.5230963230133057, 0.0...</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.0075929355807602406, 0.5020358562469482, 0....</td>\n",
       "      <td>[0.007549029774963856, 0.4967707693576813, 0.0...</td>\n",
       "      <td>[0.007505123969167471, 0.4915056824684143, 0.0...</td>\n",
       "      <td>[0.007461218163371086, 0.48624056577682495, 0....</td>\n",
       "      <td>[0.007417312357574701, 0.48097550868988037, 0....</td>\n",
       "      <td>[0.007373405620455742, 0.47571036219596863, 0....</td>\n",
       "      <td>[0.006934346631169319, 0.4230593740940094, 0.0...</td>\n",
       "      <td>[0.006495286710560322, 0.3704083561897278, 0.0...</td>\n",
       "      <td>[0.005617167800664902, 0.26510632038116455, 0....</td>\n",
       "      <td>[0.004739048890769482, 0.1598043143749237, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Any response helps and makes me feel like I’m ...</td>\n",
       "      <td>[15]</td>\n",
       "      <td>Any response helps and makes me feel like I’m ...</td>\n",
       "      <td>Any response helps and makes me feel like I’m ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0.008541022427380085, 0.0018819638062268496, ...</td>\n",
       "      <td>[0.011030198074877262, 0.0018687736010178924, ...</td>\n",
       "      <td>Their</td>\n",
       "      <td>[0.0034218698274344206, 0.0018512787064537406,...</td>\n",
       "      <td>[0.00848983135074377, 0.0018816570518538356, 0...</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.00828506425023079, 0.0018804295687004924, 0...</td>\n",
       "      <td>[0.008233873173594475, 0.0018801226979121566, ...</td>\n",
       "      <td>[0.008182681165635586, 0.0018798158271238208, ...</td>\n",
       "      <td>[0.008131490088999271, 0.0018795090727508068, ...</td>\n",
       "      <td>[0.008080299012362957, 0.001879202201962471, 0...</td>\n",
       "      <td>[0.008029107004404068, 0.0018788952147588134, ...</td>\n",
       "      <td>[0.007517192047089338, 0.0018758268561214209, ...</td>\n",
       "      <td>[0.007005276624113321, 0.0018727582646533847, ...</td>\n",
       "      <td>[0.005981446243822575, 0.0018666211981326342, ...</td>\n",
       "      <td>[0.004957615397870541, 0.0018604842480272055, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Man I love Canada🇨🇦</td>\n",
       "      <td>[18]</td>\n",
       "      <td>Man I love Canada🇨🇦</td>\n",
       "      <td>Man I love Canada🇨🇦</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0.0395917110145092, 0.0032190720085054636, 0....</td>\n",
       "      <td>[0.0395917110145092, 0.0032190720085054636, 0....</td>\n",
       "      <td>Their</td>\n",
       "      <td>[0.0034218698274344206, 0.0018512787064537406,...</td>\n",
       "      <td>[0.03923001512885094, 0.0032053941395133734, 0...</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.037783220410346985, 0.003150682197883725, 0...</td>\n",
       "      <td>[0.03742152079939842, 0.003137004328891635, 0....</td>\n",
       "      <td>[0.03705982491374016, 0.0031233264598995447, 0...</td>\n",
       "      <td>[0.036698125302791595, 0.003109648823738098, 0...</td>\n",
       "      <td>[0.03633642941713333, 0.0030959707219153643, 0...</td>\n",
       "      <td>[0.03597472608089447, 0.0030822926200926304, 0...</td>\n",
       "      <td>[0.03235774114727974, 0.002945513231679797, 0....</td>\n",
       "      <td>[0.028740758076310158, 0.002808733843266964, 0...</td>\n",
       "      <td>[0.021506790071725845, 0.002535175299271941, 0...</td>\n",
       "      <td>[0.014272822067141533, 0.0022616167552769184, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[NAME]. Get off of the computer my man. Get so...</td>\n",
       "      <td>[1, 5]</td>\n",
       "      <td>[NAME]. Get off of the computer my man. Get so...</td>\n",
       "      <td>[NAME]. Get off of the computer my man. Get so...</td>\n",
       "      <td>[0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0.002575087361037731, 0.0015578194288536906, ...</td>\n",
       "      <td>[0.0019456521840766072, 0.0014526814920827746,...</td>\n",
       "      <td>Their</td>\n",
       "      <td>[0.0034218698274344206, 0.0018512787064537406,...</td>\n",
       "      <td>[0.0025835551787167788, 0.001560754026286304, ...</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.002617426449432969, 0.0015724922996014357, ...</td>\n",
       "      <td>[0.0026258942671120167, 0.0015754270134493709,...</td>\n",
       "      <td>[0.0026343620847910643, 0.0015783614944666624,...</td>\n",
       "      <td>[0.002642829902470112, 0.0015812962083145976, ...</td>\n",
       "      <td>[0.002651297952979803, 0.001584230805747211, 0...</td>\n",
       "      <td>[0.002659765537828207, 0.0015871652867645025, ...</td>\n",
       "      <td>[0.0027444439474493265, 0.001616511377505958, ...</td>\n",
       "      <td>[0.0028291221242398024, 0.00164585723541677, 0...</td>\n",
       "      <td>[0.0029984787106513977, 0.0017045490676537156,...</td>\n",
       "      <td>[0.0031678350642323494, 0.0017632408998906612,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>Disgusting. Need to get the tooth hole fixed😂</td>\n",
       "      <td>[11]</td>\n",
       "      <td>Disgusting. Need to get the tooth hole fixed</td>\n",
       "      <td>Disgusting. Need to get the tooth hole fixedsl...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...</td>\n",
       "      <td>[0.004368587397038937, 0.004051181487739086, 0...</td>\n",
       "      <td>[0.004809109028428793, 0.004940819460898638, 0...</td>\n",
       "      <td>sleeptrain</td>\n",
       "      <td>[0.0038460460491478443, 0.002463676268234849, ...</td>\n",
       "      <td>[0.004363361746072769, 0.004035306628793478, 0...</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.004342460073530674, 0.003971806261688471, 0...</td>\n",
       "      <td>[0.004337234888225794, 0.003955930937081575, 0...</td>\n",
       "      <td>[0.004332009702920914, 0.003940056078135967, 0...</td>\n",
       "      <td>[0.0043267845176160336, 0.003924181219190359, ...</td>\n",
       "      <td>[0.004321558866649866, 0.003908305894583464, 0...</td>\n",
       "      <td>[0.004316333215683699, 0.003892430802807212, 0...</td>\n",
       "      <td>[0.004264079034328461, 0.003733680583536625, 0...</td>\n",
       "      <td>[0.00421182531863451, 0.0035749298986047506, 0...</td>\n",
       "      <td>[0.004107316955924034, 0.0032574287615716457, ...</td>\n",
       "      <td>[0.004002808593213558, 0.0029399278573691845, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>Damn. Is that what those shorts are supposed t...</td>\n",
       "      <td>[3, 7]</td>\n",
       "      <td>Damn. Is that what those shorts are supposed t...</td>\n",
       "      <td>Damn. Is that what those shorts are supposed t...</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0.002395796123892069, 0.003962398506700993, 0...</td>\n",
       "      <td>[0.0022101914510130882, 0.0036026104353368282,...</td>\n",
       "      <td>sleeptrain</td>\n",
       "      <td>[0.0038460460491478443, 0.002463676268234849, ...</td>\n",
       "      <td>[0.0024102984461933374, 0.003947411198168993, ...</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.0024683086667209864, 0.0038874621968716383,...</td>\n",
       "      <td>[0.002482810989022255, 0.0038724751211702824, ...</td>\n",
       "      <td>[0.002497313544154167, 0.0038574880454689264, ...</td>\n",
       "      <td>[0.0025118160992860794, 0.0038425009697675705,...</td>\n",
       "      <td>[0.0025263186544179916, 0.003827513661235571, ...</td>\n",
       "      <td>[0.00254082097671926, 0.0038125261198729277, 0...</td>\n",
       "      <td>[0.002685846295207739, 0.00366265419870615, 0....</td>\n",
       "      <td>[0.0028308711480349302, 0.003512781811878085, ...</td>\n",
       "      <td>[0.0031209210865199566, 0.003213037271052599, ...</td>\n",
       "      <td>[0.003410971025004983, 0.0029132929630577564, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>Love my 90DF Family Reddit too! 💙</td>\n",
       "      <td>[18]</td>\n",
       "      <td>Love my 90DF Family Reddit too!</td>\n",
       "      <td>Love my 90DF Family Reddit too! Their</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0.04514281824231148, 0.0031404898036271334, 0...</td>\n",
       "      <td>[0.05588092282414436, 0.0028951778076589108, 0...</td>\n",
       "      <td>Their</td>\n",
       "      <td>[0.0034218698274344206, 0.0018512787064537406,...</td>\n",
       "      <td>[0.04472561180591583, 0.003127597738057375, 0....</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.04305677115917206, 0.0030760292429476976, 0...</td>\n",
       "      <td>[0.042639560997486115, 0.0030631371773779392, ...</td>\n",
       "      <td>[0.04222235456109047, 0.003050245111808181, 0....</td>\n",
       "      <td>[0.041805144399404526, 0.0030373530462384224, ...</td>\n",
       "      <td>[0.04138793423771858, 0.0030244607478380203, 0...</td>\n",
       "      <td>[0.04097072035074234, 0.003011568682268262, 0....</td>\n",
       "      <td>[0.0367986299097538, 0.0028826475609093904, 0....</td>\n",
       "      <td>[0.03262653201818466, 0.0027537266723811626, 0...</td>\n",
       "      <td>[0.024282343685626984, 0.002495884196832776, 0...</td>\n",
       "      <td>[0.015938155353069305, 0.002238042186945677, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>Very very nice to see this irl. Nice post 👌🏼</td>\n",
       "      <td>[0, 4]</td>\n",
       "      <td>Very very nice to see this irl. Nice post</td>\n",
       "      <td>Very very nice to see this irl. Nice post Thei...</td>\n",
       "      <td>[1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0.9282577633857727, 0.0016476279124617577, 0....</td>\n",
       "      <td>[0.9373844265937805, 0.001385554438456893, 0.0...</td>\n",
       "      <td>Their</td>\n",
       "      <td>[0.0034218698274344206, 0.0018512787064537406,...</td>\n",
       "      <td>[0.9190093874931335, 0.001649664482101798, 0.0...</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.8820159435272217, 0.0016578104114159942, 0....</td>\n",
       "      <td>[0.8727676272392273, 0.0016598469810560346, 0....</td>\n",
       "      <td>[0.8635192513465881, 0.0016618834342807531, 0....</td>\n",
       "      <td>[0.8542709350585938, 0.0016639200039207935, 0....</td>\n",
       "      <td>[0.8450225591659546, 0.001665956573560834, 0.0...</td>\n",
       "      <td>[0.8357741832733154, 0.0016679929103702307, 0....</td>\n",
       "      <td>[0.7432906031608582, 0.0016883581411093473, 0....</td>\n",
       "      <td>[0.6508070230484009, 0.0017087231390178204, 0....</td>\n",
       "      <td>[0.46583980321884155, 0.00174945336766541, 0.0...</td>\n",
       "      <td>[0.280872642993927, 0.001790183479897678, 0.00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>No. Or at least that’s what I suspect🤔</td>\n",
       "      <td>[22]</td>\n",
       "      <td>No. Or at least that’s what I suspect</td>\n",
       "      <td>No. Or at least that’s what I suspectTheir</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0.0010888505494222045, 0.0015277293277904391,...</td>\n",
       "      <td>[0.0012807887978851795, 0.0016302895965054631,...</td>\n",
       "      <td>Their</td>\n",
       "      <td>[0.0034218698274344206, 0.0018512787064537406,...</td>\n",
       "      <td>[0.0011121807619929314, 0.0015309648588299751,...</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.001205501495860517, 0.0015439067501574755, ...</td>\n",
       "      <td>[0.001228831708431244, 0.0015471422811970115, ...</td>\n",
       "      <td>[0.0012521619210019708, 0.0015503776958212256,...</td>\n",
       "      <td>[0.0012754921335726976, 0.0015536133432760835,...</td>\n",
       "      <td>[0.0012988222297281027, 0.0015568488743156195,...</td>\n",
       "      <td>[0.0013221524422988296, 0.0015600841725245118,...</td>\n",
       "      <td>[0.0015554544515907764, 0.0015924392500892282,...</td>\n",
       "      <td>[0.0017887563444674015, 0.0016247940948233008,...</td>\n",
       "      <td>[0.0022553601302206516, 0.0016895040171220899,...</td>\n",
       "      <td>[0.0027219639159739017, 0.0017542139394208789,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>114 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text       labels  \\\n",
       "0                   [NAME] is such a legendary daddy 😩         [27]   \n",
       "1    Hahahah thank you so much, username does not c...  [1, 10, 15]   \n",
       "2    Any response helps and makes me feel like I’m ...         [15]   \n",
       "3                                  Man I love Canada🇨🇦         [18]   \n",
       "4    [NAME]. Get off of the computer my man. Get so...       [1, 5]   \n",
       "..                                                 ...          ...   \n",
       "109      Disgusting. Need to get the tooth hole fixed😂         [11]   \n",
       "110  Damn. Is that what those shorts are supposed t...       [3, 7]   \n",
       "111                  Love my 90DF Family Reddit too! 💙         [18]   \n",
       "112       Very very nice to see this irl. Nice post 👌🏼       [0, 4]   \n",
       "113             No. Or at least that’s what I suspect🤔         [22]   \n",
       "\n",
       "                                     emoji_delete_text  \\\n",
       "0                    [NAME] is such a legendary daddy    \n",
       "1    Hahahah thank you so much, username does not c...   \n",
       "2    Any response helps and makes me feel like I’m ...   \n",
       "3                                  Man I love Canada🇨🇦   \n",
       "4    [NAME]. Get off of the computer my man. Get so...   \n",
       "..                                                 ...   \n",
       "109       Disgusting. Need to get the tooth hole fixed   \n",
       "110  Damn. Is that what those shorts are supposed t...   \n",
       "111                   Love my 90DF Family Reddit too!    \n",
       "112         Very very nice to see this irl. Nice post    \n",
       "113              No. Or at least that’s what I suspect   \n",
       "\n",
       "                                  emoji_translate_text  \\\n",
       "0              [NAME] is such a legendary daddy Their    \n",
       "1    Hahahah thank you so much, username does not c...   \n",
       "2    Any response helps and makes me feel like I’m ...   \n",
       "3                                  Man I love Canada🇨🇦   \n",
       "4    [NAME]. Get off of the computer my man. Get so...   \n",
       "..                                                 ...   \n",
       "109  Disgusting. Need to get the tooth hole fixedsl...   \n",
       "110  Damn. Is that what those shorts are supposed t...   \n",
       "111             Love my 90DF Family Reddit too! Their    \n",
       "112  Very very nice to see this irl. Nice post Thei...   \n",
       "113        No. Or at least that’s what I suspectTheir    \n",
       "\n",
       "                                       label_to_vector  \\\n",
       "0    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1    [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...   \n",
       "2    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "3    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "4    [0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "..                                                 ...   \n",
       "109  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...   \n",
       "110  [0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "111  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "112  [1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "113  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                             emoji_delete_text_emotion  \\\n",
       "0    [0.8371853232383728, 0.0010130126029253006, 0....   \n",
       "1    [0.007812465541064739, 0.5283613801002502, 0.0...   \n",
       "2    [0.008541022427380085, 0.0018819638062268496, ...   \n",
       "3    [0.0395917110145092, 0.0032190720085054636, 0....   \n",
       "4    [0.002575087361037731, 0.0015578194288536906, ...   \n",
       "..                                                 ...   \n",
       "109  [0.004368587397038937, 0.004051181487739086, 0...   \n",
       "110  [0.002395796123892069, 0.003962398506700993, 0...   \n",
       "111  [0.04514281824231148, 0.0031404898036271334, 0...   \n",
       "112  [0.9282577633857727, 0.0016476279124617577, 0....   \n",
       "113  [0.0010888505494222045, 0.0015277293277904391,...   \n",
       "\n",
       "                          emoji_translate_text_emotion   only_emoji  \\\n",
       "0    [0.7986921072006226, 0.0009594232542440295, 0....       Their    \n",
       "1    [0.00707726925611496, 0.5504684448242188, 0.00...       Their    \n",
       "2    [0.011030198074877262, 0.0018687736010178924, ...       Their    \n",
       "3    [0.0395917110145092, 0.0032190720085054636, 0....       Their    \n",
       "4    [0.0019456521840766072, 0.0014526814920827746,...       Their    \n",
       "..                                                 ...          ...   \n",
       "109  [0.004809109028428793, 0.004940819460898638, 0...  sleeptrain    \n",
       "110  [0.0022101914510130882, 0.0036026104353368282,...  sleeptrain    \n",
       "111  [0.05588092282414436, 0.0028951778076589108, 0...       Their    \n",
       "112  [0.9373844265937805, 0.001385554438456893, 0.0...       Their    \n",
       "113  [0.0012807887978851795, 0.0016302895965054631,...       Their    \n",
       "\n",
       "                                    only_emoji_emotion  \\\n",
       "0    [0.0034218698274344206, 0.0018512787064537406,...   \n",
       "1    [0.0034218698274344206, 0.0018512787064537406,...   \n",
       "2    [0.0034218698274344206, 0.0018512787064537406,...   \n",
       "3    [0.0034218698274344206, 0.0018512787064537406,...   \n",
       "4    [0.0034218698274344206, 0.0018512787064537406,...   \n",
       "..                                                 ...   \n",
       "109  [0.0038460460491478443, 0.002463676268234849, ...   \n",
       "110  [0.0038460460491478443, 0.002463676268234849, ...   \n",
       "111  [0.0034218698274344206, 0.0018512787064537406,...   \n",
       "112  [0.0034218698274344206, 0.0018512787064537406,...   \n",
       "113  [0.0034218698274344206, 0.0018512787064537406,...   \n",
       "\n",
       "                                        emoji_weight_1  ...  \\\n",
       "0    [0.8288477063179016, 0.0010213953210040927, 0....  ...   \n",
       "1    [0.007768559735268354, 0.5230963230133057, 0.0...  ...   \n",
       "2    [0.00848983135074377, 0.0018816570518538356, 0...  ...   \n",
       "3    [0.03923001512885094, 0.0032053941395133734, 0...  ...   \n",
       "4    [0.0025835551787167788, 0.001560754026286304, ...  ...   \n",
       "..                                                 ...  ...   \n",
       "109  [0.004363361746072769, 0.004035306628793478, 0...  ...   \n",
       "110  [0.0024102984461933374, 0.003947411198168993, ...  ...   \n",
       "111  [0.04472561180591583, 0.003127597738057375, 0....  ...   \n",
       "112  [0.9190093874931335, 0.001649664482101798, 0.0...  ...   \n",
       "113  [0.0011121807619929314, 0.0015309648588299751,...  ...   \n",
       "\n",
       "                                        emoji_weight_5  \\\n",
       "0    [0.7954971194267273, 0.0010549259604886174, 0....   \n",
       "1    [0.0075929355807602406, 0.5020358562469482, 0....   \n",
       "2    [0.00828506425023079, 0.0018804295687004924, 0...   \n",
       "3    [0.037783220410346985, 0.003150682197883725, 0...   \n",
       "4    [0.002617426449432969, 0.0015724922996014357, ...   \n",
       "..                                                 ...   \n",
       "109  [0.004342460073530674, 0.003971806261688471, 0...   \n",
       "110  [0.0024683086667209864, 0.0038874621968716383,...   \n",
       "111  [0.04305677115917206, 0.0030760292429476976, 0...   \n",
       "112  [0.8820159435272217, 0.0016578104114159942, 0....   \n",
       "113  [0.001205501495860517, 0.0015439067501574755, ...   \n",
       "\n",
       "                                        emoji_weight_6  \\\n",
       "0    [0.7871595621109009, 0.0010633085621520877, 0....   \n",
       "1    [0.007549029774963856, 0.4967707693576813, 0.0...   \n",
       "2    [0.008233873173594475, 0.0018801226979121566, ...   \n",
       "3    [0.03742152079939842, 0.003137004328891635, 0....   \n",
       "4    [0.0026258942671120167, 0.0015754270134493709,...   \n",
       "..                                                 ...   \n",
       "109  [0.004337234888225794, 0.003955930937081575, 0...   \n",
       "110  [0.002482810989022255, 0.0038724751211702824, ...   \n",
       "111  [0.042639560997486115, 0.0030631371773779392, ...   \n",
       "112  [0.8727676272392273, 0.0016598469810560346, 0....   \n",
       "113  [0.001228831708431244, 0.0015471422811970115, ...   \n",
       "\n",
       "                                        emoji_weight_7  \\\n",
       "0    [0.7788218855857849, 0.001071691163815558, 0.0...   \n",
       "1    [0.007505123969167471, 0.4915056824684143, 0.0...   \n",
       "2    [0.008182681165635586, 0.0018798158271238208, ...   \n",
       "3    [0.03705982491374016, 0.0031233264598995447, 0...   \n",
       "4    [0.0026343620847910643, 0.0015783614944666624,...   \n",
       "..                                                 ...   \n",
       "109  [0.004332009702920914, 0.003940056078135967, 0...   \n",
       "110  [0.002497313544154167, 0.0038574880454689264, ...   \n",
       "111  [0.04222235456109047, 0.003050245111808181, 0....   \n",
       "112  [0.8635192513465881, 0.0016618834342807531, 0....   \n",
       "113  [0.0012521619210019708, 0.0015503776958212256,...   \n",
       "\n",
       "                                        emoji_weight_8  \\\n",
       "0    [0.7704842686653137, 0.00108007388189435, 0.00...   \n",
       "1    [0.007461218163371086, 0.48624056577682495, 0....   \n",
       "2    [0.008131490088999271, 0.0018795090727508068, ...   \n",
       "3    [0.036698125302791595, 0.003109648823738098, 0...   \n",
       "4    [0.002642829902470112, 0.0015812962083145976, ...   \n",
       "..                                                 ...   \n",
       "109  [0.0043267845176160336, 0.003924181219190359, ...   \n",
       "110  [0.0025118160992860794, 0.0038425009697675705,...   \n",
       "111  [0.041805144399404526, 0.0030373530462384224, ...   \n",
       "112  [0.8542709350585938, 0.0016639200039207935, 0....   \n",
       "113  [0.0012754921335726976, 0.0015536133432760835,...   \n",
       "\n",
       "                                        emoji_weight_9  \\\n",
       "0    [0.7621466517448425, 0.0010884565999731421, 0....   \n",
       "1    [0.007417312357574701, 0.48097550868988037, 0....   \n",
       "2    [0.008080299012362957, 0.001879202201962471, 0...   \n",
       "3    [0.03633642941713333, 0.0030959707219153643, 0...   \n",
       "4    [0.002651297952979803, 0.001584230805747211, 0...   \n",
       "..                                                 ...   \n",
       "109  [0.004321558866649866, 0.003908305894583464, 0...   \n",
       "110  [0.0025263186544179916, 0.003827513661235571, ...   \n",
       "111  [0.04138793423771858, 0.0030244607478380203, 0...   \n",
       "112  [0.8450225591659546, 0.001665956573560834, 0.0...   \n",
       "113  [0.0012988222297281027, 0.0015568488743156195,...   \n",
       "\n",
       "                                       emoji_weight_10  \\\n",
       "0    [0.7538089752197266, 0.0010968392016366124, 0....   \n",
       "1    [0.007373405620455742, 0.47571036219596863, 0....   \n",
       "2    [0.008029107004404068, 0.0018788952147588134, ...   \n",
       "3    [0.03597472608089447, 0.0030822926200926304, 0...   \n",
       "4    [0.002659765537828207, 0.0015871652867645025, ...   \n",
       "..                                                 ...   \n",
       "109  [0.004316333215683699, 0.003892430802807212, 0...   \n",
       "110  [0.00254082097671926, 0.0038125261198729277, 0...   \n",
       "111  [0.04097072035074234, 0.003011568682268262, 0....   \n",
       "112  [0.8357741832733154, 0.0016679929103702307, 0....   \n",
       "113  [0.0013221524422988296, 0.0015600841725245118,...   \n",
       "\n",
       "                                       emoji_weight_20  \\\n",
       "0    [0.6704326272010803, 0.0011806658003479242, 0....   \n",
       "1    [0.006934346631169319, 0.4230593740940094, 0.0...   \n",
       "2    [0.007517192047089338, 0.0018758268561214209, ...   \n",
       "3    [0.03235774114727974, 0.002945513231679797, 0....   \n",
       "4    [0.0027444439474493265, 0.001616511377505958, ...   \n",
       "..                                                 ...   \n",
       "109  [0.004264079034328461, 0.003733680583536625, 0...   \n",
       "110  [0.002685846295207739, 0.00366265419870615, 0....   \n",
       "111  [0.0367986299097538, 0.0028826475609093904, 0....   \n",
       "112  [0.7432906031608582, 0.0016883581411093473, 0....   \n",
       "113  [0.0015554544515907764, 0.0015924392500892282,...   \n",
       "\n",
       "                                       emoji_weight_30  \\\n",
       "0    [0.5870562791824341, 0.0012644925154745579, 0....   \n",
       "1    [0.006495286710560322, 0.3704083561897278, 0.0...   \n",
       "2    [0.007005276624113321, 0.0018727582646533847, ...   \n",
       "3    [0.028740758076310158, 0.002808733843266964, 0...   \n",
       "4    [0.0028291221242398024, 0.00164585723541677, 0...   \n",
       "..                                                 ...   \n",
       "109  [0.00421182531863451, 0.0035749298986047506, 0...   \n",
       "110  [0.0028308711480349302, 0.003512781811878085, ...   \n",
       "111  [0.03262653201818466, 0.0027537266723811626, 0...   \n",
       "112  [0.6508070230484009, 0.0017087231390178204, 0....   \n",
       "113  [0.0017887563444674015, 0.0016247940948233008,...   \n",
       "\n",
       "                                       emoji_weight_50  \\\n",
       "0    [0.4203035831451416, 0.0014321457128971815, 0....   \n",
       "1    [0.005617167800664902, 0.26510632038116455, 0....   \n",
       "2    [0.005981446243822575, 0.0018666211981326342, ...   \n",
       "3    [0.021506790071725845, 0.002535175299271941, 0...   \n",
       "4    [0.0029984787106513977, 0.0017045490676537156,...   \n",
       "..                                                 ...   \n",
       "109  [0.004107316955924034, 0.0032574287615716457, ...   \n",
       "110  [0.0031209210865199566, 0.003213037271052599, ...   \n",
       "111  [0.024282343685626984, 0.002495884196832776, 0...   \n",
       "112  [0.46583980321884155, 0.00174945336766541, 0.0...   \n",
       "113  [0.0022553601302206516, 0.0016895040171220899,...   \n",
       "\n",
       "                                       emoji_weight_70  \n",
       "0    [0.2535509169101715, 0.0015997989103198051, 0....  \n",
       "1    [0.004739048890769482, 0.1598043143749237, 0.0...  \n",
       "2    [0.004957615397870541, 0.0018604842480272055, ...  \n",
       "3    [0.014272822067141533, 0.0022616167552769184, ...  \n",
       "4    [0.0031678350642323494, 0.0017632408998906612,...  \n",
       "..                                                 ...  \n",
       "109  [0.004002808593213558, 0.0029399278573691845, ...  \n",
       "110  [0.003410971025004983, 0.0029132929630577564, ...  \n",
       "111  [0.015938155353069305, 0.002238042186945677, 0...  \n",
       "112  [0.280872642993927, 0.001790183479897678, 0.00...  \n",
       "113  [0.0027219639159739017, 0.0017542139394208789,...  \n",
       "\n",
       "[114 rows x 22 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_eval_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emoji weight 1% emotion Loss: 0.03191280737519264\n",
      "emoji weight 3% emotion Loss: 0.03185516968369484\n",
      "emoji weight 4% emotion Loss: 0.03183911368250847\n",
      "emoji weight 5% emotion Loss: 0.03183156996965408\n",
      "emoji weight 6% emotion Loss: 0.03183254599571228\n",
      "emoji weight 7% emotion Loss: 0.03184202313423157\n",
      "emoji weight 8% emotion Loss: 0.03186001256108284\n",
      "emoji weight 9% emotion Loss: 0.031886518001556396\n",
      "emoji weight 10% emotion Loss: 0.03192152455449104\n",
      "emoji weight 20% emotion Loss: 0.032739754766225815\n",
      "emoji weight 30% emotion Loss: 0.03440907597541809\n",
      "emoji weight 50% emotion Loss: 0.04030097648501396\n",
      "emoji weight 70% emotion Loss: 0.04959724098443985\n"
     ]
    }
   ],
   "source": [
    "# 교수님께서 이야기해주신 대로!! Weight 부여해서 \n",
    "\n",
    "w_1_loss = evaluation(torch.tensor(new_eval_dataset['emoji_weight_1'].to_list()), torch.tensor(new_eval_dataset['label_to_vector'].to_list()))\n",
    "w_3_loss = evaluation(torch.tensor(new_eval_dataset['emoji_weight_3'].to_list()), torch.tensor(new_eval_dataset['label_to_vector'].to_list()))\n",
    "w_4_loss = evaluation(torch.tensor(new_eval_dataset['emoji_weight_4'].to_list()), torch.tensor(new_eval_dataset['label_to_vector'].to_list()))\n",
    "w_5_loss = evaluation(torch.tensor(new_eval_dataset['emoji_weight_5'].to_list()), torch.tensor(new_eval_dataset['label_to_vector'].to_list()))\n",
    "w_6_loss = evaluation(torch.tensor(new_eval_dataset['emoji_weight_6'].to_list()), torch.tensor(new_eval_dataset['label_to_vector'].to_list()))\n",
    "w_7_loss = evaluation(torch.tensor(new_eval_dataset['emoji_weight_7'].to_list()), torch.tensor(new_eval_dataset['label_to_vector'].to_list()))\n",
    "w_8_loss = evaluation(torch.tensor(new_eval_dataset['emoji_weight_8'].to_list()), torch.tensor(new_eval_dataset['label_to_vector'].to_list()))\n",
    "w_9_loss = evaluation(torch.tensor(new_eval_dataset['emoji_weight_9'].to_list()), torch.tensor(new_eval_dataset['label_to_vector'].to_list()))\n",
    "w_10_loss = evaluation(torch.tensor(new_eval_dataset['emoji_weight_10'].to_list()), torch.tensor(new_eval_dataset['label_to_vector'].to_list()))\n",
    "w_20_loss = evaluation(torch.tensor(new_eval_dataset['emoji_weight_20'].to_list()), torch.tensor(new_eval_dataset['label_to_vector'].to_list()))\n",
    "w_30_loss = evaluation(torch.tensor(new_eval_dataset['emoji_weight_30'].to_list()), torch.tensor(new_eval_dataset['label_to_vector'].to_list()))\n",
    "w_50_loss = evaluation(torch.tensor(new_eval_dataset['emoji_weight_50'].to_list()), torch.tensor(new_eval_dataset['label_to_vector'].to_list()))\n",
    "w_70_loss = evaluation(torch.tensor(new_eval_dataset['emoji_weight_70'].to_list()), torch.tensor(new_eval_dataset['label_to_vector'].to_list()))\n",
    "print(f\"emoji weight 1% emotion Loss: {w_1_loss}\")\n",
    "print(f\"emoji weight 3% emotion Loss: {w_3_loss}\")\n",
    "print(f\"emoji weight 4% emotion Loss: {w_4_loss}\")\n",
    "print(f\"emoji weight 5% emotion Loss: {w_5_loss}\")\n",
    "print(f\"emoji weight 6% emotion Loss: {w_6_loss}\")\n",
    "print(f\"emoji weight 7% emotion Loss: {w_7_loss}\")\n",
    "print(f\"emoji weight 8% emotion Loss: {w_8_loss}\")\n",
    "print(f\"emoji weight 9% emotion Loss: {w_9_loss}\")\n",
    "print(f\"emoji weight 10% emotion Loss: {w_10_loss}\")\n",
    "print(f\"emoji weight 20% emotion Loss: {w_20_loss}\")\n",
    "print(f\"emoji weight 30% emotion Loss: {w_30_loss}\")\n",
    "print(f\"emoji weight 50% emotion Loss: {w_50_loss}\")\n",
    "print(f\"emoji weight 70% emotion Loss: {w_70_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Word2Vec.__init__() got an unexpected keyword argument 'binary'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[67], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m e2v \u001b[38;5;241m=\u001b[39m \u001b[43mgsm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mWord2Vec\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43memoji2vec.bin\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbinary\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: Word2Vec.__init__() got an unexpected keyword argument 'binary'"
     ]
    }
   ],
   "source": [
    "e2v = gsm.Word2Vec('emoji2vec.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
